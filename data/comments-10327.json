[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1018980020",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10327#issuecomment-1018980020",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10327",
        "id": 1018980020,
        "node_id": "IC_kwDOCVq1mM48vGa0",
        "user": {
            "login": "yuslepukhin",
            "id": 11303988,
            "node_id": "MDQ6VXNlcjExMzAzOTg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11303988?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yuslepukhin",
            "html_url": "https://github.com/yuslepukhin",
            "followers_url": "https://api.github.com/users/yuslepukhin/followers",
            "following_url": "https://api.github.com/users/yuslepukhin/following{/other_user}",
            "gists_url": "https://api.github.com/users/yuslepukhin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yuslepukhin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yuslepukhin/subscriptions",
            "organizations_url": "https://api.github.com/users/yuslepukhin/orgs",
            "repos_url": "https://api.github.com/users/yuslepukhin/repos",
            "events_url": "https://api.github.com/users/yuslepukhin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yuslepukhin/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-01-22T00:03:08Z",
        "updated_at": "2022-01-22T00:03:08Z",
        "author_association": "MEMBER",
        "body": "Since you can not pre-allocate tensor on GPU ahead of time, you will need to deal with GPU memory that ORT allocates on output. To gain access to that memory, call `data_ptr()` on the corresponding output OrtValue which would be a pointer to that buffer on a GPU device.  You can obtain the shape by calling `shape()`. You can then decide what to do with it.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1018980020/reactions",
            "total_count": 4,
            "+1": 4,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1026716566",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10327#issuecomment-1026716566",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10327",
        "id": 1026716566,
        "node_id": "IC_kwDOCVq1mM49MnOW",
        "user": {
            "login": "Ki6an",
            "id": 63173962,
            "node_id": "MDQ6VXNlcjYzMTczOTYy",
            "avatar_url": "https://avatars.githubusercontent.com/u/63173962?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Ki6an",
            "html_url": "https://github.com/Ki6an",
            "followers_url": "https://api.github.com/users/Ki6an/followers",
            "following_url": "https://api.github.com/users/Ki6an/following{/other_user}",
            "gists_url": "https://api.github.com/users/Ki6an/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Ki6an/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Ki6an/subscriptions",
            "organizations_url": "https://api.github.com/users/Ki6an/orgs",
            "repos_url": "https://api.github.com/users/Ki6an/repos",
            "events_url": "https://api.github.com/users/Ki6an/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Ki6an/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-02-01T10:58:34Z",
        "updated_at": "2022-02-01T10:58:55Z",
        "author_association": "NONE",
        "body": "thank you for the response, ik this is not related to onnxruntime but do you know how to create a torch tensor from a data pointer? \r\n\r\nafter some searching, I found that using [dlpack ](https://github.com/microsoft/onnxruntime/issues/4162) is a plausible workaround.\r\n\r\nhttps://github.com/microsoft/onnxruntime/blob/50ae97a8bd5184915f2bb2e81727f05770d74d9f/orttraining/orttraining/python/training/ortmodule/_utils.py#L13-L18\r\n\r\nI think it is available only in the `onnxruntime-training` library. are there any plans on including it in the `onnxruntime-gpu`?\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1026716566/reactions",
            "total_count": 3,
            "+1": 3,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1100581297",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10327#issuecomment-1100581297",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10327",
        "id": 1100581297,
        "node_id": "IC_kwDOCVq1mM5BmYmx",
        "user": {
            "login": "stale[bot]",
            "id": 26384082,
            "node_id": "MDM6Qm90MjYzODQwODI=",
            "avatar_url": "https://avatars.githubusercontent.com/in/1724?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stale%5Bbot%5D",
            "html_url": "https://github.com/apps/stale",
            "followers_url": "https://api.github.com/users/stale%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/stale%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stale%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/stale%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/stale%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/stale%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stale%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "created_at": "2022-04-16T05:55:03Z",
        "updated_at": "2022-04-16T05:55:03Z",
        "author_association": "NONE",
        "body": "This issue has been automatically marked as stale due to inactivity and will be closed in 7 days if no further activity occurs. If further support is needed, please provide an update and/or more details.\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1100581297/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1129412854",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10327#issuecomment-1129412854",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10327",
        "id": 1129412854,
        "node_id": "IC_kwDOCVq1mM5DUXj2",
        "user": {
            "login": "brevity2021",
            "id": 88120581,
            "node_id": "MDQ6VXNlcjg4MTIwNTgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/88120581?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/brevity2021",
            "html_url": "https://github.com/brevity2021",
            "followers_url": "https://api.github.com/users/brevity2021/followers",
            "following_url": "https://api.github.com/users/brevity2021/following{/other_user}",
            "gists_url": "https://api.github.com/users/brevity2021/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/brevity2021/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/brevity2021/subscriptions",
            "organizations_url": "https://api.github.com/users/brevity2021/orgs",
            "repos_url": "https://api.github.com/users/brevity2021/repos",
            "events_url": "https://api.github.com/users/brevity2021/events{/privacy}",
            "received_events_url": "https://api.github.com/users/brevity2021/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-17T23:22:35Z",
        "updated_at": "2022-05-17T23:24:28Z",
        "author_association": "NONE",
        "body": "Hi @Ki6an, thanks for the question & answer. I am facing the same issue (`torch.from_numpy(ort_output.numpy()` is too slow) and wonder whether the dlpack workaround above still works. I'm using Onnxruntime 1.11.1 and it seems that `OrtValue` does not have the `to_dlpack` API. Thanks!",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1129412854/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1129440077",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10327#issuecomment-1129440077",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10327",
        "id": 1129440077,
        "node_id": "IC_kwDOCVq1mM5DUeNN",
        "user": {
            "login": "brevity2021",
            "id": 88120581,
            "node_id": "MDQ6VXNlcjg4MTIwNTgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/88120581?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/brevity2021",
            "html_url": "https://github.com/brevity2021",
            "followers_url": "https://api.github.com/users/brevity2021/followers",
            "following_url": "https://api.github.com/users/brevity2021/following{/other_user}",
            "gists_url": "https://api.github.com/users/brevity2021/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/brevity2021/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/brevity2021/subscriptions",
            "organizations_url": "https://api.github.com/users/brevity2021/orgs",
            "repos_url": "https://api.github.com/users/brevity2021/repos",
            "events_url": "https://api.github.com/users/brevity2021/events{/privacy}",
            "received_events_url": "https://api.github.com/users/brevity2021/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-18T00:20:08Z",
        "updated_at": "2022-05-18T00:20:27Z",
        "author_association": "NONE",
        "body": "\r\n\r\n> Hi @Ki6an, thanks for the question & answer. I am facing the same issue (`torch.from_numpy(ort_output.numpy()` is too slow) and wonder whether the dlpack workaround above still works. I'm using Onnxruntime 1.11.1 and it seems that `OrtValue` does not have the `to_dlpack` API. Thanks!\r\n\r\nI was able to use the following code:\r\nInstall the package: `pip install onnxruntime-training==1.11.1` \r\n\r\n```from onnxruntime.training.ortmodule._utils import _ortvalue_to_torch_tensor\r\n# x is an ortvalue\r\ndevice=torch.device('cuda')\r\na =_ortvalue_to_torch_tensor( x._ortvalue,  device)\r\n```\r\nIs that the way you used it?\r\n\r\nHowever, in my case the running/conversion time ratio seems not as big as yours, the running time/conversion time is 1000:1 in my case (when using `torch.from_numpy`. using the _ortvalue_to_torch_tensor reduces the conversion time to 1/5).",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1129440077/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1129493902",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10327#issuecomment-1129493902",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10327",
        "id": 1129493902,
        "node_id": "IC_kwDOCVq1mM5DUrWO",
        "user": {
            "login": "Ki6an",
            "id": 63173962,
            "node_id": "MDQ6VXNlcjYzMTczOTYy",
            "avatar_url": "https://avatars.githubusercontent.com/u/63173962?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Ki6an",
            "html_url": "https://github.com/Ki6an",
            "followers_url": "https://api.github.com/users/Ki6an/followers",
            "following_url": "https://api.github.com/users/Ki6an/following{/other_user}",
            "gists_url": "https://api.github.com/users/Ki6an/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Ki6an/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Ki6an/subscriptions",
            "organizations_url": "https://api.github.com/users/Ki6an/orgs",
            "repos_url": "https://api.github.com/users/Ki6an/repos",
            "events_url": "https://api.github.com/users/Ki6an/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Ki6an/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-18T02:11:15Z",
        "updated_at": "2022-05-18T02:12:32Z",
        "author_association": "NONE",
        "body": "@brevity2021  if you are able to use both `onnxruntime-gpu` and `onnxruntime-training` libraries at the same time after installing them from pip.  \r\nthen yes, import it as `from onnxruntime.training.ortmodule._utils import _ortvalue_to_torch_tensor` and use it as you've shown.\r\n\r\n> However, in my case the running/conversion time ratio seems not as big as yours, the running time/conversion time is 1000:1 in my case (when using torch.from_numpy. using the _ortvalue_to_torch_tensor reduces the conversion time to 1/5).\r\n\r\nglad you were able to reduce the conversion time,\r\nre: running/conversion ratio: I think it depends on the model you are running. the above numbers were for the t5 model, and  I was converting the pkvs (around 24 large tensors) to torch.tensors.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1129493902/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1130315674",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10327#issuecomment-1130315674",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10327",
        "id": 1130315674,
        "node_id": "IC_kwDOCVq1mM5DXz-a",
        "user": {
            "login": "brevity2021",
            "id": 88120581,
            "node_id": "MDQ6VXNlcjg4MTIwNTgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/88120581?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/brevity2021",
            "html_url": "https://github.com/brevity2021",
            "followers_url": "https://api.github.com/users/brevity2021/followers",
            "following_url": "https://api.github.com/users/brevity2021/following{/other_user}",
            "gists_url": "https://api.github.com/users/brevity2021/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/brevity2021/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/brevity2021/subscriptions",
            "organizations_url": "https://api.github.com/users/brevity2021/orgs",
            "repos_url": "https://api.github.com/users/brevity2021/repos",
            "events_url": "https://api.github.com/users/brevity2021/events{/privacy}",
            "received_events_url": "https://api.github.com/users/brevity2021/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-05-18T17:51:49Z",
        "updated_at": "2022-05-18T17:51:49Z",
        "author_association": "NONE",
        "body": "> @brevity2021 if you are able to use both `onnxruntime-gpu` and `onnxruntime-training` libraries at the same time after installing them from pip. then yes, import it as `from onnxruntime.training.ortmodule._utils import _ortvalue_to_torch_tensor` and use it as you've shown.\r\n> \r\n> > However, in my case the running/conversion time ratio seems not as big as yours, the running time/conversion time is 1000:1 in my case (when using torch.from_numpy. using the _ortvalue_to_torch_tensor reduces the conversion time to 1/5).\r\n> \r\n> glad you were able to reduce the conversion time, re: running/conversion ratio: I think it depends on the model you are running. the above numbers were for the t5 model, and I was converting the pkvs (around 24 large tensors) to torch.tensors.\r\n\r\nThank you for your prompt reply! I was using a different seq2seq model, and I didn't use pkvs (per my previous experiment that didn't help much on gpu), so that explains the conversion difference. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1130315674/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]