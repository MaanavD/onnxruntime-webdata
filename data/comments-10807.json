[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1062102010",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10807#issuecomment-1062102010",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10807",
        "id": 1062102010,
        "node_id": "IC_kwDOCVq1mM4_TmP6",
        "user": {
            "login": "wangyems",
            "id": 52801275,
            "node_id": "MDQ6VXNlcjUyODAxMjc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/52801275?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyems",
            "html_url": "https://github.com/wangyems",
            "followers_url": "https://api.github.com/users/wangyems/followers",
            "following_url": "https://api.github.com/users/wangyems/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyems/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyems/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyems/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyems/orgs",
            "repos_url": "https://api.github.com/users/wangyems/repos",
            "events_url": "https://api.github.com/users/wangyems/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyems/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-08T18:58:45Z",
        "updated_at": "2022-03-08T18:58:45Z",
        "author_association": "MEMBER",
        "body": "You can rely on that script for partial optimization. Further optimizations for T5 are in our backlog. \r\n\r\nAs an alternative, ORT with TRT EP(with TRT version 8.2) has better performance on T5 which was confirmed by us. You can build ORT with TRT EP and run model with specifying TensorrtExecutionProvider in EP list.\r\n\r\nreference:\r\n[build ORT with TRT EP](https://github.com/microsoft/onnxruntime/blob/master/dockerfiles/Dockerfile.tensorrt)\r\n[inference example](https://onnxruntime.ai/docs/execution-providers/TensorRT-ExecutionProvider.html)",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1062102010/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1062117839",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10807#issuecomment-1062117839",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10807",
        "id": 1062117839,
        "node_id": "IC_kwDOCVq1mM4_TqHP",
        "user": {
            "login": "GenVr",
            "id": 82599723,
            "node_id": "MDQ6VXNlcjgyNTk5NzIz",
            "avatar_url": "https://avatars.githubusercontent.com/u/82599723?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GenVr",
            "html_url": "https://github.com/GenVr",
            "followers_url": "https://api.github.com/users/GenVr/followers",
            "following_url": "https://api.github.com/users/GenVr/following{/other_user}",
            "gists_url": "https://api.github.com/users/GenVr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GenVr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GenVr/subscriptions",
            "organizations_url": "https://api.github.com/users/GenVr/orgs",
            "repos_url": "https://api.github.com/users/GenVr/repos",
            "events_url": "https://api.github.com/users/GenVr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GenVr/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-08T19:18:22Z",
        "updated_at": "2022-03-08T19:18:22Z",
        "author_association": "NONE",
        "body": "@wangyems My model has a max_length = 1024, and using TensorRT (I created the container and used the code) I have worse times than pytorch. This is because with lengths greater than 256 it seems not to be convenient. Can you confirm this too?\r\n\r\nThen\r\n> You can rely on that script for partial optimization. Further optimizations for T5 are in our backlog.\r\n\r\nWhat are the codes or parts of interest for the T5 model from the [code](https://github.com/microsoft/onnxruntime/blob/master/onnxruntime/python/tools/transformers/notebooks/PyTorch_Bert-Squad_OnnxRuntime_GPU.ipynb)? Is it convenient for models with max_length = 1024?\r\n\r\nThank you.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1062117839/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1062204720",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10807#issuecomment-1062204720",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10807",
        "id": 1062204720,
        "node_id": "IC_kwDOCVq1mM4_T_Uw",
        "user": {
            "login": "wangyems",
            "id": 52801275,
            "node_id": "MDQ6VXNlcjUyODAxMjc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/52801275?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyems",
            "html_url": "https://github.com/wangyems",
            "followers_url": "https://api.github.com/users/wangyems/followers",
            "following_url": "https://api.github.com/users/wangyems/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyems/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyems/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyems/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyems/orgs",
            "repos_url": "https://api.github.com/users/wangyems/repos",
            "events_url": "https://api.github.com/users/wangyems/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyems/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-08T21:01:32Z",
        "updated_at": "2022-03-08T21:01:32Z",
        "author_association": "MEMBER",
        "body": "We only compare it with ORT CUDA EP so I have limited information about how it compares with Pytorch. \r\n\r\nThere are a couple of possible causes that could make your ORT-TRT run looks slow:\r\n1. ORT-TRT needs a few warm-ups run. It's better to benchmark it after that.\r\n2. Use IOBinding just like in ORT CUDA run.\r\n3. Compare to Pytorch with exact same input. Avoid padding in ORT-TRT run by exporting the onnx model with dynamic input.\r\n\r\nIf you'd like to use the CUDA EP, just follow the Bert tutorial. The code is shared.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1062204720/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1062946599",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10807#issuecomment-1062946599",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10807",
        "id": 1062946599,
        "node_id": "IC_kwDOCVq1mM4_W0cn",
        "user": {
            "login": "GenVr",
            "id": 82599723,
            "node_id": "MDQ6VXNlcjgyNTk5NzIz",
            "avatar_url": "https://avatars.githubusercontent.com/u/82599723?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GenVr",
            "html_url": "https://github.com/GenVr",
            "followers_url": "https://api.github.com/users/GenVr/followers",
            "following_url": "https://api.github.com/users/GenVr/following{/other_user}",
            "gists_url": "https://api.github.com/users/GenVr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GenVr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GenVr/subscriptions",
            "organizations_url": "https://api.github.com/users/GenVr/orgs",
            "repos_url": "https://api.github.com/users/GenVr/repos",
            "events_url": "https://api.github.com/users/GenVr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GenVr/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-09T13:56:54Z",
        "updated_at": "2022-03-09T13:56:54Z",
        "author_association": "NONE",
        "body": "@wangyems I'm using a TensorRT container for TRT, [this ](https://developer.nvidia.com/blog/optimizing-t5-and-gpt-2-for-real-time-inference-with-tensorrt/)\"setting up\" code and then [this ](https://github.com/NVIDIA/TensorRT/blob/release/8.2/demo/HuggingFace/notebooks/t5.ipynb)code for conversion and inference. \r\n\r\nAre they the most up-to-date versions and codes? I know that for a T5 with lengths greater than 256 the inference time is worse than pytorch, but a TRT fix had to be made about that.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1062946599/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1063610239",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/10807#issuecomment-1063610239",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/10807",
        "id": 1063610239,
        "node_id": "IC_kwDOCVq1mM4_ZWd_",
        "user": {
            "login": "wangyems",
            "id": 52801275,
            "node_id": "MDQ6VXNlcjUyODAxMjc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/52801275?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wangyems",
            "html_url": "https://github.com/wangyems",
            "followers_url": "https://api.github.com/users/wangyems/followers",
            "following_url": "https://api.github.com/users/wangyems/following{/other_user}",
            "gists_url": "https://api.github.com/users/wangyems/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wangyems/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wangyems/subscriptions",
            "organizations_url": "https://api.github.com/users/wangyems/orgs",
            "repos_url": "https://api.github.com/users/wangyems/repos",
            "events_url": "https://api.github.com/users/wangyems/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wangyems/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-03-10T03:16:59Z",
        "updated_at": "2022-03-10T03:16:59Z",
        "author_association": "MEMBER",
        "body": "@GenVr Seems like you're working on native TRT. Suggest raising an issue here: https://github.com/NVIDIA/TensorRT/issues",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1063610239/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]