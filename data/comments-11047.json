[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1089820987",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11047#issuecomment-1089820987",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11047",
        "id": 1089820987,
        "node_id": "IC_kwDOCVq1mM5A9Vk7",
        "user": {
            "login": "hariharans29",
            "id": 9969784,
            "node_id": "MDQ6VXNlcjk5Njk3ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9969784?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hariharans29",
            "html_url": "https://github.com/hariharans29",
            "followers_url": "https://api.github.com/users/hariharans29/followers",
            "following_url": "https://api.github.com/users/hariharans29/following{/other_user}",
            "gists_url": "https://api.github.com/users/hariharans29/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hariharans29/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hariharans29/subscriptions",
            "organizations_url": "https://api.github.com/users/hariharans29/orgs",
            "repos_url": "https://api.github.com/users/hariharans29/repos",
            "events_url": "https://api.github.com/users/hariharans29/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hariharans29/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-06T04:58:32Z",
        "updated_at": "2022-04-06T04:58:32Z",
        "author_association": "MEMBER",
        "body": "`When we did profiling with NSight we found that all of the operations were being executed in a single stream. Is this expected for all models, or does it potentially indicate some optimization issue?`\r\n\r\nThis is expected. The CUDA EP only supports the sequential executor which means all of the operations are executed sequentially on the same stream. Some other EPs like the CPU EP support the parallel executor, a concept if applied to the CUDA EP would mean that we could potentially use different streams to parallelize node executions but enabling this is non-trivial for the CUDA EP and is currently not in the pipeline.\r\n\r\n`To try and circumvent this, we tried making concurrent requests to the gpu session by making async calls (see code example below). Again, latency-wise it seemed that these requests were being serialized into a single stream, and profiling with NSight confirmed this.`\r\n\r\nCurrently, there is only one stream per CUDA EP and unfortunately due to this the concurrent requests are being serviced by this single stream. We plan to enable per-thread streams in the CUDA EP which should mean that concurrent requests can be serviced by different streams in parallel. \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1089820987/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1090499788",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11047#issuecomment-1090499788",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11047",
        "id": 1090499788,
        "node_id": "IC_kwDOCVq1mM5A_7TM",
        "user": {
            "login": "dashesy",
            "id": 873905,
            "node_id": "MDQ6VXNlcjg3MzkwNQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/873905?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dashesy",
            "html_url": "https://github.com/dashesy",
            "followers_url": "https://api.github.com/users/dashesy/followers",
            "following_url": "https://api.github.com/users/dashesy/following{/other_user}",
            "gists_url": "https://api.github.com/users/dashesy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dashesy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dashesy/subscriptions",
            "organizations_url": "https://api.github.com/users/dashesy/orgs",
            "repos_url": "https://api.github.com/users/dashesy/repos",
            "events_url": "https://api.github.com/users/dashesy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dashesy/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-06T17:04:40Z",
        "updated_at": "2022-04-06T17:04:40Z",
        "author_association": "NONE",
        "body": "Perhaps it would be a little easier if different sessions (different processes) could use different streams? Then we could parallelize by loading the model to memory in 2 processes?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1090499788/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1090507845",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11047#issuecomment-1090507845",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11047",
        "id": 1090507845,
        "node_id": "IC_kwDOCVq1mM5A_9RF",
        "user": {
            "login": "admayber",
            "id": 44822281,
            "node_id": "MDQ6VXNlcjQ0ODIyMjgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/44822281?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/admayber",
            "html_url": "https://github.com/admayber",
            "followers_url": "https://api.github.com/users/admayber/followers",
            "following_url": "https://api.github.com/users/admayber/following{/other_user}",
            "gists_url": "https://api.github.com/users/admayber/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/admayber/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/admayber/subscriptions",
            "organizations_url": "https://api.github.com/users/admayber/orgs",
            "repos_url": "https://api.github.com/users/admayber/repos",
            "events_url": "https://api.github.com/users/admayber/events{/privacy}",
            "received_events_url": "https://api.github.com/users/admayber/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-06T17:11:41Z",
        "updated_at": "2022-04-06T17:11:41Z",
        "author_association": "MEMBER",
        "body": "Agreed with @dashesy, I have not tried this yet but support would be good if it doesn't currently exist",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1090507845/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1090509565",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11047#issuecomment-1090509565",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11047",
        "id": 1090509565,
        "node_id": "IC_kwDOCVq1mM5A_9r9",
        "user": {
            "login": "hariharans29",
            "id": 9969784,
            "node_id": "MDQ6VXNlcjk5Njk3ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9969784?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hariharans29",
            "html_url": "https://github.com/hariharans29",
            "followers_url": "https://api.github.com/users/hariharans29/followers",
            "following_url": "https://api.github.com/users/hariharans29/following{/other_user}",
            "gists_url": "https://api.github.com/users/hariharans29/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hariharans29/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hariharans29/subscriptions",
            "organizations_url": "https://api.github.com/users/hariharans29/orgs",
            "repos_url": "https://api.github.com/users/hariharans29/repos",
            "events_url": "https://api.github.com/users/hariharans29/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hariharans29/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-06T17:13:38Z",
        "updated_at": "2022-04-06T17:13:38Z",
        "author_association": "MEMBER",
        "body": "Just to be clear - different sessions do use different streams. It is just that within one session, we are limited to using one compute stream and this is affecting the concurrency aspect.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1090509565/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]