[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1111544608",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11348#issuecomment-1111544608",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11348",
        "id": 1111544608,
        "node_id": "IC_kwDOCVq1mM5CQNMg",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-27T22:33:20Z",
        "updated_at": "2022-04-27T22:39:18Z",
        "author_association": "MEMBER",
        "body": "The optimized model is tied with the execution providers because different providers might only support a subset of operators. It might encounter issue to use CUDA to optimize a model, then run the model in CPU.\r\n\r\nIf you run the optimized model with same execution providers (For example, optimize model in CUDA ep, and run the optimized model in CUDA ep again), there shall not be problem.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1111544608/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1112802286",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/11348#issuecomment-1112802286",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/11348",
        "id": 1112802286,
        "node_id": "IC_kwDOCVq1mM5CVAPu",
        "user": {
            "login": "hariharans29",
            "id": 9969784,
            "node_id": "MDQ6VXNlcjk5Njk3ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9969784?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hariharans29",
            "html_url": "https://github.com/hariharans29",
            "followers_url": "https://api.github.com/users/hariharans29/followers",
            "following_url": "https://api.github.com/users/hariharans29/following{/other_user}",
            "gists_url": "https://api.github.com/users/hariharans29/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hariharans29/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hariharans29/subscriptions",
            "organizations_url": "https://api.github.com/users/hariharans29/orgs",
            "repos_url": "https://api.github.com/users/hariharans29/repos",
            "events_url": "https://api.github.com/users/hariharans29/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hariharans29/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-04-29T01:32:39Z",
        "updated_at": "2022-04-29T01:32:39Z",
        "author_association": "MEMBER",
        "body": "Prima facie, it is a bug since when the graph optimization level is GraphOptimizationLevel.ORT_ENABLE_BASIC, the dumped graph shouldn't contain any operators that are not part of the ONNX standard and in this case the dumped graph leaks some ORT partitioning information in the form of the MemCpy nodes. The fix is to dump the graph after the basic optimization has finished and before the paritioning and copy node insertion steps. \r\n\r\nBut the impact of this should be low - as a work-around you can use just the CPU EP to dump the optimized graph and that won't leak ORT partitioning details (as you illustrated). The flip side is instantiating an InferenceSession using the CPU EP just for this. \r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1112802286/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]