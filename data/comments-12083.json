[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1175382124",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12083#issuecomment-1175382124",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12083",
        "id": 1175382124,
        "node_id": "IC_kwDOCVq1mM5GDuhs",
        "user": {
            "login": "stevenlix",
            "id": 38092805,
            "node_id": "MDQ6VXNlcjM4MDkyODA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/38092805?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stevenlix",
            "html_url": "https://github.com/stevenlix",
            "followers_url": "https://api.github.com/users/stevenlix/followers",
            "following_url": "https://api.github.com/users/stevenlix/following{/other_user}",
            "gists_url": "https://api.github.com/users/stevenlix/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stevenlix/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stevenlix/subscriptions",
            "organizations_url": "https://api.github.com/users/stevenlix/orgs",
            "repos_url": "https://api.github.com/users/stevenlix/repos",
            "events_url": "https://api.github.com/users/stevenlix/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stevenlix/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-05T18:48:20Z",
        "updated_at": "2022-07-05T18:48:20Z",
        "author_association": "MEMBER",
        "body": "TensorRT EP can achieve performance parity with native TensorRT. One of the benefits to use TensorRT EP is to run models that can't run in native TensorRT if there are TensorRT unsupported ops in the model. Those ops will fallback to other EPs like CUDA or CPU in OnnxRuntime automatically.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1175382124/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1175718549",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12083#issuecomment-1175718549",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12083",
        "id": 1175718549,
        "node_id": "IC_kwDOCVq1mM5GFAqV",
        "user": {
            "login": "hafidh561",
            "id": 46504516,
            "node_id": "MDQ6VXNlcjQ2NTA0NTE2",
            "avatar_url": "https://avatars.githubusercontent.com/u/46504516?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hafidh561",
            "html_url": "https://github.com/hafidh561",
            "followers_url": "https://api.github.com/users/hafidh561/followers",
            "following_url": "https://api.github.com/users/hafidh561/following{/other_user}",
            "gists_url": "https://api.github.com/users/hafidh561/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hafidh561/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hafidh561/subscriptions",
            "organizations_url": "https://api.github.com/users/hafidh561/orgs",
            "repos_url": "https://api.github.com/users/hafidh561/repos",
            "events_url": "https://api.github.com/users/hafidh561/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hafidh561/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-06T02:47:27Z",
        "updated_at": "2022-07-06T02:47:27Z",
        "author_association": "NONE",
        "body": "> TensorRT EP can achieve performance parity with native TensorRT. One of the benefits to use TensorRT EP is to run models that can't run in native TensorRT if there are TensorRT unsupported ops in the model. Those ops will fallback to other EPs like CUDA or CPU in OnnxRuntime automatically.\r\n\r\nIs there any benchmark for it?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1175718549/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]