[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1183790330",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12165#issuecomment-1183790330",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12165",
        "id": 1183790330,
        "node_id": "IC_kwDOCVq1mM5GjzT6",
        "user": {
            "login": "fdwr",
            "id": 1809166,
            "node_id": "MDQ6VXNlcjE4MDkxNjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1809166?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fdwr",
            "html_url": "https://github.com/fdwr",
            "followers_url": "https://api.github.com/users/fdwr/followers",
            "following_url": "https://api.github.com/users/fdwr/following{/other_user}",
            "gists_url": "https://api.github.com/users/fdwr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fdwr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fdwr/subscriptions",
            "organizations_url": "https://api.github.com/users/fdwr/orgs",
            "repos_url": "https://api.github.com/users/fdwr/repos",
            "events_url": "https://api.github.com/users/fdwr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fdwr/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-13T23:49:44Z",
        "updated_at": "2022-07-14T17:50:54Z",
        "author_association": "MEMBER",
        "body": "@contentis \r\n\r\n> I would like to do the same when using DML as ep\r\n\r\nTo clarify, the request is to extend the *Python* API? (because there's already a way via `OrtDmlApi::CreateGPUAllocationFromD3DResource` and `Ort::Value::CreateTensor` to achieve this in C++ https://github.com/fdwr/OnnxRuntimeDirectMLEPSample/blob/master/main.cpp#L865)\r\n\r\n>highly inefficient especially when the data is already on the device\r\n\r\nIf via Python, how is it that you acquired an existing [`ID3D12Resource`](https://docs.microsoft.com/en-us/windows/win32/api/d3d12/nn-d3d12-id3d12resource)? Is this from some other Python library that wraps D3D resources?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1183790330/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1183842659",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12165#issuecomment-1183842659",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12165",
        "id": 1183842659,
        "node_id": "IC_kwDOCVq1mM5GkAFj",
        "user": {
            "login": "phrozon89",
            "id": 71076515,
            "node_id": "MDQ6VXNlcjcxMDc2NTE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/71076515?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/phrozon89",
            "html_url": "https://github.com/phrozon89",
            "followers_url": "https://api.github.com/users/phrozon89/followers",
            "following_url": "https://api.github.com/users/phrozon89/following{/other_user}",
            "gists_url": "https://api.github.com/users/phrozon89/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/phrozon89/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/phrozon89/subscriptions",
            "organizations_url": "https://api.github.com/users/phrozon89/orgs",
            "repos_url": "https://api.github.com/users/phrozon89/repos",
            "events_url": "https://api.github.com/users/phrozon89/events{/privacy}",
            "received_events_url": "https://api.github.com/users/phrozon89/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-14T01:16:50Z",
        "updated_at": "2022-07-14T01:16:50Z",
        "author_association": "NONE",
        "body": "On Jul 13, 2022 10:02 AM, Luca ***@***.***> wrote:\r\nDescribe the bug\r\nWhen using the CUDA/TensorRT EP I am able to create my resources (input/output) directly on the device using IOBindings. I would like to do the same when using DML as ep, but so far I was not able to find any way to do so. Looking into the Python API and C++ sources I only found \"CPU\", \"CUDA\" as options for the device type.\r\nUrgency\r\nHaving H2D and D2H copies every time you run a model is highly inefficient especially when the data is already on the device or needs to be processed further on the GPU (e.g. hardware decoding/encoding).\r\nSystem information\r\nWindows 11ORT 1.12 (master)Python 3.9Visual Studio version (if applicable): 2022CUDA/cuDNN version: 11.7GPU model and memory: A6000\r\n\r\nâ€”Reply to this email directly, view it on GitHub, or unsubscribe.You are receiving this because you are subscribed to this thread.Message ID: ***@***.***>",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1183842659/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 1,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1184055284",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12165#issuecomment-1184055284",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12165",
        "id": 1184055284,
        "node_id": "IC_kwDOCVq1mM5Gkz_0",
        "user": {
            "login": "contentis",
            "id": 29352092,
            "node_id": "MDQ6VXNlcjI5MzUyMDky",
            "avatar_url": "https://avatars.githubusercontent.com/u/29352092?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/contentis",
            "html_url": "https://github.com/contentis",
            "followers_url": "https://api.github.com/users/contentis/followers",
            "following_url": "https://api.github.com/users/contentis/following{/other_user}",
            "gists_url": "https://api.github.com/users/contentis/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/contentis/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/contentis/subscriptions",
            "organizations_url": "https://api.github.com/users/contentis/orgs",
            "repos_url": "https://api.github.com/users/contentis/repos",
            "events_url": "https://api.github.com/users/contentis/events{/privacy}",
            "received_events_url": "https://api.github.com/users/contentis/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-14T06:39:09Z",
        "updated_at": "2022-07-14T06:40:55Z",
        "author_association": "NONE",
        "body": "There is DirectPython, although I'm not familiar with it, or better said DX in general. But if I understand correctly [ID3D12Resource](https://docs.microsoft.com/en-us/windows/win32/api/d3d12/nn-d3d12-id3d12resource) is just linear memory space, so shouldn't it be possible to handle the (DX) resource creation by ORT and then be able to give it a pointer to memory on the device. Or having a CUDA/DX interop.\r\n\r\nPS: Is there any better documentation for the C++ use case, or samples? All samples I found started and ended with CPU resources. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1184055284/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1184735698",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/12165#issuecomment-1184735698",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/12165",
        "id": 1184735698,
        "node_id": "IC_kwDOCVq1mM5GnaHS",
        "user": {
            "login": "fdwr",
            "id": 1809166,
            "node_id": "MDQ6VXNlcjE4MDkxNjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1809166?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fdwr",
            "html_url": "https://github.com/fdwr",
            "followers_url": "https://api.github.com/users/fdwr/followers",
            "following_url": "https://api.github.com/users/fdwr/following{/other_user}",
            "gists_url": "https://api.github.com/users/fdwr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fdwr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fdwr/subscriptions",
            "organizations_url": "https://api.github.com/users/fdwr/orgs",
            "repos_url": "https://api.github.com/users/fdwr/repos",
            "events_url": "https://api.github.com/users/fdwr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fdwr/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2022-07-14T17:51:55Z",
        "updated_at": "2022-07-14T17:51:55Z",
        "author_association": "MEMBER",
        "body": "> There is DirectPython\r\n\r\nðŸ¤” I'll read about it.\r\n\r\n> then be able to give it a pointer to memory on the device\r\n\r\nSo is it more that you would already have an ID3D12Resource, and you want to pass that into ORT via the Python API, or that you're okay with ORT allocating the tensor on the GPU, and getting the ID3D12Resource out of it (for uploading/downloading data from it)?\r\n\r\n> All samples I found started and ended with CPU resources.\r\n\r\nWell there isn't an *official* sample yet (I know someone on my partner team has it on their todo list), but I do have a small app that I've been using myself, which directly uploads to a GPU tensor. See https://github.com/fdwr/OnnxRuntimeDirectMLEPSample/blob/master/main.cpp#L865.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/1184735698/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]