[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/521852545",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1632#issuecomment-521852545",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1632",
        "id": 521852545,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUyMTg1MjU0NQ==",
        "user": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-08-16T01:32:51Z",
        "updated_at": "2019-08-16T01:32:51Z",
        "author_association": "MEMBER",
        "body": "1. Yes\r\n2. No. Set it a random string. Please search symbolic shape in the onnx repo.\r\n3. Don't worry. It's easy.\r\n\r\nWe have an example for such use case: \r\nhttps://github.com/microsoft/onnxruntime/tree/master/samples/c_cxx/imagenet\r\n\r\nBut, onnxruntime also has some limitation and drawbacks on this approach. As you can see, in the example, when batch size changed, I choose to delete the session and re-create it. Through it is not necessary, but, practically speaking, in this special scenario (doing inference on a large dataset on GPU), it must be the best performant way.  \r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/521852545/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/521854603",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1632#issuecomment-521854603",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1632",
        "id": 521854603,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUyMTg1NDYwMw==",
        "user": {
            "login": "minus-one",
            "id": 666952,
            "node_id": "MDQ6VXNlcjY2Njk1Mg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/666952?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/minus-one",
            "html_url": "https://github.com/minus-one",
            "followers_url": "https://api.github.com/users/minus-one/followers",
            "following_url": "https://api.github.com/users/minus-one/following{/other_user}",
            "gists_url": "https://api.github.com/users/minus-one/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/minus-one/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/minus-one/subscriptions",
            "organizations_url": "https://api.github.com/users/minus-one/orgs",
            "repos_url": "https://api.github.com/users/minus-one/repos",
            "events_url": "https://api.github.com/users/minus-one/events{/privacy}",
            "received_events_url": "https://api.github.com/users/minus-one/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-08-16T01:45:32Z",
        "updated_at": "2019-08-16T01:46:06Z",
        "author_association": "NONE",
        "body": "Awesome! Thanks for the reply.\r\n\r\nYes, as you say, batch-works. \r\nIf I by-pass the CheckShapes for the outermost dim, it worked fine.\r\n\r\nSo, if I change the resnet50v2's outermost dimension to a random string, it would pass-through the CheckShapes check as well.\r\nMaybe, the onnx-model-zoo should be updated to reflect this ? \r\n\r\nOne last question,\r\n> Through it is not necessary, but, practically speaking, in this special scenario (doing inference on a large dataset on GPU), it must be the best performant way.\r\n\r\n\r\nWhy is it performant to recreate the session ? I would presume session creation takes time. Is this to clear off unnecessary internal structures onnxruntime has ?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/521854603/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/521857237",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1632#issuecomment-521857237",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1632",
        "id": 521857237,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUyMTg1NzIzNw==",
        "user": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-08-16T02:00:56Z",
        "updated_at": "2019-08-16T02:01:26Z",
        "author_association": "MEMBER",
        "body": "> Is this to clear off unnecessary internal structures onnxruntime has ?\r\n\r\nYes. To avoid running out of memory.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/521857237/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/521871042",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1632#issuecomment-521871042",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1632",
        "id": 521871042,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUyMTg3MTA0Mg==",
        "user": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-08-16T03:27:39Z",
        "updated_at": "2019-08-16T03:28:13Z",
        "author_association": "MEMBER",
        "body": "> Maybe, the onnx-model-zoo should be updated to reflect this ?\r\n\r\n@faxu If it is needed, I can help.(updating the model to support dynamic shape)",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/521871042/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/522196735",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1632#issuecomment-522196735",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1632",
        "id": 522196735,
        "node_id": "MDEyOklzc3VlQ29tbWVudDUyMjE5NjczNQ==",
        "user": {
            "login": "snnn",
            "id": 856316,
            "node_id": "MDQ6VXNlcjg1NjMxNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/856316?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snnn",
            "html_url": "https://github.com/snnn",
            "followers_url": "https://api.github.com/users/snnn/followers",
            "following_url": "https://api.github.com/users/snnn/following{/other_user}",
            "gists_url": "https://api.github.com/users/snnn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snnn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snnn/subscriptions",
            "organizations_url": "https://api.github.com/users/snnn/orgs",
            "repos_url": "https://api.github.com/users/snnn/repos",
            "events_url": "https://api.github.com/users/snnn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snnn/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-08-17T02:24:40Z",
        "updated_at": "2019-08-17T02:24:40Z",
        "author_association": "MEMBER",
        "body": "@minus-one If you need any further help, please let me know. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/522196735/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/646925620",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1632#issuecomment-646925620",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1632",
        "id": 646925620,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY0NjkyNTYyMA==",
        "user": {
            "login": "dharma135",
            "id": 3920108,
            "node_id": "MDQ6VXNlcjM5MjAxMDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3920108?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dharma135",
            "html_url": "https://github.com/dharma135",
            "followers_url": "https://api.github.com/users/dharma135/followers",
            "following_url": "https://api.github.com/users/dharma135/following{/other_user}",
            "gists_url": "https://api.github.com/users/dharma135/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dharma135/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dharma135/subscriptions",
            "organizations_url": "https://api.github.com/users/dharma135/orgs",
            "repos_url": "https://api.github.com/users/dharma135/repos",
            "events_url": "https://api.github.com/users/dharma135/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dharma135/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-06-20T02:47:11Z",
        "updated_at": "2020-06-20T02:47:11Z",
        "author_association": "NONE",
        "body": "> \r\n> \r\n>     1. Yes\r\n> \r\n>     2. No. Set it a random string. Please search symbolic shape in the onnx repo.\r\n> \r\n>     3. Don't worry. It's easy.\r\n> \r\n> \r\n> We have an example for such use case:\r\n> https://github.com/microsoft/onnxruntime/tree/master/samples/c_cxx/imagenet\r\n> \r\n> But, onnxruntime also has some limitation and drawbacks on this approach. As you can see, in the example, when batch size changed, I choose to delete the session and re-create it. Through it is not necessary, but, practically speaking, in this special scenario (doing inference on a large dataset on GPU), it must be the best performant way.\r\n\r\nHello, \r\nI am trying to run inference calls in a for loop with variable batch size.\r\nfor (int bs=1; bs <32; bs++) {\r\n    1. Set input_dim[0] = bs; // or set input_dim[0] = 5;\r\n     2. Create input tensor\r\n     3. Call session_.run()\r\n     4. Gather results from output_tensor\r\n}\r\nI see Memory consumption keeps increasing as the for loop progresses that if after step 4, if i do not recreate the session like it is done in Line 236 in the code below\r\nhttps://github.com/microsoft/onnxruntime/blob/master/samples/c_cxx/imagenet/async_ring_buffer.h\r\nLeak happens even if i set batch size to same value but i repeatedly call session.run with new input tensor. \r\nWhat actually happens when we call\r\nsession_ = Ort::Session(env_, model_path_.c_str(), session_options);",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/646925620/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/668034638",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1632#issuecomment-668034638",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1632",
        "id": 668034638,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY2ODAzNDYzOA==",
        "user": {
            "login": "Karnav123",
            "id": 36244620,
            "node_id": "MDQ6VXNlcjM2MjQ0NjIw",
            "avatar_url": "https://avatars.githubusercontent.com/u/36244620?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Karnav123",
            "html_url": "https://github.com/Karnav123",
            "followers_url": "https://api.github.com/users/Karnav123/followers",
            "following_url": "https://api.github.com/users/Karnav123/following{/other_user}",
            "gists_url": "https://api.github.com/users/Karnav123/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Karnav123/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Karnav123/subscriptions",
            "organizations_url": "https://api.github.com/users/Karnav123/orgs",
            "repos_url": "https://api.github.com/users/Karnav123/repos",
            "events_url": "https://api.github.com/users/Karnav123/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Karnav123/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-08-03T13:51:29Z",
        "updated_at": "2020-08-03T13:51:29Z",
        "author_association": "NONE",
        "body": "> I understand that onnxruntime does not care about batch-size itself, and that batch-size can be set as the first dimension of the model and you can use the first dimension as the batch-size.\r\n> \r\n> To do batch inference, we just create an input_tensor OrtValue of appropriate size (based on input dimensions and the batch-size) and send it to OrtRun. (C-API)\r\n> \r\n> I have couple of generic questions surrounding this:\r\n> \r\n> 1. Lets say the outermost dim of the model is 1. Does this mean, it will only support a batch-size of 1 ?\r\n> 2. For every batch-size, do I need to tweak the model-shape (outermost dim) to reflect the batch-size ?\r\n> 3. It would not be non-trivial to Run the inference with different batch sizes across invocations (OrtRun C-api) as you would have to load different models in memory ?\r\n> \r\n> Specifically, lets say we take the resnet50v2 from the onnx-zoo,\r\n> the inputname: data, has a shape: {1,3,224,224}.\r\n> When I call OrtRun, with a OrtValue of dimension {2,3,224,224}, it shows an error in CheckShapes (inference_session.c) \"Got invalid dimensions for input:\"\r\n> Is this an expected error because the model shape's outermost dim is 1.\r\n> \r\n> Weird observation: Here is the kicker, Batch inference worked in \"some\" older version of onnxruntime on the same resnet50v2 model, with shape as {1,3,224,224}. It didn't care about the outer most dim, and it just did batch inference for all the inputs happily.\r\n> \r\n> **Urgency**\r\n> none\r\n> \r\n> **System information**\r\n> \r\n> * OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n>   Linux Ubuntu 18.04\r\n> * ONNX Runtime installed from (source or binary):\r\n>   0.5.0 source\r\n\r\nI am facing a similar issue. Could you please elaborate on the solution that fixed the issue for you.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/668034638/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/668088249",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/1632#issuecomment-668088249",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/1632",
        "id": 668088249,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY2ODA4ODI0OQ==",
        "user": {
            "login": "minus-one",
            "id": 666952,
            "node_id": "MDQ6VXNlcjY2Njk1Mg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/666952?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/minus-one",
            "html_url": "https://github.com/minus-one",
            "followers_url": "https://api.github.com/users/minus-one/followers",
            "following_url": "https://api.github.com/users/minus-one/following{/other_user}",
            "gists_url": "https://api.github.com/users/minus-one/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/minus-one/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/minus-one/subscriptions",
            "organizations_url": "https://api.github.com/users/minus-one/orgs",
            "repos_url": "https://api.github.com/users/minus-one/repos",
            "events_url": "https://api.github.com/users/minus-one/events{/privacy}",
            "received_events_url": "https://api.github.com/users/minus-one/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-08-03T15:31:16Z",
        "updated_at": "2020-08-03T15:31:16Z",
        "author_association": "NONE",
        "body": "A quick answer is in this unrelated issue: https://github.com/microsoft/onnxruntime/issues/1467#issuecomment-514322927\r\nBasically the model's input shape has to be tweaked to ensure it has a dim_param set.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/668088249/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]