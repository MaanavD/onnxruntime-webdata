[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/557662195",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2463#issuecomment-557662195",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2463",
        "id": 557662195,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU1NzY2MjE5NQ==",
        "user": {
            "login": "hariharans29",
            "id": 9969784,
            "node_id": "MDQ6VXNlcjk5Njk3ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9969784?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hariharans29",
            "html_url": "https://github.com/hariharans29",
            "followers_url": "https://api.github.com/users/hariharans29/followers",
            "following_url": "https://api.github.com/users/hariharans29/following{/other_user}",
            "gists_url": "https://api.github.com/users/hariharans29/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hariharans29/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hariharans29/subscriptions",
            "organizations_url": "https://api.github.com/users/hariharans29/orgs",
            "repos_url": "https://api.github.com/users/hariharans29/repos",
            "events_url": "https://api.github.com/users/hariharans29/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hariharans29/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-11-22T19:27:43Z",
        "updated_at": "2019-11-22T19:29:20Z",
        "author_association": "MEMBER",
        "body": "AFAIK - we already support 4-D tensor in NCHW format resizing where batch > 1 and scale > 1. The only limitation is imposed on **scales** (not the input itself). For such a 4-D input, outermost scales must be both 1 (i.e.) we support \"bilinear\" resizing (outermost scales requiring to be 1) for multi-channel  multi-batch inputs.\r\n\r\nTo simplify:\r\n\r\n1) Input shape that is currently accepted by ORT:\r\ninput_shape = [2, 3, 224, 224] (2 images each with 3 channels)\r\nscales_shape = [1, 1, x, x]\r\n\r\nIs this what you need ?\r\n\r\n2) Input shape (that is valid per spec) but not yet supported by ORT:\r\ninput_shape = [2, 3, 224, 224] (2 images each with 3 channels)\r\nscales_shape = [2, 2, x, x]\r\n\r\nThis is not supported yet as \"quadrilinear\" resizing is not supported yet.\r\n\r\nSharing a simple single node model (with just Resize node) and some toy expected inputs/ expected outputs will help. \r\n  ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/557662195/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/558050507",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2463#issuecomment-558050507",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2463",
        "id": 558050507,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU1ODA1MDUwNw==",
        "user": {
            "login": "yangia",
            "id": 34333375,
            "node_id": "MDQ6VXNlcjM0MzMzMzc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/34333375?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yangia",
            "html_url": "https://github.com/yangia",
            "followers_url": "https://api.github.com/users/yangia/followers",
            "following_url": "https://api.github.com/users/yangia/following{/other_user}",
            "gists_url": "https://api.github.com/users/yangia/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yangia/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yangia/subscriptions",
            "organizations_url": "https://api.github.com/users/yangia/orgs",
            "repos_url": "https://api.github.com/users/yangia/repos",
            "events_url": "https://api.github.com/users/yangia/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yangia/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-11-25T08:42:53Z",
        "updated_at": "2019-11-25T08:42:53Z",
        "author_association": "NONE",
        "body": "> AFAIK - we already support 4-D tensor in NCHW format resizing where batch > 1 and scale > 1. The only limitation is imposed on **scales** (not the input itself). For such a 4-D input, outermost scales must be both 1 (i.e.) we support \"bilinear\" resizing (outermost scales requiring to be 1) for multi-channel multi-batch inputs.\r\n> \r\n> To simplify:\r\n> \r\n> 1. Input shape that is currently accepted by ORT:\r\n>    input_shape = [2, 3, 224, 224] (2 images each with 3 channels)\r\n>    scales_shape = [1, 1, x, x]\r\n> \r\n> Is this what you need ?\r\n> \r\n> 1. Input shape (that is valid per spec) but not yet supported by ORT:\r\n>    input_shape = [2, 3, 224, 224] (2 images each with 3 channels)\r\n>    scales_shape = [2, 2, x, x]\r\n> \r\n> This is not supported yet as \"quadrilinear\" resizing is not supported yet.\r\n> \r\n> Sharing a simple single node model (with just Resize node) and some toy expected inputs/ expected outputs will help.\r\n\r\nThe Resize operator was conveted from pytorch `interpolate` operator. So I cannot verify if your suggestion 1 works. What I need is definitely your suggestion 1.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/558050507/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/558053008",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2463#issuecomment-558053008",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2463",
        "id": 558053008,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU1ODA1MzAwOA==",
        "user": {
            "login": "yangia",
            "id": 34333375,
            "node_id": "MDQ6VXNlcjM0MzMzMzc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/34333375?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yangia",
            "html_url": "https://github.com/yangia",
            "followers_url": "https://api.github.com/users/yangia/followers",
            "following_url": "https://api.github.com/users/yangia/following{/other_user}",
            "gists_url": "https://api.github.com/users/yangia/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yangia/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yangia/subscriptions",
            "organizations_url": "https://api.github.com/users/yangia/orgs",
            "repos_url": "https://api.github.com/users/yangia/repos",
            "events_url": "https://api.github.com/users/yangia/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yangia/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-11-25T08:50:04Z",
        "updated_at": "2019-11-25T08:50:04Z",
        "author_association": "NONE",
        "body": "I found the convertion script in pytorch symbolic_opset11.py as this\r\n```\r\ndef _interpolate(name, dim, interpolate_mode):\r\n    def symbolic_fn(g, input, output_size, align_corners=None):\r\n        align_corners = sym_help._maybe_get_scalar(align_corners)\r\n        output_size = sym_help._maybe_get_const(output_size, 'is')\r\n        if sym_help._is_value(output_size):\r\n            offsets = g.op(\"Constant\", value_t=torch.ones(2, dtype=torch.int64))\r\n            output_size = g.op(\"Cast\", output_size, to_i=sym_help.cast_pytorch_to_onnx[\"Long\"])\r\n            output_size = g.op(\"Concat\", offsets, output_size, axis_i=0)\r\n        else:\r\n            output_size = [1 if i < 2 else output_size[-(dim - i)] for i in range(0, dim)]\r\n            output_size = g.op(\"Constant\", value_t=torch.tensor(output_size))\r\n        coordinate_transformation_mode = \"asymmetric\" if interpolate_mode == \"nearest\" \\\r\n            else \"align_corners\" if align_corners else \"pytorch_half_pixel\"\r\n        empty_tensor = g.op(\"Constant\", value_t=torch.tensor([], dtype=torch.float32))\r\n        return g.op(\"Resize\",\r\n                    input,\r\n                    empty_tensor,  # roi only takes effect whith coordinate_transformation_mode=\"tf_crop_and_resize\"\r\n                    empty_tensor,  # scales is not needed since we are sending out_size\r\n                    output_size,\r\n                    coordinate_transformation_mode_s=coordinate_transformation_mode,\r\n                    cubic_coeff_a_f=-0.75,  # only valid when mode=\"cubic\"\r\n                    mode_s=interpolate_mode,  # nearest, linear, or cubic\r\n                    nearest_mode_s=\"floor\")  # only valid when mode=\"nearest\"\r\n    return symbolic_fn\r\n```\r\nHere we can notice that `scales` are not given in the conversion. So the question is, why ORT still check the `scales`? and where the `scales` under checkment comes from? I looked into the `scales` and found that it is 4-D, and I have no idea where it comes from.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/558053008/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/558374079",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2463#issuecomment-558374079",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2463",
        "id": 558374079,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU1ODM3NDA3OQ==",
        "user": {
            "login": "hariharans29",
            "id": 9969784,
            "node_id": "MDQ6VXNlcjk5Njk3ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9969784?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hariharans29",
            "html_url": "https://github.com/hariharans29",
            "followers_url": "https://api.github.com/users/hariharans29/followers",
            "following_url": "https://api.github.com/users/hariharans29/following{/other_user}",
            "gists_url": "https://api.github.com/users/hariharans29/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hariharans29/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hariharans29/subscriptions",
            "organizations_url": "https://api.github.com/users/hariharans29/orgs",
            "repos_url": "https://api.github.com/users/hariharans29/repos",
            "events_url": "https://api.github.com/users/hariharans29/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hariharans29/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-11-25T22:43:24Z",
        "updated_at": "2019-11-25T22:43:24Z",
        "author_association": "MEMBER",
        "body": "Please check the ONNX spec for Resize - https://github.com/onnx/onnx/blob/master/docs/Operators.md#Resize. It has an input 'scales' that defines the final output shape of the resized tensor.\r\n\r\nAny conversion framework (in this case - the PyTorch exporter) if generating an ONNX model, should comply with the ONNX spec and hence the final model will have scales in it, even if you can't see it in the conversion snippet you pasted.  (I think scales is being computed by the given `output_size` and the `input` in `g.op()`). I\r\n\r\nIf it is case-1 you need, it is supported by ORT. Please share the converted ONNX model you get from PyTorch and the expected input and output and someone will help take a look. Thanks. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/558374079/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/565964166",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2463#issuecomment-565964166",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2463",
        "id": 565964166,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU2NTk2NDE2Ng==",
        "user": {
            "login": "longtaohuang",
            "id": 20283212,
            "node_id": "MDQ6VXNlcjIwMjgzMjEy",
            "avatar_url": "https://avatars.githubusercontent.com/u/20283212?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/longtaohuang",
            "html_url": "https://github.com/longtaohuang",
            "followers_url": "https://api.github.com/users/longtaohuang/followers",
            "following_url": "https://api.github.com/users/longtaohuang/following{/other_user}",
            "gists_url": "https://api.github.com/users/longtaohuang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/longtaohuang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/longtaohuang/subscriptions",
            "organizations_url": "https://api.github.com/users/longtaohuang/orgs",
            "repos_url": "https://api.github.com/users/longtaohuang/repos",
            "events_url": "https://api.github.com/users/longtaohuang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/longtaohuang/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-12-16T08:50:59Z",
        "updated_at": "2019-12-16T08:50:59Z",
        "author_association": "NONE",
        "body": "@yangia I have met the same problem as you described, and I tried to solve it with your trials, in my solution I used torch.split and torch.cat, the solution to traversal the sliced tensor I used is FOR structure.\r\n     Then I got the error: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n    Have you met this problem and how did you solve it? Thanks so much if you can reply me.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/565964166/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/568917722",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2463#issuecomment-568917722",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2463",
        "id": 568917722,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU2ODkxNzcyMg==",
        "user": {
            "login": "emilianavt",
            "id": 38952746,
            "node_id": "MDQ6VXNlcjM4OTUyNzQ2",
            "avatar_url": "https://avatars.githubusercontent.com/u/38952746?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/emilianavt",
            "html_url": "https://github.com/emilianavt",
            "followers_url": "https://api.github.com/users/emilianavt/followers",
            "following_url": "https://api.github.com/users/emilianavt/following{/other_user}",
            "gists_url": "https://api.github.com/users/emilianavt/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/emilianavt/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/emilianavt/subscriptions",
            "organizations_url": "https://api.github.com/users/emilianavt/orgs",
            "repos_url": "https://api.github.com/users/emilianavt/repos",
            "events_url": "https://api.github.com/users/emilianavt/events{/privacy}",
            "received_events_url": "https://api.github.com/users/emilianavt/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-12-25T17:25:51Z",
        "updated_at": "2019-12-25T17:29:08Z",
        "author_association": "NONE",
        "body": "Due to slow CPU inference speed of Pytorch on Windows, I decided to switch to doing inference with onnxruntime, which is much faster. However, I also encountered this issue while converting my model. I worked around it by modifying `torch/onnx/symbolic_opset11.py` as follows.\r\n\r\nOriginal code in `_interpolate`:\r\n\r\n            empty_tensor = g.op(\"Constant\", value_t=torch.tensor([], dtype=torch.float32))\r\n            return g.op(\"Resize\",\r\n                        input,\r\n                        empty_tensor,  # roi only takes effect whith coordinate_transformation_mode=\"tf_crop_and_resize\"\r\n                        empty_tensor,  # scales is not needed since we are sending out_size\r\n                        output_size,\r\n                        coordinate_transformation_mode_s=coordinate_transformation_mode,\r\n                        cubic_coeff_a_f=-0.75,  # only valid when mode=\"cubic\"\r\n                        mode_s=interpolate_mode,  # nearest, linear, or cubic\r\n                        nearest_mode_s=\"floor\")  # only valid when mode=\"nearest\"\r\n\r\nModified code:\r\n\r\n            empty_tensor = g.op(\"Constant\", value_t=torch.tensor([], dtype=torch.float32))\r\n            scales = sym_help._interpolate_size_to_scales(g, input, output_size, dim)\r\n            return g.op(\"Resize\",\r\n                        input,\r\n                        empty_tensor,  # roi only takes effect whith coordinate_transformation_mode=\"tf_crop_and_resize\"\r\n                        scales,\r\n                        coordinate_transformation_mode_s=coordinate_transformation_mode,\r\n                        cubic_coeff_a_f=-0.75,  # only valid when mode=\"cubic\"\r\n                        mode_s=interpolate_mode,  # nearest, linear, or cubic\r\n                        nearest_mode_s=\"floor\")  # only valid when mode=\"nearest\"\r\n\r\nHowever, I believe this is actually a bug in onnxruntime. The ONNX specs say:\r\n\r\n> sizes (optional) : tensor(int64)\r\n> The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. **Only one of 'scales' and 'sizes' can be specified.**\r\n\r\nThis implies that requiring scales or both scales and sizes as onnxruntime does is not correct.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/568917722/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/569176137",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2463#issuecomment-569176137",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2463",
        "id": 569176137,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU2OTE3NjEzNw==",
        "user": {
            "login": "yangia",
            "id": 34333375,
            "node_id": "MDQ6VXNlcjM0MzMzMzc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/34333375?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yangia",
            "html_url": "https://github.com/yangia",
            "followers_url": "https://api.github.com/users/yangia/followers",
            "following_url": "https://api.github.com/users/yangia/following{/other_user}",
            "gists_url": "https://api.github.com/users/yangia/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yangia/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yangia/subscriptions",
            "organizations_url": "https://api.github.com/users/yangia/orgs",
            "repos_url": "https://api.github.com/users/yangia/repos",
            "events_url": "https://api.github.com/users/yangia/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yangia/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-12-27T03:18:00Z",
        "updated_at": "2019-12-27T03:18:00Z",
        "author_association": "NONE",
        "body": "> @yangia I have met the same problem as you described, and I tried to solve it with your trials, in my solution I used torch.split and torch.cat, the solution to traversal the sliced tensor I used is FOR structure.\r\n> Then I got the error: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\r\n> Have you met this problem and how did you solve it? Thanks so much if you can reply me.\r\n\r\nI didn't use torch.split. I silced with `for`, and then concatenated with torch.cat. The conversion of torch.split seems to have something wrong with it. Not sure.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/569176137/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/569176277",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2463#issuecomment-569176277",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2463",
        "id": 569176277,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU2OTE3NjI3Nw==",
        "user": {
            "login": "yangia",
            "id": 34333375,
            "node_id": "MDQ6VXNlcjM0MzMzMzc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/34333375?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yangia",
            "html_url": "https://github.com/yangia",
            "followers_url": "https://api.github.com/users/yangia/followers",
            "following_url": "https://api.github.com/users/yangia/following{/other_user}",
            "gists_url": "https://api.github.com/users/yangia/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yangia/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yangia/subscriptions",
            "organizations_url": "https://api.github.com/users/yangia/orgs",
            "repos_url": "https://api.github.com/users/yangia/repos",
            "events_url": "https://api.github.com/users/yangia/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yangia/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-12-27T03:19:08Z",
        "updated_at": "2019-12-27T03:19:08Z",
        "author_association": "NONE",
        "body": "> Due to slow CPU inference speed of Pytorch on Windows, I decided to switch to doing inference with onnxruntime, which is much faster. However, I also encountered this issue while converting my model. I worked around it by modifying `torch/onnx/symbolic_opset11.py` as follows.\r\n> \r\n> Original code in `_interpolate`:\r\n> \r\n> ```\r\n>         empty_tensor = g.op(\"Constant\", value_t=torch.tensor([], dtype=torch.float32))\r\n>         return g.op(\"Resize\",\r\n>                     input,\r\n>                     empty_tensor,  # roi only takes effect whith coordinate_transformation_mode=\"tf_crop_and_resize\"\r\n>                     empty_tensor,  # scales is not needed since we are sending out_size\r\n>                     output_size,\r\n>                     coordinate_transformation_mode_s=coordinate_transformation_mode,\r\n>                     cubic_coeff_a_f=-0.75,  # only valid when mode=\"cubic\"\r\n>                     mode_s=interpolate_mode,  # nearest, linear, or cubic\r\n>                     nearest_mode_s=\"floor\")  # only valid when mode=\"nearest\"\r\n> ```\r\n> \r\n> Modified code:\r\n> \r\n> ```\r\n>         empty_tensor = g.op(\"Constant\", value_t=torch.tensor([], dtype=torch.float32))\r\n>         scales = sym_help._interpolate_size_to_scales(g, input, output_size, dim)\r\n>         return g.op(\"Resize\",\r\n>                     input,\r\n>                     empty_tensor,  # roi only takes effect whith coordinate_transformation_mode=\"tf_crop_and_resize\"\r\n>                     scales,\r\n>                     coordinate_transformation_mode_s=coordinate_transformation_mode,\r\n>                     cubic_coeff_a_f=-0.75,  # only valid when mode=\"cubic\"\r\n>                     mode_s=interpolate_mode,  # nearest, linear, or cubic\r\n>                     nearest_mode_s=\"floor\")  # only valid when mode=\"nearest\"\r\n> ```\r\n> \r\n> However, I believe this is actually a bug in onnxruntime. The ONNX specs say:\r\n> \r\n> > sizes (optional) : tensor(int64)\r\n> > The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. **Only one of 'scales' and 'sizes' can be specified.**\r\n> \r\n> This implies that requiring scales or both scales and sizes as onnxruntime does is not correct.\r\n\r\nThank you for your reply. I will try it later.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/569176277/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/653347537",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2463#issuecomment-653347537",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2463",
        "id": 653347537,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY1MzM0NzUzNw==",
        "user": {
            "login": "stale[bot]",
            "id": 26384082,
            "node_id": "MDM6Qm90MjYzODQwODI=",
            "avatar_url": "https://avatars.githubusercontent.com/in/1724?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stale%5Bbot%5D",
            "html_url": "https://github.com/apps/stale",
            "followers_url": "https://api.github.com/users/stale%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/stale%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stale%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/stale%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/stale%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/stale%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stale%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "created_at": "2020-07-03T04:57:58Z",
        "updated_at": "2020-07-03T04:57:58Z",
        "author_association": "NONE",
        "body": "This issue has been automatically marked as stale due to inactivity and will be closed in 7 days if no further activity occurs. If further support is needed, please provide an update and/or more details.\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/653347537/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/656971901",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2463#issuecomment-656971901",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2463",
        "id": 656971901,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY1Njk3MTkwMQ==",
        "user": {
            "login": "stale[bot]",
            "id": 26384082,
            "node_id": "MDM6Qm90MjYzODQwODI=",
            "avatar_url": "https://avatars.githubusercontent.com/in/1724?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stale%5Bbot%5D",
            "html_url": "https://github.com/apps/stale",
            "followers_url": "https://api.github.com/users/stale%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/stale%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stale%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/stale%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/stale%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/stale%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stale%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "created_at": "2020-07-11T02:39:40Z",
        "updated_at": "2020-07-11T02:39:40Z",
        "author_association": "NONE",
        "body": "This issue has been automatically closed due to inactivity. Please reactivate if further support is needed.\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/656971901/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]