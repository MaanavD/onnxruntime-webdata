[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/569245533",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2750#issuecomment-569245533",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2750",
        "id": 569245533,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU2OTI0NTUzMw==",
        "user": {
            "login": "24hours",
            "id": 650407,
            "node_id": "MDQ6VXNlcjY1MDQwNw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/650407?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/24hours",
            "html_url": "https://github.com/24hours",
            "followers_url": "https://api.github.com/users/24hours/followers",
            "following_url": "https://api.github.com/users/24hours/following{/other_user}",
            "gists_url": "https://api.github.com/users/24hours/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/24hours/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/24hours/subscriptions",
            "organizations_url": "https://api.github.com/users/24hours/orgs",
            "repos_url": "https://api.github.com/users/24hours/repos",
            "events_url": "https://api.github.com/users/24hours/events{/privacy}",
            "received_events_url": "https://api.github.com/users/24hours/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-12-27T10:54:24Z",
        "updated_at": "2019-12-27T10:54:24Z",
        "author_association": "NONE",
        "body": "you have preallocated input into gpu memory \r\n```dummy_input = torch.randn(10, 3, 224, 224, device='cuda')```\r\n\r\n``` ort_session.run``` need to allocate into input gpu before running, resulting in slower performance. \r\n\r\nas a comparison, I got \r\nI have same speed ( 1ms )  for onnxruntime and torch for Alexnet on Quadro RTX 6000.\r\nHowever, \r\nResnet50 torch ( 6 ms ) , onnxruntime ( 3 ms )\r\n\r\nbatch size = 1, image = 224x224.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/569245533/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/572341099",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2750#issuecomment-572341099",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2750",
        "id": 572341099,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU3MjM0MTA5OQ==",
        "user": {
            "login": "pranavsharma",
            "id": 2732907,
            "node_id": "MDQ6VXNlcjI3MzI5MDc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2732907?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranavsharma",
            "html_url": "https://github.com/pranavsharma",
            "followers_url": "https://api.github.com/users/pranavsharma/followers",
            "following_url": "https://api.github.com/users/pranavsharma/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranavsharma/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranavsharma/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranavsharma/subscriptions",
            "organizations_url": "https://api.github.com/users/pranavsharma/orgs",
            "repos_url": "https://api.github.com/users/pranavsharma/repos",
            "events_url": "https://api.github.com/users/pranavsharma/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranavsharma/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-01-09T01:40:08Z",
        "updated_at": "2020-01-09T01:40:08Z",
        "author_association": "MEMBER",
        "body": "@24hours has already addressed the issue. The input was preallocated on the GPU in the case of torch. Closing this.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/572341099/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/643593263",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2750#issuecomment-643593263",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2750",
        "id": 643593263,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY0MzU5MzI2Mw==",
        "user": {
            "login": "gaoteng-git",
            "id": 10429114,
            "node_id": "MDQ6VXNlcjEwNDI5MTE0",
            "avatar_url": "https://avatars.githubusercontent.com/u/10429114?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gaoteng-git",
            "html_url": "https://github.com/gaoteng-git",
            "followers_url": "https://api.github.com/users/gaoteng-git/followers",
            "following_url": "https://api.github.com/users/gaoteng-git/following{/other_user}",
            "gists_url": "https://api.github.com/users/gaoteng-git/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gaoteng-git/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gaoteng-git/subscriptions",
            "organizations_url": "https://api.github.com/users/gaoteng-git/orgs",
            "repos_url": "https://api.github.com/users/gaoteng-git/repos",
            "events_url": "https://api.github.com/users/gaoteng-git/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gaoteng-git/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-06-13T08:49:48Z",
        "updated_at": "2020-06-13T08:58:38Z",
        "author_association": "NONE",
        "body": "> you have preallocated input into gpu memory\r\n> `dummy_input = torch.randn(10, 3, 224, 224, device='cuda')`\r\n> \r\n> ` ort_session.run` need to allocate into input gpu before running, resulting in slower performance.\r\n> \r\n> as a comparison, I got\r\n> I have same speed ( 1ms ) for onnxruntime and torch for Alexnet on Quadro RTX 6000.\r\n> However,\r\n> Resnet50 torch ( 6 ms ) , onnxruntime ( 3 ms )\r\n> \r\n> batch size = 1, image = 224x224.\r\n\r\nHow could I allocate input to GPU? (which GPU data type do \"ort_session.run\" \"inputs\" argument accept?) I also need to compare the inference performance of onnx runtime with other frameworks, but didn't find any code example or API doc to show this(most examples give inputs on CPU directly to the \"run\").",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/643593263/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/643655308",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2750#issuecomment-643655308",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2750",
        "id": 643655308,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY0MzY1NTMwOA==",
        "user": {
            "login": "pranavsharma",
            "id": 2732907,
            "node_id": "MDQ6VXNlcjI3MzI5MDc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2732907?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranavsharma",
            "html_url": "https://github.com/pranavsharma",
            "followers_url": "https://api.github.com/users/pranavsharma/followers",
            "following_url": "https://api.github.com/users/pranavsharma/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranavsharma/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranavsharma/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranavsharma/subscriptions",
            "organizations_url": "https://api.github.com/users/pranavsharma/orgs",
            "repos_url": "https://api.github.com/users/pranavsharma/repos",
            "events_url": "https://api.github.com/users/pranavsharma/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranavsharma/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-06-13T17:45:00Z",
        "updated_at": "2020-06-13T17:45:00Z",
        "author_association": "MEMBER",
        "body": "Follow the example here https://github.com/microsoft/onnxruntime/blob/master/orttraining/orttraining/python/ort_trainer.py#L92. The key idea is to use iobinding. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/643655308/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/782892044",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2750#issuecomment-782892044",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2750",
        "id": 782892044,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc4Mjg5MjA0NA==",
        "user": {
            "login": "fengyuentau",
            "id": 17219438,
            "node_id": "MDQ6VXNlcjE3MjE5NDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/17219438?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fengyuentau",
            "html_url": "https://github.com/fengyuentau",
            "followers_url": "https://api.github.com/users/fengyuentau/followers",
            "following_url": "https://api.github.com/users/fengyuentau/following{/other_user}",
            "gists_url": "https://api.github.com/users/fengyuentau/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fengyuentau/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fengyuentau/subscriptions",
            "organizations_url": "https://api.github.com/users/fengyuentau/orgs",
            "repos_url": "https://api.github.com/users/fengyuentau/repos",
            "events_url": "https://api.github.com/users/fengyuentau/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fengyuentau/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-21T17:19:54Z",
        "updated_at": "2021-02-21T17:19:54Z",
        "author_association": "NONE",
        "body": "Example for iobinding: https://www.onnxruntime.ai/python/api_summary.html#id2. This one is more informative and easier than @pranavsharma 's.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/782892044/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/972659228",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2750#issuecomment-972659228",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2750",
        "id": 972659228,
        "node_id": "IC_kwDOCVq1mM45-Zoc",
        "user": {
            "login": "FrancescoSaverioZuppichini",
            "id": 15908060,
            "node_id": "MDQ6VXNlcjE1OTA4MDYw",
            "avatar_url": "https://avatars.githubusercontent.com/u/15908060?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/FrancescoSaverioZuppichini",
            "html_url": "https://github.com/FrancescoSaverioZuppichini",
            "followers_url": "https://api.github.com/users/FrancescoSaverioZuppichini/followers",
            "following_url": "https://api.github.com/users/FrancescoSaverioZuppichini/following{/other_user}",
            "gists_url": "https://api.github.com/users/FrancescoSaverioZuppichini/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/FrancescoSaverioZuppichini/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/FrancescoSaverioZuppichini/subscriptions",
            "organizations_url": "https://api.github.com/users/FrancescoSaverioZuppichini/orgs",
            "repos_url": "https://api.github.com/users/FrancescoSaverioZuppichini/repos",
            "events_url": "https://api.github.com/users/FrancescoSaverioZuppichini/events{/privacy}",
            "received_events_url": "https://api.github.com/users/FrancescoSaverioZuppichini/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-18T08:54:13Z",
        "updated_at": "2021-11-18T08:54:13Z",
        "author_association": "NONE",
        "body": "Same here, even if I time the execution of both runtime to include the tensor creation on GPU, vanilla pytorch is 3x faster than onnx",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/972659228/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]