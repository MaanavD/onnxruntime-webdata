[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/569946581",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2763#issuecomment-569946581",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2763",
        "id": 569946581,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU2OTk0NjU4MQ==",
        "user": {
            "login": "nietras",
            "id": 10798831,
            "node_id": "MDQ6VXNlcjEwNzk4ODMx",
            "avatar_url": "https://avatars.githubusercontent.com/u/10798831?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nietras",
            "html_url": "https://github.com/nietras",
            "followers_url": "https://api.github.com/users/nietras/followers",
            "following_url": "https://api.github.com/users/nietras/following{/other_user}",
            "gists_url": "https://api.github.com/users/nietras/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nietras/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nietras/subscriptions",
            "organizations_url": "https://api.github.com/users/nietras/orgs",
            "repos_url": "https://api.github.com/users/nietras/repos",
            "events_url": "https://api.github.com/users/nietras/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nietras/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2019-12-31T15:34:45Z",
        "updated_at": "2019-12-31T15:34:45Z",
        "author_association": "CONTRIBUTOR",
        "body": "A `BenchmarkDotNet` example running a simple MNIST is shown below. Note we try to \"cache\" as much as possible.\r\n\r\n```csharp\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.IO;\r\nusing System.Linq;\r\nusing BenchmarkDotNet.Attributes;\r\nusing BenchmarkDotNet.Diagnostics.Windows.Configs;\r\nusing Microsoft.ML.OnnxRuntime;\r\nusing Microsoft.ML.OnnxRuntime.Tensors;\r\n\r\nnamespace OnnxRuntimeBenchmark\r\n{\r\n    [NativeMemoryProfiler]\r\n    [MemoryDiagnoser]\r\n    public class Bench\r\n    {\r\n        readonly InferenceSession _session;\r\n        readonly Dictionary<string, NamedOnnxValue> _inputNameToNamedOnnxValue;\r\n\r\n        public Bench()\r\n        {\r\n            var modelData = Helper.GetBytes(() => new FileStream(\"model.onnx\",\r\n                FileMode.Open, FileAccess.Read));\r\n            var options = new SessionOptions();\r\n            _session = new InferenceSession(modelData, options);\r\n\r\n            var inputMetadata = _session.InputMetadata;\r\n            var outputMetadata = _session.OutputMetadata;\r\n\r\n            var inputNameToTensor = inputMetadata.ToDictionary(p => p.Key, p =>\r\n            {\r\n                // There are 3 leading dims, [-1,1,1]\r\n                var dimensions = p.Value.Dimensions;\r\n                dimensions[0] = 1; // Batch-size 1\r\n                var tensor = new DenseTensor<float>(dimensions);\r\n                var buffer = tensor.Buffer;\r\n                return tensor;\r\n            });\r\n\r\n            _inputNameToNamedOnnxValue = inputNameToTensor.ToDictionary(p => p.Key,\r\n                p => NamedOnnxValue.CreateFromTensor(p.Key, p.Value));\r\n        }\r\n\r\n        [Benchmark]\r\n        public float Run()\r\n        {\r\n            using (var outputs = _session.Run(_inputNameToNamedOnnxValue.Values))\r\n            {\r\n                // Should be IReadOnlyList to allow indexing\r\n                var output = outputs.Single();\r\n                var outputTensor = output.AsTensor<float>();\r\n                Span<int> index = stackalloc int[outputTensor.Rank];\r\n                return outputTensor[index];\r\n            }\r\n        }\r\n    }\r\n}\r\n```\r\nNote you should be able to run this with any `onnx` model, as an example and since main issue here is allocs per `Run` one can use the simple MNIST model as in https://github.com/onnx/models/tree/master/vision/classification/mnist\r\n\r\nA quick run of this gives using Microsoft.ML.OnnxRuntime.MKLML 1.1.0.\r\n\r\n``` ini\r\n\r\nBenchmarkDotNet=v0.12.0, OS=Windows 10.0.17763.864 (1809/October2018Update/Redstone5)\r\nIntel Core i7-8700 CPU 3.20GHz (Coffee Lake), 1 CPU, 12 logical and 6 physical cores\r\n  [Host]     : .NET Framework 4.8 (4.8.4042.0), X64 RyuJIT\r\n  DefaultJob : .NET Framework 4.8 (4.8.4042.0), X64 RyuJIT\r\n```\r\n| Method |     Mean |    Error |   StdDev | Gen 0 | Gen 1 | Gen 2 | Allocated | Allocated native memory | Native memory leak |\r\n|------- |---------:|---------:|---------:|------:|------:|------:|----------:|------------------------:|-------------------:|\r\n|    Run | 63.68 us | 0.146 us | 0.137 us |     - |     - |     - |     723 B |                  4820 B |                  - |\r\n\r\nWe don't care about the native memory allocs, these are just included for completeness. The main point here is not so much the `723` bytes per call but the huge amount of instances per call, and also when running models with more than one input this gets worse e.g. multiply by number of inputs.\r\n\r\nAnd yes this is on .NET Framework which we have to run on. Using the OnnxRuntime package with that has some issues, excessive package references being one.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/569946581/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/572302915",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2763#issuecomment-572302915",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2763",
        "id": 572302915,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU3MjMwMjkxNQ==",
        "user": {
            "login": "jignparm",
            "id": 13698702,
            "node_id": "MDQ6VXNlcjEzNjk4NzAy",
            "avatar_url": "https://avatars.githubusercontent.com/u/13698702?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jignparm",
            "html_url": "https://github.com/jignparm",
            "followers_url": "https://api.github.com/users/jignparm/followers",
            "following_url": "https://api.github.com/users/jignparm/following{/other_user}",
            "gists_url": "https://api.github.com/users/jignparm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jignparm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jignparm/subscriptions",
            "organizations_url": "https://api.github.com/users/jignparm/orgs",
            "repos_url": "https://api.github.com/users/jignparm/repos",
            "events_url": "https://api.github.com/users/jignparm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jignparm/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-01-08T23:12:29Z",
        "updated_at": "2020-01-08T23:12:29Z",
        "author_association": "CONTRIBUTOR",
        "body": ">This causes GC pauses above our budget.\r\n\r\nThe C# API running time performance should be quite close to native C /C++ API.  Since there's no native memory leak in the table above (running on CPU, and excluding TensorRT), how do the GC pauses manifest? Are they causing slowdown, compared to native C++/C? \r\n\r\nThe number of allocations may seem high, but it's not clear if they are higher than necessary (i.e. what are they being compared to?) -- but if they are impacting running time and causing C# to be substantially slower than native C/C++, it requires investigation.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/572302915/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/572516526",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2763#issuecomment-572516526",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2763",
        "id": 572516526,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU3MjUxNjUyNg==",
        "user": {
            "login": "nietras",
            "id": 10798831,
            "node_id": "MDQ6VXNlcjEwNzk4ODMx",
            "avatar_url": "https://avatars.githubusercontent.com/u/10798831?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nietras",
            "html_url": "https://github.com/nietras",
            "followers_url": "https://api.github.com/users/nietras/followers",
            "following_url": "https://api.github.com/users/nietras/following{/other_user}",
            "gists_url": "https://api.github.com/users/nietras/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nietras/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nietras/subscriptions",
            "organizations_url": "https://api.github.com/users/nietras/orgs",
            "repos_url": "https://api.github.com/users/nietras/repos",
            "events_url": "https://api.github.com/users/nietras/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nietras/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-01-09T11:18:03Z",
        "updated_at": "2020-01-09T11:18:03Z",
        "author_association": "CONTRIBUTOR",
        "body": "> The C# API running time performance should be quite close to native C /C++ API. Since there's no native memory leak in the table above (running on CPU, and excluding TensorRT), how do the GC pauses manifest? Are they causing slowdown, compared to native C++/C?\r\n\r\n@jignparm running time and native memory leak are of no concern with regards to managed allocations. Managed allocations cause a build up of garbage that the GC has to collect. This causes GC pauses. Of the entire application. Way above our budget. There is no need for all these allocations in the C# code for the OnnxRuntime. \r\n\r\n> if they are impacting running time and causing C# to be substantially slower than native C/C++, it requires investigation.\r\n\r\n@jignparm in my view this is wrong, the problem here is not whether C# is \"substantially slower\" than native C/C++, that is comparing apples with oranges. .NET has a garbage collector, this is fundamentally different from C++ and cannot be compared. GC pauses are a real concern for latency sensitive applications. You will not see them in micro-benchmarks with regards to running time. ASP.NET Core is the poster example for how reducing allocations improved overall performance of it and worst case latency. ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/572516526/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/572730159",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2763#issuecomment-572730159",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2763",
        "id": 572730159,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU3MjczMDE1OQ==",
        "user": {
            "login": "jignparm",
            "id": 13698702,
            "node_id": "MDQ6VXNlcjEzNjk4NzAy",
            "avatar_url": "https://avatars.githubusercontent.com/u/13698702?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jignparm",
            "html_url": "https://github.com/jignparm",
            "followers_url": "https://api.github.com/users/jignparm/followers",
            "following_url": "https://api.github.com/users/jignparm/following{/other_user}",
            "gists_url": "https://api.github.com/users/jignparm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jignparm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jignparm/subscriptions",
            "organizations_url": "https://api.github.com/users/jignparm/orgs",
            "repos_url": "https://api.github.com/users/jignparm/repos",
            "events_url": "https://api.github.com/users/jignparm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jignparm/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-01-09T20:00:07Z",
        "updated_at": "2020-01-09T20:00:07Z",
        "author_association": "CONTRIBUTOR",
        "body": ">This causes GC pauses. Of the entire application.\r\n\r\nAny idea how much time  is spent due to GC pauses  in your scenario (i.e. how much are these pauses contributing to the overall running time of the C# application versus C/C++ application)?\r\n\r\nThe standard deviation of 0.137us coupled with a mean of 63.68us in the table above is implying that the vast majority of inference runs are completed in expected time, with very little variance.\r\n\r\n>Way above our budget\r\n\r\nWhat's the budget, and does the C/C++ API fall within the budget?\r\n\r\nFor latency sensitive applications, I'm assuming the concern is not about the majority of the runs, but the outliers instead (i.e. the slowest run, which would be due to the GC pauses, is what you're looking to optimize). Does the benchmarking framework also report the slowest and fastest 1% of the runs?\r\n\r\n\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/572730159/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/572742386",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2763#issuecomment-572742386",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2763",
        "id": 572742386,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU3Mjc0MjM4Ng==",
        "user": {
            "login": "jignparm",
            "id": 13698702,
            "node_id": "MDQ6VXNlcjEzNjk4NzAy",
            "avatar_url": "https://avatars.githubusercontent.com/u/13698702?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jignparm",
            "html_url": "https://github.com/jignparm",
            "followers_url": "https://api.github.com/users/jignparm/followers",
            "following_url": "https://api.github.com/users/jignparm/following{/other_user}",
            "gists_url": "https://api.github.com/users/jignparm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jignparm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jignparm/subscriptions",
            "organizations_url": "https://api.github.com/users/jignparm/orgs",
            "repos_url": "https://api.github.com/users/jignparm/repos",
            "events_url": "https://api.github.com/users/jignparm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jignparm/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-01-09T20:33:02Z",
        "updated_at": "2020-01-09T20:33:02Z",
        "author_association": "CONTRIBUTOR",
        "body": "Another question --  is the concern mostly about overall app health (i.e. other portions of the application are being negatively impacted due to allocations), or is the primary concern that GC kicks in during inference runs? \r\n\r\nRegarding reducing managed allocations -- blittable types are already pinned in memory to avoid data copies. In some cases, like string tensor types, the additional allocations are unavoidable (each string has to be converted to UTF-8).  It may be possible to slightly reduce the number of overall allocations (besides the ones due to tensor operations), but some concrete data points regarding impact would help quantify the negative effects of the allocations.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/572742386/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/580685246",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2763#issuecomment-580685246",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2763",
        "id": 580685246,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU4MDY4NTI0Ng==",
        "user": {
            "login": "nietras",
            "id": 10798831,
            "node_id": "MDQ6VXNlcjEwNzk4ODMx",
            "avatar_url": "https://avatars.githubusercontent.com/u/10798831?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nietras",
            "html_url": "https://github.com/nietras",
            "followers_url": "https://api.github.com/users/nietras/followers",
            "following_url": "https://api.github.com/users/nietras/following{/other_user}",
            "gists_url": "https://api.github.com/users/nietras/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nietras/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nietras/subscriptions",
            "organizations_url": "https://api.github.com/users/nietras/orgs",
            "repos_url": "https://api.github.com/users/nietras/repos",
            "events_url": "https://api.github.com/users/nietras/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nietras/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-01-31T10:50:58Z",
        "updated_at": "2020-01-31T11:15:23Z",
        "author_association": "CONTRIBUTOR",
        "body": "> the standard deviation of 0.137us coupled with a mean of 63.68us in the table above is implying that the vast majority of inference runs are completed in expected time, with very little variance.\r\n\r\n@jignparm as I mentioned, :), you cannot use BDN results as a measurement for GC pauses, especially since no GC occurred during the run.\r\n\r\n> What's the budget\r\n\r\nThe budget I am talking about are the GC pauses, not inference times. Inference times have nothing to do with this issue. It is the after effects of running `Run` and the many allocations this does and the many built up allocations over time that causes too long GC pauses for us.\r\n\r\n> the primary concern that GC kicks in during inference runs?\r\n\r\nNo, it doesn't matter if it kicks in during inference runs, but it matters for other parts of our application that control real world hardware in soft real time.\r\n\r\n> blittable types are already pinned in memory to avoid data copies\r\n\r\nYes, this is great! And why ONNX Runtime has much less overhead that other libs.\r\n\r\n> may be possible to slightly reduce the number of overall allocations\r\n\r\nI forked ONNX Runtime and have reduced it to **zero** for our case, this involved making a new overload to `Run` and some admittedly ugly hacks. In my view the API should allow advanced users to pick a zero allocation path, this is why the native C API should not be internal/private, it should be public, the C API is public for C/C++ users, but for some reason it is hidden for C# users, this implies C# users do not know how to handle the C API, we do. :)\r\n\r\nHaving an easy to use API is, of course, great. I am not saying remove that, but great APIs are built in levels. Low level for advanced users, high level for ease of use. Both should be available.\r\n\r\n> concrete data points regarding impact would help quantify the negative effects of the allocations.\r\n\r\nWe run long running tests +24 hours to evaluate performance of our industrial application. Within that time we measure GC pauses using `perfview`. Our maximum budget could be say 10ms, with the code in ONNX Runtime for C#, this rises to 30ms for example. I do understand that GC pauses have variance here, and our average GC pause is ~2ms, it is the worst case that matters to us though.\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/580685246/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/585130259",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2763#issuecomment-585130259",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2763",
        "id": 585130259,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU4NTEzMDI1OQ==",
        "user": {
            "login": "jignparm",
            "id": 13698702,
            "node_id": "MDQ6VXNlcjEzNjk4NzAy",
            "avatar_url": "https://avatars.githubusercontent.com/u/13698702?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jignparm",
            "html_url": "https://github.com/jignparm",
            "followers_url": "https://api.github.com/users/jignparm/followers",
            "following_url": "https://api.github.com/users/jignparm/following{/other_user}",
            "gists_url": "https://api.github.com/users/jignparm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jignparm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jignparm/subscriptions",
            "organizations_url": "https://api.github.com/users/jignparm/orgs",
            "repos_url": "https://api.github.com/users/jignparm/repos",
            "events_url": "https://api.github.com/users/jignparm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jignparm/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-02-12T10:09:47Z",
        "updated_at": "2020-02-12T10:09:47Z",
        "author_association": "CONTRIBUTOR",
        "body": ">...but it matters for other parts of our application that control real world hardware in soft real time.\r\n\r\n>...Low level for advanced users, high level for ease of use. Both should be available.\r\n\r\nUsing C#  a real time environment is a bit of an odd choice because you cannot control GC to any reasonable degree. \r\n\r\nAs you mentioned above, having a lower-level C# API  to mitigate the number of manage allocations  and avoid GC entirely would be one way to enable real-time scenarios in C#. The current C# API was designed primarily for ease-of-use and for quick adoption, while keeping the average latency/throughput as close to native API speed as possible.\r\n\r\n>I forked ONNX Runtime and have reduced it to zero for our case,\r\n\r\nGlad to hear that you have a solution that works for you in the interim. I'll keep this issue open for tracking purposes as a \"good-to-have\" feature.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/585130259/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/653347627",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2763#issuecomment-653347627",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2763",
        "id": 653347627,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY1MzM0NzYyNw==",
        "user": {
            "login": "stale[bot]",
            "id": 26384082,
            "node_id": "MDM6Qm90MjYzODQwODI=",
            "avatar_url": "https://avatars.githubusercontent.com/in/1724?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stale%5Bbot%5D",
            "html_url": "https://github.com/apps/stale",
            "followers_url": "https://api.github.com/users/stale%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/stale%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stale%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/stale%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/stale%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/stale%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stale%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "created_at": "2020-07-03T04:58:15Z",
        "updated_at": "2020-07-03T04:58:15Z",
        "author_association": "NONE",
        "body": "This issue has been automatically marked as stale due to inactivity and will be closed in 7 days if no further activity occurs. If further support is needed, please provide an update and/or more details.\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/653347627/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/656971847",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/2763#issuecomment-656971847",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/2763",
        "id": 656971847,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY1Njk3MTg0Nw==",
        "user": {
            "login": "stale[bot]",
            "id": 26384082,
            "node_id": "MDM6Qm90MjYzODQwODI=",
            "avatar_url": "https://avatars.githubusercontent.com/in/1724?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stale%5Bbot%5D",
            "html_url": "https://github.com/apps/stale",
            "followers_url": "https://api.github.com/users/stale%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/stale%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stale%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/stale%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/stale%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/stale%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stale%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "created_at": "2020-07-11T02:39:25Z",
        "updated_at": "2020-07-11T02:39:25Z",
        "author_association": "NONE",
        "body": "This issue has been automatically closed due to inactivity. Please reactivate if further support is needed.\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/656971847/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]