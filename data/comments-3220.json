[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/599909856",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3220#issuecomment-599909856",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3220",
        "id": 599909856,
        "node_id": "MDEyOklzc3VlQ29tbWVudDU5OTkwOTg1Ng==",
        "user": {
            "login": "pranav-prakash",
            "id": 10335022,
            "node_id": "MDQ6VXNlcjEwMzM1MDIy",
            "avatar_url": "https://avatars.githubusercontent.com/u/10335022?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranav-prakash",
            "html_url": "https://github.com/pranav-prakash",
            "followers_url": "https://api.github.com/users/pranav-prakash/followers",
            "following_url": "https://api.github.com/users/pranav-prakash/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranav-prakash/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranav-prakash/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranav-prakash/subscriptions",
            "organizations_url": "https://api.github.com/users/pranav-prakash/orgs",
            "repos_url": "https://api.github.com/users/pranav-prakash/repos",
            "events_url": "https://api.github.com/users/pranav-prakash/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranav-prakash/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-03-17T07:02:36Z",
        "updated_at": "2020-03-17T07:02:36Z",
        "author_association": "CONTRIBUTOR",
        "body": "I believe this is because even in `dynamic` quantization mode you must specify the output scale for all the quantized operators (only the input scales are dynamically computed). You can use the `calibrate.py` script to do this.\r\n\r\nPerhaps to make this more clear, instead of the `assert` an exception could be thrown (e.g \"Output quantization parameters not specified for node {}\")",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/599909856/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/600158309",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3220#issuecomment-600158309",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3220",
        "id": 600158309,
        "node_id": "MDEyOklzc3VlQ29tbWVudDYwMDE1ODMwOQ==",
        "user": {
            "login": "marph91",
            "id": 33229141,
            "node_id": "MDQ6VXNlcjMzMjI5MTQx",
            "avatar_url": "https://avatars.githubusercontent.com/u/33229141?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/marph91",
            "html_url": "https://github.com/marph91",
            "followers_url": "https://api.github.com/users/marph91/followers",
            "following_url": "https://api.github.com/users/marph91/following{/other_user}",
            "gists_url": "https://api.github.com/users/marph91/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/marph91/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/marph91/subscriptions",
            "organizations_url": "https://api.github.com/users/marph91/orgs",
            "repos_url": "https://api.github.com/users/marph91/repos",
            "events_url": "https://api.github.com/users/marph91/events{/privacy}",
            "received_events_url": "https://api.github.com/users/marph91/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-03-17T16:12:28Z",
        "updated_at": "2020-03-17T16:12:28Z",
        "author_association": "NONE",
        "body": "Thanks for the clarification. After reading it again I'm understanding more. However, it's not working yet. My use case is:\r\n- specifying the scales and zero points manually (because they are restricted to 2^x, respectively 0)\r\n- using `quantize.py` with static quantization to convert all `Conv` layers to `QuantizeLinear -> QLinearConv -> DequantizeLinear`\r\n\r\nIs this possible at all? Is there any example of using `quantize.py` with static quantization on a real model?\r\n\r\nThe corresponding code is:\r\n```python\r\nimport numpy as np\r\nimport onnx\r\n\r\nfrom quantize import quantize, QuantizationMode\r\n\r\n\r\ndef calibrate_custom(model):\r\n    quant_dict = {}\r\n    for node in model.graph.node:\r\n        if node.op_type == \"Conv\":\r\n            quant_dict[node.input[0]] = [np.uint8(128), np.float32(0.0)]\r\n            quant_dict[node.output[0]] = [np.uint8(128), np.float32(0.0)]\r\n    return quant_dict\r\n\r\n\r\ndef main():\r\n    filename = \"squeezenet1.1.onnx\"\r\n    filename_q = \"squeezenet1.1_quantized.onnx\"\r\n\r\n    model = onnx.load(filename)\r\n\r\n    param_q = calibrate_custom(model)\r\n\r\n    quantized_model = quantize(model, quantization_mode=QuantizationMode.QLinearOps,\r\n                               static=True,\r\n                               quantization_params=param_q)\r\n\r\n    onnx.save(quantized_model, filename_q)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\n```\r\n> python3 calibrate.py \r\nWarning: The original model opset version is 7, which does not support quantized operators.\r\n            The opset version of quantized model will be set to 10. Use onnx model checker to verify model after quantization.\r\nTraceback (most recent call last):\r\n  File \"calibrate.py\", line 32, in <module>\r\n    main()\r\n  File \"calibrate.py\", line 26, in main\r\n    quantization_params=param_q)\r\n  File \"/home/workspace/pocket-cnn/code/python_tools/cnn_onnx/quantize.py\", line 1486, in quantize\r\n    quantizer.quantize_model()\r\n  File \"/home/workspace/pocket-cnn/code/python_tools/cnn_onnx/quantize.py\", line 312, in quantize_model\r\n    new_list += self._quantize_convolution(node, new_list)\r\n  File \"/home/workspace/pocket-cnn/code/python_tools/cnn_onnx/quantize.py\", line 1359, in _quantize_convolution\r\n    return self._quantize_convolution_qlinear_ops(node, new_nodes_list)\r\n  File \"/home/workspace/pocket-cnn/code/python_tools/cnn_onnx/quantize.py\", line 1252, in _quantize_convolution_qlinear_ops\r\n    quantized_bias_name = self._quantize_bias(node, nodes)\r\n  File \"/home/workspace/pocket-cnn/code/python_tools/cnn_onnx/quantize.py\", line 904, in _quantize_bias\r\n    node.input[0]].scale_name\r\nKeyError: 'data'\r\n```\r\n\r\n`data` is the input of the whole model. It isn't found in the dict `self.quantized_value_map`. But I think it is correct. `data` isn't in this dict, because it didn't get quantized.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/600158309/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/600243228",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3220#issuecomment-600243228",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3220",
        "id": 600243228,
        "node_id": "MDEyOklzc3VlQ29tbWVudDYwMDI0MzIyOA==",
        "user": {
            "login": "pranav-prakash",
            "id": 10335022,
            "node_id": "MDQ6VXNlcjEwMzM1MDIy",
            "avatar_url": "https://avatars.githubusercontent.com/u/10335022?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranav-prakash",
            "html_url": "https://github.com/pranav-prakash",
            "followers_url": "https://api.github.com/users/pranav-prakash/followers",
            "following_url": "https://api.github.com/users/pranav-prakash/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranav-prakash/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranav-prakash/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranav-prakash/subscriptions",
            "organizations_url": "https://api.github.com/users/pranav-prakash/orgs",
            "repos_url": "https://api.github.com/users/pranav-prakash/repos",
            "events_url": "https://api.github.com/users/pranav-prakash/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranav-prakash/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-03-17T18:58:29Z",
        "updated_at": "2020-03-17T23:58:16Z",
        "author_association": "CONTRIBUTOR",
        "body": "Yes this is possible, although the version of `calibrate.py`/`quantize.py` upstream doesn't properly implement static quantization. Take a look at my [fork](https://github.com/pranav-prakash/onnxruntime-riscv/tree/systolic/systolic_runner/quantization) which extends their scripts to handle full-static quantization.\r\n\r\nThe particular change relevant in this case was modifying the `_quantize_bias` function so that inputs are looked up in the `quantization_params` dict as a fallback, which is the cause of the error you ran into. The relevant diff is just changing line 903 to:\r\n```\r\n            if node.input[0] in self.quantized_value_map:\r\n                input_scale_name = self.quantized_value_map[\r\n                    node.input[0]].scale_name\r\n            elif node.input[0] in self.quantization_params:\r\n                _, input_scale_name, _, _, _ = self._get_quantization_params(\r\n                    node.input[0])\r\n            else:\r\n                raise ValueError(\r\n                    \"Expected {} to be in quantized value map for static quantization\"\r\n                    .format(node.input[0]))\r\n```\r\n(The fact that the previous condition does check `node.input[0] not in self.quantization_params` makes me think that this was an accidental omission. This is is a straightforward fix that someone should probably PR).\r\n\r\nI tested your above script with the `quantize.py` from my fork and it works fine there. Also as a side-note I think the order of your parameters in the the `quantization_params` dict is backwards. Doing `[np.uint8(128), np.float32(0.0)]` means a zero-point of 128 and a scale of 0 which is probably not what you want. \r\n\r\nIf you plan to use the `calibrate.py` script to automatically generate the scales, take note that my fork uses `int8` quantization, so you'll have to comment out the set of lines in [calibrate.py:222](https://github.com/pranav-prakash/onnxruntime-riscv/blob/systolic/systolic_runner/quantization/calibrate.py#L222) and uncomment the following set. \r\n\r\nYou'll also have to change back [quantize.py:1458](https://github.com/pranav-prakash/onnxruntime-riscv/blob/systolic/systolic_runner/quantization/quantize.py#L1458) to `symmetric_activation=False` and `symmetric_activation=False`.\r\n\r\nI've successfully tested this on various models including squeezenet and googlenet. Let me know if anything doesn't work though, since I've only really been focusing on our specific use case. \r\n\r\nAside—If there's interest I'd be happy to work on upstreaming the changes for `int8` support in the calibrate/quantizer scripts, since the changes made were pretty minor. (Onnxruntime itself does not support `int8` however, so it might not be of much use).",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/600243228/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/600500644",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3220#issuecomment-600500644",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3220",
        "id": 600500644,
        "node_id": "MDEyOklzc3VlQ29tbWVudDYwMDUwMDY0NA==",
        "user": {
            "login": "marph91",
            "id": 33229141,
            "node_id": "MDQ6VXNlcjMzMjI5MTQx",
            "avatar_url": "https://avatars.githubusercontent.com/u/33229141?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/marph91",
            "html_url": "https://github.com/marph91",
            "followers_url": "https://api.github.com/users/marph91/followers",
            "following_url": "https://api.github.com/users/marph91/following{/other_user}",
            "gists_url": "https://api.github.com/users/marph91/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/marph91/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/marph91/subscriptions",
            "organizations_url": "https://api.github.com/users/marph91/orgs",
            "repos_url": "https://api.github.com/users/marph91/repos",
            "events_url": "https://api.github.com/users/marph91/events{/privacy}",
            "received_events_url": "https://api.github.com/users/marph91/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-03-18T08:57:19Z",
        "updated_at": "2020-03-18T08:57:19Z",
        "author_association": "NONE",
        "body": "Thanks for your help! The script is now working and I can test a little bit around. If there is enough time, I will try to use the calibration script for the use case, too. In general it would be good to have the fix in `_quantize_bias` upstream, to prevent others to have this issue.\r\n\r\nAbout the parameters, you are right. Somehow the chosen values in the tutorial, led me to the wrong assumption that scale is the first parameter.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/600500644/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]