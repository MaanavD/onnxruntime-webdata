[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/624464802",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3802#issuecomment-624464802",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3802",
        "id": 624464802,
        "node_id": "MDEyOklzc3VlQ29tbWVudDYyNDQ2NDgwMg==",
        "user": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-05-06T06:25:42Z",
        "updated_at": "2020-05-06T06:25:42Z",
        "author_association": "MEMBER",
        "body": "There are a few things that happen at load time which will require more memory than the model size. \r\n\r\nTwo main ones are:\r\n\r\nWhen model optimization runs to do things like constant folding it may create new initializers to replace nodes. Any redundant initializers will be removed at the end of that process, but memory usage will be higher while it's running. You could try disabling the optimizers to see if that helps.\r\n\r\ne.g.\r\n    so = ort.SessionOptions\r\n    so.graph_optimization_level = ort.GraphOptimizationLevel.ORT_DISABLE_ALL\r\n    sess = ort.InferenceSession(model_path, so)\r\n\r\nAdditionally the initializers (i.e. weights) from the model file's protobuf format are converted to the ORT in-memory format. After the conversion the original initializers from the protobuf are freed, but until that point you'll have roughly double the size of the initializers in memory. \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/624464802/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/624728906",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3802#issuecomment-624728906",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3802",
        "id": 624728906,
        "node_id": "MDEyOklzc3VlQ29tbWVudDYyNDcyODkwNg==",
        "user": {
            "login": "do-van-long",
            "id": 62899677,
            "node_id": "MDQ6VXNlcjYyODk5Njc3",
            "avatar_url": "https://avatars.githubusercontent.com/u/62899677?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/do-van-long",
            "html_url": "https://github.com/do-van-long",
            "followers_url": "https://api.github.com/users/do-van-long/followers",
            "following_url": "https://api.github.com/users/do-van-long/following{/other_user}",
            "gists_url": "https://api.github.com/users/do-van-long/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/do-van-long/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/do-van-long/subscriptions",
            "organizations_url": "https://api.github.com/users/do-van-long/orgs",
            "repos_url": "https://api.github.com/users/do-van-long/repos",
            "events_url": "https://api.github.com/users/do-van-long/events{/privacy}",
            "received_events_url": "https://api.github.com/users/do-van-long/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-05-06T15:46:46Z",
        "updated_at": "2020-05-06T15:46:46Z",
        "author_association": "NONE",
        "body": "Thanks @skottmckay for your clarification. It helps me a bit when initializing an ORT session but it still uses about GB memory (for centerface.onnx model of 7MB). Luckily, the session is initialized successfully without using SWAP memory.\r\n\r\nI have also tried to save an optimized version by adding this line:\r\n`so.optimized_model_filepath = optimized_centerface.onnx`\r\n\r\nAfter initializing the session, an optimized version is saved. However, I could not start a session with the optimized model (onnx.checker.check_model call was successful). This line\r\n`sess = ort.InferenceSession('optimized_centerface.onnx')`\r\nproduced error \"Fatal error: TRTKernel_0 is not a registered function/op\".\r\n\r\nHow can I use the optimized model? Or is there any way to start an ORT session faster?\r\n\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/624728906/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/624933893",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3802#issuecomment-624933893",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3802",
        "id": 624933893,
        "node_id": "MDEyOklzc3VlQ29tbWVudDYyNDkzMzg5Mw==",
        "user": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-05-06T22:58:49Z",
        "updated_at": "2020-05-06T22:58:49Z",
        "author_association": "MEMBER",
        "body": "TRTKernel_0 is a fused subgraph created by TensorRT. You haven't mentioned building with or enabling the TensorRT execution provider anywhere though, and without doing that there shouldn't (afaik) be a way to get a node like that in the optimized graph. \r\n\r\nAre you actually using the TensorRT execution provider? ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/624933893/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/653950956",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3802#issuecomment-653950956",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3802",
        "id": 653950956,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY1Mzk1MDk1Ng==",
        "user": {
            "login": "stale[bot]",
            "id": 26384082,
            "node_id": "MDM6Qm90MjYzODQwODI=",
            "avatar_url": "https://avatars.githubusercontent.com/in/1724?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stale%5Bbot%5D",
            "html_url": "https://github.com/apps/stale",
            "followers_url": "https://api.github.com/users/stale%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/stale%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stale%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/stale%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/stale%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/stale%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stale%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "created_at": "2020-07-05T23:10:57Z",
        "updated_at": "2020-07-05T23:10:57Z",
        "author_association": "NONE",
        "body": "This issue has been automatically marked as stale due to inactivity and will be closed in 7 days if no further activity occurs. If further support is needed, please provide an update and/or more details.\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/653950956/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/657322847",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3802#issuecomment-657322847",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3802",
        "id": 657322847,
        "node_id": "MDEyOklzc3VlQ29tbWVudDY1NzMyMjg0Nw==",
        "user": {
            "login": "stale[bot]",
            "id": 26384082,
            "node_id": "MDM6Qm90MjYzODQwODI=",
            "avatar_url": "https://avatars.githubusercontent.com/in/1724?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stale%5Bbot%5D",
            "html_url": "https://github.com/apps/stale",
            "followers_url": "https://api.github.com/users/stale%5Bbot%5D/followers",
            "following_url": "https://api.github.com/users/stale%5Bbot%5D/following{/other_user}",
            "gists_url": "https://api.github.com/users/stale%5Bbot%5D/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stale%5Bbot%5D/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stale%5Bbot%5D/subscriptions",
            "organizations_url": "https://api.github.com/users/stale%5Bbot%5D/orgs",
            "repos_url": "https://api.github.com/users/stale%5Bbot%5D/repos",
            "events_url": "https://api.github.com/users/stale%5Bbot%5D/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stale%5Bbot%5D/received_events",
            "type": "Bot",
            "site_admin": false
        },
        "created_at": "2020-07-13T02:15:38Z",
        "updated_at": "2020-07-13T02:15:38Z",
        "author_association": "NONE",
        "body": "This issue has been automatically closed due to inactivity. Please reactivate if further support is needed.\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/657322847/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/725562636",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3802#issuecomment-725562636",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3802",
        "id": 725562636,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNTU2MjYzNg==",
        "user": {
            "login": "BharathJaina",
            "id": 15356264,
            "node_id": "MDQ6VXNlcjE1MzU2MjY0",
            "avatar_url": "https://avatars.githubusercontent.com/u/15356264?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/BharathJaina",
            "html_url": "https://github.com/BharathJaina",
            "followers_url": "https://api.github.com/users/BharathJaina/followers",
            "following_url": "https://api.github.com/users/BharathJaina/following{/other_user}",
            "gists_url": "https://api.github.com/users/BharathJaina/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/BharathJaina/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/BharathJaina/subscriptions",
            "organizations_url": "https://api.github.com/users/BharathJaina/orgs",
            "repos_url": "https://api.github.com/users/BharathJaina/repos",
            "events_url": "https://api.github.com/users/BharathJaina/events{/privacy}",
            "received_events_url": "https://api.github.com/users/BharathJaina/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-11T17:40:41Z",
        "updated_at": "2020-11-11T17:40:41Z",
        "author_association": "NONE",
        "body": "Hi @skottmckay,\r\n\r\nI'm using **resnet50v2** model and optimized with the tensorrt and when I'm loading the same file, it is failing with the following error: \r\n\"**_Fatal error: TRTKernel_graph_resnet50v2_0 is not a registered function/op_**\" \r\nand with **mobilenet**, error:\r\n\"**_Fatal error: TRTKernel_graph_mobilenet_1.00_224_0 is not a registered function/op_**\"\r\n\r\nBelow is the script to generat the optimized file:\r\n```\r\n    sess_options = onnxruntime.SessionOptions()\r\n    sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_DISABLE_ALL #Varying with all the options\r\n    sess_options.execution_mode = onnxruntime.ExecutionMode.ORT_SEQUENTIAL\r\n    sess_options.optimized_model_filepath = model_file\r\n    sess_options.intra_op_num_threads = 2\r\n    session = onnxruntime.InferenceSession(original_model, sess_options, providers=\"TensorrtExecutionProvider\")\r\n\r\n#Loading new session\r\n   session2 = onnxruntime.InferenceSession(model_file, sess_options, providers=\"TensorrtExecutionProvider\")\r\n```\r\n\r\nFor CPU and CUDA as the execution providers, they are working, but isn't the case with TensorRT",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/725562636/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/725834133",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3802#issuecomment-725834133",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3802",
        "id": 725834133,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNTgzNDEzMw==",
        "user": {
            "login": "skottmckay",
            "id": 979079,
            "node_id": "MDQ6VXNlcjk3OTA3OQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/979079?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skottmckay",
            "html_url": "https://github.com/skottmckay",
            "followers_url": "https://api.github.com/users/skottmckay/followers",
            "following_url": "https://api.github.com/users/skottmckay/following{/other_user}",
            "gists_url": "https://api.github.com/users/skottmckay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skottmckay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skottmckay/subscriptions",
            "organizations_url": "https://api.github.com/users/skottmckay/orgs",
            "repos_url": "https://api.github.com/users/skottmckay/repos",
            "events_url": "https://api.github.com/users/skottmckay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skottmckay/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-12T04:46:48Z",
        "updated_at": "2020-11-12T04:46:48Z",
        "author_association": "MEMBER",
        "body": "TensorRT needs to compile nodes at runtime. We probably shouldn't allow saving an optimized model if TensorRT compiled nodes as it won't be able to be loaded (we don't have a mechanism to save the compiled functions - just the node information).\r\n\r\nIf you want to use an EP that compiles nodes the best you can do is to optimize the model using ORT_ENABLE_BASIC with just the ORT CPU EP enabled. That will do things like constant folding but not use internal operators that may limit the nodes TensorRT could take. At runtime you can load that optimized mode with the TensorRT enabled and optimization set to ORT_ENABLE_ALL.\r\n\r\nWhether that helps with memory usage is unknown. I don't know how large the cost of TensorRT compiling nodes is. I would expect it to be significant though",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/725834133/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/726096218",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/3802#issuecomment-726096218",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/3802",
        "id": 726096218,
        "node_id": "MDEyOklzc3VlQ29tbWVudDcyNjA5NjIxOA==",
        "user": {
            "login": "BharathJaina",
            "id": 15356264,
            "node_id": "MDQ6VXNlcjE1MzU2MjY0",
            "avatar_url": "https://avatars.githubusercontent.com/u/15356264?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/BharathJaina",
            "html_url": "https://github.com/BharathJaina",
            "followers_url": "https://api.github.com/users/BharathJaina/followers",
            "following_url": "https://api.github.com/users/BharathJaina/following{/other_user}",
            "gists_url": "https://api.github.com/users/BharathJaina/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/BharathJaina/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/BharathJaina/subscriptions",
            "organizations_url": "https://api.github.com/users/BharathJaina/orgs",
            "repos_url": "https://api.github.com/users/BharathJaina/repos",
            "events_url": "https://api.github.com/users/BharathJaina/events{/privacy}",
            "received_events_url": "https://api.github.com/users/BharathJaina/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-11-12T14:01:31Z",
        "updated_at": "2020-11-12T14:01:31Z",
        "author_association": "NONE",
        "body": "Thanks for confirming. The Load time turns around, ~15s. But at the same time, inference time for 1st input set is ~9s, normally[or from second input set in the same session] it is 3/4**ms**.  \r\nAm I missing anything?",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/726096218/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]