[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/746204220",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/6060#issuecomment-746204220",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/6060",
        "id": 746204220,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc0NjIwNDIyMA==",
        "user": {
            "login": "zirui",
            "id": 2908628,
            "node_id": "MDQ6VXNlcjI5MDg2Mjg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2908628?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zirui",
            "html_url": "https://github.com/zirui",
            "followers_url": "https://api.github.com/users/zirui/followers",
            "following_url": "https://api.github.com/users/zirui/following{/other_user}",
            "gists_url": "https://api.github.com/users/zirui/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zirui/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zirui/subscriptions",
            "organizations_url": "https://api.github.com/users/zirui/orgs",
            "repos_url": "https://api.github.com/users/zirui/repos",
            "events_url": "https://api.github.com/users/zirui/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zirui/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2020-12-16T12:18:56Z",
        "updated_at": "2020-12-16T12:19:17Z",
        "author_association": "NONE",
        "body": "the `different output` problem was caused by my silly mistake(missed used pytorch models), and i have solved it.\r\nso i changed the title of this issue",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/746204220/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/756619837",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/6060#issuecomment-756619837",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/6060",
        "id": 756619837,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc1NjYxOTgzNw==",
        "user": {
            "login": "tianleiwu",
            "id": 30328909,
            "node_id": "MDQ6VXNlcjMwMzI4OTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30328909?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tianleiwu",
            "html_url": "https://github.com/tianleiwu",
            "followers_url": "https://api.github.com/users/tianleiwu/followers",
            "following_url": "https://api.github.com/users/tianleiwu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tianleiwu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tianleiwu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tianleiwu/subscriptions",
            "organizations_url": "https://api.github.com/users/tianleiwu/orgs",
            "repos_url": "https://api.github.com/users/tianleiwu/repos",
            "events_url": "https://api.github.com/users/tianleiwu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tianleiwu/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-01-08T08:23:39Z",
        "updated_at": "2021-01-08T08:23:39Z",
        "author_association": "MEMBER",
        "body": "@zirui, I think the cause is M40 does not support FP16. \r\n\r\nYou might try fp16 on P100, V100, T4 or newer GPUs. \r\n\r\n![image](https://user-images.githubusercontent.com/30328909/103990640-6c367180-5146-11eb-8ed1-95218efc8149.png)\r\nIf you look at spec of M40, it does not mention fp16. I think calculation will be done in FP32, and when model is FP16, there will be extra data conversion between FP32 and FP16. So, it is expected that FP16 is slower than FP32 in M40.\r\n\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/756619837/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/757185155",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/6060#issuecomment-757185155",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/6060",
        "id": 757185155,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc1NzE4NTE1NQ==",
        "user": {
            "login": "zirui",
            "id": 2908628,
            "node_id": "MDQ6VXNlcjI5MDg2Mjg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2908628?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zirui",
            "html_url": "https://github.com/zirui",
            "followers_url": "https://api.github.com/users/zirui/followers",
            "following_url": "https://api.github.com/users/zirui/following{/other_user}",
            "gists_url": "https://api.github.com/users/zirui/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zirui/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zirui/subscriptions",
            "organizations_url": "https://api.github.com/users/zirui/orgs",
            "repos_url": "https://api.github.com/users/zirui/repos",
            "events_url": "https://api.github.com/users/zirui/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zirui/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-01-09T13:24:39Z",
        "updated_at": "2021-01-11T01:06:35Z",
        "author_association": "NONE",
        "body": "> @zirui, I think the cause is M40 does not support FP16.\r\n> \r\n> You might try fp16 on P100, V100, T4 or newer GPUs.\r\n> \r\n> ![image](https://user-images.githubusercontent.com/30328909/103990640-6c367180-5146-11eb-8ed1-95218efc8149.png)\r\n> If you look at spec of M40, it does not mention fp16. I think calculation will be done in FP32, and when model is FP16, there will be extra data conversion between FP32 and FP16. So, it is expected that FP16 is slower than FP32 in M40.\r\n\r\nthanks @tianleiwu,\r\nI checked the gpu of my test machine, actually it is Tesla P40(i have another machine with M40, i confused them), and it seems that  neither M40 nor P40 support fp16,\r\ni will close this issue\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/757185155/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]