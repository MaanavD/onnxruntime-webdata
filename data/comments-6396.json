[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/778580392",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/6396#issuecomment-778580392",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/6396",
        "id": 778580392,
        "node_id": "MDEyOklzc3VlQ29tbWVudDc3ODU4MDM5Mg==",
        "user": {
            "login": "yufenglee",
            "id": 30486710,
            "node_id": "MDQ6VXNlcjMwNDg2NzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/30486710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yufenglee",
            "html_url": "https://github.com/yufenglee",
            "followers_url": "https://api.github.com/users/yufenglee/followers",
            "following_url": "https://api.github.com/users/yufenglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yufenglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yufenglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yufenglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yufenglee/orgs",
            "repos_url": "https://api.github.com/users/yufenglee/repos",
            "events_url": "https://api.github.com/users/yufenglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yufenglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-02-13T08:00:57Z",
        "updated_at": "2021-02-13T08:00:57Z",
        "author_association": "MEMBER",
        "body": "1. How to get dimension or shape of inputs in onnxruntime/core/providers/cpu/math/matmul.cc\r\n\r\nWhat changes need to done in matmul.cc code to get all these information of input\r\n_**The tensor has member function Shape, which can get the shape information. Is it what you are asking about? Alternatively, you can call onnx function https://github.com/onnx/onnx/blob/5e8bc2c6c6079eef8de10c3743fb67a8a364d885/onnx/shape_inference.py#L34 . After that, you should be able to get the shape info from the shape info from the field https://github.com/onnx/onnx/blob/5e8bc2c6c6079eef8de10c3743fb67a8a364d885/onnx/onnx.proto#L174**_\r\n\r\n2. What change need to implement in matmul.cc to use GemmBatch, like in TensorFlow by default BatchMatmul is supported as sperate operation.\r\nORT has a custom op [FusedMatMul](https://github.com/microsoft/onnxruntime/blob/df3d6bad5fccee4c161a1c68338dd3d97ccf8243/onnxruntime/core/graph/contrib_ops/contrib_defs.cc#L1620), which supports alpha and transpose. Even though it doesn't have support of beta *C, it can support most of the practical cases. You may extend it if you need supports of beta*C. \r\n3. how to integrate custom or third party library with it instead of mlas, such as cblas to perform matmul operation\r\nwe ever had support of mklml, and removed it because mlas has better or at least on par performance with mklml and its size is very small. cblas is quite slow. What library do you want to integrate? ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/778580392/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]