[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/801549017",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7044#issuecomment-801549017",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7044",
        "id": 801549017,
        "node_id": "MDEyOklzc3VlQ29tbWVudDgwMTU0OTAxNw==",
        "user": {
            "login": "Craigacp",
            "id": 729696,
            "node_id": "MDQ6VXNlcjcyOTY5Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/729696?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Craigacp",
            "html_url": "https://github.com/Craigacp",
            "followers_url": "https://api.github.com/users/Craigacp/followers",
            "following_url": "https://api.github.com/users/Craigacp/following{/other_user}",
            "gists_url": "https://api.github.com/users/Craigacp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Craigacp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Craigacp/subscriptions",
            "organizations_url": "https://api.github.com/users/Craigacp/orgs",
            "repos_url": "https://api.github.com/users/Craigacp/repos",
            "events_url": "https://api.github.com/users/Craigacp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Craigacp/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-03-18T01:30:50Z",
        "updated_at": "2021-03-18T01:30:50Z",
        "author_association": "CONTRIBUTOR",
        "body": "The Java GPU artifact is linked against CUDA which means it triggers a linker error when it fails to resolve some of the symbols when CUDA isn't available. I think the ORT team are considering making the CUDA execution provider packaged into a separate library, which could then be dependently loaded if CUDA is available and if it's not it would throw a different linker error which could be caught and fall back to CPU execution. Checking to see if the GPU device is available when CUDA is present is a little trickier, but the CUDA execution provider itself might make that check.\r\n\r\nHowever at the moment the Java API cannot load any execution providers which are packaged in separate libraries due to a hard coded path in the ORT library loader and a lack of an appropriate entry point for Java, so we'd need to fix that first (tracked in #6553). ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/801549017/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/801756394",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7044#issuecomment-801756394",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7044",
        "id": 801756394,
        "node_id": "MDEyOklzc3VlQ29tbWVudDgwMTc1NjM5NA==",
        "user": {
            "login": "thhart",
            "id": 2632538,
            "node_id": "MDQ6VXNlcjI2MzI1Mzg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2632538?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/thhart",
            "html_url": "https://github.com/thhart",
            "followers_url": "https://api.github.com/users/thhart/followers",
            "following_url": "https://api.github.com/users/thhart/following{/other_user}",
            "gists_url": "https://api.github.com/users/thhart/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/thhart/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/thhart/subscriptions",
            "organizations_url": "https://api.github.com/users/thhart/orgs",
            "repos_url": "https://api.github.com/users/thhart/repos",
            "events_url": "https://api.github.com/users/thhart/events{/privacy}",
            "received_events_url": "https://api.github.com/users/thhart/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-03-18T09:08:17Z",
        "updated_at": "2021-03-18T09:08:17Z",
        "author_association": "NONE",
        "body": "Thanks for picking up, meanwhile I will separate the libraries and make a GPU detector before executing Java. Just an idea, maybe it is wise to introduce an environment variable ONNX_PROVIDER_SELECTOR = CPU | GPU | AUTOMATIC to force the library loading and device detection, AUTOMATIC support might be postponed then until fully implemented.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/801756394/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/801931726",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7044#issuecomment-801931726",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7044",
        "id": 801931726,
        "node_id": "MDEyOklzc3VlQ29tbWVudDgwMTkzMTcyNg==",
        "user": {
            "login": "Craigacp",
            "id": 729696,
            "node_id": "MDQ6VXNlcjcyOTY5Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/729696?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Craigacp",
            "html_url": "https://github.com/Craigacp",
            "followers_url": "https://api.github.com/users/Craigacp/followers",
            "following_url": "https://api.github.com/users/Craigacp/following{/other_user}",
            "gists_url": "https://api.github.com/users/Craigacp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Craigacp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Craigacp/subscriptions",
            "organizations_url": "https://api.github.com/users/Craigacp/orgs",
            "repos_url": "https://api.github.com/users/Craigacp/repos",
            "events_url": "https://api.github.com/users/Craigacp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Craigacp/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-03-18T13:36:40Z",
        "updated_at": "2021-03-18T13:36:54Z",
        "author_association": "CONTRIBUTOR",
        "body": "We can't do that at the moment without doubling the size of the jar as it would require shipping both a GPU and non-GPU native library in the same jar. If CUDA is broken out into a separate provider then as I mentioned above a bunch of work needs to happen before the Java binding will support GPUs again.\r\n\r\nHowever you can currently control this by overriding the library loading, if you have the native libraries unpacked on disk somewhere you can tell the JVM to load either the CPU or GPU native libraries (keeping the same jar files) by setting the appropriate `onnxruntime.native.{onnxruntime,onnxruntime4j_jni}.path` variable on startup. The library loading logic is here - https://github.com/microsoft/onnxruntime/blob/master/java/src/main/java/ai/onnxruntime/OnnxRuntime.java#L156.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/801931726/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/858184726",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7044#issuecomment-858184726",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7044",
        "id": 858184726,
        "node_id": "MDEyOklzc3VlQ29tbWVudDg1ODE4NDcyNg==",
        "user": {
            "login": "Craigacp",
            "id": 729696,
            "node_id": "MDQ6VXNlcjcyOTY5Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/729696?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Craigacp",
            "html_url": "https://github.com/Craigacp",
            "followers_url": "https://api.github.com/users/Craigacp/followers",
            "following_url": "https://api.github.com/users/Craigacp/following{/other_user}",
            "gists_url": "https://api.github.com/users/Craigacp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Craigacp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Craigacp/subscriptions",
            "organizations_url": "https://api.github.com/users/Craigacp/orgs",
            "repos_url": "https://api.github.com/users/Craigacp/repos",
            "events_url": "https://api.github.com/users/Craigacp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Craigacp/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-06-10T00:14:38Z",
        "updated_at": "2021-06-10T00:14:38Z",
        "author_association": "CONTRIBUTOR",
        "body": "Note for the fix in #8013 you'll need to detect if you have a GPU manually (one method could be shell calling out to see if `nvidia-smi` is present, or if `lsmod | grep nvidia` returns anything, but it's going to be platform dependent) and then only load the CUDA provider if you do, but at least you'll be able to use the onnxruntime_gpu jar everywhere.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/858184726/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]