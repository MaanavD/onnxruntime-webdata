[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/829061022",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7499#issuecomment-829061022",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7499",
        "id": 829061022,
        "node_id": "MDEyOklzc3VlQ29tbWVudDgyOTA2MTAyMg==",
        "user": {
            "login": "KyloEntro",
            "id": 64692412,
            "node_id": "MDQ6VXNlcjY0NjkyNDEy",
            "avatar_url": "https://avatars.githubusercontent.com/u/64692412?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/KyloEntro",
            "html_url": "https://github.com/KyloEntro",
            "followers_url": "https://api.github.com/users/KyloEntro/followers",
            "following_url": "https://api.github.com/users/KyloEntro/following{/other_user}",
            "gists_url": "https://api.github.com/users/KyloEntro/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/KyloEntro/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/KyloEntro/subscriptions",
            "organizations_url": "https://api.github.com/users/KyloEntro/orgs",
            "repos_url": "https://api.github.com/users/KyloEntro/repos",
            "events_url": "https://api.github.com/users/KyloEntro/events{/privacy}",
            "received_events_url": "https://api.github.com/users/KyloEntro/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-04-29T08:56:17Z",
        "updated_at": "2021-04-29T08:56:17Z",
        "author_association": "NONE",
        "body": "By using TensorRT EP, TensorRT will optimize the onnx model for your device. If caching is not enabled, it will do this step each time. \r\nYou can force to make a cache by setting an environment variable. export ORT_TENSORRT_ENGINE_CACHE_ENABLE=1\r\n\r\nPlease read this post : https://www.onnxruntime.ai/docs/reference/execution-providers/TensorRT-ExecutionProvider.html#configuring-environment-variables",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/829061022/reactions",
            "total_count": 2,
            "+1": 2,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/829190323",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7499#issuecomment-829190323",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7499",
        "id": 829190323,
        "node_id": "MDEyOklzc3VlQ29tbWVudDgyOTE5MDMyMw==",
        "user": {
            "login": "lipo5476",
            "id": 22189633,
            "node_id": "MDQ6VXNlcjIyMTg5NjMz",
            "avatar_url": "https://avatars.githubusercontent.com/u/22189633?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/lipo5476",
            "html_url": "https://github.com/lipo5476",
            "followers_url": "https://api.github.com/users/lipo5476/followers",
            "following_url": "https://api.github.com/users/lipo5476/following{/other_user}",
            "gists_url": "https://api.github.com/users/lipo5476/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/lipo5476/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/lipo5476/subscriptions",
            "organizations_url": "https://api.github.com/users/lipo5476/orgs",
            "repos_url": "https://api.github.com/users/lipo5476/repos",
            "events_url": "https://api.github.com/users/lipo5476/events{/privacy}",
            "received_events_url": "https://api.github.com/users/lipo5476/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-04-29T12:17:40Z",
        "updated_at": "2021-04-29T12:17:40Z",
        "author_association": "NONE",
        "body": "Hi KyloEntro,\r\n\r\nThat looks great, I was able to save the TensorRT engine file and profile. What is necessary to force ONNXRT to load the cached engine file instead of ONNX model?\r\n\r\nThank you\r\nMarek",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/829190323/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/829199699",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7499#issuecomment-829199699",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7499",
        "id": 829199699,
        "node_id": "MDEyOklzc3VlQ29tbWVudDgyOTE5OTY5OQ==",
        "user": {
            "login": "KyloEntro",
            "id": 64692412,
            "node_id": "MDQ6VXNlcjY0NjkyNDEy",
            "avatar_url": "https://avatars.githubusercontent.com/u/64692412?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/KyloEntro",
            "html_url": "https://github.com/KyloEntro",
            "followers_url": "https://api.github.com/users/KyloEntro/followers",
            "following_url": "https://api.github.com/users/KyloEntro/following{/other_user}",
            "gists_url": "https://api.github.com/users/KyloEntro/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/KyloEntro/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/KyloEntro/subscriptions",
            "organizations_url": "https://api.github.com/users/KyloEntro/orgs",
            "repos_url": "https://api.github.com/users/KyloEntro/repos",
            "events_url": "https://api.github.com/users/KyloEntro/events{/privacy}",
            "received_events_url": "https://api.github.com/users/KyloEntro/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-04-29T12:32:34Z",
        "updated_at": "2021-04-29T12:32:34Z",
        "author_association": "NONE",
        "body": "Because Nvidia TensorRT use its own format to do inference by including many optimisation depends on your device.\r\n\r\nTensorRT need to parse your ONNX model to \"understand\" how your model is built and convert to something it know. This step is very time consuming and optimized version is only compatible with your device, if you move the .engine file to another device, it will not work. \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/829199699/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/829230740",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7499#issuecomment-829230740",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7499",
        "id": 829230740,
        "node_id": "MDEyOklzc3VlQ29tbWVudDgyOTIzMDc0MA==",
        "user": {
            "login": "lipo5476",
            "id": 22189633,
            "node_id": "MDQ6VXNlcjIyMTg5NjMz",
            "avatar_url": "https://avatars.githubusercontent.com/u/22189633?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/lipo5476",
            "html_url": "https://github.com/lipo5476",
            "followers_url": "https://api.github.com/users/lipo5476/followers",
            "following_url": "https://api.github.com/users/lipo5476/following{/other_user}",
            "gists_url": "https://api.github.com/users/lipo5476/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/lipo5476/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/lipo5476/subscriptions",
            "organizations_url": "https://api.github.com/users/lipo5476/orgs",
            "repos_url": "https://api.github.com/users/lipo5476/repos",
            "events_url": "https://api.github.com/users/lipo5476/events{/privacy}",
            "received_events_url": "https://api.github.com/users/lipo5476/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-04-29T13:18:52Z",
        "updated_at": "2021-04-29T13:18:52Z",
        "author_association": "NONE",
        "body": "Thank you, I fully understand that.\r\nI was able to improve the load of model in memory from 50 seconds to 7-10 seconds which is great.\r\nThanks again",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/829230740/reactions",
            "total_count": 2,
            "+1": 2,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/858675482",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/7499#issuecomment-858675482",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/7499",
        "id": 858675482,
        "node_id": "MDEyOklzc3VlQ29tbWVudDg1ODY3NTQ4Mg==",
        "user": {
            "login": "lipo5476",
            "id": 22189633,
            "node_id": "MDQ6VXNlcjIyMTg5NjMz",
            "avatar_url": "https://avatars.githubusercontent.com/u/22189633?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/lipo5476",
            "html_url": "https://github.com/lipo5476",
            "followers_url": "https://api.github.com/users/lipo5476/followers",
            "following_url": "https://api.github.com/users/lipo5476/following{/other_user}",
            "gists_url": "https://api.github.com/users/lipo5476/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/lipo5476/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/lipo5476/subscriptions",
            "organizations_url": "https://api.github.com/users/lipo5476/orgs",
            "repos_url": "https://api.github.com/users/lipo5476/repos",
            "events_url": "https://api.github.com/users/lipo5476/events{/privacy}",
            "received_events_url": "https://api.github.com/users/lipo5476/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-06-10T14:33:35Z",
        "updated_at": "2021-06-10T14:33:35Z",
        "author_association": "NONE",
        "body": "Hi @KyloEntro,\r\n\r\none question to tensorRT engine file caching, is there version or compatibility check between the ONNX model and tensorRT engine file?\r\nI mean, will it recognize if the ONNX model has changed and the TRT engine file is generated for the old version of ONNX model?\r\n\r\nThanks in advance.\r\nRegards",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/858675482/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]