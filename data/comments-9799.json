[
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/973186663",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9799#issuecomment-973186663",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9799",
        "id": 973186663,
        "node_id": "IC_kwDOCVq1mM46AaZn",
        "user": {
            "login": "hariharans29",
            "id": 9969784,
            "node_id": "MDQ6VXNlcjk5Njk3ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9969784?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hariharans29",
            "html_url": "https://github.com/hariharans29",
            "followers_url": "https://api.github.com/users/hariharans29/followers",
            "following_url": "https://api.github.com/users/hariharans29/following{/other_user}",
            "gists_url": "https://api.github.com/users/hariharans29/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hariharans29/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hariharans29/subscriptions",
            "organizations_url": "https://api.github.com/users/hariharans29/orgs",
            "repos_url": "https://api.github.com/users/hariharans29/repos",
            "events_url": "https://api.github.com/users/hariharans29/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hariharans29/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-18T19:27:34Z",
        "updated_at": "2021-11-18T19:27:34Z",
        "author_association": "MEMBER",
        "body": "Thanks for the detailed and well articulated report.\r\n\r\nWe will have to take a look into this. Nothing jumps to my mind on first thought. \r\n\r\nSome follow-up questions:\r\n\r\n1) What happens if you move away from the OrtValue setup (i.e.) just feed vanilla numpy arrays to the `session.run()` ? This will tell us if the issue is with the runtime itself or if there is something going on at OrtValue creation time.\r\n\r\n2) Is this the only model you are able to repro this behavior with ? Are you able to repro this with a model without Identity in it ?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/973186663/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/973641602",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9799#issuecomment-973641602",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9799",
        "id": 973641602,
        "node_id": "IC_kwDOCVq1mM46CJeC",
        "user": {
            "login": "hariharans29",
            "id": 9969784,
            "node_id": "MDQ6VXNlcjk5Njk3ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9969784?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hariharans29",
            "html_url": "https://github.com/hariharans29",
            "followers_url": "https://api.github.com/users/hariharans29/followers",
            "following_url": "https://api.github.com/users/hariharans29/following{/other_user}",
            "gists_url": "https://api.github.com/users/hariharans29/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hariharans29/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hariharans29/subscriptions",
            "organizations_url": "https://api.github.com/users/hariharans29/orgs",
            "repos_url": "https://api.github.com/users/hariharans29/repos",
            "events_url": "https://api.github.com/users/hariharans29/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hariharans29/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-19T01:21:14Z",
        "updated_at": "2021-11-19T01:21:14Z",
        "author_association": "MEMBER",
        "body": "I tried building the latest master from this commit: 76715ad52560d762f1cfafb2202c962e17d85c44\r\n\r\nAnd I couldn't repro this even after running the repro script a lot of times:\r\n![image](https://user-images.githubusercontent.com/9969784/142527147-69087319-b5eb-4e34-af39-1d658ed1bdee.png)\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/973641602/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/973655679",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9799#issuecomment-973655679",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9799",
        "id": 973655679,
        "node_id": "IC_kwDOCVq1mM46CM5_",
        "user": {
            "login": "UlrichFreitag",
            "id": 62822473,
            "node_id": "MDQ6VXNlcjYyODIyNDcz",
            "avatar_url": "https://avatars.githubusercontent.com/u/62822473?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/UlrichFreitag",
            "html_url": "https://github.com/UlrichFreitag",
            "followers_url": "https://api.github.com/users/UlrichFreitag/followers",
            "following_url": "https://api.github.com/users/UlrichFreitag/following{/other_user}",
            "gists_url": "https://api.github.com/users/UlrichFreitag/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/UlrichFreitag/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/UlrichFreitag/subscriptions",
            "organizations_url": "https://api.github.com/users/UlrichFreitag/orgs",
            "repos_url": "https://api.github.com/users/UlrichFreitag/repos",
            "events_url": "https://api.github.com/users/UlrichFreitag/events{/privacy}",
            "received_events_url": "https://api.github.com/users/UlrichFreitag/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-19T01:55:25Z",
        "updated_at": "2021-11-19T02:17:01Z",
        "author_association": "NONE",
        "body": ">     1. What happens if you move away from the OrtValue setup (i.e.) just feed vanilla numpy arrays to the `session.run()` ? This will tell us if the issue is with the runtime itself or if there is something going on at OrtValue creation time.\r\nNice! It worked just fine without the OrtValue setup! I have some questions then:\r\n1. I thought it was something mandatory when reading the doc? \r\n2. Am I really using the GPU with that?\r\n3.  What is the use of `ortvalue_from_numpy` in that case?\r\n\r\nThe function `onnxrt_inference` is now:\r\n```python\r\ndef onnxrt_inference(ort_session, arr, device):\r\n    upstreams_onnxrt = {  # removal of the unused inputs\r\n        \"input\": arr # ort.OrtValue.ortvalue_from_numpy(arr, device, ONNXRT_DEVICE_IDX)\r\n    }\r\n    outs = ort_session.run(\r\n        input_feed=upstreams_onnxrt,\r\n        output_names=OUTPUT_NAMES)\r\n    assert len(outs) == 1\r\n    return outs[0]\r\n```\r\n\r\n>     2. Is this the only model you are able to repro this behavior with ? Are you able to repro this with a model without Identity in it ?\r\nNo, I just created a minimal example. But I had the issues with bigger models. I really think the cause comes from the OrtValue setup as you suggested.\r\n\r\n\r\n> I tried building the latest master from this commit: [76715ad](https://github.com/microsoft/onnxruntime/commit/76715ad52560d762f1cfafb2202c962e17d85c44)\r\n> \r\n> And I couldn't repro this even after running the repro script a lot of times\r\n\r\nWeird! I just build/installed onnxruntime-gpu from this commit [76715ad](https://github.com/microsoft/onnxruntime/commit/76715ad52560d762f1cfafb2202c962e17d85c44) and I still can reproduce this issue :disappointed: - Can you reproduce it with onnxruntime-gpu 1.9.0 maybe?\r\n\r\nHowever! I noticed that for some reasons, I had to change the line 53 of `reproduce_bug_onnxrt_infer.py` from `    for seq_length in range(50):` to `    for seq_length in range(200):` to have some errors at one moment... Weirdly I couldn't reproduced it either for like one minute or two with just 50 seq_lengths... :man_shrugging:. The only difference is that my GPUs are under heavy load right now and that I removed the OrtValue setup before puting it back to test the original script against the new build (and I confirm again that using plain numpy array works very well)\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/973655679/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/973659899",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9799#issuecomment-973659899",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9799",
        "id": 973659899,
        "node_id": "IC_kwDOCVq1mM46CN77",
        "user": {
            "login": "UlrichFreitag",
            "id": 62822473,
            "node_id": "MDQ6VXNlcjYyODIyNDcz",
            "avatar_url": "https://avatars.githubusercontent.com/u/62822473?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/UlrichFreitag",
            "html_url": "https://github.com/UlrichFreitag",
            "followers_url": "https://api.github.com/users/UlrichFreitag/followers",
            "following_url": "https://api.github.com/users/UlrichFreitag/following{/other_user}",
            "gists_url": "https://api.github.com/users/UlrichFreitag/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/UlrichFreitag/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/UlrichFreitag/subscriptions",
            "organizations_url": "https://api.github.com/users/UlrichFreitag/orgs",
            "repos_url": "https://api.github.com/users/UlrichFreitag/repos",
            "events_url": "https://api.github.com/users/UlrichFreitag/events{/privacy}",
            "received_events_url": "https://api.github.com/users/UlrichFreitag/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-19T02:05:09Z",
        "updated_at": "2021-11-19T02:05:21Z",
        "author_association": "NONE",
        "body": "Btw, since there is no Dockerfile to create plain whl file from master for Python 3.9, I created this Dockerfile inspired from your [CUDA Dockerfile](https://github.com/microsoft/onnxruntime/blob/master/dockerfiles/Dockerfile.cuda). I'm sharing this, because maybe I did something wrong? I doubt it since I can reproduce the bug from 1.9.0 with an official build... But we never know.\r\n\r\n I added the RTX 2070 (Turing), and RTX 3090 (Ampere) support by adding `75;80;86` to `CMAKE_CUDA_ARCHITECTURES`\r\n\r\n```\r\nFROM nvcr.io/nvidia/cuda:11.4.1-cudnn8-devel-ubuntu20.04\r\n\r\nENV PATH /usr/local/nvidia/bin:/usr/local/cuda/bin:${PATH}\r\n\r\nENV TZ=Europe/Paris\r\nRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone\r\n\r\nRUN DEBIAN_FRONTEND=\"noninteractive\" apt update && apt-get install -y software-properties-common\r\nRUN add-apt-repository ppa:deadsnakes/ppa && apt-get install -y python3.9 python3.9-dev python3-pip\r\nRUN pip install virtualenv\r\n\r\nENV VIRTUAL_ENV=/opt/virtualenv\r\nRUN virtualenv -p python3.9 $VIRTUAL_ENV\r\nENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\r\nRUN pip install numpy\r\n\r\nADD . /code\r\nRUN apt-get update && \\\r\n    apt-get install -y --no-install-recommends ca-certificates g++ gcc make git aria2 && \\\r\n    aria2c -q -d /tmp -o cmake-3.21.0-linux-x86_64.tar.gz https://github.com/Kitware/CMake/releases/download/v3.21.0/cmake-3.21.0-linux-x86_64.tar.gz && \\\r\n    tar -zxf /tmp/cmake-3.21.0-linux-x86_64.tar.gz --strip=1 -C /usr\r\nRUN cd /code && /bin/bash ./build.sh --skip_submodule_sync --cuda_home /usr/local/cuda --cudnn_home /usr/lib/x86_64-linux-gnu/ \\\r\n    --use_cuda --config Release --build_wheel --update --build --parallel --cmake_extra_defines ONNXRUNTIME_VERSION=$(cat ./VERSION_NUMBER) \\\r\n    'CMAKE_CUDA_ARCHITECTURES=37;50;52;60;70;75;80;86'\r\n```\r\n\r\nI just `docker cp` the wheel file after that to test it in my dev env for now.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/973659899/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/973664529",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9799#issuecomment-973664529",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9799",
        "id": 973664529,
        "node_id": "IC_kwDOCVq1mM46CPER",
        "user": {
            "login": "hariharans29",
            "id": 9969784,
            "node_id": "MDQ6VXNlcjk5Njk3ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9969784?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hariharans29",
            "html_url": "https://github.com/hariharans29",
            "followers_url": "https://api.github.com/users/hariharans29/followers",
            "following_url": "https://api.github.com/users/hariharans29/following{/other_user}",
            "gists_url": "https://api.github.com/users/hariharans29/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hariharans29/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hariharans29/subscriptions",
            "organizations_url": "https://api.github.com/users/hariharans29/orgs",
            "repos_url": "https://api.github.com/users/hariharans29/repos",
            "events_url": "https://api.github.com/users/hariharans29/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hariharans29/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-19T02:15:18Z",
        "updated_at": "2021-11-19T02:15:18Z",
        "author_association": "MEMBER",
        "body": "Spoke too soon.\r\n\r\nI forgot to mention that my repro attempt was on Windows, on Linux I am able to repro it :(\r\n\r\n![image](https://user-images.githubusercontent.com/9969784/142552604-1cc70156-b6d0-4f0d-8931-b493c78ec8a0.png)\r\n\r\nSo, I guess this doesn't have anything to do with how you built ORT (the Dockerfile comment)\r\n\r\nAnswering your other questions:\r\n\r\nI thought it was something mandatory when reading the doc?\r\nThis isn't mandatory. This is just an optional way to send in data to ORT. This is the equivalent of Torch.Tensor (or an initial version of it)\r\n\r\nAm I really using the GPU with that?\r\nYes, Using numpy or OrtValue to send data in has no effect as to where the nodes in your model graph run on. If you send in numpy data and it is \"required\" on CUDA, ORT will make the copy (as opposed to you creating an OrtValue with memory backing on CUDA). You can use nvidia-smi to check GPU usage.\r\n\r\nWhat is the use of ortvalue_from_numpy in that case?\r\nWell, it is just an interface to create an OrtValue with its data residing on CUDA/CPU memory from a numpy object. It isn't a pre-requisite for using ORT.\r\n\r\nIt was mostly created in the context of our IOBinding functionality. See some samples here: https://github.com/microsoft/onnxruntime/blob/1541784f6c0e03a6defb8f562f7ae96368dd09ef/onnxruntime/test/python/onnxruntime_test_python_iobinding.py#L7\r\n\r\n\r\nBut this is a good bug to chase down. I will dig into this a bit more.",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/973664529/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/973673027",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9799#issuecomment-973673027",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9799",
        "id": 973673027,
        "node_id": "IC_kwDOCVq1mM46CRJD",
        "user": {
            "login": "hariharans29",
            "id": 9969784,
            "node_id": "MDQ6VXNlcjk5Njk3ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9969784?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hariharans29",
            "html_url": "https://github.com/hariharans29",
            "followers_url": "https://api.github.com/users/hariharans29/followers",
            "following_url": "https://api.github.com/users/hariharans29/following{/other_user}",
            "gists_url": "https://api.github.com/users/hariharans29/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hariharans29/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hariharans29/subscriptions",
            "organizations_url": "https://api.github.com/users/hariharans29/orgs",
            "repos_url": "https://api.github.com/users/hariharans29/repos",
            "events_url": "https://api.github.com/users/hariharans29/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hariharans29/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-19T02:34:59Z",
        "updated_at": "2021-11-19T02:34:59Z",
        "author_association": "MEMBER",
        "body": "Btw - are you able to run your script with 1.7 without issues ? ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/973673027/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/973680455",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9799#issuecomment-973680455",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9799",
        "id": 973680455,
        "node_id": "IC_kwDOCVq1mM46CS9H",
        "user": {
            "login": "UlrichFreitag",
            "id": 62822473,
            "node_id": "MDQ6VXNlcjYyODIyNDcz",
            "avatar_url": "https://avatars.githubusercontent.com/u/62822473?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/UlrichFreitag",
            "html_url": "https://github.com/UlrichFreitag",
            "followers_url": "https://api.github.com/users/UlrichFreitag/followers",
            "following_url": "https://api.github.com/users/UlrichFreitag/following{/other_user}",
            "gists_url": "https://api.github.com/users/UlrichFreitag/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/UlrichFreitag/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/UlrichFreitag/subscriptions",
            "organizations_url": "https://api.github.com/users/UlrichFreitag/orgs",
            "repos_url": "https://api.github.com/users/UlrichFreitag/repos",
            "events_url": "https://api.github.com/users/UlrichFreitag/events{/privacy}",
            "received_events_url": "https://api.github.com/users/UlrichFreitag/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-19T02:52:44Z",
        "updated_at": "2021-11-19T02:52:44Z",
        "author_association": "NONE",
        "body": "Thank you very much for your reply! It solves my use case at least :partying_face: \r\n\r\n\r\n> Btw - are you able to run your script with 1.7 without issues ?\r\n\r\nI had some issues, but I managed. The bug is still there on this version. You need to change the `ONNX_OPSET_VERSION` to 13 in the export script and comment the `gpu_mem_limit` argument of the cuda provider in the infer script.\r\n\r\nSadly I can't go before 1.7 since I don't have the proper Python version installed.\r\n\r\nHere are the changes:\r\n* New onnx file: [test_bug.onnx.zip](https://github.com/microsoft/onnxruntime/files/7567484/test_bug.onnx.zip)\r\n\r\n\r\n**`reproduce_bug_onnxrt_export.py:`**\r\n```python\r\nimport torch\r\nfrom torch import nn\r\n\r\n\r\nPARTIAL_SHAPE = (16, 7, 5, 3, 3)  # Problematic shape\r\n# PARTIAL_SHAPE = (7, 5, 3, 3)      # No errors occurs with this shape\r\n\r\nONNX_OPSET_VERSION = 13\r\nONNX_FILEPATH = \"test_bug.onnx\"\r\nINPUT_NAMES = [\"input\"]\r\nOUTPUT_NAMES = [\"output\"]\r\nDYNAMIC_AXES = {\"input\": {\"seq_length\": 0}}\r\nDYNAMIC_AXES = {\"input\": [0]}\r\nONNXRT_DEVICE = \"cuda\"\r\nONNXRT_DEVICE_IDX = 1\r\n\r\n\r\nMODEL = nn.Identity()\r\n\r\nexample_tensors = [torch.ones(1, *PARTIAL_SHAPE)]\r\ntorch.onnx.export(\r\n    model=MODEL,\r\n    args=example_tensors,\r\n    f=ONNX_FILEPATH,\r\n    input_names=INPUT_NAMES,\r\n    output_names=OUTPUT_NAMES,\r\n    dynamic_axes=DYNAMIC_AXES,\r\n    operator_export_type=torch.onnx.OperatorExportTypes.ONNX,\r\n    opset_version=ONNX_OPSET_VERSION,\r\n    do_constant_folding=True,\r\n    verbose=False)\r\n```\r\n\r\n**`reproduce_bug_onnxrt_infer.py:`**\r\n```python\r\nimport numpy as np\r\nimport onnxruntime as ort\r\n\r\n\r\nPARTIAL_SHAPE = (16, 7, 5, 3, 3)  # Problematic shape\r\n# PARTIAL_SHAPE = (7, 5, 3, 3)      # No errors occurs with this shape\r\n\r\n\r\nONNX_OPSET_VERSION = 14\r\nONNX_FILEPATH = \"test_bug.onnx\"\r\nINPUT_NAMES = [\"input\"]\r\nOUTPUT_NAMES = [\"output\"]\r\nDYNAMIC_AXES = {\"input\": {\"seq_length\": 0}}\r\nDYNAMIC_AXES = {\"input\": [0]}\r\nONNXRT_DEVICE = \"cuda\"\r\nONNXRT_DEVICE_CUDA_IDX = 0\r\nONNXRT_DEVICE_IDX = 0\r\n\r\n\r\ndef create_onnxrt_session(onnx_filepath, device):\r\n    cuda_providers = [\r\n        (\"CUDAExecutionProvider\", {\r\n            \"device_id\": ONNXRT_DEVICE_IDX,\r\n            \"arena_extend_strategy\": \"kNextPowerOfTwo\",\r\n            # \"gpu_mem_limit\": 2 * 1024 * 1024 * 1024,\r\n            \"cudnn_conv_algo_search\": \"EXHAUSTIVE\",\r\n            \"do_copy_in_default_stream\": True,\r\n        })\r\n    ]\r\n    cpu_providers = [\"CPUExecutionProvider\"]\r\n\r\n    providers = cuda_providers if device == \"cuda\" else cpu_providers\r\n    sess_options = ort.SessionOptions()\r\n    sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_DISABLE_ALL\r\n    return ort.InferenceSession(onnx_filepath, providers=providers, sess_options=sess_options)\r\n\r\n\r\ndef onnxrt_inference(ort_session, arr, device):\r\n    upstreams_onnxrt = {  # removal of the unused inputs\r\n        \"input\": ort.OrtValue.ortvalue_from_numpy(arr, device, ONNXRT_DEVICE_IDX)}\r\n    outs = ort_session.run(\r\n        input_feed=upstreams_onnxrt,\r\n        output_names=OUTPUT_NAMES)\r\n    assert len(outs) == 1\r\n    return outs[0]\r\n\r\n\r\ndef print_result(device, is_session_shared):\r\n    np.random.seed(42)\r\n    session = create_onnxrt_session(ONNX_FILEPATH, device)\r\n\r\n    is_good = True\r\n    for seq_length in range(50):\r\n        if not is_session_shared:\r\n            session = create_onnxrt_session(ONNX_FILEPATH, device)\r\n        inps = np.random.randn(seq_length, *PARTIAL_SHAPE).astype(np.float32)\r\n        outs = onnxrt_inference(session, inps, device)\r\n        if not np.allclose(inps, outs):\r\n            max_diff = np.max(np.abs(inps - outs))\r\n            print(f\"BUG on seq_length: {seq_length}  -  max_diff: {max_diff}\")\r\n            is_good = False\r\n            continue\r\n\r\n    if is_good:\r\n        print(\"Everything went fine\")\r\n\r\n\r\n\r\nprint(\"Results with SINGLE inference Session for CPU\")\r\nprint_result(\"cpu\", is_session_shared=False)\r\n\r\nprint(\"Results with SHARED inference Session for CPU\")\r\nprint_result(\"cpu\", is_session_shared=True)\r\n\r\nONNXRT_DEVICE_IDX = ONNXRT_DEVICE_CUDA_IDX\r\nprint(\"Results with SHARED inference Session for CUDA\")\r\nprint_result(\"cuda\", is_session_shared=True)\r\n\r\nprint(\"Results with SINGLE inference Session for CUDA\")\r\nprint_result(\"cuda\", is_session_shared=False)\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/973680455/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/975109327",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9799#issuecomment-975109327",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9799",
        "id": 975109327,
        "node_id": "IC_kwDOCVq1mM46HvzP",
        "user": {
            "login": "hariharans29",
            "id": 9969784,
            "node_id": "MDQ6VXNlcjk5Njk3ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9969784?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hariharans29",
            "html_url": "https://github.com/hariharans29",
            "followers_url": "https://api.github.com/users/hariharans29/followers",
            "following_url": "https://api.github.com/users/hariharans29/following{/other_user}",
            "gists_url": "https://api.github.com/users/hariharans29/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hariharans29/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hariharans29/subscriptions",
            "organizations_url": "https://api.github.com/users/hariharans29/orgs",
            "repos_url": "https://api.github.com/users/hariharans29/repos",
            "events_url": "https://api.github.com/users/hariharans29/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hariharans29/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-22T04:47:59Z",
        "updated_at": "2021-11-22T04:51:07Z",
        "author_association": "MEMBER",
        "body": "When `OrtValue.ortvalue_from_numpy()` is invoked, we use `cudaMemcpy()` to reflect the numpy buffer's contents to the device memory. \r\n\r\nThis is what the [CUDA Runtime API documentation](https://docs.nvidia.com/cuda/cuda-driver-api/api-sync-behavior.html) says about this particular cudaMemcpy operation:\r\n\r\n![image](https://user-images.githubusercontent.com/9969784/142802334-f921bf09-82c4-462f-a718-f43077577553.png)\r\n\r\nI think what is happening is that sometimes, the numpy array's contents haven't reflected into the cuda device memory and we start processing the input before the copy is complete. We use a non-blocking stream in our sessions to do cuda operations using (i.e..) this stream does not implicitly sync with the default stream and this underlying race condition is the root cause for this bug.\r\n\r\nIf I add a line to do a default stream sync after the memcpy operation in this function, the bug goes away:\r\nhttps://github.com/microsoft/onnxruntime/blob/16ddaf564c14436a3978a3f3f3316b899977a5cd/onnxruntime/core/providers/cuda/cuda_provider_factory.cc#L133\r\n\r\nI will think about a solution for this. Thanks for reporting this.\r\n\r\n ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/975109327/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 1,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    },
    {
        "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/975527163",
        "html_url": "https://github.com/microsoft/onnxruntime/issues/9799#issuecomment-975527163",
        "issue_url": "https://api.github.com/repos/microsoft/onnxruntime/issues/9799",
        "id": 975527163,
        "node_id": "IC_kwDOCVq1mM46JVz7",
        "user": {
            "login": "UlrichFreitag",
            "id": 62822473,
            "node_id": "MDQ6VXNlcjYyODIyNDcz",
            "avatar_url": "https://avatars.githubusercontent.com/u/62822473?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/UlrichFreitag",
            "html_url": "https://github.com/UlrichFreitag",
            "followers_url": "https://api.github.com/users/UlrichFreitag/followers",
            "following_url": "https://api.github.com/users/UlrichFreitag/following{/other_user}",
            "gists_url": "https://api.github.com/users/UlrichFreitag/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/UlrichFreitag/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/UlrichFreitag/subscriptions",
            "organizations_url": "https://api.github.com/users/UlrichFreitag/orgs",
            "repos_url": "https://api.github.com/users/UlrichFreitag/repos",
            "events_url": "https://api.github.com/users/UlrichFreitag/events{/privacy}",
            "received_events_url": "https://api.github.com/users/UlrichFreitag/received_events",
            "type": "User",
            "site_admin": false
        },
        "created_at": "2021-11-22T13:34:08Z",
        "updated_at": "2021-11-22T13:34:08Z",
        "author_association": "NONE",
        "body": "Ah! This makes sense! Well done and good news :smiley: ",
        "reactions": {
            "url": "https://api.github.com/repos/microsoft/onnxruntime/issues/comments/975527163/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "performed_via_github_app": null
    }
]