id,title,type,state,created,first_update,closed,time_to_update,time_to_close,url
102,b'How to get rid of large native/onnxruntime.pdb',Software,closed,2018-12-05T11:43:18Z,2018-12-06 02:05:59+00:00,2021-09-07T17:49:34Z,0,1007,https://api.github.com/repos/microsoft/onnxruntime/issues/102
113,b'Cross compile error on Linux for ARM',Software,closed,2018-12-06T01:58:25Z,2018-12-06 20:58:17+00:00,2018-12-10T23:57:59Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/113
114,b'Is InferenceSession.Run thread-safe?',Software,closed,2018-12-06T02:23:41Z,2018-12-06 02:30:48+00:00,2018-12-06T04:11:25Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/114
116,"b""Unable to load DLL 'onnxruntime.dll': The specified module could not be found.""",Software,closed,2018-12-06T08:12:42Z,2018-12-06 08:14:19+00:00,2018-12-07T20:33:03Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/116
145,b'Will have plan to support RISC-V processor? Or how to port to different processor?',Software,closed,2018-12-11T05:43:27Z,2018-12-11 07:24:00+00:00,2020-07-25T06:40:35Z,0,592,https://api.github.com/repos/microsoft/onnxruntime/issues/145
156,b'OnnxRuntime C# library - add support for Sequence and Map model output types',Software,closed,2018-12-12T18:08:10Z,2019-02-04 18:22:21+00:00,2019-03-06T00:00:41Z,54,83,https://api.github.com/repos/microsoft/onnxruntime/issues/156
167,b'CPU runtime inference speed  slow',Software,closed,2018-12-13T09:55:54Z,2018-12-13 23:20:42+00:00,2019-03-14T07:29:11Z,0,90,https://api.github.com/repos/microsoft/onnxruntime/issues/167
186,b'GTest submodule conflicts',Software,closed,2018-12-17T06:36:58Z,2019-02-21 00:54:44+00:00,2020-07-25T07:40:15Z,65,586,https://api.github.com/repos/microsoft/onnxruntime/issues/186
187,"b""segmentation fault when Tile's repeat contains 0""",Software,closed,2018-12-17T07:26:35Z,2018-12-17 19:49:54+00:00,2019-01-16T05:35:00Z,0,29,https://api.github.com/repos/microsoft/onnxruntime/issues/187
204,b'Get reshape error for Tensorflow BERT model',Software,closed,2018-12-18T15:22:06Z,2018-12-18 15:22:44+00:00,2019-02-08T15:25:12Z,0,52,https://api.github.com/repos/microsoft/onnxruntime/issues/204
218,b'Tokenize a string with a regular expression.',Software,closed,2018-12-19T15:45:03Z,2019-01-02 22:32:05+00:00,2019-04-09T17:53:26Z,14,111,https://api.github.com/repos/microsoft/onnxruntime/issues/218
230,b'Lack of reproducibility',Software,closed,2018-12-20T04:45:08Z,2019-02-20 21:27:28+00:00,2019-03-20T00:02:03Z,62,89,https://api.github.com/repos/microsoft/onnxruntime/issues/230
232,b'Interface between Onnx Runtime and Execution Provider',Software,closed,2018-12-20T08:57:06Z,2018-12-21 17:30:56+00:00,2018-12-22T00:24:37Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/232
237,b'Build error',Software,closed,2018-12-21T09:13:44Z,2019-02-20 21:35:19+00:00,2019-03-26T19:07:44Z,61,95,https://api.github.com/repos/microsoft/onnxruntime/issues/237
247,b'Installation issue in windows10 RS4 with py3.6 (both CPU and CUDA)',Software,closed,2018-12-23T03:14:32Z,2019-01-02 19:41:50+00:00,2019-01-02T19:41:50Z,10,10,https://api.github.com/repos/microsoft/onnxruntime/issues/247
249,b'ONNX Runtime and ONNXIFI',Software,closed,2018-12-24T01:39:37Z,2018-12-29 05:56:53+00:00,2019-03-13T19:20:35Z,5,79,https://api.github.com/repos/microsoft/onnxruntime/issues/249
250,b'pip install failed',Software,closed,2018-12-24T06:37:55Z,2018-12-26 07:03:48+00:00,2018-12-26T07:03:48Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/250
251,b'Error: DLL load failed',Software,closed,2018-12-25T09:04:29Z,2019-01-02 19:48:44+00:00,2019-01-02T19:48:44Z,8,8,https://api.github.com/repos/microsoft/onnxruntime/issues/251
254,b'set session_thread_pool_size failed.',Software,closed,2018-12-26T03:38:03Z,2018-12-28 03:17:47+00:00,2019-01-02T19:45:52Z,1,7,https://api.github.com/repos/microsoft/onnxruntime/issues/254
255,"b'exception when Loop input ""M"" ""cond"" are empty strings'",Software,closed,2018-12-26T09:02:47Z,2018-12-28 23:57:40+00:00,2019-02-20T21:49:40Z,2,56,https://api.github.com/repos/microsoft/onnxruntime/issues/255
265,b'CUDA Test failed on Windows',Software,closed,2018-12-28T03:08:35Z,2019-01-02 18:46:54+00:00,2019-03-28T04:13:08Z,5,90,https://api.github.com/repos/microsoft/onnxruntime/issues/265
271,b'deploy on ARM device(Android) ',Software,closed,2019-01-02T08:57:50Z,2019-01-02 19:12:21+00:00,2019-06-04T20:56:31Z,0,153,https://api.github.com/repos/microsoft/onnxruntime/issues/271
284,"b'Build fails, protobuf needs to handle russian characters in the path of build command'",Software,closed,2019-01-06T02:38:48Z,2019-02-20 21:52:27+00:00,2020-07-25T07:40:27Z,45,566,https://api.github.com/repos/microsoft/onnxruntime/issues/284
300,"b'Build Test ""failed"", ""bidirectional simple weights no bias"" test from GRUTest takes too much time'",Software,closed,2019-01-09T08:09:14Z,2019-02-20 21:53:45+00:00,2019-03-13T19:23:42Z,42,63,https://api.github.com/repos/microsoft/onnxruntime/issues/300
303,b'Delay load cudart',Software,closed,2019-01-10T00:36:48Z,2019-01-10 00:42:22+00:00,2019-01-29T16:50:38Z,0,19,https://api.github.com/repos/microsoft/onnxruntime/issues/303
309,b'Inconsistency of ONNX proto',Software,closed,2019-01-10T03:30:28Z,2019-01-10 06:05:04+00:00,2019-01-10T06:05:04Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/309
310,"b'python api, onnxtuntime load model error'",Software,closed,2019-01-10T10:09:02Z,2019-01-11 00:54:18+00:00,2019-01-11T01:26:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/310
1118,b'OnnxRuntime library in 3rd-party x64 .NET Framework 4.5 application',Software,closed,2019-05-28T20:02:32Z,2019-05-29 17:58:07+00:00,2019-06-06T23:44:57Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/1118
1122,b'Option/Mode to Build Onnx Runtime with Full Onnx Support',Software,closed,2019-05-28T23:10:14Z,2019-05-29 17:54:23+00:00,2020-03-10T23:19:35Z,0,287,https://api.github.com/repos/microsoft/onnxruntime/issues/1122
1123,b'C++ Library Linking Question',Software,closed,2019-05-29T00:11:10Z,2019-05-29 16:28:26+00:00,2019-05-29T16:28:26Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1123
1126,b'Predict slow',Software,closed,2019-05-29T02:12:05Z,2019-05-29 17:48:57+00:00,2019-05-30T06:50:08Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1126
1127,b'import onnxruntime error',Software,closed,2019-05-29T10:03:35Z,2019-05-29 17:48:33+00:00,2019-05-30T19:37:50Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1127
1133,b'[ShapeInferenceError] Attribute dilations has incorrect size',Software,closed,2019-05-30T03:15:11Z,2019-05-30 05:43:58+00:00,2019-05-31T20:46:44Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1133
1134,b'Use C++ API in shared library',Software,closed,2019-05-30T18:43:59Z,2019-05-30 18:54:24+00:00,2019-05-30T19:15:11Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1134
1135,b'Handle the case where there is only one core in the machine.',Software,closed,2019-05-30T19:31:52Z,2019-05-31 00:23:11+00:00,2019-12-17T18:22:13Z,0,200,https://api.github.com/repos/microsoft/onnxruntime/issues/1135
1138,b'Could not find an implementation for the node Relu(1)',Software,closed,2019-05-31T01:16:55Z,2019-05-31 01:37:02+00:00,2019-05-31T02:15:12Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1138
1142,"b'Load/Inference on GPU (C, C++)'",Software,closed,2019-05-31T09:57:06Z,2019-05-31 16:42:03+00:00,2019-06-03T00:39:23Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/1142
1153,b'Run part of the graph',Software,closed,2019-06-03T22:24:25Z,2019-06-03 22:51:25+00:00,2019-06-03T22:51:25Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1153
1155,b'Enable Debug Prints Though out the Execution',Software,closed,2019-06-03T23:13:14Z,2019-06-03 23:41:30+00:00,2019-07-01T16:02:58Z,0,27,https://api.github.com/repos/microsoft/onnxruntime/issues/1155
1162,b'TSAN report for data races',Software,closed,2019-06-05T02:18:45Z,2019-06-05 20:42:39+00:00,2019-07-04T04:24:01Z,0,29,https://api.github.com/repos/microsoft/onnxruntime/issues/1162
1164,b'[ShapeInferenceError] Mismatch between number of source and target dimensions. Source=1 Target=0',Software,closed,2019-06-05T07:47:46Z,2019-06-05 09:18:08+00:00,2019-06-06T08:51:37Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1164
1166,"b""RuntimeError: Unable to handle object of type <class 'float'>""",Software,closed,2019-06-05T10:25:39Z,2019-06-05 15:31:22+00:00,2019-06-05T15:31:21Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1166
1170,b'pip install fails on Windows?',Software,closed,2019-06-05T23:11:16Z,2019-06-06 09:22:47+00:00,2019-06-06T09:22:47Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1170
1173,b'float 16 inference support',Software,closed,2019-06-06T03:28:19Z,2019-06-06 18:57:21+00:00,2019-06-12T03:53:31Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/1173
1174,"b""Error when loading with C#: An unhandled exception of type 'System.AccessViolationException' occurred in Microsoft.ML.OnnxRuntime.dll""",Software,closed,2019-06-06T08:47:30Z,2019-06-06 11:34:58+00:00,2019-06-06T11:34:58Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1174
1175,"b""error: unknown type name '_Frees_ptr_opt_'""",Software,closed,2019-06-06T14:10:34Z,2019-06-06 19:00:48+00:00,2019-06-07T18:52:23Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1175
1176,b'Need to be able to explain predictions from ONNX models (aka need Shapley values from onnxruntime)',Software,closed,2019-06-06T16:03:01Z,2019-06-06 18:49:16+00:00,2020-03-17T18:23:30Z,0,285,https://api.github.com/repos/microsoft/onnxruntime/issues/1176
1177,b'Question about ParallelFor',Software,closed,2019-06-06T16:57:26Z,2019-06-06 18:42:06+00:00,2019-06-06T21:08:01Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1177
1179,b'Upsample not matching numbers in linear mode',Software,closed,2019-06-06T18:31:33Z,2019-06-06 18:48:49+00:00,2019-06-06T20:09:37Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1179
1180,b'android deployment',Software,closed,2019-06-06T18:38:46Z,2019-06-06 19:06:11+00:00,2019-06-12T01:19:58Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/1180
1187,b'onnxruntime with Openvino build error.',Software,closed,2019-06-07T12:00:39Z,2019-06-07 17:29:20+00:00,2019-06-11T17:13:25Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/1187
1203,b'Test failed when building wheel',Software,closed,2019-06-11T07:46:13Z,2019-06-11 16:45:14+00:00,2019-06-20T20:57:06Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/1203
1204,b'Weird results for evaluation of squeezenet in C_Api_Sample.cpp',Software,closed,2019-06-11T14:10:33Z,2019-06-11 16:45:40+00:00,2019-06-11T22:01:38Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1204
1212,b'[TypeInferenceError] Graph attribute inferencing failed',Software,closed,2019-06-12T12:27:17Z,2019-06-12 16:43:06+00:00,2019-06-25T21:55:35Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/1212
1213,b'perftest: set parallel executor and thread pool size separately',Software,closed,2019-06-12T17:03:55Z,2019-06-12 17:36:25+00:00,2019-06-17T17:41:35Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/1213
10457,b'Build linker error',Software,open,2022-02-03T07:26:59Z,2022-02-03 15:19:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10457
10463,"b'""Non-zero status code returned while running Reshape node"" on dynamic batch sized model'",Software,closed,2022-02-03T19:07:07Z,2022-02-03 19:28:03+00:00,2022-02-15T14:12:27Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/10463
10466,b'Issues building with both --use_rocm and --build_shared_lib specified',Software,open,2022-02-03T20:44:59Z,2022-02-03 23:10:55+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10466
10468,b'Creating a separate repo for MLAS library',Software,open,2022-02-03T21:59:28Z,2022-02-03 22:16:35+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10468
10472,b'C++ OnnxRuntime_GPU: Session Run throws an access violation exception',Software,closed,2022-02-04T07:55:29Z,2022-02-04 17:20:46+00:00,2022-02-08T12:23:01Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/10472
10473,b'PropagateCastOps uses and modifies 3 global containers at runtime',Software,closed,2022-02-04T19:57:22Z,2022-02-04 23:10:12+00:00,2022-02-11T16:34:40Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/10473
10477,b'Fusion Reshape bug whith multiple graphs in a model',Software,open,2022-02-07T09:59:04Z,2022-02-07 18:10:45+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10477
10479,b'NuGet package fails ARM64EC build',Software,closed,2022-02-07T18:45:27Z,2022-02-08 07:31:28+00:00,2022-02-08T07:31:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10479
10482,b'OverflowException thrown when pinning the Buffer of Tensor from DisposableNamedOnnxValue in C#',Software,closed,2022-02-07T20:08:03Z,2022-02-11 18:45:55+00:00,2022-02-22T23:13:09Z,3,15,https://api.github.com/repos/microsoft/onnxruntime/issues/10482
10484,"b'raise Exception(""Incomplete symbolic shape inference"") when running ""symbolic_shape_infer.py""'",Software,open,2022-02-07T23:09:26Z,2022-02-11 18:47:57+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/10484
10486,"b'When using CUDA device, Attempt to use DefaultLogger but none has been registered.'",Software,closed,2022-02-08T02:14:20Z,2022-02-08 12:04:45+00:00,2022-02-09T17:45:47Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/10486
10490,b'Possible memory leak on GetInputName & GetOutputName',Software,closed,2022-02-08T09:58:11Z,2022-02-08 09:58:28+00:00,2022-02-10T07:07:10Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/10490
10491,b'Onnx softplus accuracy problem',Software,closed,2022-02-08T10:03:27Z,2022-02-08 10:07:48+00:00,2022-02-08T10:07:48Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10491
10492,b'C++ OnnxRuntime-GPU Slower than Python OnnxRuntime-GPU/C++ OnnxRuntime-CPU',Software,open,2022-02-08T10:53:50Z,2022-02-11 19:23:53+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/10492
10500,b'Onnxruntime infer bn node failed',Software,closed,2022-02-09T08:25:42Z,2022-02-09 17:09:58+00:00,2022-02-11T19:51:45Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/10500
10501,b'Release 1.7.0 build issue',Software,closed,2022-02-09T08:53:24Z,2022-02-09 17:06:20+00:00,2022-02-09T17:06:20Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10501
10502,b'MacOs with M1 chips use CoreML to accelerate inference',Software,closed,2022-02-09T10:03:45Z,2022-02-09 21:37:25+00:00,2022-02-27T23:13:30Z,0,18,https://api.github.com/repos/microsoft/onnxruntime/issues/10502
10503,b'Attempt to statically quantize BERT with `percentile` schema results in out of memory',Software,closed,2022-02-09T10:46:49Z,2022-02-09 10:46:50+00:00,2022-02-11T19:11:44Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/10503
10504,b'Possible issue with shape inference while statically quantizing BERT',Software,open,2022-02-09T10:54:02Z,2022-02-11 19:05:21+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/10504
10509,b'Make ONNX graphs with fused ONNXRuntime plugins runnable by TensorRT execution provider ?',Software,open,2022-02-09T22:51:53Z,2022-02-11 19:07:25+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10509
10513,b'Resize error: Scale value should be greater than 0.',Software,closed,2022-02-10T05:06:39Z,2022-02-10 08:19:52+00:00,2022-02-10T14:00:32Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10513
10514,b'Strange behavior of ReduceMax with NaN Values',Software,open,2022-02-10T08:34:17Z,2022-02-11 18:59:34+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10514
10516,"b""failed to inference ONNX model: TypeError: Cannot read properties of undefined (reading 'InferenceSession')""",Software,closed,2022-02-10T15:26:11Z,2022-02-11 19:00:26+00:00,2022-03-16T17:04:33Z,1,34,https://api.github.com/repos/microsoft/onnxruntime/issues/10516
10517,b'Model errors our on unsupported If operator in gradient builder',Software,open,2022-02-10T16:07:25Z,2022-02-11 18:50:15+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10517
10525,b'.NET onnxruntime Protobuf parsing failed',Software,closed,2022-02-11T05:56:37Z,2022-02-11 09:20:31+00:00,2022-02-11T09:20:31Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10525
10529,b'Memory protection error when running on linux',Software,closed,2022-02-11T20:48:24Z,2022-02-11 23:05:46+00:00,2022-02-11T23:05:46Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10529
10537,b'NCHWc Data format Query',Software,open,2022-02-12T22:09:37Z,2022-02-14 19:17:16+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10537
10538,b'slower after graph optimization!',Software,open,2022-02-13T20:05:25Z,2022-02-14 19:14:48+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10538
10540,b'Onnx runtime accuracy result',Software,closed,2022-02-14T03:46:19Z,2022-02-15 02:50:23+00:00,2022-02-16T06:08:45Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/10540
10542,b'onnxruntime and onnxruntime-gpu produce different output for ReduceL1 operator',Software,open,2022-02-14T04:45:06Z,2022-02-14 19:10:51+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10542
10543,b'Run maskrcnn onnx from pytorch and inference on c++ with gpu sometimes will error',Software,open,2022-02-14T06:22:49Z,2022-02-14 19:07:48+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10543
10546,b'Exception in DirectML on second inference run',Software,open,2022-02-14T17:45:58Z,2022-02-14 19:04:19+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10546
10555,b'Error compiling time in ubuntu Jetson Nano',Software,open,2022-02-14T23:12:14Z,2022-02-15 03:16:00+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10555
10559,b'onnxruntime quantization model slower than onnxruntime model.',Software,closed,2022-02-15T09:25:25Z,2022-02-15 19:07:07+00:00,2022-02-15T22:51:21Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10559
10561,b'Unit Tests failure while building on Windows with CUDA EP',Software,open,2022-02-15T13:41:44Z,2022-02-15 19:06:45+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10561
10563,b'LoadLibrary error 126 when creating CUDA session',Software,closed,2022-02-15T15:41:54Z,2022-02-15 19:21:50+00:00,2022-02-28T09:41:55Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/10563
10564,b'Provide a way to handle errors in the C++ API when exceptions are disabled',Software,closed,2022-02-15T16:01:15Z,2022-02-15 19:09:22+00:00,2022-02-28T21:34:42Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/10564
10571,b'Calibration ranges for Histogram-based approaches gives very bad performances on the task (BERT / SQuAD).',Software,open,2022-02-16T17:33:57Z,2022-02-16 21:08:00+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10571
10580,b'commit 7e092a7e3f8f9f590de0ac5548035e8fa4d512f8 caused build error',Software,closed,2022-02-17T05:12:12Z,2022-02-17 06:48:54+00:00,2022-02-19T07:30:50Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/10580
10584,"b""error: parameter 'b' set but not used [-Werror,-Wunused-but-set-parameter]""",Software,closed,2022-02-17T08:30:15Z,2022-02-17 19:43:38+00:00,2022-02-19T06:47:14Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/10584
10585,"b""error: definition of implicit copy constructor for 'SafeInt<unsigned long>' is deprecated because it hasprovided copy assignment operator [-Werror,-Wdeprecated-copy-with-user-provided-copy]""",Software,closed,2022-02-17T08:42:57Z,2022-02-17 19:43:08+00:00,2022-02-19T06:49:36Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/10585
10586,b'Add logging to file option',Software,open,2022-02-17T13:17:55Z,2022-02-17 19:42:18+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10586
10589,b'ORT library files are missing versions.',Software,open,2022-02-17T18:49:19Z,2022-02-17 19:36:06+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10589
10593,"b""error:TypeError: unsupported operand type(s) for ^: 'NoneType' and 'int'""",Software,closed,2022-02-18T03:42:33Z,2022-02-18 07:02:18+00:00,2022-03-10T01:00:16Z,0,19,https://api.github.com/repos/microsoft/onnxruntime/issues/10593
10596,"b""Issue using OnnxRuntime on Android with NDK project: error: redefinition of 'ONNXTensorElementDataType','ONNXType', 'OrtSparseFormat', etc.""",Software,closed,2022-02-18T06:23:26Z,2022-02-18 06:57:26+00:00,2022-02-18T17:47:44Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10596
10600,b'Building Error',Software,open,2022-02-19T02:56:53Z,2022-02-19 06:24:32+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10600
10601,"b""OpenVINO Execution provider's CPU Utility is low""",Software,open,2022-02-19T04:25:55Z,2022-02-19 06:19:54+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10601
10602,b'How to use OpenVINO GetAvailableDevices?',Software,open,2022-02-19T14:17:28Z,2022-02-19 18:52:43+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10602
10603,b'call for Vulkan support',Software,open,2022-02-20T00:52:45Z,2022-02-21 02:59:58+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10603
10604,b'performance limited with fp16 on directml',Software,open,2022-02-20T07:21:15Z,2022-02-21 01:49:32+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10604
10605,b'runtime/core/mlas/lib/pooling.cpp:1345:23: error: unused variable \xe2\x80\x98BitFlipVector\xe2\x80\x99 [-Werror=unused-variable]',Software,open,2022-02-20T13:50:19Z,2022-02-21 04:56:19+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10605
10606,b'how to get DML device index of specified card',Software,open,2022-02-21T03:22:48Z,2022-02-21 03:23:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10606
10607,b'GridSample with bicubic interpolation and border padding',Software,open,2022-02-21T05:17:24Z,2022-02-21 23:18:14+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10607
10608,b'why it take 200 seconds to run onnxruntime.InferenceSession',Software,open,2022-02-21T07:33:58Z,2022-02-24 10:02:22+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/10608
10610,b'Building OnnxRuntime v1.10.0 with CUDAExecutionProvider for sm_75 GPU fails in CUDA10.2 environment',Software,open,2022-02-21T08:01:37Z,2022-02-21 22:48:49+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10610
10611,b'C + + onnxruntime GPU is ten times slower than CPU',Software,open,2022-02-21T10:03:44Z,2022-03-02 10:02:22+00:00,,8,,https://api.github.com/repos/microsoft/onnxruntime/issues/10611
10612,b'Need help building for AWS EC2 instances with ARM CPU and T4G GPU',Software,closed,2022-02-21T10:42:17Z,2022-02-22 01:58:12+00:00,2022-02-22T01:58:12Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10612
10613,b'Optimization for T5 transformer models.',Software,open,2022-02-21T11:07:28Z,2022-02-23 19:59:22+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/10613
10617,"b'QLinearGlobalAveragePool error occurred while inference quantized model with ""INT8""'",Software,closed,2022-02-22T01:13:21Z,2022-02-24 20:54:03+00:00,2022-03-07T01:49:09Z,2,13,https://api.github.com/repos/microsoft/onnxruntime/issues/10617
10618,"b""[E:onnxruntime:, sequential_executor.cc:346 Execute] Non-zero status code returned while running Add node. Name:'Add_1363' Status Message: /onnxruntime_src/onnxruntime/core/providers/cpu/math/element_wise_ops.h:505 void onnxruntime::BroadcastIterator::Append(ptrdiff_t, ptrdiff_t) axis == 1 || axis == largest was false. Attempting to broadcast an axis by a dimension other than 1. 9 by 505""",Software,open,2022-02-22T02:46:46Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/10618
10620,b'about providers and providers_options in InferenceSession',Software,open,2022-02-22T06:57:26Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/10620
10629,b'How to use mimalloc in Linux?',Software,open,2022-02-23T01:32:13Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/10629
10635,b' 5 - onnxruntime_global_thread_pools_test (Failed)',Software,open,2022-02-23T08:24:47Z,2022-02-23 08:30:23+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10635
10636,b'CPU & CUDA execution provider produce different value',Software,open,2022-02-23T09:32:48Z,2022-02-24 20:52:12+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10636
10639,b'No libonnxruntime_providers_cuda.so generated?',Software,open,2022-02-23T10:56:17Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/10639
10648,b'ORT is not correctly exporting Nvidia Apex FusedLayerNorm correctly',Software,closed,2022-02-23T21:40:24Z,2022-02-25 19:03:44+00:00,2022-04-14T00:44:43Z,1,49,https://api.github.com/repos/microsoft/onnxruntime/issues/10648
10657,b'onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION ',Software,open,2022-02-24T08:37:33Z,2022-02-24 10:07:26+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10657
10660,b'Issue using NNAPI on Android device',Software,open,2022-02-24T09:22:09Z,2022-02-24 09:31:14+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10660
10664,"b'Bug with Reshape when allowzero=1, and shape has unknown dimension'",Software,closed,2022-02-24T20:15:05Z,2022-02-24 20:15:06+00:00,2022-03-01T18:47:49Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/10664
10669,b'Include ONNX Runtime in Unreal Engine 4',Software,closed,2022-02-24T21:55:34Z,2022-02-28 20:24:35+00:00,2022-03-08T05:04:49Z,3,11,https://api.github.com/repos/microsoft/onnxruntime/issues/10669
10673,b'Get wrong result when use webgl backend ',Software,open,2022-02-25T08:10:01Z,2022-02-25 18:59:39+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10673
10676,b'run time',Software,closed,2022-02-25T15:22:27Z,2022-02-25 17:51:22+00:00,2022-02-25T17:53:21Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10676
10677,b'onnxruntime::Graph::CleanUnusedInitializersAndNodeArgs initializer_node_arg != nullptr was false.',Software,open,2022-02-25T15:36:57Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/10677
10679,b'Capability to export tensors in C++',Software,open,2022-02-25T19:48:22Z,2022-03-08 04:57:07+00:00,,10,,https://api.github.com/repos/microsoft/onnxruntime/issues/10679
10683,b'run time at the first time',Software,closed,2022-02-26T00:38:25Z,2022-04-12 03:16:55+00:00,2022-04-12T03:16:55Z,45,45,https://api.github.com/repos/microsoft/onnxruntime/issues/10683
10685,b'Clarify pip install instructions: GPU vs. CPU',Documentation,closed,2022-02-26T01:48:45Z,2022-02-26 03:59:50+00:00,2022-03-02T04:35:50Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/10685
10689,b'Need help on the following from wiki listed roadmap.',Documentation,open,2022-02-27T11:02:38Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/10689
10693,b'The prediction in C + + is inconsistent with that in py',Software,closed,2022-02-28T09:37:04Z,2022-02-28 18:38:24+00:00,2022-03-02T09:27:40Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/10693
10698,b'Local function with If: GraphProto attribute inferencing is not enabled in this InferenceContextImpl instance.',Software,open,2022-02-28T17:30:04Z,2022-03-09 16:40:23+00:00,,8,,https://api.github.com/repos/microsoft/onnxruntime/issues/10698
10706,b'Error: two nodes with same node name (Slice_34)',Software,open,2022-03-01T08:10:06Z,2022-03-02 22:41:12+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10706
10708,b'C++ inference with DirectML: ERROR: Dimensions of the View are invalid.',Software,open,2022-03-01T11:09:03Z,2022-03-01 11:09:04+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10708
10709,b'Unable to Convert Longformer Transformer to Onnx',Software,closed,2022-03-01T12:41:15Z,2022-03-02 22:40:19+00:00,2022-03-03T20:54:09Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/10709
10710,b'The ONNX graph converted from tf.image.crop_and_resize() function will cause a different result by ORT nightly build.',Software,closed,2022-03-01T16:28:58Z,2022-03-02 22:44:01+00:00,2022-03-17T21:43:26Z,1,16,https://api.github.com/repos/microsoft/onnxruntime/issues/10710
10726,b'selu get wrong result',Software,closed,2022-03-02T07:44:06Z,2022-03-02 22:44:34+00:00,2022-03-09T03:53:28Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/10726
10727,b'Output shape is mismatched with ONNX SPEC about Resize_tf_crop_and_size with scale input',Software,open,2022-03-02T08:13:38Z,2022-03-02 22:45:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10727
10728,"b'how to run onnx model with quantizelinear and dequantizelinear node ,is it supported now? or we should add qdq to onnx in onnxruntime style'",Software,closed,2022-03-02T08:52:54Z,2022-03-02 09:20:33+00:00,2022-03-02T09:20:33Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10728
10730,b'Why onnxruntime does not support parallel execution mode of CUDA?',Software,closed,2022-03-02T10:45:44Z,2022-03-02 22:45:04+00:00,2022-03-08T02:19:13Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/10730
10731,b'gpu onnxruntime lib',Software,open,2022-03-02T12:20:50Z,2022-03-02 20:24:14+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10731
10732,b'ILearningModelSessionOptionsNative for setting IntraopNumThreads not available on Windows 10',Software,closed,2022-03-02T15:57:35Z,2022-03-02 22:48:21+00:00,2022-03-12T00:41:31Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/10732
10733,b'Component Governance updates for branch `rel-1.9.1`',Software,closed,2022-03-02T18:39:53Z,2022-03-02 20:18:51+00:00,2022-03-02T20:18:51Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10733
10736,b'CPU inference freezes on server with SLURM task manager',Software,closed,2022-03-02T19:07:02Z,2022-03-02 22:49:20+00:00,2022-03-07T12:38:53Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/10736
10740,b'[ortmodule] GraphExecutionManager self._device = None',Software,open,2022-03-02T23:22:58Z,2022-03-02 23:25:44+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10740
10741,"b'Unable to inference on exported ONNX model - Seeing error ""Non concat axis dimensions must match: Axis has mismatched dimensions""'",Software,closed,2022-03-02T23:29:17Z,2022-03-02 23:29:18+00:00,2022-03-09T20:20:56Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/10741
10742,b'Onnx model consumes huge CPU memory',Software,open,2022-03-02T23:31:06Z,2022-03-05 05:58:51+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/10742
10743,b'inference qdq model failed with TRT EP.',Software,open,2022-03-03T02:18:06Z,2022-03-05 05:59:22+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/10743
10745,b'build on windows cup is fine\xef\xbc\x8cbut cuda not',Software,open,2022-03-03T04:17:43Z,2022-03-03 07:51:23+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10745
10746,b'When using CUDA the first run is very slow',Software,open,2022-03-03T07:01:46Z,2022-03-03 07:01:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10746
10749,b'Is there a version of  onnxruntime that is compatible with windows 7?',Software,open,2022-03-03T08:42:36Z,2022-03-03 19:51:08+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10749
10750,b'Build with --use_openvino failed',Software,open,2022-03-03T11:09:50Z,2022-03-05 06:01:55+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10750
10751,b'Where is the .lib file and headers located after build from source?',Software,closed,2022-03-03T12:23:16Z,2022-03-04 06:58:02+00:00,2022-03-04T06:58:02Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10751
10758,b'Component Governance Alert on `cmake/external/protobuf`',Software,open,2022-03-03T19:34:26Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/10758
10761,b'Shape Inference does not work with onnx1.11.0 due to onnx shape inference enchancement',Software,closed,2022-03-03T22:22:56Z,2022-03-03 22:59:29+00:00,2022-03-17T05:47:03Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/10761
10763,"b'can build on windows with  Geforce 1060 card, cuda 11.0 cudnn 8.0.2 successfully?'",Software,open,2022-03-04T02:15:39Z,2022-03-05 06:02:33+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10763
10764,b'very slow in inference ',Software,open,2022-03-04T03:05:54Z,2022-03-08 00:05:01+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/10764
10767,"b""Error about  'Undefined symbol: _OrtGetApiBase'""",Software,closed,2022-03-04T10:16:21Z,2022-03-05 06:06:45+00:00,2022-03-15T08:02:24Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/10767
10768,b'Non-zero status code returned while running LSTM node',Software,open,2022-03-04T11:05:16Z,2022-03-05 06:07:06+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10768
10770,"b'E:onnxruntime:Default, tensorrt_execution_provider.h:50 log] [2022-03-04 13:39:28   ERROR] ../rtSafe/safeRuntime.cpp (25) - Cuda Error in allocate: 2 (out of memory)'",Software,closed,2022-03-04T13:41:46Z,2022-03-05 06:07:46+00:00,2022-03-18T05:16:13Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/10770
10772,b'Nonexistent header included at provider_api.h',Software,closed,2022-03-04T16:29:07Z,2022-03-04 16:51:15+00:00,2022-03-04T16:51:15Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10772
10774,b'Multiple wasm models with web workers (proxies) [web-wasm]',Software,closed,2022-03-04T20:09:50Z,2022-03-05 20:18:12+00:00,2022-03-06T18:30:17Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/10774
10783,b'Warning after exporting repeat_interleave to onnx with dynamic axes',Software,open,2022-03-05T19:14:02Z,2022-03-07 19:41:10+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/10783
10786,b'ONNX models give slower inference in Python Multiprocessing',Software,open,2022-03-06T05:20:51Z,2022-03-07 19:42:46+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10786
10787,b'Quantizing Yolov5 model from ultralytics is giving poor mAP',Software,closed,2022-03-06T20:03:27Z,2022-03-07 19:43:19+00:00,2022-03-10T16:57:51Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/10787
10789,b'Inference time of onnxruntime gpu increases at very high batch sizes',Software,open,2022-03-07T07:34:25Z,2022-03-07 19:01:45+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10789
10805,b'OnnxRuntime GPU very poor perfomance in .Net',Software,open,2022-03-08T08:18:07Z,2022-03-08 16:22:59+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10805
10806,b'Onnxruntime-gpu try to find missmatched cuda lib.',Software,closed,2022-03-08T08:34:46Z,2022-03-08 16:52:39+00:00,2022-03-11T02:50:14Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/10806
10807,b'T5 Model with ONNX Runtime on GPU',Software,closed,2022-03-08T16:21:47Z,2022-03-08 16:49:50+00:00,2022-03-10T03:16:59Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/10807
10809,b'Where are the 1.11.0 NuGet Packages?',Software,closed,2022-03-08T20:10:18Z,2022-03-09 17:19:06+00:00,2022-03-09T17:19:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10809
10814,b'Inquiry on adding company to Organizations and products using ONNX Runtime list',Software,closed,2022-03-09T00:32:37Z,2022-03-09 06:47:19+00:00,2022-03-09T17:18:23Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10814
10818,"b""CMake build doesn't generate a config file""",Software,closed,2022-03-09T17:26:13Z,2022-03-09 18:53:36+00:00,2022-03-24T17:39:08Z,0,15,https://api.github.com/repos/microsoft/onnxruntime/issues/10818
10834,"b""I can't find a example for GPU multi input""",Documentation,closed,2022-03-10T17:09:33Z,2022-03-10 19:23:40+00:00,2022-03-16T17:40:19Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/10834
10837,b'Plan to support OnnxRuntimeTraining on Windows?',Software,closed,2022-03-10T19:37:49Z,2022-03-11 01:17:13+00:00,2022-03-21T21:40:24Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/10837
10838,b'Transformer optimizer outputs confusing error',Software,open,2022-03-10T19:39:55Z,2022-03-10 22:18:07+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10838
10839,b'Missing documentation on LayerNormalization contrib spec',Documentation,closed,2022-03-10T21:56:39Z,2022-03-10 22:19:08+00:00,2022-03-18T18:40:06Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/10839
10846,b'Potential issue with asymmetric calibration resulting in very low accuracy',Documentation,closed,2022-03-11T09:01:00Z,2022-03-11 17:38:13+00:00,2022-03-11T22:52:37Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10846
10849,"b'C++ is 10x slower compared with Python, CPU only'",Software,open,2022-03-11T16:13:07Z,2022-03-11 17:47:07+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10849
10852,"b""[build] [web] Using --enable_training_ops gives error: 'result_of<Eigen::internal::scalar_exp_op<float> (const float &)>' is deprecated""",Software,closed,2022-03-11T19:22:58Z,2022-03-11 19:26:54+00:00,2022-03-24T23:07:42Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/10852
10853,b'Cannot run IO Binding with int64 PyTorch tensors',Software,open,2022-03-12T01:35:58Z,2022-03-14 03:46:16+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/10853
10854,b'does nnapi (armv7a or armv8a) support model contain lstm ?',Software,open,2022-03-12T09:30:33Z,2022-03-14 02:57:43+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10854
10855,b'Windows 32 bit performance much slower than 64bit?',Software,open,2022-03-12T16:53:33Z,2022-03-14 02:50:06+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10855
10856,b'DmlExecutionProvider is much slower than CPUExecutionProvider',Software,open,2022-03-13T08:04:11Z,2022-03-14 02:22:20+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10856
10863,b'Different inference results from python and C# ',Software,open,2022-03-14T18:13:19Z,2022-03-17 09:49:31+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/10863
10873,b'Does WebGL fail when network inputs are not dimensions in powers of two?',Software,open,2022-03-15T10:41:56Z,2022-03-15 16:59:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10873
10874,b'Problems with predictions on MacBook Air with M1 chip in Java project based on Maven',Software,closed,2022-03-15T12:36:21Z,2022-03-15 17:16:57+00:00,2022-03-25T23:23:18Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/10874
10876,b'FunctionImpl should consider nested subgraphs when updating graph inputs/outputs',Software,open,2022-03-15T18:00:42Z,2022-03-15 18:02:57+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10876
10877,b'Version 1.10.0 not compiling',Software,closed,2022-03-15T20:30:27Z,2022-03-15 23:52:41+00:00,2022-03-16T15:23:44Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10877
10888,b'TensorRT conversion support on Huggingface transformers quantized models.',Software,open,2022-03-16T06:52:06Z,2022-03-17 00:56:59+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10888
10892,"b'onnxruntime/capi/onnxruntime_inference_collection.py"", line 370, in _create_inference_session     sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model) onnxruntime.capi.onnxruntime_pybind11_state.InvalidProtobuf: [ONNXRuntimeError] : 7 : INVALID_PROTOBUF : Load model from onnx_data/cpm_large_opt.onnx failed:Protobuf parsing failed.'",Software,open,2022-03-16T13:35:09Z,2022-03-17 03:22:11+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10892
10893,b'python3 -m onnxruntime_tools.transformers.optimizer  when opt_level=1 comes error for BERT',Software,open,2022-03-16T14:09:39Z,2022-03-17 00:57:29+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10893
10894,b'1 : Fail : Non-zero status code returned while running FusedConv node.',Software,open,2022-03-16T17:02:33Z,2022-03-17 00:59:10+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10894
10897,b'[ORTModule] Tensors are not in the same device',Software,open,2022-03-16T21:13:03Z,2022-03-16 21:13:13+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10897
10902,b'onnxruntime TRT EP link for 1.9 is incorrect',Documentation,closed,2022-03-17T00:20:42Z,2022-03-17 00:55:00+00:00,2022-03-17T18:56:26Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10902
10905,"b'After using onnxruntime.transformers.optimizer to optimize onnx, the optimized model fail to tensorrt'",Documentation,open,2022-03-17T04:25:38Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/10905
10913,b'[web] ES6 modules',Software,open,2022-03-17T13:29:14Z,2022-03-20 08:01:13+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/10913
10914,b'TensorRT Execution [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization',Software,open,2022-03-17T14:00:48Z,2022-03-17 17:20:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10914
10918,b'Building for Wasm - Undefined Symbols from absiel',Software,open,2022-03-17T17:35:45Z,2022-03-18 17:38:16+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10918
10919,b'slow fp16 performance ',Software,open,2022-03-17T17:58:57Z,2022-03-21 18:44:50+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/10919
10924,b'ORT python API raises ImportError if windows is not installed at `C:\\Windows` or vcruntime140_1.dll is not installed under `C:\\Windows\\System32`',Software,closed,2022-03-17T19:18:38Z,2022-03-17 19:18:52+00:00,2022-03-22T01:02:58Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/10924
10930,b'onnxruntime TensorRT Related Questions',Software,open,2022-03-18T02:33:32Z,2022-03-21 18:44:03+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/10930
10936,b'Runtime Exception when relu is followed by a clip',Software,open,2022-03-18T05:04:50Z,2022-03-18 05:04:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10936
10939,b'ORT nightly version 1.11.0.dev20220311003 supports numpy <= 1.21',Software,closed,2022-03-18T09:40:50Z,2022-03-18 09:41:21+00:00,2022-04-15T17:08:06Z,0,28,https://api.github.com/repos/microsoft/onnxruntime/issues/10939
10941,"b""Error Nodes in a graph must be topologically sorted, however input 'Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Slice_1/begin:0' of node: name: Add__1005 OpType: Add""",Software,closed,2022-03-18T14:46:22Z,2022-03-19 13:00:22+00:00,2022-03-19T13:00:22Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10941
10942,b'Result difference when running beam search on ONNX T5 model.',Software,closed,2022-03-18T16:48:37Z,2022-03-18 16:48:37+00:00,2022-03-20T08:17:00Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/10942
10946,b'torch_onnx_export_helper.py hits wrong path for preproduction Torch versions',Software,closed,2022-03-18T21:18:31Z,2022-03-18 21:34:42+00:00,2022-03-18T23:00:36Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10946
10950,b'MatMul fusion failed at scalar input',Software,closed,2022-03-19T06:29:14Z,2022-03-21 18:11:27+00:00,2022-04-15T06:06:28Z,2,26,https://api.github.com/repos/microsoft/onnxruntime/issues/10950
10951,"b'why convert onnx model to ort, only basic optim level can run but extend or all level create session failed?'",Software,open,2022-03-19T14:44:05Z,2022-03-21 18:15:25+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/10951
10955,b'Unstable behavior in CUDA EP',Software,closed,2022-03-20T07:07:59Z,2022-03-21 18:16:10+00:00,2022-03-25T20:51:41Z,1,5,https://api.github.com/repos/microsoft/onnxruntime/issues/10955
10957,"b'[web] ""Uncaught (in promise) 1991937888"" or ""RuntimeError: abort(undefined)"" when loading multiple sessions of a large model'",Software,open,2022-03-20T14:56:51Z,2022-03-21 18:17:40+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10957
10961,b'can openmp used for android device of armv7a or armv8a?',Software,open,2022-03-21T07:18:32Z,2022-03-21 18:20:36+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10961
10967,b'The outputs of session.run()',Software,closed,2022-03-22T06:33:03Z,2022-03-22 07:21:33+00:00,2022-03-22T07:21:33Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10967
10968,b'Reference for adding two custom kernels to onnxruntime #211',Documentation,closed,2022-03-22T09:56:33Z,2022-03-22 17:20:09+00:00,2022-03-22T17:46:20Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10968
10975,b'C++ onnxruntime profiling',Documentation,open,2022-03-22T20:07:41Z,2022-03-22 22:18:07+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10975
10976,b'MinGW support (MSYS2)',Software,open,2022-03-22T20:29:11Z,2022-03-22 22:32:29+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10976
10977,b'Slow load time of .onnx model with external data from 1.7 to 1.10',Software,closed,2022-03-22T22:41:19Z,2022-03-22 22:48:04+00:00,2022-03-23T14:03:40Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10977
10982,b'Memory Leak When Running CPU Model in C++',Software,open,2022-03-23T13:26:13Z,2022-03-23 17:59:12+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10982
10988,b'Page missing: convert to ort referring',Software,closed,2022-03-24T05:49:36Z,2022-03-24 05:50:29+00:00,2022-03-24T05:50:29Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10988
10989,b'Onnxruntime slower than tensorflow keras when infer data',Software,closed,2022-03-24T06:33:14Z,2022-03-24 17:19:49+00:00,2022-04-11T01:56:22Z,0,17,https://api.github.com/repos/microsoft/onnxruntime/issues/10989
10990,"b'[Lot of people have this issue]  The model can not ""really"" do inference; Loading issue is solved.'",Software,closed,2022-03-24T06:34:06Z,2022-03-24 17:22:15+00:00,2022-04-20T03:37:30Z,0,26,https://api.github.com/repos/microsoft/onnxruntime/issues/10990
10991,"b""docker can't clone git repository for ARM64""",Software,open,2022-03-24T07:07:02Z,2022-03-24 17:23:15+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10991
10992,b'`run_with_iobinding` is not outputting the expected result for batched input data for `T5` model running on ort `CUDA EP`. ',Software,closed,2022-03-24T11:41:35Z,2022-03-24 17:23:57+00:00,2022-04-04T13:40:43Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/10992
10993,b'Accessing OrtStatus from external C code',Software,closed,2022-03-24T17:46:23Z,2022-03-24 18:19:52+00:00,2022-03-24T18:19:52Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10993
10994,b'Could not find an implementation for Trilu node - ORT Model Optimizer',Software,open,2022-03-24T20:05:54Z,2022-03-24 20:14:38+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10994
11000,b'Xor with broadcasting computes error ',Software,open,2022-03-25T07:11:13Z,2022-03-27 19:07:04+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/11000
11005,b'Reorder input and Reorder output Ops',Documentation,open,2022-03-25T19:50:26Z,2022-03-27 19:11:08+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11005
11007,"b'C++ DML runtime works with debug DLL, but not with release'",Software,closed,2022-03-25T20:16:30Z,2022-03-25 20:29:14+00:00,2022-04-04T10:50:14Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/11007
11010,b'Inconsistent behavior between CPU and GPU on ReLU operator when input is NaN',Software,open,2022-03-25T23:48:39Z,2022-03-27 19:11:25+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11010
11011,b'is it supported for QDQ convolution model in tensorrt backend now? ',Software,open,2022-03-26T06:38:54Z,2022-03-26 08:42:02+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11011
11012,b'Sigmoid and relu ONNXRuntimeError',Software,closed,2022-03-26T08:08:06Z,2022-03-27 19:13:03+00:00,2022-04-04T03:19:05Z,1,8,https://api.github.com/repos/microsoft/onnxruntime/issues/11012
11013,"b""MAUI: Unable to use ONNX: Reference to type 'ReadOnlySpan<>' claims it is defined in 'mscorlib', but it could not be found""",Software,open,2022-03-26T15:00:03Z,2022-03-27 19:14:07+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11013
11016,"b'0xc00007b error, could not startup exe at all with onnxruntime1.7 win-x64 cpu on win10'",Software,open,2022-03-27T04:24:19Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11016
11017,b'Failed to build onnxruntime-vitisai docker container due to missing NO_PUBKEY',Software,open,2022-03-27T09:54:53Z,2022-03-27 19:19:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11017
11019,b'Huggingface Transformers Shape Inference Issue',Software,open,2022-03-28T01:50:20Z,2022-03-28 01:50:55+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11019
11020,b'high memory occupy when quantization with big calibrate dataset',Software,open,2022-03-28T07:46:45Z,2022-03-28 21:25:25+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11020
11021,b'kalid-onnxruntime  Fatal error: Gemm is not a registered function/op',Software,open,2022-03-28T09:13:33Z,2022-03-28 21:56:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11021
11022,b'MlasConvertHalfToFloatBuffer   the CPU usage is high.',Software,closed,2022-03-28T11:41:04Z,2022-03-28 21:50:27+00:00,2022-04-14T05:44:30Z,0,16,https://api.github.com/repos/microsoft/onnxruntime/issues/11022
11024,b'A core dump happens when sending zero shape input to Mul operator',Software,closed,2022-03-28T16:33:17Z,2022-03-28 21:34:57+00:00,2022-03-29T21:14:00Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11024
11026,b'Updating state of the network',Software,open,2022-03-28T17:54:09Z,2022-03-28 21:49:18+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11026
11037,b'pip install onnxruntime --- No matching distribution found for onnxruntime',Software,closed,2022-03-28T23:40:02Z,2022-03-28 23:44:41+00:00,2022-03-29T21:42:42Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11037
11041,"b"" Can't constant fold SequenceEmpty node""",Software,open,2022-03-29T13:58:41Z,2022-03-29 13:59:04+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11041
11042,b'CoreML compile error',Software,closed,2022-03-29T15:45:23Z,2022-03-29 16:28:16+00:00,2022-03-29T21:11:07Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11042
11047,b'Cuda EP parallelization issues for batches',Software,open,2022-03-29T23:05:10Z,2022-03-30 00:35:24+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11047
11052,b'Missing benchmark_t5.py',Software,closed,2022-03-30T08:27:59Z,2022-03-30 17:58:20+00:00,2022-03-31T03:10:26Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11052
11054,b'Problems with predictions on MacBook Air with M1 chip in Java project based on Maven (even on onnxruntime 1.11.0 - latest at this moment) - no osx-aarch64 dir in the native runtimes dir',Software,open,2022-03-30T12:52:12Z,2022-03-30 13:34:00+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11054
11057,b'cuda memory free or empty cashe on python',Software,closed,2022-03-30T22:10:26Z,2022-03-30 22:51:40+00:00,2022-03-30T22:51:40Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11057
11064,b'onnxruntime==1.11.0 installation error in python 3.10.0',Software,closed,2022-03-31T03:07:28Z,2022-03-31 04:56:02+00:00,2022-04-05T05:26:16Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/11064
11069,"b'C++ API, ""tried creating tensor with negative value in shape"" error when \'permute\' and \'reshape\' functions are used'",Software,open,2022-03-31T09:55:36Z,2022-04-26 19:33:44+00:00,,26,,https://api.github.com/repos/microsoft/onnxruntime/issues/11069
11072,b'ONNXQuantizer: ValueError: Message onnx.ModelProto exceeds maximum protobuf size of 2GB: 3850562186',Software,closed,2022-03-31T15:19:58Z,2022-03-31 16:58:54+00:00,2022-04-21T17:31:41Z,0,21,https://api.github.com/repos/microsoft/onnxruntime/issues/11072
11073,"b'Dynamic shape is not supported for now, for input:input_1:0'",Software,closed,2022-03-31T15:28:09Z,2022-03-31 17:29:33+00:00,2022-04-06T02:40:18Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/11073
11085,b'Keeping hidden state vector of RNN layers inside the model at online operation',Software,closed,2022-04-01T12:07:59Z,2022-04-01 19:24:48+00:00,2022-04-13T11:24:42Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/11085
11086,b'onnxruntime runs inference on CPU even though GPU is available',Software,closed,2022-04-01T13:23:49Z,2022-04-02 01:08:59+00:00,2022-04-02T01:08:59Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11086
11087,b'Inference session creation freezes',Software,open,2022-04-01T14:41:54Z,2022-04-04 08:40:13+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/11087
11090,"b""compile with cuda error:Couldn't find CUDA library root.""",Software,open,2022-04-02T01:15:46Z,2022-04-02 07:13:23+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11090
11091,"b'Runtime error during infer a Constant Node with ""value_floats"" or ""value_ints""'",Software,closed,2022-04-02T03:45:51Z,2022-04-04 09:28:06+00:00,2022-04-05T21:39:23Z,2,3,https://api.github.com/repos/microsoft/onnxruntime/issues/11091
11092,"b'Always getting ""Failed to create CUDAExecutionProvider""'",Software,open,2022-04-02T03:52:54Z,2022-04-02 15:21:14+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11092
11095,b'ONNX model gives different outputs when run in python vs javascript',Software,closed,2022-04-03T01:54:39Z,2022-04-04 05:51:04+00:00,2022-04-04T22:22:45Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11095
11096,b'Observing difference in outputs from decoder with IO bindings.',Software,closed,2022-04-03T15:09:28Z,2022-04-03 15:09:28+00:00,2022-04-05T09:13:44Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11096
11098,b'ONNX Runtime Mobile Training (Android/iOS)',Software,open,2022-04-04T03:01:14Z,2022-04-04 03:21:25+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11098
11099,b'Performance reduction due to copying of output OrtValues to numpy arrays',Software,open,2022-04-04T07:58:51Z,2022-04-05 05:56:20+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11099
11101,"b""onnxruntime.capi.onnxruntime_pybind11_state.OrtVal' object has no attribute '_get_c_value'""",Software,closed,2022-04-04T11:16:40Z,2022-04-04 11:58:15+00:00,2022-04-04T11:58:15Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11101
11104,b'Link to onnxruntime test data is down',Software,closed,2022-04-04T16:58:08Z,2022-04-04 19:40:12+00:00,2022-04-04T19:40:12Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11104
11107,b'Slice behavior wrong with negative step and end = INT_MAX',Software,open,2022-04-04T18:14:04Z,2022-04-04 21:17:38+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11107
11108,b'Integrate with ONNX 1.11.0 release branch',Software,closed,2022-04-04T18:21:55Z,2022-04-04 18:21:55+00:00,2022-04-04T18:22:40Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11108
11117,b'python 3.10 release ETA?',Software,closed,2022-04-05T09:22:10Z,2022-04-05 16:57:47+00:00,2022-04-12T03:18:23Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/11117
11118,b'Memory leak during inference',Software,closed,2022-04-05T10:57:01Z,2022-04-05 16:58:23+00:00,2022-04-06T21:49:36Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11118
11119,b'Conversion of  T5 decoder with past_key_values to float16.',Software,open,2022-04-05T14:00:45Z,2022-04-05 14:00:45+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11119
11122,b'Using DnnlExecutionProvider for inference is much slower  than using CPUExecutionProvider.',Software,open,2022-04-06T07:04:21Z,2022-04-06 19:47:23+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11122
11123,b'Different detection output values for C++ and Python with onnxruntime ',Software,open,2022-04-06T08:16:02Z,2022-05-08 06:34:57+00:00,,31,,https://api.github.com/repos/microsoft/onnxruntime/issues/11123
11124,b'[Documentation Request] Undocumented removed args in mobile performance tuning page',Software,closed,2022-04-06T09:19:42Z,2022-04-06 10:02:28+00:00,2022-04-13T01:11:43Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/11124
11129,b'Failed to build with protobuf 3.20',Software,open,2022-04-06T20:36:44Z,2022-04-14 19:36:21+00:00,,7,,https://api.github.com/repos/microsoft/onnxruntime/issues/11129
11133,b'Documentation for io binding',Documentation,open,2022-04-07T00:06:02Z,2022-04-10 22:29:41+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/11133
11135,b'docker container linux  run onnxruntime infer  core dumped',Documentation,open,2022-04-07T02:52:33Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11135
11137,b'onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Load model from ./onnx_files/GPT2_opt_with_fusion.onnx failed:Node (Reshape_Fuse_0) Op (Reshape) [ShapeInferenceError] Cannot parse data from external tensors. Please load external data into raw data for tensor: constant_shape_0',Documentation,open,2022-04-07T07:05:19Z,2022-08-04 14:31:29+00:00,,119,,https://api.github.com/repos/microsoft/onnxruntime/issues/11137
11140,b'create inference session failed for onnxrt1.9.0',Documentation,closed,2022-04-07T09:02:43Z,2022-04-08 05:43:36+00:00,2022-04-08T05:43:36Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11140
11141,"b'C# - InferenceSession fails with ""invalid weights type of Int8"" even though Int8 enabled in TensorRT'",Software,closed,2022-04-07T15:49:28Z,2022-04-07 22:03:40+00:00,2022-04-20T03:14:15Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/11141
11142,b'Documentation for c++ libs linux installs',Software,closed,2022-04-07T16:19:18Z,2022-04-07 17:28:25+00:00,2022-04-07T17:28:25Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11142
11151,b'[question] yolov5-onnx-float16 not improve on GPU',Software,open,2022-04-08T03:48:23Z,2022-04-13 02:31:26+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/11151
11156,b'How to use Flask with onnxruntime',Software,open,2022-04-08T14:05:32Z,2022-04-25 08:39:35+00:00,,16,,https://api.github.com/repos/microsoft/onnxruntime/issues/11156
11159,b'Instruction level profiling in onnxruntime ',Software,open,2022-04-08T16:08:15Z,2022-04-08 19:35:22+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11159
11165,b'the inference time of c++ onnxruntime and python onnxruntime',Software,closed,2022-04-11T03:36:33Z,2022-04-12 03:18:30+00:00,2022-04-12T03:18:30Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11165
11166,b'bug need to solve',Software,closed,2022-04-11T04:55:31Z,2022-04-11 09:00:20+00:00,2022-04-12T07:03:57Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11166
11169,b'No c++ header files for building custom op',Software,open,2022-04-11T08:01:01Z,2022-04-12 08:29:19+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11169
11173,b'A normal output of convolution layer multiplies infinity will result in NaN',Software,open,2022-04-11T16:38:19Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11173
11178,b'Build from source issue on Windows',Software,open,2022-04-11T20:04:31Z,2022-04-11 22:35:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11178
11181,b'onnxruntime-web is 11-17x times slower than native inference',Software,open,2022-04-12T00:22:24Z,2022-04-12 03:01:28+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11181
11182,b'Problems building from source directly on Raspberry Pi 3B+ ARM32 version',Software,closed,2022-04-12T03:13:15Z,2022-04-12 03:46:44+00:00,2022-04-12T03:46:44Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11182
11186,b'Custom Op does not support dynamic input/output number',Software,open,2022-04-12T08:34:09Z,2022-04-12 17:23:01+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11186
11188,b'dlopen failed for libonnxruntime4j_jni.so library',Software,closed,2022-04-12T13:18:43Z,2022-04-12 14:00:19+00:00,2022-04-12T14:00:19Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11188
11189,b'Evaluating oonxruntime .ORT format by Python',Software,closed,2022-04-12T14:14:31Z,2022-04-12 17:33:17+00:00,2022-04-13T12:31:09Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11189
11192,b'Can not build Webassembly version',Software,closed,2022-04-12T20:25:41Z,2022-04-12 21:46:35+00:00,2022-04-15T10:14:52Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/11192
11195,b'Performance degradation on GatherElements',Software,open,2022-04-12T23:28:19Z,2022-04-13 05:21:08+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11195
11198,b'Saving GPT2LMHeadModel_ConfigurableOneStepSearch error.',Software,open,2022-04-13T02:26:11Z,2022-04-13 05:22:19+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11198
11200,b'How to compress the sparse matrix in onnx model',Software,open,2022-04-13T03:17:24Z,2022-04-13 18:28:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11200
11201,"b'Inference time for qunatized onnx models, TensorRT> CUDA> CPU. Is this expected? '",Software,open,2022-04-13T06:02:57Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11201
11202,b'Load the ONNX model  error',Software,closed,2022-04-13T08:19:07Z,2022-04-13 18:32:59+00:00,2022-04-15T08:31:11Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/11202
11204,b'linker error douring build for Xamarin.ios on Apple M1 based host',Software,open,2022-04-13T10:41:06Z,2022-04-13 18:31:01+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11204
11205,"b""auto_set_affinity can't be set to true for parallel executor""",Software,open,2022-04-13T11:18:15Z,2022-04-13 18:00:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11205
11210,b'Create script to export BART encoder and decoder for use with custom beam search op',Software,open,2022-04-13T20:42:21Z,2022-04-13 20:42:21+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11210
11212,"b""ImportError: cannot import name 'torch_interop_utils' from 'onnxruntime.training.ortmodule.torch_cpp_extensions'""",Software,open,2022-04-14T12:48:26Z,2022-04-14 17:36:16+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11212
11217,b'[web] ~100 seconds to load model/InferenceSession',Software,open,2022-04-14T20:13:49Z,2022-04-14 20:48:43+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11217
11218,b'[web] Why is `ort.env.wasm.proxy` not `true` by default?',Software,open,2022-04-14T20:32:05Z,2022-04-14 20:49:19+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11218
11222,b'Tensor::SizeInBytes() returns incorrect size for empty strided tensors',Software,open,2022-04-15T02:00:01Z,2022-04-15 02:00:03+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11222
11225,b'Question on quantize tool ',Software,open,2022-04-15T07:54:16Z,2022-04-15 20:21:43+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11225
11227,b'Error build ORT on RTX3090 Win10 VS2022',Software,open,2022-04-15T10:29:30Z,2022-04-15 20:22:06+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11227
11229,b'Session load fails with Detectron2',Software,closed,2022-04-15T15:56:48Z,2022-04-19 16:16:36+00:00,2022-04-21T14:00:40Z,4,5,https://api.github.com/repos/microsoft/onnxruntime/issues/11229
11230,b'Unable to use any OnnxRuntime packages >1.7 with CMake',Software,closed,2022-04-15T19:44:24Z,2022-04-18 18:04:23+00:00,2022-04-18T18:04:23Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/11230
11232,b'NonZero shape inference behavior with scalar input mismatches ONNX and PyTorch',Software,open,2022-04-15T21:57:06Z,2022-04-15 21:57:06+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11232
11234,b'Quantied model get impossiable to inference result mode.',Software,closed,2022-04-16T13:14:52Z,2022-04-18 05:02:56+00:00,2022-04-18T14:58:31Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/11234
11235,b'Unhandled exception at 0x00007FFABE6A9538 (cudnn_cnn_infer64_8.dll) in Onnx.exe',Software,open,2022-04-16T17:48:50Z,2022-04-18 23:16:29+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/11235
11236,b'Silly error message',Software,open,2022-04-16T19:29:49Z,2022-04-19 20:58:59+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/11236
11239,"b'[React Native .ort Model Loading Error] ""Error: Can\'t load a model: No content provider: ...""'",Software,open,2022-04-16T21:01:13Z,2022-04-18 05:05:39+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11239
11240,"b'I want use gpu on my jetson nx2 platform with c++, how should i do?'",Software,open,2022-04-17T03:48:20Z,2022-04-18 05:07:27+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11240
11241,"b'One ONNX graph will result in an ""UpdateState bias should be 1D"" Error on GPU but success on CPU'",Software,open,2022-04-17T09:30:42Z,2022-04-21 21:56:14+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/11241
11242,b'Concat unable to quantized in onnxruntime?',Software,closed,2022-04-17T14:21:39Z,2022-04-18 05:14:49+00:00,2022-04-21T17:32:57Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/11242
11243,b'Windows PDB files?',Software,closed,2022-04-17T18:49:27Z,2022-04-18 18:08:39+00:00,2022-04-18T18:08:39Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11243
11245,b'Error in converting the model with mixed precision.',Software,closed,2022-04-18T10:48:45Z,2022-04-18 10:48:46+00:00,2022-04-18T18:56:09Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11245
11246,"b""IOBinding doesn't release the Python GIL""",Software,closed,2022-04-18T11:23:39Z,2022-04-18 17:15:41+00:00,2022-04-18T20:07:45Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11246
11253,b'Test data 404',Software,open,2022-04-18T22:03:11Z,2022-04-19 23:04:16+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11253
11254,b'Input tensor for if node experiences redundant host <-> device memory copies',Software,open,2022-04-18T22:31:24Z,2022-04-21 17:13:56+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/11254
11257,"b""Non-zero status code returned while running Slice node. Name:'Slice_24' Status Message: slice.cc:153 FillVectorsFromInput Starts must be a 1-D array""",Software,open,2022-04-19T03:49:59Z,2022-04-20 22:27:26+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11257
11258,b'how to convert the quantized onnx model gnerated by ort into tensorrt?',Software,closed,2022-04-19T06:32:59Z,2022-04-19 21:09:42+00:00,2022-04-19T21:09:42Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11258
11259,b'CRF module',Software,closed,2022-04-19T08:23:56Z,2022-04-19 08:41:40+00:00,2022-04-20T00:58:49Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11259
11260,b'additional gains from QDQ',Software,closed,2022-04-19T12:04:34Z,2022-04-19 20:55:56+00:00,2022-04-19T20:55:56Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11260
11262,b'Empty strided tensors are contiguous',Software,open,2022-04-19T16:50:18Z,2022-04-19 16:50:19+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11262
11268,b'Unsupported If operator in gradient builder for Hugging Face Transformers RoBERTa model',Software,open,2022-04-20T04:29:20Z,2022-05-13 17:17:05+00:00,,23,,https://api.github.com/repos/microsoft/onnxruntime/issues/11268
11270,b'optimize_model : new model types',Software,open,2022-04-20T07:23:05Z,2022-04-20 20:35:54+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11270
11271,b'TensorRT EP could not open shared library from ?',Software,open,2022-04-20T07:24:44Z,2022-04-20 20:28:27+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11271
11272,b'Disabled Test No Longer Build After CUDA EP Refactorization',Software,open,2022-04-20T08:46:18Z,2022-04-20 17:45:44+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11272
11273,"b'"" CMAKE_CUDA_ARCHITECTURES must be valid if set"" when manually building onnx runtime on jetson nano '",Software,closed,2022-04-20T09:06:02Z,2022-04-20 17:16:00+00:00,2022-04-20T17:16:00Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11273
11274,b'The onnx model of IMDN is slower than the original pytorch model and output many warnings ',Software,open,2022-04-20T11:10:32Z,2022-04-21 03:29:40+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11274
11276,b'provider_api.h can easily cause redefinition error',Software,closed,2022-04-20T12:17:06Z,2022-04-20 12:19:55+00:00,2022-04-20T16:44:35Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11276
11277,b'pulled master 1.12 quantization get unexpected result',Software,open,2022-04-20T16:08:16Z,2022-04-20 22:01:37+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11277
11278,"b""LSTM export ONNX:Non-zero status code returned while running ScatterElements node. Name:'ScatterElements_880'""",Software,open,2022-04-20T16:20:13Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11278
11279,b'Type Error when training Hugging Face Transformers GPT2 with fp16 enabled',Software,open,2022-04-20T17:30:44Z,2022-04-20 20:39:01+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11279
11284,b'sklearn SVM model converted into ONNX model but gives different output results',Software,open,2022-04-20T21:40:43Z,2022-04-20 22:28:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11284
11286,b'Quantize model accuracy drops',Software,open,2022-04-20T22:54:06Z,2022-04-21 20:07:07+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11286
11292,"b""Can't find gpt2_helper  ModuleNotFoundError: No module named 'gpt2_helper'""",Software,open,2022-04-21T05:59:15Z,2022-04-21 20:08:55+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11292
11293,b'Why gpt2-xl (based transformer-xl) onnx slower than the originer pytorch',Software,open,2022-04-21T08:26:07Z,2022-04-21 19:56:07+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11293
11295,b'is the effect of onnx on Bert affected by python version?',Software,open,2022-04-21T12:00:25Z,2022-04-21 19:55:13+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11295
11297,b'C# Api for Training',Software,closed,2022-04-21T15:00:53Z,2022-04-21 19:49:46+00:00,2022-04-26T17:57:39Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/11297
11305,b'Use unregister_custom_op_symbolic in pytorch_export_contrib_ops',Software,open,2022-04-21T23:57:49Z,2022-07-21 17:47:55+00:00,,90,,https://api.github.com/repos/microsoft/onnxruntime/issues/11305
11312,b'Conv2d_transpose requires asymmetric padding which the CUDA EP currently does not support',Software,open,2022-04-22T07:58:14Z,2022-04-25 17:49:48+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/11312
11313,b'ValueError: Only float type quantization is supported. Weights onnx::Concat_1052 is INT64. ',Software,open,2022-04-22T08:46:56Z,2022-05-02 18:35:37+00:00,,10,,https://api.github.com/repos/microsoft/onnxruntime/issues/11313
11315,b'Use black and isort Python auto formatting',Software,closed,2022-04-22T15:43:41Z,2022-04-22 15:43:41+00:00,2022-04-29T17:25:57Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/11315
11322,b'Sample code in CUDA EP does not compile',Documentation,closed,2022-04-22T19:42:52Z,2022-04-24 23:46:38+00:00,2022-06-08T00:39:20Z,2,46,https://api.github.com/repos/microsoft/onnxruntime/issues/11322
11323,b'CPUExecutionProvider but GPU visible',Documentation,closed,2022-04-22T20:20:02Z,2022-04-26 11:20:58+00:00,2022-04-26T11:23:01Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/11323
11332,b'pip could not find a version that satisfies the requirement',Software,closed,2022-04-23T10:44:35Z,2022-04-24 06:24:35+00:00,2022-04-24T06:24:35Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11332
11333,b'TVM EP and TensorRT EP do not support dynamic inputs',Software,open,2022-04-23T17:41:20Z,2022-05-03 23:59:02+00:00,,10,,https://api.github.com/repos/microsoft/onnxruntime/issues/11333
11341,b'Tensor type mismatch. T !=N11onnxruntime17PrimitiveDataTypeIfEE error when inferencing with resnet50_v1.onnx in C++',Software,closed,2022-04-25T07:25:40Z,2022-05-04 00:49:16+00:00,2022-05-04T21:22:48Z,8,9,https://api.github.com/repos/microsoft/onnxruntime/issues/11341
11342,b'OrtIoBinding GetBoundOutputValues to CPU from CUDA',Software,closed,2022-04-25T08:30:40Z,2022-05-04 18:25:22+00:00,2022-05-15T03:42:56Z,9,19,https://api.github.com/repos/microsoft/onnxruntime/issues/11342
11343,b'MacOS M1 binary compilation and possibility to fine tune a model in C++',Software,open,2022-04-25T13:35:45Z,2022-05-04 14:05:57+00:00,,9,,https://api.github.com/repos/microsoft/onnxruntime/issues/11343
11347,b'Possible to run inference purely sequentially and not have onnx pin a thread',Software,closed,2022-04-25T20:17:23Z,2022-05-18 15:23:26+00:00,2022-05-18T15:23:26Z,22,22,https://api.github.com/repos/microsoft/onnxruntime/issues/11347
11348,b'CUDAExecutionProvider optimized model adds incompatible node resulting in Failed to find kernel for MemcpyToHost',Software,open,2022-04-25T22:17:55Z,2022-05-02 18:29:18+00:00,,6,,https://api.github.com/repos/microsoft/onnxruntime/issues/11348
11350,b'Integrate LGTM for code quality monitoring',Software,closed,2022-04-25T22:57:07Z,2022-04-25 22:57:44+00:00,2022-04-25T23:59:09Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11350
11351,b'Set up Codecov for test coverage monitoring',Software,open,2022-04-25T23:01:04Z,2022-04-25 23:01:04+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11351
11356,b'Lower performance on Inceptionv3/4 model with TensorRT EP than TensorRT directly',Software,open,2022-04-26T05:32:41Z,2022-04-26 05:36:41+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11356
11357,b'C++ inference with DirectML:How to use DirectML in C++ library?',Software,closed,2022-04-26T05:45:51Z,2022-04-27 04:12:48+00:00,2022-04-27T04:12:49Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11357
11360,"b'For CUDA Provider, ConcatFromSequence Op Used Inappropriate cudaMemcpyAsync Kind'",Software,closed,2022-04-26T07:42:20Z,2022-04-26 19:05:03+00:00,2022-04-27T18:21:16Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11360
11362,b'CUDAExecutionProvider not releasing memory after terminate session',Software,open,2022-04-26T11:10:58Z,2022-05-12 01:25:33+00:00,,15,,https://api.github.com/repos/microsoft/onnxruntime/issues/11362
11363,b'Can ONNX get gradient directly through API like torch.autograd.grad(...)??',Software,closed,2022-04-26T13:04:52Z,2022-04-27 04:11:03+00:00,2022-04-27T04:11:03Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11363
11367,b'Using If node on top of an ONNX model makes it 3-4X slower during inference',Software,closed,2022-04-26T19:22:24Z,2022-04-26 19:22:25+00:00,2022-05-01T08:56:53Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/11367
11373,"b'""Parameter \'b\' set but not used"" error on M1 mac '",Software,closed,2022-04-27T02:14:40Z,2022-04-27 04:08:12+00:00,2022-04-28T17:51:59Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11373
11377,"b'When I build ios framework with ""--use_coreml"", can this framework run on iOS 11.0 ?'",Software,closed,2022-04-27T12:02:44Z,2022-05-01 16:21:03+00:00,2022-05-01T16:21:03Z,4,4,https://api.github.com/repos/microsoft/onnxruntime/issues/11377
11378,b'ONNX Runtime compatibility for Jetson AGX Xavier',Software,open,2022-04-27T13:43:23Z,2022-05-03 18:56:56+00:00,,6,,https://api.github.com/repos/microsoft/onnxruntime/issues/11378
11384,"b'[fp16] model generates NaN results on fp16, while it generates correct results on fp32'",Software,closed,2022-04-28T00:07:53Z,2022-04-28 16:26:17+00:00,2022-04-29T01:17:43Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11384
11446,"b'crashed in construction of Ort::Env, xcode13, iPhoneX'",Software,open,2022-04-28T09:39:31Z,2022-05-05 15:21:01+00:00,,7,,https://api.github.com/repos/microsoft/onnxruntime/issues/11446
11392,b'Potential use after free',Software,closed,2022-04-28T22:20:35Z,2022-04-28 23:28:00+00:00,2022-04-28T23:28:00Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11392
11394,"b""iOS: Attempting to JIT compile method ''Microsoft.ML.OnnxRuntime.Tensors.DenseTensor`1<single> MyClass:SomeMethod()'' while running in aot-only mode""",Software,closed,2022-04-29T07:29:14Z,2022-04-29 12:50:39+00:00,2022-05-03T08:11:24Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/11394
11395,b'ONNXRuntime Issue',Software,closed,2022-04-29T08:56:42Z,2022-05-02 18:56:12+00:00,2022-05-02T18:56:12Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/11395
11397,b'About running onnxruntime in singularity container',Software,open,2022-04-29T11:52:20Z,2022-05-02 18:29:49+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/11397
11399,b'Benchmark code using torch.onnx.export',Software,open,2022-04-29T19:34:42Z,2022-05-03 23:56:30+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/11399
11400,b'[Documentation Request]',Software,closed,2022-04-29T19:52:38Z,2022-05-02 18:31:43+00:00,2022-05-02T18:31:42Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/11400
11406,b'Can API CreateTensorWithDataAsOrtValue take const void* as the input parameter type?',Software,closed,2022-04-29T23:56:56Z,2022-05-04 18:01:46+00:00,2022-05-05T20:44:41Z,4,5,https://api.github.com/repos/microsoft/onnxruntime/issues/11406
11407,b'About building a singularity container with reference to DockerFile.cuda',Software,closed,2022-04-30T02:33:39Z,2022-05-03 18:13:56+00:00,2022-05-03T18:13:56Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/11407
11408,b'CSharp Example does not work with new version of imageSharp due to API Change',Software,closed,2022-04-30T06:00:21Z,2022-05-02 18:26:25+00:00,2022-05-10T17:26:37Z,2,10,https://api.github.com/repos/microsoft/onnxruntime/issues/11408
11409,b'About building onnxruntime singularity container with DockerFile',Software,open,2022-04-30T11:52:11Z,2022-04-30 11:52:21+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11409
11410,b'SIGSEGV when convert_version',Software,closed,2022-04-30T16:34:44Z,2022-05-02 18:30:57+00:00,2022-05-02T18:30:57Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/11410
11412,b'Build error in ubuntu 20.04',Software,closed,2022-05-01T12:53:33Z,2022-05-02 14:59:38+00:00,2022-05-02T14:59:37Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11412
11413,b' Issue loading onnx model to wasm using `onnxruntime-web`',Software,closed,2022-05-01T16:04:16Z,2022-05-02 18:21:10+00:00,2022-05-06T20:09:44Z,1,5,https://api.github.com/repos/microsoft/onnxruntime/issues/11413
11414,b'Update docs for building with oneDNN execution provider GPU support. OpenCL SDK deprecated.',Documentation,open,2022-05-01T20:43:50Z,2022-05-02 18:20:59+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11414
11415,b'Static quantization+per_channel is wrong for MobileNetV3 ',Software,open,2022-05-02T08:06:15Z,2022-05-02 18:20:43+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11415
11418,b'GPU pipelines failing because of CUDA signing issues',Software,closed,2022-05-02T18:50:51Z,2022-05-02 18:50:51+00:00,2022-05-03T19:05:20Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11418
11433,b'Is the OrtEnvironment  only one in global?',Software,closed,2022-05-04T05:43:13Z,2022-05-04 16:07:41+00:00,2022-05-04T16:07:41Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11433
11434,"b""cannot import name 'quantize_qat' from 'onnxruntime.quantization'""",Software,closed,2022-05-04T06:15:52Z,2022-05-04 17:55:33+00:00,2022-05-09T21:46:13Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/11434
11435,b'How to use more gpu to parallel compute?',Software,closed,2022-05-04T07:14:49Z,2022-05-04 16:10:36+00:00,2022-05-04T16:10:39Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11435
11436,b'Can I quantize TreeEnsembleClassifier op?',Software,open,2022-05-04T08:41:09Z,2022-05-04 16:17:37+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11436
11438,b'Onnx T5 fp16 conversion without past_key_values',Software,open,2022-05-04T16:01:54Z,2022-05-04 16:01:55+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11438
11444,b'Add  a C/C++ header with full semantic version of the library',Software,closed,2022-05-05T11:17:31Z,2022-05-05 16:28:52+00:00,2022-05-06T19:42:40Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11444
11447,"b""Wrong type used in ACL provider's pool.cc""",Software,closed,2022-05-05T16:04:52Z,2022-05-05 17:13:43+00:00,2022-06-07T16:06:32Z,0,33,https://api.github.com/repos/microsoft/onnxruntime/issues/11447
11449,b'onnxruntime gpu inference benchmarking',Software,closed,2022-05-05T17:12:12Z,2022-05-05 23:39:06+00:00,2022-05-05T23:39:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11449
11451,b'JAVA API does not handle exceptions correctly - causing crash or potential memory leak',Software,open,2022-05-05T21:43:10Z,2022-05-05 21:43:10+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11451
11453,b'How to run a double input onnx model',Software,open,2022-05-06T09:53:36Z,2022-05-06 17:25:52+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11453
11455,b'does onnxruntime support xlnet model?',Software,open,2022-05-06T15:36:48Z,2022-05-06 17:30:44+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11455
11462,b'Build fail on Jetson Nano',Software,open,2022-05-07T23:15:17Z,2022-05-09 16:54:23+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11462
11464,b'Update docs for CUDA Execution Provider',Software,closed,2022-05-09T08:23:44Z,2022-05-09 16:50:02+00:00,2022-06-08T18:57:52Z,0,30,https://api.github.com/repos/microsoft/onnxruntime/issues/11464
11469,b'build for Android from source (Windows 11)',Software,closed,2022-05-09T19:14:33Z,2022-05-09 21:15:12+00:00,2022-05-10T13:58:39Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11469
11472,b'Remove reference to symbolic_helper because it is supposed to be private',Software,closed,2022-05-09T23:14:05Z,2022-05-09 23:14:21+00:00,2022-05-10T01:04:07Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11472
11473,b'Build migraphx EP from source failing on master branch',Software,open,2022-05-09T23:19:11Z,2022-05-09 23:23:16+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11473
11476,b'NOT_IMPLEMENTED : Failed to find kernel for FusedConv',Software,open,2022-05-10T03:18:31Z,2022-05-10 22:38:41+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11476
11477,b'Add Ascend backend support',Software,open,2022-05-10T03:44:46Z,2022-05-10 22:35:16+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11477
11480,b'Windows11 x64 prebuilt',Software,closed,2022-05-10T20:17:38Z,2022-05-10 22:33:23+00:00,2022-05-10T22:49:24Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11480
11485,b'How to know what execution provides the models in zoo are runnable on\xef\xbc\x9f',Software,open,2022-05-11T01:48:04Z,2022-05-12 00:01:25+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11485
11488,b'Android NNAPI: Exception during initialization: unordered_map::at: key not found',Software,open,2022-05-11T02:46:55Z,2022-05-11 23:28:26+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11488
11490,b'InferenceSession giving different results than the original sklearn SVC model',Software,open,2022-05-11T14:37:22Z,2022-05-12 01:17:57+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11490
11496,b'Inconsistent result of Resize compared to the reference implementation from ONNX',Software,open,2022-05-12T02:32:40Z,2022-05-13 16:40:08+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11496
11497,b'How to use float_16 on onnxruntime Inference',Software,closed,2022-05-12T02:48:50Z,2022-05-12 02:51:15+00:00,2022-05-12T17:31:25Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11497
1214,"b'Build fails, complains ceil is not a member of std'",Software,closed,2019-06-12T17:41:39Z,2019-06-12 21:06:49+00:00,2019-06-13T00:59:22Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1214
1215,"b'Build fails, complains __builtin_isnan is not a member of std'",Software,closed,2019-06-12T17:47:09Z,2019-06-12 21:07:23+00:00,2019-06-13T00:59:32Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1215
1224,b'Maxpool unexpected shape with dilation>1',Software,closed,2019-06-13T19:58:37Z,2019-06-13 20:01:46+00:00,2019-06-27T19:09:40Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/1224
1228,b'How to limit the cpu_num to 1?',Software,closed,2019-06-14T08:14:14Z,2019-06-14 15:17:18+00:00,2019-10-07T22:04:30Z,0,115,https://api.github.com/repos/microsoft/onnxruntime/issues/1228
1229,b'Problem with loading converted onnx model',Software,closed,2019-06-14T10:48:48Z,2019-06-14 23:43:27+00:00,2019-07-11T18:35:33Z,0,27,https://api.github.com/repos/microsoft/onnxruntime/issues/1229
1230,b'MeanVarianceNormalization operator test uses undocumented attributes in ONNX.',Software,closed,2019-06-14T14:00:15Z,2019-06-14 18:45:06+00:00,2019-06-14T19:38:54Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1230
1232,b'ARM build fail both on cross and native compile (requested alignment 128 is larger than 64)',Software,closed,2019-06-15T09:52:15Z,2019-06-15 09:57:11+00:00,2019-06-24T17:12:03Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/1232
1234,b'Scan Op support',Software,closed,2019-06-17T06:17:08Z,2019-06-17 06:49:44+00:00,2019-06-17T06:49:44Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1234
1246,b'Fallback to CPU execution provider for Op type: Unsqueeze',Software,closed,2019-06-18T01:34:20Z,2019-06-19 01:26:12+00:00,2019-06-19T01:28:01Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1246
1252,b'Python wheels does not include libtvm.so when --use_tvm is switched on',Software,closed,2019-06-19T07:23:57Z,2019-06-19 17:14:11+00:00,2019-06-29T00:11:35Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/1252
1253,b'Remove executor threadpool',Software,closed,2019-06-19T12:58:29Z,2019-06-19 17:11:49+00:00,2019-06-19T17:26:50Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1253
1256,b'Python Wrapper for Raspberry Pi',Software,closed,2019-06-19T18:15:02Z,2019-06-20 07:15:16+00:00,2019-11-06T21:30:51Z,0,140,https://api.github.com/repos/microsoft/onnxruntime/issues/1256
1257,b'YOLO V3 error ',Software,closed,2019-06-19T18:49:35Z,2019-06-19 18:52:36+00:00,2019-06-20T18:48:44Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1257
1258,b'ONNX backend test: test_mod_float_mixed_sign_example_cpu is failing ',Software,closed,2019-06-19T19:03:35Z,2019-06-19 19:06:24+00:00,2019-06-19T19:06:24Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1258
1260,b'Query the version number of OnnxRuntime and/or of a Model?',Software,closed,2019-06-19T21:28:38Z,2019-06-20 00:54:30+00:00,2019-06-20T22:42:13Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1260
1272,b'loop output empty tensor',Software,closed,2019-06-21T06:54:02Z,2019-06-21 07:17:57+00:00,2019-06-21T07:17:57Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1272
1273,b'Mobile GPU NVIDIA Quatro - performance issues',Software,closed,2019-06-21T14:42:31Z,2019-06-22 00:15:55+00:00,2019-08-02T17:31:50Z,0,42,https://api.github.com/repos/microsoft/onnxruntime/issues/1273
1278,b'Build failing on Windows: onnxruntime master branch',Software,closed,2019-06-21T22:39:51Z,2019-06-24 21:44:50+00:00,2019-06-24T21:45:00Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/1278
1279,b'Build with Intel C++ Compiler',Software,closed,2019-06-21T23:24:55Z,2019-06-23 04:18:47+00:00,2019-06-28T00:17:54Z,1,6,https://api.github.com/repos/microsoft/onnxruntime/issues/1279
1281,b'MKLDNN Update',Software,closed,2019-06-22T04:03:53Z,2019-06-24 16:10:19+00:00,2020-03-10T23:10:16Z,2,262,https://api.github.com/repos/microsoft/onnxruntime/issues/1281
1284,b'Loading ONNX model fails with Fatal error: ConstantFill is not a registered function/op',Software,closed,2019-06-24T07:16:07Z,2019-06-24 07:39:27+00:00,2019-06-25T11:03:00Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1284
1286,b'Extremely Slow Download Speed of Test Data in China',Software,closed,2019-06-24T08:43:15Z,2019-06-24 18:06:32+00:00,2019-06-26T00:16:30Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1286
1294,b'Expose session options in server command line',Software,closed,2019-06-26T14:26:17Z,2019-06-26 14:26:18+00:00,2020-07-25T07:40:17Z,0,394,https://api.github.com/repos/microsoft/onnxruntime/issues/1294
1297,b'Documentation on JSON profile report',Documentation,closed,2019-06-26T18:51:00Z,2019-06-26 21:41:37+00:00,2019-10-21T21:50:23Z,0,117,https://api.github.com/repos/microsoft/onnxruntime/issues/1297
1300,b'Runtime issue with mkldnn',Documentation,closed,2019-06-26T21:40:31Z,2019-06-26 21:54:21+00:00,2019-06-26T21:54:21Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1300
1304,b'Adding metric logging to Runtime Server',Software,closed,2019-06-27T00:53:29Z,2019-06-27 16:41:54+00:00,2020-07-25T07:40:28Z,0,394,https://api.github.com/repos/microsoft/onnxruntime/issues/1304
1305,b'Msbuild fails using onnxruntime.sln',Software,closed,2019-06-27T01:33:33Z,2019-06-27 16:42:11+00:00,2019-07-03T20:00:12Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/1305
1306,b'Improve Test Data Compression',Software,closed,2019-06-27T03:29:28Z,2019-06-27 07:14:58+00:00,2019-06-27T07:14:57Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1306
1308,b'python onnxruntime not using multiple threads for application of ml model',Software,closed,2019-06-27T14:07:26Z,2019-06-27 16:09:44+00:00,2020-03-10T23:22:56Z,0,257,https://api.github.com/repos/microsoft/onnxruntime/issues/1308
1311,b'cannot use fasterrcnn onnx model in c# api',Software,closed,2019-06-27T21:29:35Z,2019-06-28 19:44:23+00:00,2019-06-28T19:44:23Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1311
1313,b'OneHot should treat negative axis as range from last dimension',Software,closed,2019-06-28T03:28:38Z,2019-06-28 21:17:02+00:00,2019-07-01T21:29:34Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/1313
11502,"b'C#, How to access the different output layer of inference (semantic segmentation)'",Software,open,2022-05-12T15:04:03Z,2022-05-13 16:42:32+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11502
11505,b'[Documentation Request]',Software,open,2022-05-12T16:31:45Z,2022-05-13 16:43:29+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11505
11507,b'Load ORT Model in React-Native Expo',Software,closed,2022-05-12T20:01:43Z,2022-05-13 16:46:15+00:00,2022-05-27T15:12:57Z,0,14,https://api.github.com/repos/microsoft/onnxruntime/issues/11507
11509,b'onnxruntime error',Software,open,2022-05-12T21:04:25Z,2022-05-13 16:48:42+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11509
11510,b'[Documentation Request] tensorAt for Csharp?',Software,open,2022-05-12T21:18:12Z,2022-05-13 16:50:25+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11510
11511,b'Inference on Onnx with external data not working since PR 11320 (location planning logic)',Software,closed,2022-05-12T22:00:08Z,2022-05-12 22:00:09+00:00,2022-06-01T21:46:13Z,0,19,https://api.github.com/repos/microsoft/onnxruntime/issues/11511
11512,"b""ARM64 build need manually add onnxruntime.lb and it's path to the VC project file""",Software,open,2022-05-12T22:59:05Z,2022-05-13 16:53:35+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11512
11515,"b""Can't run a model on ARM64 device""",Software,closed,2022-05-13T00:11:33Z,2022-06-06 20:54:19+00:00,2022-06-06T20:54:19Z,24,24,https://api.github.com/repos/microsoft/onnxruntime/issues/11515
11517,b'About Convolution Implementation',Software,open,2022-05-13T15:56:10Z,2022-05-13 16:54:47+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11517
11519,"b'Wish to use ""convert_onnx_models_to_ort.py"" and requesting guide'",Software,closed,2022-05-13T20:06:10Z,2022-05-16 17:11:16+00:00,2022-05-31T20:02:23Z,2,17,https://api.github.com/repos/microsoft/onnxruntime/issues/11519
11523,b'Tile fails for scalars on CPU',Software,open,2022-05-13T22:58:16Z,2022-05-20 00:03:24+00:00,,6,,https://api.github.com/repos/microsoft/onnxruntime/issues/11523
11525,b'Fake quantization when the padding of convollution layer is asymmetric or pad_w != pad_h',Software,open,2022-05-14T16:15:50Z,2022-07-11 23:02:09+00:00,,58,,https://api.github.com/repos/microsoft/onnxruntime/issues/11525
11528,b'How to use the onnxruntime API to request cuda memory ',Software,closed,2022-05-15T09:28:20Z,2022-05-17 21:06:13+00:00,2022-05-18T19:11:45Z,2,3,https://api.github.com/repos/microsoft/onnxruntime/issues/11528
11529,b'How to release a session properly?',Software,open,2022-05-15T09:30:00Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11529
11530,b'Fail to convert model with reusable blocks',Software,open,2022-05-15T10:23:14Z,2022-05-15 13:09:55+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11530
11532,b'CPUExecutionProvider outputs wrong value for a quantized model',Software,open,2022-05-16T02:47:39Z,2022-05-19 17:57:05+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/11532
11535,b'TensorRT EP session creation fails with invalid weights type of Int8 when ORT_TENSORRT_INT8_ENABLE set to 1',Software,open,2022-05-16T10:53:34Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11535
11536,b'onnxruntime cannot used in a subgraph an output created in the main graph',Software,closed,2022-05-16T12:34:37Z,2022-05-31 17:21:31+00:00,2022-05-31T17:21:31Z,15,15,https://api.github.com/repos/microsoft/onnxruntime/issues/11536
11537,b'CUDA/CPU EP session creation fails with Could not find an implementation for QuantizeLinear(13)',Software,closed,2022-05-16T13:02:08Z,2022-05-19 17:57:34+00:00,2022-06-01T17:51:54Z,3,16,https://api.github.com/repos/microsoft/onnxruntime/issues/11537
11541,b'Using a model with float input types causes space issue',Software,open,2022-05-16T21:57:13Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11541
11544,"b'i build onnxruntime with c++ api, and create dynamic dll  and can c sharp call the dll directly?'",Software,closed,2022-05-17T04:55:41Z,2022-05-19 17:05:12+00:00,2022-05-19T17:05:41Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/11544
11545,"b'Undefined symbols for architecture arm64:   ""_OrtGetApiBase"" ... ld: symbol(s) not found for architecture arm64'",Software,closed,2022-05-17T05:01:33Z,2022-05-17 20:35:46+00:00,2022-05-17T20:35:46Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11545
11547,b'build onnxruntime1.11.1 error',Software,closed,2022-05-17T09:31:17Z,2022-05-18 18:01:38+00:00,2022-05-25T02:20:47Z,1,7,https://api.github.com/repos/microsoft/onnxruntime/issues/11547
11548,b'Non-zero status code returned ',Software,open,2022-05-17T09:33:40Z,2022-05-17 18:45:43+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11548
11549,"b""Windows CUDA_PATH is set but CUDA wasn't able to be loaded""",Software,closed,2022-05-17T11:36:06Z,2022-05-17 18:39:55+00:00,2022-05-18T08:09:03Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11549
11550,"b'how to use c sharp to call libonnxruntime.dll? i build the onnxruntime dynamic dll, did it can be encapsulated c++ dll in order to c sharp called'",Software,open,2022-05-17T14:39:24Z,2022-05-17 18:37:15+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11550
11551,"b""can c sharp call onnxruntime c++ dll   don't use c# third lib\xef\xbc\x9f i create onnxruntime c++ project,but i want to call the dll with c sharp""",Software,open,2022-05-17T15:48:06Z,2022-05-17 15:49:02+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11551
11557,b'Minimal build documentation does not include all important limitations',Documentation,open,2022-05-17T23:35:56Z,2022-05-19 17:03:28+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11557
11558,b'T5-Large Export Results in ProtoBuf Error due to 2GB External Data when using padded inputs',Software,open,2022-05-18T04:44:56Z,2022-05-20 00:04:54+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11558
11559,b'ONNX support for Stan models',Software,closed,2022-05-18T05:18:42Z,2022-05-19 18:05:36+00:00,2022-05-19T18:05:37Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11559
11561,b'CUDA failure 100: no CUDA-capable device is detected ; error when inferencing on a GPUVM',Software,open,2022-05-18T12:59:34Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11561
11562,b'CUDA_PATH is present but not recognized.',Software,closed,2022-05-18T14:54:15Z,2022-05-18 15:04:10+00:00,2022-05-18T15:04:10Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11562
11563,b'Specify CPUs to use for parallel inference when external CPU pinning is used',Software,open,2022-05-18T16:17:12Z,2022-05-19 17:16:58+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11563
11564,b'[C#] Possible to expose contributed operators as API accessible through c#?',Software,closed,2022-05-18T19:42:01Z,2022-05-19 16:53:04+00:00,2022-05-31T19:49:43Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/11564
11567,b'[js/web] Inference is Broken in Safari when Cross Origin Isolation is active',Software,open,2022-05-19T02:56:03Z,2022-05-19 02:56:57+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11567
11570,b'Header missmatch C/C++  - mac',Software,open,2022-05-19T07:48:09Z,2022-05-19 16:57:22+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11570
11572,"b""TensorRT EP doesn't load in C# API""",Software,closed,2022-05-19T08:56:37Z,2022-05-19 16:58:08+00:00,2022-05-20T17:43:23Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11572
11573,b'missing header files from win gpu zip package in rev 1.11.1',Software,closed,2022-05-19T17:32:39Z,2022-05-19 17:37:31+00:00,2022-05-24T05:56:19Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/11573
11576,b'The effect of turning optimization on and off on quantized model performance',Software,open,2022-05-20T02:32:57Z,2022-05-20 17:09:38+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11576
11581,"b'onnxruntime-gpu inference slow when once, but fast when continuous'",Software,closed,2022-05-20T08:59:01Z,2022-05-20 09:02:18+00:00,2022-05-27T02:09:24Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/11581
11582,b'ONNXRUNTIME + OpenVINO on ARM64 ',Software,open,2022-05-20T10:33:10Z,2022-05-23 05:49:21+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/11582
11583,b'did it can build onnxruntime with any cuda version by source code ? is not relate to onnxtuntime version?',Software,closed,2022-05-20T15:10:21Z,2022-05-20 17:08:11+00:00,2022-05-20T17:08:11Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11583
11584,b'did it can build onnxruntime with any cuda version by source code ? is not relate to onnxtuntime version?',Software,open,2022-05-20T15:14:46Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11584
11588,b'Segmentation fault for openvino EP',Software,closed,2022-05-22T15:29:29Z,2022-05-23 05:48:54+00:00,2022-05-24T02:27:05Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11588
11590,b'cpu and gpu results is not the same',Software,open,2022-05-23T04:31:54Z,2022-05-23 04:43:33+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11590
11592,b'CUDNN failure 4: CUDNN_STATUS_INTERNAL_ERROR ; error when inferencing on a GPUVM',Software,open,2022-05-23T06:48:20Z,2022-05-24 06:24:40+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11592
11594,b'oneDNN C++ API support?',Software,closed,2022-05-23T08:59:53Z,2022-05-23 19:51:24+00:00,2022-05-23T19:51:24Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11594
11595,b'issues with pybind11 repository while installing',Software,open,2022-05-23T09:45:41Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11595
11599,b'Where to find how QLinearConv is implemented?',Software,closed,2022-05-23T13:28:44Z,2022-05-23 19:44:36+00:00,2022-05-27T15:14:28Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/11599
11603,b'onnxruntime with use_acl build error',Software,open,2022-05-24T01:34:23Z,2022-05-24 01:40:15+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11603
11604,b'Bad performance for QDQ model with openvino EP ',Software,open,2022-05-24T02:58:24Z,2022-05-24 18:25:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11604
11605,b'Inference failure with ORT1.11',Software,closed,2022-05-24T03:29:01Z,2022-05-24 17:18:19+00:00,2022-06-03T23:16:55Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/11605
11607,b'Unable to build onnxruntime_v1.10.0 C++ api with --enable_memory_profile --enable_cuda_profiling flags',Software,open,2022-05-24T13:03:58Z,2022-05-24 21:52:25+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11607
11613,b'Missing packages of ort-nightly on TestPyPI for some environments',Software,closed,2022-05-24T18:04:58Z,2022-05-24 18:04:58+00:00,2022-05-24T18:24:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11613
11614,b'Shape inference fails',Software,open,2022-05-24T18:07:50Z,2022-05-25 12:12:04+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11614
11618,b'[`Microsoft.ML.OnnxRuntime.*` NuGet Packages] Replace Xamarin.iOS + Xamarin.Android Dependencies with .NET iOS and .NET Android',Software,open,2022-05-25T00:04:55Z,2022-05-25 02:26:59+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11618
11620,b'This repo is missing important files',Software,closed,2022-05-25T02:43:15Z,2022-05-25 20:56:14+00:00,2022-05-25T20:56:14Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11620
11621,b'building \xe2\x80\x94\xe2\x80\x94libonnxruntime_providers_cuda.so Error running link command: No such file or directory',Software,open,2022-05-25T07:00:47Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11621
11622,b'which version onnxruntime did cuda 11.2 can install? there is no correspond version in official DOCs',Software,closed,2022-05-25T07:01:12Z,2022-05-25 18:11:25+00:00,2022-05-25T18:11:25Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11622
11623,b' can onnxruntime-gpu-1.7 be installed with cuda 11.1/cudnn 8.0.4  env? i saw official docs onnxruntime-gpu-1.7 is corrospond to 11.0',Software,closed,2022-05-25T08:06:58Z,2022-05-25 18:05:26+00:00,2022-05-25T18:05:26Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11623
11624,b'how to set providers with onnx runtime-gpu1.70 ?',Software,open,2022-05-25T08:27:10Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11624
11627,b'Why does `enable_cpu_mem_arena` have such a large effect on memory usage during inference? ',Documentation,open,2022-05-25T15:10:59Z,2022-05-25 19:39:56+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11627
11628,"b'using multithread to call onnxruntime inference,'",Documentation,open,2022-05-25T15:19:56Z,2022-05-26 05:10:16+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11628
11634,b'quantize_static failed with shufflenet_v2_x0_5',Software,closed,2022-05-26T06:02:10Z,2022-05-26 06:02:25+00:00,2022-05-31T21:29:45Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/11634
11635,b'Error: (MaxPool) [ShapeInferenceError] Attribute strides has incorrect size',Software,closed,2022-05-26T07:09:37Z,2022-05-26 07:17:57+00:00,2022-05-31T03:25:40Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/11635
11637,b'Is there a C++ API in onnxruntime like torch::autograd::grad()?',Software,open,2022-05-26T08:44:48Z,2022-05-26 18:18:19+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11637
11640,b'ONNX release 1.12.0',Software,open,2022-05-26T17:54:35Z,2022-05-26 17:54:36+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11640
11646,b'which tags should i download of onnxruntime-gpu 1.6 for c#',Software,open,2022-05-27T02:15:20Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11646
11648,b'build for c#',Software,open,2022-05-27T03:46:59Z,2022-06-01 15:14:11+00:00,,5,,https://api.github.com/repos/microsoft/onnxruntime/issues/11648
11652,b'output shape can not be specified in com.microsoft::GridSample op ',Software,open,2022-05-27T09:27:28Z,2022-05-27 09:27:51+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11652
11653,b'[C#] Provide custom_op_library.dll',Software,closed,2022-05-27T12:06:41Z,2022-05-27 15:44:30+00:00,2022-05-27T15:44:30Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11653
11654,b'[C#] Basic build instruction to generate custom_op_library.dll ',Software,closed,2022-05-27T12:11:04Z,2022-05-31 19:37:19+00:00,2022-05-31T19:37:18Z,4,4,https://api.github.com/repos/microsoft/onnxruntime/issues/11654
11655,b'[C#] Documentation on how to coordinate the external Onnxruntime-Extension',Documentation,closed,2022-05-27T12:23:47Z,2022-05-31 17:07:59+00:00,2022-06-03T14:23:09Z,4,7,https://api.github.com/repos/microsoft/onnxruntime/issues/11655
11656,b'[Windows/Linux & C#] ONNX Runtime Build Issues on Win11 x64 Visual Studio 2022 AND WSL2 Ubuntu 20.04 GCC 9.4.0',Software,closed,2022-05-27T16:15:34Z,2022-05-28 00:54:18+00:00,2022-06-01T23:03:01Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/11656
11657,"b'[Documentation, Windows, c#] Add an entry on Build for Custom Op development'",Documentation,open,2022-05-27T16:22:31Z,2022-05-31 17:04:54+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/11657
11660,b'quantizer incorrectly eliminates Relu in case of static symmetric QDQ quantization',Software,closed,2022-05-27T20:40:30Z,2022-05-31 17:03:58+00:00,2022-06-08T16:21:17Z,3,11,https://api.github.com/repos/microsoft/onnxruntime/issues/11660
11661,b'Missing link on InferenceHighLevelDesign.md',Documentation,closed,2022-05-27T23:53:37Z,2022-05-31 17:02:55+00:00,2022-06-08T04:39:59Z,3,11,https://api.github.com/repos/microsoft/onnxruntime/issues/11661
11662,b'[C#] Update onnxruntime_dependencies diagram with contributed and custom operators API',Documentation,open,2022-05-27T23:58:11Z,2022-05-28 00:13:28+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11662
11663,b'Installing ORTModule torch extension reports TypeError',Software,open,2022-05-28T01:25:26Z,2022-05-31 13:59:37+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/11663
11666,b'Python inference with IOBinding and DirectML',Software,open,2022-05-28T03:13:30Z,2022-05-31 16:54:40+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/11666
11668,b'when set inter_op_num=0 with ORT_PARALLEL model the performance is very bad than inter_op_num=1?',Software,open,2022-05-28T09:31:19Z,2022-07-11 23:00:14+00:00,,44,,https://api.github.com/repos/microsoft/onnxruntime/issues/11668
11669,b'[python notebook] Inference_GPT2-OneStepSearch_OnnxRuntime_CPU.ipynb - session.run error',Software,closed,2022-05-28T19:31:11Z,2022-05-31 19:35:13+00:00,2022-05-31T19:35:13Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/11669
11670,b'[Prerelease c# ] ONNXRuntime v1.12',Software,closed,2022-05-28T21:24:42Z,2022-05-28 21:27:27+00:00,2022-06-01T23:40:23Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/11670
11672,b'PrepareForCompute Non concat axis dimensions must match',Software,open,2022-05-29T21:45:34Z,2022-05-31 16:49:53+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11672
11676,b'C++ torch::Tensor Convert to Ort::Value',Software,closed,2022-05-30T09:05:24Z,2022-05-31 07:45:21+00:00,2022-05-31T08:42:35Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11676
11677,b'The problem that the output image of super-resolution reconstructed image is gray nine-pattern',Software,closed,2022-05-30T09:07:06Z,2022-06-01 02:22:09+00:00,2022-06-01T02:22:09Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11677
11678,b'How to implement a new operator inference function?',Software,open,2022-05-30T10:09:28Z,2022-05-31 16:45:56+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11678
11679,b'[web] `ort.InferenceSession.create` silently hangs/fails on iOS/iPad browsers if COEP/COOP headers are set',Software,open,2022-05-30T10:39:20Z,2022-05-31 16:41:16+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11679
11680,b'OnnxRuntime on python 3.10.*',Software,open,2022-05-30T12:33:29Z,2022-05-30 15:22:56+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11680
11683,"b""RunOpt object has no attribute 'add_run_config_entry'""",Software,closed,2022-05-31T06:26:03Z,2022-05-31 16:38:05+00:00,2022-06-01T03:09:31Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11683
11684,b'Add transformer optimization for pre layer normalization?',Software,open,2022-05-31T07:04:25Z,2022-05-31 16:27:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11684
11685,b'which onnxruntime-gpu version is compatible for CUDA 11.1 ?',Software,open,2022-05-31T09:00:09Z,2022-05-31 16:18:04+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11685
11686,b'Converted ONNX model works with v1.9.0 but not with v1.11.1',Software,closed,2022-05-31T12:11:32Z,2022-05-31 16:17:28+00:00,2022-05-31T17:06:41Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11686
11688,b'Real-ESRGAN slow onnxruntime inference compared to Pytorch one',Software,open,2022-05-31T15:08:16Z,2022-05-31 16:16:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11688
11691,b'WASM build process not outputting WASM and JS file',Software,open,2022-05-31T21:09:02Z,2022-06-01 17:11:05+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11691
11693,"b""Linux CI pipelines can't test unreleased versions of ONNX""",Software,open,2022-05-31T22:47:27Z,2022-05-31 22:47:27+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11693
11695,b'[js/web] WebGPU backend',Software,open,2022-06-01T02:58:39Z,2022-06-01 17:06:23+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11695
11698,b'onnx_runtime speed unstable when inference on cpu',Software,closed,2022-06-01T06:55:45Z,2022-06-01 16:54:02+00:00,2022-06-02T01:41:20Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11698
11701,b'Dynamic quantization of Albert model',Software,open,2022-06-01T15:28:07Z,2022-06-01 16:53:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11701
11702,b'Low level profiling for onnxrt Conv kernel(default backend)',Software,open,2022-06-01T18:56:06Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11702
11703,b'Ort::SessionOptions::AppendExecutionProvider_CUDA_V2 missing from C++ API',Software,closed,2022-06-01T19:18:51Z,2022-06-01 23:18:41+00:00,2022-06-02T11:14:30Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11703
11706,b'CUDA EP spending lots of time idling',Software,open,2022-06-01T20:18:37Z,2022-06-01 23:19:47+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11706
11708,b'Inference Session in GPT-NEO-1.3B fails',Software,closed,2022-06-01T23:52:17Z,2022-06-02 17:08:20+00:00,2022-06-09T01:32:10Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/11708
11710,"b'[c#, Windows] Where are the models in onnxruntime/build/Windows/models?'",Software,closed,2022-06-02T01:31:18Z,2022-06-02 01:33:33+00:00,2022-06-02T02:29:31Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11710
11713,b'Race condition when setting do_copy_in_default_stream to false',Software,open,2022-06-02T13:07:52Z,2022-06-02 13:08:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11713
11717,b'OptionalHasElement causes Seg-fault ',Software,closed,2022-06-02T20:17:00Z,2022-06-02 20:26:59+00:00,2022-06-30T20:38:35Z,0,28,https://api.github.com/repos/microsoft/onnxruntime/issues/11717
11718,b'Reading back multidimensional output in C++',Software,open,2022-06-02T20:51:30Z,2022-06-03 17:06:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11718
11719,b'CI build is setting CMake variables that are ignored',Software,closed,2022-06-02T21:35:05Z,2022-06-02 22:53:14+00:00,2022-06-07T01:38:57Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/11719
11720,"b'""Build for Android"" docs doesn\'t mention how to run tests'",Software,closed,2022-06-02T22:57:45Z,2022-06-02 22:57:45+00:00,2022-06-09T00:05:11Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/11720
11725,b'Could not find an implementation for Relu(14)',Software,open,2022-06-03T09:21:33Z,2022-06-03 17:04:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11725
11727,b'Next release?',Software,closed,2022-06-03T13:55:30Z,2022-06-03 16:56:53+00:00,2022-06-03T18:40:23Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11727
11735,b'how to get the remaining GPU memory to get the batch size?',Software,open,2022-06-04T02:58:09Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11735
11736,b'ssd_mobilenet_v1 infer error for TensorRT Execution Provider',Software,open,2022-06-04T10:00:36Z,2022-06-06 17:54:50+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/11736
11737,b'why is there an error when executing ~Base() { OrtRelease(p_); } in onnxruntime_cxx_api.h?',Software,closed,2022-06-05T11:19:00Z,2022-06-05 11:21:55+00:00,2022-06-08T18:24:19Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/11737
11738,b'build rknpu backend error',Software,open,2022-06-05T12:51:06Z,2022-06-07 20:46:35+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/11738
11739,b'how to convert protobuf based onnx model to flat buffer based onnx model?',Software,closed,2022-06-05T13:41:52Z,2022-06-06 17:53:18+00:00,2022-06-08T02:36:57Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/11739
11740,b'[Feature Request] Manual VRAM flushing or automatic flushing after OOM error',Software,open,2022-06-05T19:09:09Z,2022-07-14 18:30:53+00:00,,38,,https://api.github.com/repos/microsoft/onnxruntime/issues/11740
11744,b'How to give built DLLs different names?',Software,closed,2022-06-06T13:12:26Z,2022-06-06 18:57:10+00:00,2022-06-08T00:05:04Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11744
11746,b'Looking for info on  NCHWc convoultion algorithm - why is performance so much better?',Software,closed,2022-06-06T18:21:55Z,2022-06-06 18:34:08+00:00,2022-06-06T18:34:08Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11746
11750,"b""pip installed Transformer's benchmark.py has incorrect call to config_modifier.""",Software,closed,2022-06-06T22:48:42Z,2022-06-07 08:13:50+00:00,2022-06-07T22:49:37Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11750
11751,b'Pip installed Transformer Benchmark cannot run on TF ',Software,open,2022-06-06T22:57:44Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11751
11757,b'coverage report step failed due to permission',Software,closed,2022-06-07T02:41:34Z,2022-06-07 02:43:34+00:00,2022-06-07T02:43:40Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11757
11759,b'QLinearAdd accuracy issue',Software,closed,2022-06-07T08:44:38Z,2022-06-08 16:49:29+00:00,2022-06-10T02:31:32Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/11759
11760,b'Converted ONNX model works onnx runtime 1',Software,closed,2022-06-07T10:12:56Z,2022-06-07 10:14:22+00:00,2022-06-07T10:14:22Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11760
11761,b'Converted ONNX model works in Python but not in C++',Software,open,2022-06-07T10:38:46Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11761
11763,b'The directory structure of source code compilation is inconsistent with the downloaded library',Software,closed,2022-06-07T13:32:25Z,2022-06-07 20:48:38+00:00,2022-06-07T20:48:38Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11763
11764,b'build onnxruntime with --android_abi=armeabi-v7a error',Software,closed,2022-06-07T14:34:35Z,2022-06-08 02:11:51+00:00,2022-06-08T02:11:51Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11764
11768,"b'""(FusedConv) kernel is not supported"" : Can\'t run FP16 onnx simple model'",Software,closed,2022-06-07T18:04:17Z,2022-06-08 12:22:10+00:00,2022-07-01T14:06:35Z,0,23,https://api.github.com/repos/microsoft/onnxruntime/issues/11768
11770,b'Inconsistent RPATH setting in Linux gpu package binaries',Software,closed,2022-06-07T20:50:37Z,2022-06-07 20:57:24+00:00,2022-06-07T20:57:24Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11770
11771,b'Runtime Error: module compiled against API version 0xf but this version of numpy is 0xd',Software,closed,2022-06-07T20:58:21Z,2022-06-07 21:04:33+00:00,2022-06-07T21:04:33Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11771
11781,b'LoadOrtModel ORT model verification failed',Software,closed,2022-06-08T09:47:29Z,2022-06-09 09:53:51+00:00,2022-06-09T09:53:51Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/11781
11783,b'Bugs in fusing the ONNX_ML_DOMAIN op with the standard onnx op',Software,closed,2022-06-08T11:09:35Z,2022-06-09 03:50:15+00:00,2022-06-09T03:50:15Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11783
11791,b'ORT nightly build is not discoverable on Google',Software,open,2022-06-08T22:03:50Z,2022-06-08 22:14:05+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11791
11796,"b'Target ""Python::NumPy"" not found during build from source on Windows10'",Software,open,2022-06-09T07:46:43Z,2022-06-09 17:55:33+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11796
11799,"b'A onnxruntime.dll from C:\\windows\\system32 is loaded from python cytpes.CDLL call while loading an x64 onnxruntime based dll, resulting in a crash'",Software,closed,2022-06-09T13:29:47Z,2022-06-09 13:30:18+00:00,2022-06-09T17:50:03Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11799
11801,b'Is it possible to clear GPU memory usage used by onnxruntime session without destroying the session?',Software,open,2022-06-09T16:39:49Z,2022-06-09 19:09:48+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11801
11802,b'Linux CPU ATen pipeline broken',Software,closed,2022-06-09T16:56:01Z,2022-06-10 19:19:41+00:00,2022-06-13T21:51:19Z,1,4,https://api.github.com/repos/microsoft/onnxruntime/issues/11802
11805,b'Failed to build onnxruntime on Apple Sillion ',Software,open,2022-06-09T19:51:09Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11805
11806,b'I do not get any performance improvement after using TensorRT provider for object detection model',Software,open,2022-06-09T20:00:05Z,2022-07-11 22:52:09+00:00,,32,,https://api.github.com/repos/microsoft/onnxruntime/issues/11806
11807,b'How to install a custom build of onnxruntime with CUDA as execution provider?',Software,open,2022-06-09T20:04:55Z,2022-06-09 20:10:07+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11807
11809,"b'When I use onnxruntime to run onnx model on GPU, it sucks up too much video memory. Is that normal?'",Software,open,2022-06-10T01:53:37Z,2022-06-10 17:52:45+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11809
11810,b'Wrong output with GPT-NEO-1.3B using onnxruntime',Software,open,2022-06-10T02:16:34Z,2022-06-15 04:24:58+00:00,,5,,https://api.github.com/repos/microsoft/onnxruntime/issues/11810
11811,b'Version Support for Python 3.10',Software,closed,2022-06-10T02:23:21Z,2022-06-13 18:41:39+00:00,2022-06-13T18:41:39Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/11811
11812,b'RuntimeError: Exporting the operator resolve_conj to ONNX opset version 12 is not supported. ',Software,open,2022-06-10T03:56:07Z,2022-06-10 23:25:45+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11812
11813,b'Issue while creating session for mt5 model ',Software,closed,2022-06-10T09:07:32Z,2022-06-10 09:27:56+00:00,2022-06-23T22:23:47Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/11813
11815,b'Issue importing onnxruntime ',Software,open,2022-06-10T15:11:13Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11815
11826,b'GPU Inference Problem? LoadLibrary failed with error 126 ',Software,closed,2022-06-12T00:41:43Z,2022-06-22 19:58:12+00:00,2022-06-22T20:15:36Z,10,10,https://api.github.com/repos/microsoft/onnxruntime/issues/11826
11828,b'[Bug] Mixing negative and positive paddings causes segfault/uninitialized memory values produced in reflected pad',Software,open,2022-06-13T02:50:29Z,2022-06-13 17:02:27+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11828
11830,"b""LSTM export ONNX:  Non-zero status code returned while running ScatterElements node. Name:'ScatterElements_18' Status Message: Indices vs updates dimensions differs at position=0 11 vs 8""",Software,closed,2022-06-13T07:54:34Z,2022-06-13 08:33:42+00:00,2022-06-21T16:19:06Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/11830
11831,b'unnecessary Cast node generated from float16 precision onnx model.',Software,closed,2022-06-13T08:32:00Z,2022-06-14 05:38:15+00:00,2022-06-22T07:30:06Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/11831
11833,"b'in cmake/CMakeList.txt all avx related option all set off, do we need do anything to use avx features?'",Software,open,2022-06-13T11:31:31Z,2022-06-13 16:58:49+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11833
11836,b'[ONNXRuntimeError] FuseReluClip failure',Software,open,2022-06-13T17:07:50Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11836
11843,"b""Cuda Enabled build of onnxruntime takes runtime memory for functions those don't need cuda""",Software,closed,2022-06-14T09:41:02Z,2022-06-20 10:27:20+00:00,2022-07-06T13:44:46Z,6,22,https://api.github.com/repos/microsoft/onnxruntime/issues/11843
11846,b'Incompatible dimensions for matrix multiplication Error in StarNet model when doing InferenceSession',Software,open,2022-06-14T17:05:34Z,2022-06-16 00:20:56+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11846
11848,b'Issue while loading big model like mt5 (may be due to limited size)',Software,closed,2022-06-14T22:19:43Z,2022-06-14 22:20:04+00:00,2022-06-23T22:22:19Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/11848
11850,"b""What's the meaning of the hole of tracing file""",Software,open,2022-06-15T03:49:54Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11850
11852,b'How to use batch run\xef\xbc\x9f',Software,open,2022-06-15T07:28:41Z,2022-06-20 10:54:22+00:00,,5,,https://api.github.com/repos/microsoft/onnxruntime/issues/11852
11853,b'Use',Software,closed,2022-06-15T07:33:19Z,2022-06-15 16:56:45+00:00,2022-06-15T16:56:45Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11853
11854,b'Use NPU in NXP iMX8MP?',Software,open,2022-06-15T07:36:41Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11854
11856,b'What is the meaning of src_arg_index and dst_arg_index in EdgeEndToMatch structure?',Software,open,2022-06-15T12:45:10Z,2022-06-15 12:45:18+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11856
11869,b'Duplicate define operater<<',Software,open,2022-06-16T05:55:02Z,2022-07-11 22:37:55+00:00,,25,,https://api.github.com/repos/microsoft/onnxruntime/issues/11869
11870,b'Wrong output shape due to MergeShape failure',Software,open,2022-06-16T07:33:22Z,2022-06-22 23:51:50+00:00,,6,,https://api.github.com/repos/microsoft/onnxruntime/issues/11870
11872,b'More supported ai.onnx operators for WebGL backend',Software,open,2022-06-16T08:52:59Z,2022-06-16 21:18:29+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11872
11873,b'Not clear quantization pipeline for tensorrt ep',Software,open,2022-06-16T12:21:05Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11873
11874,b'Pytorch -> Onnx custom Yolov5 model works in python but not in JS',Software,open,2022-06-16T17:47:19Z,2022-07-11 22:36:32+00:00,,25,,https://api.github.com/repos/microsoft/onnxruntime/issues/11874
11875,"b'CUDA EP, stale input occasionally used as input to the model'",Software,closed,2022-06-16T18:25:12Z,2022-06-20 15:26:19+00:00,2022-06-20T15:26:19Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/11875
11883,b'How is QlinearConv calculated?',Software,open,2022-06-17T00:56:55Z,2022-06-22 01:51:17+00:00,,5,,https://api.github.com/repos/microsoft/onnxruntime/issues/11883
11889,b'[ONNXRuntimeError] Load model from *** failed: Unsuported type proto value case',Software,open,2022-06-17T09:14:08Z,2022-07-11 22:31:03+00:00,,24,,https://api.github.com/repos/microsoft/onnxruntime/issues/11889
11890,b'Quantize specific ops per-tensor while per_channel=True',Software,open,2022-06-17T10:08:59Z,2022-06-20 20:33:05+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/11890
11891,b'onnx and onnxruntime disagree on input with no known rank',Software,open,2022-06-17T12:48:53Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11891
11892,b'ONNX XGBoost classifier gives very different results from the original model',Software,open,2022-06-17T14:37:23Z,2022-06-21 14:58:07+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/11892
11895,"b'Bug: MatMul fails for input shapes of [0, k] and [k, ]'",Software,open,2022-06-17T18:22:55Z,2022-06-17 18:23:30+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11895
11898,b'ONNX Opset 3 is under development and not supported?',Software,closed,2022-06-17T23:52:56Z,2022-06-20 19:12:13+00:00,2022-06-23T17:05:14Z,2,5,https://api.github.com/repos/microsoft/onnxruntime/issues/11898
11899,b'Invalid Feed Input Name - Error',Software,closed,2022-06-18T00:12:30Z,2022-06-20 10:20:43+00:00,2022-06-22T23:33:40Z,2,4,https://api.github.com/repos/microsoft/onnxruntime/issues/11899
11901,b'Remove reference to internals in torch.onnx',Software,open,2022-06-18T00:53:19Z,2022-06-20 10:07:03+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/11901
11902,b'ONNX 1.12 causes test_dequantizelinear_cpu / test_quantizelinear_cpu to fail on DirectML EP',Software,closed,2022-06-18T16:33:11Z,2022-06-18 16:33:11+00:00,2022-06-20T18:04:34Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/11902
11903,b'Immense GPU memory consumption',Software,open,2022-06-18T16:36:02Z,2022-06-18 19:47:44+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11903
11907,"b""Problem with onnxruntime-tools: No module named onnxruntime.transformers.convert_to_onnx and unexpected keyword argument 'example_outputs'""",Software,closed,2022-06-19T20:31:56Z,2022-06-20 02:26:10+00:00,2022-06-29T01:31:04Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/11907
11913,b'[Documentation Request] Clarify do_copy_in_default_stream effect',Software,open,2022-06-20T16:09:25Z,2022-06-21 05:03:54+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11913
11916,b'Implement LayerNormalization kernel for opset version 17',Software,open,2022-06-20T19:28:19Z,2022-06-20 19:28:19+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11916
11921,b'onnx value_info can contain graph inputs/outputs in filtered graphs',Software,open,2022-06-20T22:41:52Z,2022-06-21 02:36:15+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11921
11927,b'ConvTranspose with auto_pad attribute',Software,open,2022-06-21T06:33:56Z,2022-06-22 23:27:04+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11927
11928,b'Percentile/entropy calibration not working for quantizing Resnet-50/MobileNet',Software,closed,2022-06-21T10:30:00Z,2022-06-22 23:27:49+00:00,2022-07-13T00:04:16Z,1,21,https://api.github.com/repos/microsoft/onnxruntime/issues/11928
11946,b'how to get inference time with c# onnxruntime-gpu-1.6.0',Software,open,2022-06-22T02:36:23Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11946
11947,b'excute dnnl provider error',Software,open,2022-06-22T03:29:56Z,2022-06-22 23:31:42+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11947
11950,b'windows11+onnxruntime1.8.0+vs2019 inferencing  crash',Software,open,2022-06-22T10:01:29Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11950
11951,b'Multi thread of single session Python vs C++ (end with core dumped)',Software,open,2022-06-22T10:43:15Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/11951
11959,b'Inference_GPT2-OneStepSearch_OnnxRuntime_CPU.ipynb Error',Software,open,2022-06-23T02:09:55Z,2022-06-23 06:31:52+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11959
11961,b'Question about quantize Gemm OP',Software,open,2022-06-23T06:35:08Z,2022-06-23 06:35:56+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11961
11964,"b""Got segmentation fault error when using 'InferenceSession' API""",Software,open,2022-06-23T10:07:41Z,2022-07-08 21:56:45+00:00,,15,,https://api.github.com/repos/microsoft/onnxruntime/issues/11964
11966,"b'how to configure lobal/shared threadpool with multithread, in c#API?'",Software,open,2022-06-23T14:07:45Z,2022-06-24 20:35:54+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11966
11967,b'set gpu option failed ',Software,open,2022-06-23T15:45:29Z,2022-06-25 00:41:01+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11967
11973,b'Wrong header included for CoreML provider factory',Software,closed,2022-06-23T22:41:38Z,2022-06-24 20:36:48+00:00,2022-07-12T01:27:02Z,0,18,https://api.github.com/repos/microsoft/onnxruntime/issues/11973
11975,"b'quant onnx model slower than pytorch with mish6 activation, howerver faster with relu6'",Software,open,2022-06-24T02:07:06Z,2022-06-24 02:07:34+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11975
11977,b'support pytorch 1.11 in export onnx scripts',Software,closed,2022-06-24T05:15:08Z,2022-06-27 02:28:45+00:00,2022-07-11T09:41:28Z,2,17,https://api.github.com/repos/microsoft/onnxruntime/issues/11977
11979,b'Different inference results in C++ and Python',Software,closed,2022-06-24T09:24:43Z,2022-06-30 02:08:32+00:00,2022-06-30T02:08:32Z,5,5,https://api.github.com/repos/microsoft/onnxruntime/issues/11979
11980,b'How to use webgl version?',Software,closed,2022-06-24T10:10:58Z,2022-06-24 20:39:34+00:00,2022-06-26T14:59:53Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/11980
11983,b'inference time is not stable',Software,open,2022-06-24T16:08:01Z,2022-06-29 00:08:42+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/11983
11985,b'Import Error in Windows debug config with eager mode',Software,open,2022-06-24T19:58:02Z,2022-06-24 20:09:33+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11985
11986,b'Scan performs worse than LSTM for CUDA EP',Software,closed,2022-06-24T22:03:08Z,2022-06-28 00:19:44+00:00,2022-07-12T17:36:52Z,3,17,https://api.github.com/repos/microsoft/onnxruntime/issues/11986
11991,b'converting pth to onnx with onnx.js',Software,closed,2022-06-25T12:25:09Z,2022-06-27 17:45:53+00:00,2022-06-27T17:45:53Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/11991
11992,b'Any interest in hosting the Rust bindings',Software,open,2022-06-25T13:26:42Z,2022-06-28 00:22:21+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/11992
11993,b'inference is different on linux and windows',Software,open,2022-06-25T23:45:42Z,2022-06-28 23:45:05+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/11993
11994,b'Inconsistent result to NumPy and PyTorch when consecutively casting a float tensor to int32 and then to bool',Software,open,2022-06-26T03:44:04Z,2022-06-28 00:27:47+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11994
11996,b' failed to initialize a session in the GPU environment',Software,open,2022-06-26T10:58:36Z,2022-06-28 00:31:40+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11996
11997,b'The test time of sess.run does not match the time of profile',Software,open,2022-06-27T02:17:46Z,2022-06-29 00:08:01+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/11997
11998,b'build with cuda 11.0 /cudnn 8.0',Software,closed,2022-06-27T03:18:19Z,2022-06-27 06:27:13+00:00,2022-06-27T06:27:13Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/11998
11999,b'build C#api with cuda 11.0 /cudnn 8.0',Software,open,2022-06-27T03:19:29Z,2022-06-27 13:40:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/11999
12002,b'build for iOS error: ld: library not found for -latomic',Software,open,2022-06-27T14:17:46Z,2022-06-28 17:23:09+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/12002
12003,b'Issue with NeMo MTEncDecModel model in ONNX IOBinding',Software,open,2022-06-27T16:37:11Z,2022-06-28 23:16:33+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/12003
12009,b'onnxruntime and onnx protobuf version confliction',Software,open,2022-06-27T23:06:47Z,2022-06-28 23:57:48+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/12009
12011,b'how to build onnxruntime from source with dnnl? ',Software,open,2022-06-28T01:26:59Z,2022-06-28 23:45:33+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12011
12014,b'FATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory',Software,open,2022-06-28T03:23:43Z,2022-06-28 23:27:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12014
12015,b'Update the ROIAlign op to the current ONNX spec',Software,closed,2022-06-28T08:59:37Z,2022-06-28 22:20:40+00:00,2022-07-01T02:11:47Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/12015
12017,b'create op ',Software,open,2022-06-28T12:30:50Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/12017
12019,b'Resize with mode linear is missing output elements',Software,open,2022-06-28T17:57:48Z,2022-06-28 22:20:29+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12019
12021,b'Nullptr returned by OrtGetApiBase()->GetApi(ORT_API_VERSION)',Software,closed,2022-06-28T18:06:57Z,2022-06-29 00:10:29+00:00,2022-06-30T16:34:44Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/12021
12023,b'This is a question that should be a discussion',Software,closed,2022-06-28T23:59:08Z,2022-06-28 23:59:28+00:00,2022-06-28T23:59:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12023
12026,b'onnxruntime arm32 build on ubuntu focal',Software,closed,2022-06-29T03:14:31Z,2022-06-29 21:55:03+00:00,2022-06-29T21:55:03Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12026
12029,"b"" undefined reference to `onnxruntime::MLFloat16::ToFloat() const'""",Software,closed,2022-06-29T06:41:05Z,2022-06-30 01:37:55+00:00,2022-07-08T07:06:11Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/12029
12038,b'Update orttraining eager mode to support torch 1.12.0',Software,open,2022-06-29T21:19:36Z,2022-06-29 21:20:27+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12038
12040,b'Microsoft.ML.OnnxRuntime.Tests.InferenceTest.TestPreTrainedModels should get opset version from the model file',Software,open,2022-06-29T22:11:16Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/12040
12042,b'Builds C# bindings and creates nuget package',Software,open,2022-06-30T02:38:35Z,2022-07-01 02:54:19+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/12042
12043,b'GlobalAveragePool on large size of ones miscalculates',Software,open,2022-06-30T04:42:25Z,2022-07-01 02:00:22+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12043
12044,b'Using onnxruntime server for model deployment',Software,open,2022-06-30T04:52:14Z,2022-07-01 01:58:43+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12044
12045,b'Fp16 Resnet50 Model cannot run in cuda provider. ',Software,closed,2022-06-30T05:47:39Z,2022-06-30 22:09:22+00:00,2022-07-01T22:31:15Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/12045
12047,b'Support pasts as inputs in gpt2 beam search operator',Software,open,2022-06-30T07:25:50Z,2022-06-30 07:26:42+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12047
12048,b'Build wasm static library bug because of missing `testdata` folder.',Software,open,2022-06-30T11:14:21Z,2022-07-01 01:50:36+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12048
12049,b'Performance in parallel session Run()',Software,open,2022-06-30T12:29:35Z,2022-07-01 01:49:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12049
12052,b'Universal build (x86_64 and arm64) error for MacOS',Software,closed,2022-06-30T16:09:54Z,2022-06-30 16:10:38+00:00,2022-07-06T16:18:02Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/12052
12055,b'Eager mode code gen support sequence of ops with multiple using attributes',Software,closed,2022-06-30T19:41:41Z,2022-07-13 13:22:25+00:00,2022-07-13T13:23:40Z,12,12,https://api.github.com/repos/microsoft/onnxruntime/issues/12055
12061,b'Builds C# bindings and creates nuget package for vs2019 install',Software,open,2022-07-01T04:47:34Z,2022-07-01 17:10:51+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12061
12064,b'onnx optimization distilbert failure',Software,open,2022-07-01T07:07:48Z,2022-07-01 16:53:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12064
12065,"b'ONNXRuntimeError for ""Where"" node when the input is too long'",Software,open,2022-07-01T12:45:35Z,2022-07-01 16:41:15+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12065
12070,b'onnxruntime use more GPU memory than pytorch',Software,open,2022-07-02T10:53:16Z,2022-07-02 10:53:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12070
12071,"b'GemmTransposeFusion error when C is transposed (`Gemm(A,B,Transpose(C)`), complained with confusing name `_transformed_transformed_transformed...`'",Software,closed,2022-07-02T16:02:48Z,2022-07-05 18:55:30+00:00,2022-07-13T05:03:35Z,3,10,https://api.github.com/repos/microsoft/onnxruntime/issues/12071
12072,b'Resnet50 performances very bad with S8S8 and per-channel with CPU on x64',Software,closed,2022-07-02T16:03:54Z,2022-07-05 17:58:07+00:00,2022-07-13T17:39:23Z,3,11,https://api.github.com/repos/microsoft/onnxruntime/issues/12072
12074,b'Unable to use custom op',Software,closed,2022-07-03T03:14:14Z,2022-07-03 04:59:29+00:00,2022-07-06T06:19:01Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/12074
12076,b'Wrong Floor output on very large input',Software,closed,2022-07-03T18:23:59Z,2022-07-05 20:40:21+00:00,2022-07-08T21:55:52Z,2,5,https://api.github.com/repos/microsoft/onnxruntime/issues/12076
12078,b'Performance issue with beam search in onnxruntime ',Software,open,2022-07-04T22:08:13Z,2022-07-04 22:09:35+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12078
12081,"b""Support for cmake's FetchContent()""",Software,open,2022-07-05T08:27:38Z,2022-07-11 22:17:44+00:00,,6,,https://api.github.com/repos/microsoft/onnxruntime/issues/12081
12082,b'Is ARMNN included in the release onnxruntime-linux-aarch64-1.11.1.tgz ibrary file?',Software,closed,2022-07-05T09:44:09Z,2022-07-05 18:56:51+00:00,2022-07-06T18:17:18Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/12082
12083,b'TensorRT Provider Vs TensorRT Native ',Software,open,2022-07-05T10:13:43Z,2022-07-05 17:57:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12083
12084,b'Onnx Runtime for Java is packaged with 200MB onnxruntime.pdb in the win-x64 native package',Software,open,2022-07-05T11:43:14Z,2022-07-05 21:08:25+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12084
12085,b'where is demo/pcd_demo.py?',Software,closed,2022-07-05T11:49:06Z,2022-07-08 17:37:43+00:00,2022-07-08T17:37:43Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/12085
12086,b'What level of reproducability is expected?',Software,open,2022-07-05T13:02:29Z,2022-07-05 18:04:51+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12086
12091,b'Resize with mode linear always produces 0.5 on GPU regardless of the input',Software,open,2022-07-05T20:33:40Z,2022-07-05 20:33:41+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12091
12098,b'Resize with `nearest` mode have inconsistent results compared to PyTorch and TVM',Software,open,2022-07-06T03:41:59Z,2022-07-06 03:45:05+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12098
12100,b'NLP csharp example',Documentation,open,2022-07-06T04:48:34Z,2022-07-08 17:34:46+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/12100
12102,b'Beamsearch operator reports error',Software,closed,2022-07-06T10:03:39Z,2022-07-06 23:05:04+00:00,2022-07-12T03:04:49Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/12102
12103,b'Requesting example on graph neural network',Software,open,2022-07-06T11:58:57Z,2022-07-11 22:06:12+00:00,,5,,https://api.github.com/repos/microsoft/onnxruntime/issues/12103
12104,b'CUDA Specified device is not supported.',Software,closed,2022-07-06T14:32:42Z,2022-07-06 19:14:06+00:00,2022-07-09T07:26:40Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/12104
12115,b'Build from source can not run python setup.py build wheel',Software,closed,2022-07-07T03:16:29Z,2022-07-07 16:52:43+00:00,2022-07-09T02:46:22Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/12115
12116,b'Question about using same logid for different session',Software,closed,2022-07-07T03:27:30Z,2022-07-07 19:23:34+00:00,2022-07-11T04:42:56Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/12116
12117,b'Compatibility matrix mismatch with release version.',Software,open,2022-07-07T04:48:03Z,2022-07-07 19:22:59+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12117
12119,b'torch.scatter_add converts to onnx format and inference result is wrong when I use onnxruntime with version 1.11.1',Software,open,2022-07-07T08:22:51Z,2022-07-07 16:58:27+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12119
12120,b'onnxruntime tensorrt  sometime cost verg log time ',Software,open,2022-07-07T11:06:24Z,2022-07-07 16:53:26+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12120
12123,b'Segmentation fault with the C++ API on MacOS M1',Software,closed,2022-07-07T17:00:53Z,2022-07-07 17:22:02+00:00,2022-07-07T17:22:02Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12123
12124,b'Getting CUDA out of memory when converting a large model',Software,open,2022-07-07T18:54:48Z,2022-07-07 18:55:41+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12124
12126,b'How do I call the same model in CUDA with many various inputs?',Software,open,2022-07-07T20:36:21Z,2022-07-08 18:25:41+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12126
12127,b'Error in symbloc_shape_infer.py: assert name in self.sympy_data_ or ...',Software,open,2022-07-07T21:39:08Z,2022-07-08 22:12:04+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/12127
12130,b'Inference time vs torch w/regard to batch_size and BatchNorm',Software,open,2022-07-08T15:03:37Z,2022-07-08 17:43:06+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12130
12131,b'ORT fails with `Validating no unexpected access using an invalid node_index` on torch converted model',Software,closed,2022-07-08T16:16:03Z,2022-07-08 16:21:02+00:00,2022-07-11T22:42:51Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/12131
12133,b'ORT 1.12 Release Candidate available for testing',Software,open,2022-07-08T19:32:45Z,2022-07-08 19:33:00+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12133
12137,b'Wav2Vec2',Software,closed,2022-07-09T13:48:42Z,2022-07-11 16:01:18+00:00,2022-07-11T16:01:18Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/12137
12142,"b'Onnxruntime NuGet package throw an exception when call ""AppendExecutionProvider_Nnapi""'",Software,open,2022-07-11T20:53:54Z,2022-07-11 21:10:39+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12142
12145,b'Is it possible to make NumThreads and CurrentThreadId methods of the Threadpool class public?',Software,open,2022-07-11T22:15:57Z,2022-07-11 23:35:56+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12145
12149,b'When will Attention OP extra_add_qk input support automatic broadcast',Software,open,2022-07-12T08:17:19Z,2022-07-12 18:03:38+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12149
12150,b'Query regarding timings under ONNXRT profiler ',Software,open,2022-07-12T10:54:57Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/12150
12151,b'[ORT 1.12] One test relative to DequantizeLinear op failed to be inferenced.',Software,closed,2022-07-12T11:39:39Z,2022-07-12 18:16:31+00:00,2022-07-25T07:03:19Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/12151
12152,b'yolov3-tiny model float16 quantization (InvalidArgument: [ONNXRuntimeError] )',Software,open,2022-07-12T11:53:49Z,2022-07-12 12:34:44+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12152
12153,b'IOBinding for Tensorflow Tensors',Software,open,2022-07-12T14:51:09Z,2022-07-12 18:25:59+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12153
12154,b'Transformer Benchmark Failures',Software,open,2022-07-12T15:15:00Z,2022-07-12 18:31:04+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12154
12160,b'Hi Does ONNX Runtime support FP16 and INT8 inference on Intel OneDNN ExecutionProvider?',Software,open,2022-07-13T03:25:19Z,2022-07-13 03:26:10+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12160
12163,b'Eager mode generator support non-tensor return types',Software,open,2022-07-13T13:26:54Z,2022-07-13 16:11:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12163
12165,b'Create resources on device for DML',Software,open,2022-07-13T15:02:35Z,2022-07-13 16:07:37+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12165
12173,b'symbolic_shape_infer.py not working with models quantized with \xf0\x9f\xa4\x97 Optimum for TensorRT',Software,open,2022-07-14T02:44:28Z,2022-07-14 04:33:24+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12173
12178,b'Static Quantization of Model with Dynamic Shaped Input',Software,open,2022-07-14T14:49:35Z,2022-07-14 15:58:28+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12178
12185,b'upgrading pip and wheels kills CUDAExecutionProvider',Software,open,2022-07-15T06:32:27Z,2022-07-15 12:35:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12185
12186,b'how to use cuda?',Software,closed,2022-07-15T07:26:14Z,2022-07-15 07:43:12+00:00,2022-07-15T07:43:12Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12186
12192,b'symbolic_shape_infer infinite loop',Software,open,2022-07-15T22:15:36Z,2022-07-15 22:35:15+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12192
12193,b'Failed to load pdb file for onnxruntime.dll when using OnnxRuntime.DirectML',Software,open,2022-07-15T22:27:39Z,2022-07-15 22:32:51+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12193
12197,b'why first session.run is too slower than after',Software,open,2022-07-16T06:03:39Z,2022-07-18 22:23:38+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/12197
12198,b'[Documentation Request] Update Documentation for ARM Cross-Compilation on Linux',Software,closed,2022-07-17T19:12:32Z,2022-07-18 22:24:28+00:00,2022-07-29T19:42:29Z,1,12,https://api.github.com/repos/microsoft/onnxruntime/issues/12198
12199,b'transformers optimization tool failed on Pytorch 1.12.0',Software,closed,2022-07-17T22:55:04Z,2022-07-18 16:59:42+00:00,2022-07-18T16:59:42Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12199
12202,b'> > `WebGLBackend 2021-10-19T19:05:16.905Z|Unable to initialize WebGLBackend. ReferenceError: document is not defined`',Software,closed,2022-07-18T07:20:55Z,2022-07-18 07:20:56+00:00,2022-07-18T07:21:17Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12202
12203,b'> > `WebGLBackend 2021-10-19T19:05:16.905Z|Unable to initialize WebGLBackend. ReferenceError: document is not defined`',Software,closed,2022-07-18T07:22:21Z,2022-07-18 07:22:21+00:00,2022-07-18T22:29:45Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12203
12206,b'Performance issue of ConvInteger',Software,open,2022-07-18T08:54:43Z,2022-07-18 22:47:01+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12206
12207,b'How to release memory after Inference session run in Python',Software,open,2022-07-18T09:29:43Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/12207
12208,b'Build Error',Software,closed,2022-07-18T10:24:46Z,2022-07-25 06:23:36+00:00,2022-07-25T06:23:36Z,6,6,https://api.github.com/repos/microsoft/onnxruntime/issues/12208
12211,b'Regarding the dynamism for custom op in ONNXRT',Software,open,2022-07-18T15:12:39Z,2022-07-18 22:34:15+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12211
12216,b'Why is there a cudaStreamSynchronize on the end of the run',Software,open,2022-07-18T18:18:26Z,2022-07-19 00:16:24+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12216
12228,b'[Documentation Request]',Software,closed,2022-07-19T03:23:05Z,2022-07-20 18:31:05+00:00,2022-07-26T07:35:23Z,1,7,https://api.github.com/repos/microsoft/onnxruntime/issues/12228
12229,b'Quantized Model Running Slow Using Cuda as EP ',Software,open,2022-07-19T04:09:41Z,2022-07-20 18:30:10+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/12229
12230,b'[Documentation Request]',Software,open,2022-07-19T04:12:31Z,2022-07-20 18:29:15+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/12230
12231,b'C++ ONNXRuntime predictions are all zero',Software,closed,2022-07-19T07:18:17Z,2022-07-20 02:07:11+00:00,2022-07-26T09:09:55Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/12231
12232,b'c++ onnxruntime run `onnxruntime_global_thread_pools_test` with `use_dnnl`  core dump',Software,closed,2022-07-19T12:15:36Z,2022-07-22 04:57:36+00:00,2022-07-22T04:57:35Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/12232
12235,b'Protobuf error in Onnx Model Zoo github repo when validating models',Software,open,2022-07-19T14:03:31Z,2022-07-19 17:08:47+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12235
12244,b'clean up build instructions for ORT Web',Software,open,2022-07-19T22:40:41Z,2022-07-19 22:40:41+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12244
12246,b'Exported beam search model consumes a lot of more memory',Software,open,2022-07-20T03:25:08Z,2022-07-20 18:27:38+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12246
12252,b'Some love for MacOS gpu',Software,closed,2022-07-20T13:31:19Z,2022-07-20 17:34:18+00:00,2022-07-20T17:34:18Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12252
12265,b'Mismatch in the order of the column names in the benchmarking script for transformer models',Software,open,2022-07-21T12:40:10Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/12265
12267,b'QNX Support',Software,closed,2022-07-21T14:22:35Z,2022-07-22 06:35:53+00:00,2022-07-22T06:35:53Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12267
12269,b'LoadLibrary failed with error 126 (DirectML)',Software,open,2022-07-21T15:18:21Z,2022-07-21 17:44:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12269
12272,b'Failed to compile from the source with cuda on windows 10 (The CMAKE_CUDA_ARCHITECTURES do not all work with this compiler)',Software,closed,2022-07-21T18:09:26Z,2022-07-21 23:13:57+00:00,2022-07-21T23:13:57Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12272
12279,b'Create OrtKernelInfo for use in CreateOp via the C API',Software,open,2022-07-22T01:30:45Z,2022-07-22 21:30:23+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12279
12282,b'TRT EP failed to create model session with CUDA custom op',Software,open,2022-07-22T05:40:53Z,2022-07-22 21:35:02+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12282
12284,"b'W:onnxruntime:, execution_frame.cc:811 VerifyOutputSizes] Expected shape from model of {800,10} does not match actual shape of {32,10} for output 499'",Software,closed,2022-07-22T06:16:31Z,2022-07-22 21:38:15+00:00,2022-07-22T21:38:15Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12284
12285,"b'Ort::Session has no ""FromArrayWithPrepackedWeightsContainer""  interface'",Software,closed,2022-07-22T10:08:01Z,2022-07-22 21:44:15+00:00,2022-07-26T03:27:51Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/12285
12286,b'An error(The SplitToSequence op is not supported) was thrown while loading an onnx file.',Software,open,2022-07-22T11:47:35Z,2022-07-22 22:01:33+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12286
12287,b'Since ORT 1.12 ort.InferenceSession throws error when the last provider is not capable',Software,open,2022-07-22T14:05:14Z,2022-07-22 22:05:33+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12287
12288,b'SafeIntOnOverflow() Integer overflow error when running inference in an ASGI server',Software,open,2022-07-22T14:58:27Z,2022-07-22 22:21:40+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12288
12289,b'Cuda allocator pointer alignment',Software,open,2022-07-22T15:00:08Z,2022-07-22 22:23:33+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12289
12290,b'Install ortmodule got  `error: unsupported option --use_fast_math`',Software,closed,2022-07-22T15:54:23Z,2022-07-22 16:15:48+00:00,2022-07-22T20:07:42Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12290
12291,b'Update setup.py so developers can install onnxruntime package locally using pip',Software,open,2022-07-22T16:24:20Z,2022-07-22 22:36:40+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12291
12296,b'c# DirectML exception after updating to 1.12.0',Software,open,2022-07-22T21:14:49Z,2022-07-22 22:38:35+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12296
12298,"b'RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!'",Software,closed,2022-07-23T07:25:34Z,2022-07-26 07:07:44+00:00,2022-07-26T07:07:44Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/12298
12299,b'Are these all cpu node types supported on ARM ? ',Software,closed,2022-07-23T07:36:39Z,2022-07-26 09:54:50+00:00,2022-07-26T09:54:49Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/12299
12300,b'Creating a tensor causes an error in C++ program using GPT2 with beam search',Software,closed,2022-07-25T03:57:09Z,2022-07-28 18:13:54+00:00,2022-08-01T03:04:25Z,3,6,https://api.github.com/repos/microsoft/onnxruntime/issues/12300
12302,"b""Resize op can't work well under Cubic mode with ORT 1.12.""",Software,open,2022-07-25T04:16:35Z,2022-07-25 23:18:41+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12302
12304,b'What header files/ lib i need to deploy my model using onnxruntime in C++',Software,closed,2022-07-25T12:12:31Z,2022-07-25 19:11:48+00:00,2022-07-25T19:11:48Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12304
12305,b'Details regarding ONNXRuntime inference with OpenVino Backend',Software,open,2022-07-25T14:37:28Z,2022-07-26 21:02:39+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/12305
12306,b'Licence the ONNX Runtime Java Inference',Software,closed,2022-07-25T15:20:16Z,2022-07-28 10:35:58+00:00,2022-07-28T10:35:58Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/12306
12312,b'Runtime Exception during initialization',Software,closed,2022-07-26T00:17:17Z,2022-07-26 18:39:09+00:00,2022-07-27T00:53:25Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/12312
12313,b'Onnxruntime-gpu Inference system memory leak over',Software,closed,2022-07-26T03:24:55Z,2022-07-26 23:53:42+00:00,2022-07-26T23:53:48Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12313
12315,b'Why the performance of onednn is worse than the common version',Software,open,2022-07-26T09:28:53Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/12315
12316,b'ONNXRT default CPU EP vs Openvino EP Performance',Software,open,2022-07-26T09:34:47Z,2022-07-27 07:36:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12316
12318,b'onnx graph partition optimize',Software,open,2022-07-26T12:23:18Z,2022-07-29 19:33:21+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/12318
12321,b'FusedConv Cuda EP invalid argument error.',Software,open,2022-07-26T15:56:07Z,2022-07-26 16:26:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12321
12322,b'ORT v1.12.0 is no longer caching with TensorRT ',Software,open,2022-07-26T17:53:14Z,2022-07-26 18:55:12+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12322
12324,b'Wrong native library directory name for M1 Mac in the Java package',Software,open,2022-07-26T18:17:33Z,2022-07-26 18:18:35+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12324
12328,b'MetaCommand exception from DirectML EP',Software,open,2022-07-26T21:44:13Z,2022-07-26 23:57:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12328
12332,"b'RobertaEncoder model export issue: 1) the export disregard the dynamic axies, and 2) the export takes extremely long (20+ minutes)'",Software,open,2022-07-27T00:47:24Z,2022-07-28 23:20:46+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/12332
12334,b'window10 ort with openvino backend error',Software,open,2022-07-27T03:06:23Z,2022-07-28 21:08:27+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/12334
12337,b'The Clone Session interface is expected',Software,closed,2022-07-27T07:33:06Z,2022-07-28 01:54:17+00:00,2022-07-28T12:01:25Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/12337
12338,"b'unsafe exception code in C++ API, wrongly declaring exceptions, incomplete constructors'",Software,open,2022-07-27T07:47:48Z,2022-07-28 01:53:19+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12338
12339,b'The latency of 1.12.0 onnxruntime-android is higher than 1.11.0 onnxruntime-android on Android',Software,closed,2022-07-27T11:22:58Z,2022-07-27 23:48:35+00:00,2022-08-01T19:49:04Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/12339
12340,b'Windows compile with win32: error LNK2019: unresolved external symbol _OrtGetApiBase@0',Software,closed,2022-07-27T12:28:11Z,2022-07-27 12:29:17+00:00,2022-07-27T12:29:17Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12340
12342,b'Unable to build Onnxruntime 1.12.0 with OpenVINO 2020.3 on Windows 10',Software,open,2022-07-27T13:20:25Z,2022-07-28 01:52:29+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12342
12343,b'Python 3.11 support',Software,open,2022-07-27T14:48:10Z,2022-07-27 14:48:32+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12343
12346,b'Quantized ONNX model output',Software,open,2022-07-27T16:56:19Z,2022-07-28 01:51:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12346
12348,b'Performance gains by ONNX inconsistent',Software,open,2022-07-27T21:15:20Z,2022-07-28 01:51:07+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12348
12357,"b'For same onnx model, the onnx runtime inference working well on python but not working on c#.'",Software,closed,2022-07-28T04:34:48Z,2022-07-28 21:07:59+00:00,2022-08-02T01:01:56Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/12357
12359,b'ONNXOptimizer: ValueError: Message onnx.ModelProto exceeds maximum protobuf size of 2GB: 2215158499',Software,open,2022-07-28T06:20:16Z,2022-07-28 06:20:16+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12359
12362,b'Integer quantization fails on Transformer-based vision model',Software,open,2022-07-28T08:14:16Z,2022-07-28 08:14:16+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12362
12365,b'Setting Openvino EP to run on one core with one thread',Software,open,2022-07-28T13:21:26Z,2022-07-28 18:06:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12365
12367,"b'.to(dtype, device) causes runtime error'",Software,closed,2022-07-28T18:03:59Z,2022-07-28 18:21:13+00:00,2022-08-03T01:33:46Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/12367
12370,b'How to load several ML models at the same time?',Software,closed,2022-07-28T18:58:31Z,2022-07-28 19:57:01+00:00,2022-07-28T19:57:01Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12370
12373,b'Unable to build tensorrt docker image',Software,open,2022-07-28T20:57:24Z,2022-07-28 21:06:24+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12373
12375,b'Failed to build onnxruntime with TensorRT on Windows 11',Software,closed,2022-07-28T22:39:20Z,2022-07-29 21:01:04+00:00,2022-08-01T17:21:45Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/12375
12380,b'Accept dictionary of tensor as input (python api)',Software,open,2022-07-29T15:55:49Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/12380
12382,b'Fail to build onnxRT with oneDNN using official build command',Software,open,2022-07-29T18:27:04Z,2022-07-29 21:05:04+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12382
12386,b'Segmentation fault',Software,open,2022-07-29T19:55:48Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/12386
12389,b'[Documentation Request] Java API docs need updating',Software,closed,2022-07-29T22:02:34Z,2022-07-29 22:02:34+00:00,2022-08-12T19:03:39Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/12389
12393,b'Build failure with gcc 11 on CentOS 7.',Software,open,2022-07-30T11:30:01Z,2022-07-30 12:12:30+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12393
12395,b'****CLA Assistant Lite bot**** All contributors have signed the CLA  \xe2\x9c\x8d\xef\xb8\x8f \xe2\x9c\x85',Software,closed,2022-07-31T00:47:24Z,2022-07-31 00:47:24+00:00,2022-08-01T17:02:58Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/12395
12401,"b'C# Session.Run ONNX FP16 type result is strange, using Python is normal'",Software,closed,2022-08-01T07:53:01Z,2022-08-03 17:12:02+00:00,2022-08-05T07:38:49Z,2,3,https://api.github.com/repos/microsoft/onnxruntime/issues/12401
12402,b'While loading the onnx file with InferenceSession getting session ID 11 error',Software,open,2022-08-01T10:36:47Z,2022-08-01 18:06:03+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12402
12407,b'Failed to build with ACL(and ARMnn)',Software,open,2022-08-01T18:31:08Z,2022-08-01 22:03:25+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12407
12411,"b'Can\'t build with OpenVINO 2022.1 (""onnxruntime_providers_shared"" does not exist)'",Software,open,2022-08-01T20:41:08Z,2022-08-01 22:03:00+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12411
12414,"b'`Env(OrtLoggingLevel, const char* logid, OrtLoggingFunction, ...` fails to pass `logid` param to log function'",Software,open,2022-08-01T23:04:21Z,2022-08-03 01:18:44+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/12414
12420,b'Linker Problem for MAUI on IOS',Software,open,2022-08-02T09:37:12Z,2022-08-02 16:23:14+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12420
12437,b'Is there a compiled onnxruntime c++ library that i can directly place it in my source code folder and include it in my code?',Software,closed,2022-08-03T06:32:46Z,2022-08-03 06:34:09+00:00,2022-08-03T09:57:31Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12437
12438,b'CMake Enabling AVX AVX2 does not improve performance',Software,closed,2022-08-03T09:46:41Z,2022-08-03 16:43:08+00:00,2022-08-03T16:43:08Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12438
12439,b'onnxruntime-node in docker image based on Alpine Linux ',Software,closed,2022-08-03T10:29:27Z,2022-08-03 16:57:42+00:00,2022-08-03T17:27:16Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12439
12444,b'maybe we could log this using the exception level',Software,closed,2022-08-03T18:16:10Z,2022-08-03 18:16:11+00:00,2022-08-03T18:16:46Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12444
12449,b'[Profiling] ETW Tracing support ONNX Runtime MLAS/DML and EPs',Software,open,2022-08-03T21:00:36Z,2022-08-04 18:04:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12449
12453,b'Superseded by #7.',Software,closed,2022-08-04T00:18:25Z,2022-08-04 00:18:26+00:00,2022-08-04T02:43:45Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12453
12454,b'**Is your feature request related to a problem? Please describe.**',Software,closed,2022-08-04T00:30:34Z,2022-08-04 00:30:35+00:00,2022-08-04T02:43:26Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12454
12455,b'**Is your feature request related to a problem? Please describe.**',Software,closed,2022-08-04T00:33:08Z,2022-08-04 00:33:09+00:00,2022-08-04T02:43:18Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12455
12456,b'contributions are welcome.',Software,closed,2022-08-04T00:39:55Z,2022-08-04 00:39:55+00:00,2022-08-04T02:43:08Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12456
12457,b'Looks good',Software,closed,2022-08-04T00:41:21Z,2022-08-04 00:41:21+00:00,2022-08-04T00:41:30Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12457
12458,b'Looks good',Software,closed,2022-08-04T00:41:42Z,2022-08-04 00:41:42+00:00,2022-08-04T02:42:24Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12458
12463,b'CUDA support for longer-input models like BigBird',Software,open,2022-08-04T08:38:12Z,2022-08-04 15:36:10+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12463
12464,b'Extracting 4D mask output of Mask RCNN with ONNX C++ API',Software,open,2022-08-04T09:35:35Z,2022-08-04 21:10:10+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12464
12466,b'[Documentation Request]',Software,closed,2022-08-04T12:46:57Z,2022-08-04 18:03:15+00:00,2022-08-04T20:50:45Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12466
12467,b'How to get the predicted output value (float) using onnxruntime c++',Software,closed,2022-08-04T13:28:11Z,2022-08-04 21:09:58+00:00,2022-08-04T22:58:12Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12467
12478,b'Got error: cpu exception in c++',Software,closed,2022-08-05T01:36:32Z,2022-08-05 03:57:23+00:00,2022-08-05T19:40:08Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12478
12479,b'I found that the OnnxRuntime used almost all of the instruction sets for the convolutional computations and I wanted to optimize for that',Software,open,2022-08-05T02:24:38Z,2022-08-05 03:58:30+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12479
12481,b'How to exit abnormally in the Python Operator (PyOp)',Software,open,2022-08-05T02:44:14Z,2022-08-05 04:03:08+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12481
12487,b'QDQ + Add nodes are not fused into QLinearAdd when the graph is optimized',Software,open,2022-08-05T10:10:28Z,2022-08-05 18:40:56+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12487
12488,b'Error 126: Cant Run Inference On GPU ',Software,open,2022-08-05T11:17:21Z,2022-08-05 16:42:32+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12488
12489,b'performance is poor when onnxruntime C++ run in intel cpu',Software,open,2022-08-05T11:58:54Z,2022-08-05 16:44:13+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12489
12491,b'SequenceMap fails when the body contains constant nodes',Software,open,2022-08-05T14:57:16Z,2022-08-05 14:58:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12491
12492,b'LSTM Y output is inconsistent with TF inference result when seq_len is effective',Software,open,2022-08-05T17:05:36Z,2022-08-05 17:06:08+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12492
12493,b'Clarify NMS sorting strategy',Software,open,2022-08-05T19:08:27Z,2022-08-09 17:09:43+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/12493
12494,b'Can I run Ort::Env env; every time there\xe2\x80\x99s a new input?',Software,closed,2022-08-05T19:43:22Z,2022-08-09 02:11:37+00:00,2022-08-09T02:11:36Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/12494
12498,b'ConvAdd Fusion produces wrong outputs when Conv has `group` attribute',Software,open,2022-08-08T00:31:28Z,2022-08-09 17:09:19+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/12498
12500,"b'[React Native Inference Session Initialization With Buffer Error] ""Error: Uint8Array is not supported""'",Software,open,2022-08-08T05:26:16Z,2022-08-09 17:08:09+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/12500
12502,b'Could not find a version that satisfies the requirement onnxruntime==1.10.0',Software,closed,2022-08-08T07:28:07Z,2022-08-09 17:05:20+00:00,2022-08-09T18:21:13Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/12502
12504,"b'On Big Endian machines like AIX, we are getting different Hash Key by the MurmurHash3::x86_32()'",Software,closed,2022-08-08T11:00:59Z,2022-08-09 17:04:35+00:00,2022-08-11T08:32:40Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/12504
12506,b'Attributes in nested function calls are zeroed out',Software,open,2022-08-08T12:24:21Z,2022-08-09 17:03:17+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/12506
12521,b'onnxruntime-android - ld: error: cannot find -lonnxruntime when building the native C++ project',Software,closed,2022-08-09T12:55:44Z,2022-08-09 16:47:44+00:00,2022-08-22T23:56:46Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/12521
12522,b'Vanilla LeViT model run with ORT is slower than PyTorch (seems even slower for large batch size)',Software,open,2022-08-09T13:23:19Z,2022-08-09 16:26:30+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12522
12523,"b""install onnxruntime 1.11.0 on Jetson Nano - protobuf requires Python '>=3.7' but the running Python is 3.6.9""",Software,closed,2022-08-09T15:47:10Z,2022-08-09 16:16:07+00:00,2022-08-09T17:17:33Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12523
12524,b'ORT built with CUDA but no processing is happening on the GPU',Software,closed,2022-08-09T16:42:13Z,2022-08-10 16:35:28+00:00,2022-08-10T16:35:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12524
12526,b'Computing loss within onnxrunitme inference (GPT2 model)',Software,open,2022-08-09T17:43:40Z,2022-08-09 17:53:36+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12526
1314,b'OneHot missing kernel for float data type with int32 indices',Software,closed,2019-06-28T04:07:09Z,2019-06-28 22:29:24+00:00,2019-07-01T21:30:35Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/1314
1315,b'How to populate onnx model with custom meta data map ?',Software,closed,2019-06-28T18:56:39Z,2019-06-29 00:12:22+00:00,2019-07-01T18:58:35Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/1315
1319,b'How to turn off warnings during execution in Python?',Software,closed,2019-06-29T13:57:18Z,2019-07-01 18:49:22+00:00,2019-12-28T11:56:05Z,2,181,https://api.github.com/repos/microsoft/onnxruntime/issues/1319
1321,"b'[Solved] ""Size Overflow"" error when executing OrtCreateTensorWithDataAsOrtValue()'",Software,closed,2019-07-01T03:01:58Z,2019-07-01 03:02:15+00:00,2019-07-01T09:08:45Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1321
1322,b'Typo',Software,closed,2019-07-01T04:20:29Z,2019-07-01 20:39:23+00:00,2019-07-02T04:25:40Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1322
1323,b'How to use C API to do inference with models with multiple inputs and outputs\xef\xbc\x9f',Software,closed,2019-07-01T09:18:30Z,2019-07-01 09:43:11+00:00,2019-10-17T22:21:19Z,0,108,https://api.github.com/repos/microsoft/onnxruntime/issues/1323
1326,"b'DynamicSlice was a removed  experimental ops. In the future, we may directly reject this operator'",Software,closed,2019-07-01T18:22:37Z,2019-07-01 20:19:28+00:00,2019-07-01T20:19:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1326
1331,b'Inconsistent results foor two consecutive results or crash with a specific ONNX model',Software,closed,2019-07-02T09:39:05Z,2019-07-02 16:37:29+00:00,2019-07-05T09:48:58Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/1331
1332,b'SSD-Resnet34 model load fails with CPU-MKL-DNN backend',Software,closed,2019-07-02T19:09:46Z,2019-07-02 19:12:12+00:00,2019-07-29T22:51:47Z,0,27,https://api.github.com/repos/microsoft/onnxruntime/issues/1332
1334,b'ssd-mobilenet model load fails with GPU backend',Software,closed,2019-07-02T21:56:28Z,2019-07-02 23:05:45+00:00,2019-07-19T20:54:10Z,0,16,https://api.github.com/repos/microsoft/onnxruntime/issues/1334
1338,b'ONNX Runtime wrong predictions for GradientBoostingClassifier and XGBClassifier',Software,closed,2019-07-03T13:19:52Z,2019-07-03 16:35:48+00:00,2019-10-25T17:41:58Z,0,114,https://api.github.com/repos/microsoft/onnxruntime/issues/1338
1341,b'Support for Intel Compiler',Software,closed,2019-07-03T21:43:37Z,2019-07-05 05:09:10+00:00,2019-10-21T21:15:58Z,1,109,https://api.github.com/repos/microsoft/onnxruntime/issues/1341
1342,"b""Master can't build due to TVM""",Software,closed,2019-07-03T21:59:46Z,2019-07-03 23:28:28+00:00,2019-07-03T23:28:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1342
1344,"b""System.IO.FileLoadException: Could not load file or assembly 'System.Runtime.CompilerServices.Unsafe,""",Software,closed,2019-07-04T09:40:35Z,2019-07-04 09:48:15+00:00,2019-07-11T19:14:34Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/1344
1345,b'Compiler Error ',Software,closed,2019-07-04T10:54:07Z,2019-07-09 17:07:35+00:00,2019-07-29T19:40:03Z,5,25,https://api.github.com/repos/microsoft/onnxruntime/issues/1345
1348,b'Performance optimization using inplace',Software,closed,2019-07-05T11:48:42Z,2019-07-07 23:18:16+00:00,2020-07-25T07:40:30Z,2,385,https://api.github.com/repos/microsoft/onnxruntime/issues/1348
1349,b'Error when linking libonnxruntime_mlas.a(SconvKernelSse2.S.o) with customized cmake build file ',Software,closed,2019-07-05T12:13:54Z,2019-07-05 20:01:05+00:00,2019-08-19T01:17:53Z,0,44,https://api.github.com/repos/microsoft/onnxruntime/issues/1349
1355,b'onnx runtime csharp InferenceSession failing with mask_rcnn from model zoo',Software,closed,2019-07-08T07:30:43Z,2019-07-08 16:56:31+00:00,2019-07-08T23:01:22Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1355
1360,b'Inference on a batch of sequences of variable lengths has stopped working',Software,closed,2019-07-08T21:56:00Z,2019-07-09 17:04:11+00:00,2019-07-23T00:43:09Z,0,14,https://api.github.com/repos/microsoft/onnxruntime/issues/1360
1366,b'C/C++ Interface how to deal with input tensors that need different types',Software,closed,2019-07-09T10:56:58Z,2019-07-09 18:52:26+00:00,2019-07-26T17:52:34Z,0,17,https://api.github.com/repos/microsoft/onnxruntime/issues/1366
1368,b'Concat - CPU Fallback',Software,closed,2019-07-09T19:43:47Z,2019-07-09 21:07:18+00:00,2019-07-10T16:16:36Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1368
1369,b'Broken links in Versioning ReadME',Documentation,closed,2019-07-09T20:22:54Z,2019-07-09 20:22:54+00:00,2019-07-10T16:37:56Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1369
1373,b'Missing cuda_provider_factory.h file in release for windows gpu',Documentation,closed,2019-07-10T12:32:30Z,2019-07-10 16:38:03+00:00,2019-07-23T20:00:07Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/1373
1382,b'onnxruntime server can use a GPU backend when available',Software,closed,2019-07-11T02:31:59Z,2019-07-11 18:22:03+00:00,2020-08-09T23:45:03Z,0,395,https://api.github.com/repos/microsoft/onnxruntime/issues/1382
1384,b'Exception when running OrtRun(): Attempt to use DefaultLogger but none has been registered. ',Software,closed,2019-07-11T06:07:03Z,2019-07-11 06:07:34+00:00,2019-07-12T02:02:22Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1384
1385,b'Redefinition due to missing guard in onnxruntime_cxx_inline.h',Software,closed,2019-07-11T09:09:16Z,2019-07-11 09:09:49+00:00,2019-07-23T15:45:39Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/1385
1390,b'Fail to create vector<Ort::Value> using onnxruntime_cxx_api and the official built issues',Software,closed,2019-07-12T03:07:00Z,2019-07-12 18:12:04+00:00,2019-07-12T18:12:04Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1390
1396,b'[TypeInferenceError] Attribute expected to have a one-dim tensor',Software,closed,2019-07-13T06:38:12Z,2019-07-13 22:33:42+00:00,2019-07-15T17:11:49Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/1396
1397,"b'when built with flag --gen_doc, onnx and onnxruntime cannot be imported in the same python script'",Software,closed,2019-07-13T10:47:16Z,2019-07-13 10:48:16+00:00,2019-07-19T18:25:32Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/1397
1399,b'Where can we find Windows debug symbols(pdb files) for released binaries',Software,closed,2019-07-13T16:48:13Z,2019-07-15 16:36:08+00:00,2019-07-16T18:15:31Z,1,3,https://api.github.com/repos/microsoft/onnxruntime/issues/1399
1400,b'Wrong result when evaluating a batch of padded sequences with varying lengths on GPU',Software,closed,2019-07-13T19:15:31Z,2019-07-15 16:34:02+00:00,2019-07-19T19:10:01Z,1,5,https://api.github.com/repos/microsoft/onnxruntime/issues/1400
1402,b'Performance Test Issue With gt/Nuphar Branch on Windows & Linux build Fails',Software,closed,2019-07-13T23:43:40Z,2019-07-13 23:43:40+00:00,2019-07-23T01:22:42Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/1402
1404,"b""ImportError: cannot import name 'RunOptions' """,Software,closed,2019-07-14T13:43:04Z,2019-07-15 14:23:31+00:00,2019-07-17T20:30:09Z,1,3,https://api.github.com/repos/microsoft/onnxruntime/issues/1404
1409,"b'""CUDA driver version is insufficent for CUDA runtime version"" exception raised when calling OrtCreateSessionFromArray in spite of the CUDA provider not being selected in session options'",Software,closed,2019-07-15T21:47:29Z,2019-07-15 21:53:15+00:00,2020-07-25T07:40:18Z,0,375,https://api.github.com/repos/microsoft/onnxruntime/issues/1409
1410,b'Question: Does Nuphar EP use openmp?',Software,closed,2019-07-15T22:54:41Z,2019-07-16 00:07:37+00:00,2019-07-16T21:54:25Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1410
12538,b'DML EP cannot load some onnx files.',Software,open,2022-08-10T05:02:54Z,2022-08-10 15:47:34+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12538
12540,b'java  deploy in k8s Failed to load library libonnxruntime_providers_cuda.so with error',Software,open,2022-08-10T08:58:31Z,2022-08-10 15:47:11+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12540
12551,b'engine decryption does not work  in TensorRT EP',Software,open,2022-08-11T03:14:16Z,2022-08-11 18:27:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12551
12556,"b'Error when exluding nodes from quantization: ""ValueError: list.remove(x): x not in list""'",Software,closed,2022-08-11T14:16:42Z,2022-08-11 16:07:13+00:00,2022-08-12T20:54:48Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/12556
12558,"b""Could not find an implementation for ConvInteger(10) node with name 'Conv_59_quant'""",Software,closed,2022-08-11T16:05:16Z,2022-08-11 18:26:55+00:00,2022-08-11T18:26:55Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12558
12567,"b'Fix the eager generator to support broadcasting ops add, sub, mul, div'",Software,open,2022-08-11T19:35:09Z,2022-08-15 16:15:05+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/12567
12573,b'Add execution provider selection for quantize_static',Software,open,2022-08-12T06:39:17Z,2022-08-12 21:26:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12573
12575,b'Missing `onnx` dependency when running cli',Software,closed,2022-08-12T10:25:54Z,2022-08-12 18:09:09+00:00,2022-08-12T18:09:09Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12575
12576,b'Potential updates on `ONNXModel.save_model_to_file` of quantization and optimization',Software,open,2022-08-12T13:48:05Z,2022-08-12 14:42:06+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12576
12577,b'Resize op generates invalid WebGL code',Software,closed,2022-08-12T19:04:17Z,2022-08-12 21:27:18+00:00,2022-08-22T04:47:29Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/12577
12579,b'Failed to find kernel for SimplifiedLayerNormalization(1) (node SimplifiedLayerNormalization). ',Software,open,2022-08-12T20:30:18Z,2022-08-12 21:30:19+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12579
12581,b'request `Ort::InitApi()` be `noexcept`',Software,open,2022-08-12T21:21:43Z,2022-08-12 21:31:27+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12581
12584,b'Document beamsearch ',Software,open,2022-08-12T21:55:46Z,2022-08-13 00:04:03+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12584
12589,b'Initializing inference session on worker thread for web applications using onnxruntime-web',Software,open,2022-08-13T01:51:13Z,2022-08-15 19:50:04+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/12589
12591,b'Bumps [terser](https://github.com/terser/terser) from 5.14.0 to 5.14.2.',Software,closed,2022-08-13T08:50:15Z,2022-08-13 08:50:16+00:00,2022-08-13T08:51:50Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12591
12592,"b""Export to multiple files with torch.onnx.export and can't load them in .NET Microsoft.ML.OnnxRuntime.""",Software,closed,2022-08-15T06:13:09Z,2022-08-16 06:06:02+00:00,2022-08-17T00:49:54Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/12592
12594,"b""Name:'MatMul_32007' Status Message: matmul_helper.h:61 Compute MatMul dimension mismatch""",Software,open,2022-08-15T12:56:02Z,2022-08-22 23:33:40+00:00,,7,,https://api.github.com/repos/microsoft/onnxruntime/issues/12594
12595,"b""RUNTIME_EXCEPTION : Non-zero status code returned while running Mul node. Name:'Mul_5'""",Software,closed,2022-08-15T16:09:13Z,2022-08-15 16:57:44+00:00,2022-08-15T16:57:44Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12595
12598,b'Build error with LLVM toolchain',Software,closed,2022-08-15T16:38:33Z,2022-08-17 17:49:57+00:00,2022-08-17T17:49:56Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/12598
12608,b'Run the onnx model converted from seq2seq and report an error',Software,open,2022-08-16T07:09:23Z,2022-08-17 03:11:08+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12608
12609,"b""onnxruntime-web bug : 'return f4' is fast as normal, but 'return f1,f2,f3,f4' is very slow in wasm and webgl mode""",Software,open,2022-08-16T10:52:02Z,2022-08-16 18:31:28+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12609
12622,b' How do I understand the error message such as: 7508808',Software,open,2022-08-17T06:28:22Z,2022-08-17 14:50:00+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12622
12623,b'Where is the definition of session.Run() in onnxruntime C++ api',Software,open,2022-08-17T06:38:02Z,2022-08-19 09:30:59+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/12623
12625,b'Customized allocator from EP is overwritten by default one in SessionState::SetupAllocators()',Software,open,2022-08-17T08:52:31Z,2022-08-17 09:13:13+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12625
12629,b'Scikit-learn model converted to ONNX results in different output shapes between Python and Java environments',Software,open,2022-08-17T14:42:50Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/12629
12636,b'cuda_provider_options.h include non existing file?',Software,open,2022-08-18T07:53:01Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/12636
12637,"b'when the model support dynamic batch \xef\xbc\x8cthe input shape [ -1,-1,80],  how can  warm up?  because of the dynamic batch , I do know the warmup batchsize number ,can it use min_batchsize and max _batchsize to warmup?'",Software,open,2022-08-18T10:27:57Z,2022-08-18 10:27:57+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12637
12638,b'The quantization model reduces the accuracy compared to the TRT',Software,open,2022-08-18T11:22:59Z,2022-08-18 16:49:35+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12638
12639,b'Failed to create TensorrtExecutionProvider using onnxruntime-gpu',Software,open,2022-08-18T13:39:51Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/12639
12648,b'Confusing exception about supported types ',Software,open,2022-08-19T01:29:41Z,2022-08-20 00:04:37+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12648
12650,b'Unable to compile ONNX Runtime on Linux 32-bit ARM',Software,closed,2022-08-19T08:12:00Z,2022-08-22 16:59:01+00:00,2022-08-24T04:10:09Z,3,4,https://api.github.com/repos/microsoft/onnxruntime/issues/12650
12652,b'get kill signal when quantize the ONNX model using quantize_static',Software,open,2022-08-19T11:26:49Z,2022-08-19 11:27:03+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12652
12654,b'Enable Global Shared Threadpool and Memory Allocator For C#',Software,open,2022-08-19T17:01:26Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/12654
12662,"b'rocm-5.2.0: onnxruntime_test_all failed with ""hipErrorNoBinaryForGpu: Unable to find code object for all current devices!""'",Software,closed,2022-08-20T06:30:02Z,2022-08-22 17:03:44+00:00,2022-08-24T08:14:00Z,2,4,https://api.github.com/repos/microsoft/onnxruntime/issues/12662
12663,"b""'make install' failed for rocm & migraphx""",Software,open,2022-08-20T11:03:48Z,2022-08-22 16:44:30+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/12663
12664,b'cmake error when adding --build_shared_lib or --build_nodejs to rocm',Software,open,2022-08-20T13:53:20Z,2022-08-22 01:32:42+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/12664
12665,b'Worker Errror :  Error: no available backend found. ERR: [wasm] TypeError: n(...).dirname is not a function',Software,closed,2022-08-20T19:19:38Z,2022-08-22 16:37:43+00:00,2022-08-22T17:28:28Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/12665
12666,b'Request to add convert_beam_search for model conversion ',Software,closed,2022-08-21T16:09:20Z,2022-08-22 16:34:32+00:00,2022-08-22T17:26:29Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/12666
12669,b'Non-zero status code returned while running TopK node. (ssdlite320_mobilenet_v3_large)',Software,open,2022-08-22T17:23:56Z,2022-08-22 21:36:41+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12669
12677,b'InstanceNormalization: The parameter is incorrect error on DirectML',Software,closed,2022-08-23T04:06:26Z,2022-08-23 16:10:12+00:00,2022-08-24T22:03:43Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/12677
12679,b'OnnxRuntime crashed when running ortSession.run() for Android',Software,open,2022-08-23T06:25:44Z,2022-08-23 16:10:31+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12679
12683,b'[Build] error: \xe2\x80\x98if constexpr\xe2\x80\x99 only available with -std=c++17 or -std=gnu++17',Software,closed,2022-08-23T14:13:35Z,2022-08-23 16:11:05+00:00,2022-08-24T01:59:37Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12683
12684,b'Loop op with maximum iterations empty input M causes failure when running symbolic_shape_infer script',Software,open,2022-08-23T15:58:02Z,2022-08-23 16:11:51+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12684
12700,b'How to run react-native e2e example?',Software,open,2022-08-24T12:58:20Z,2022-08-24 17:04:00+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12700
12706,b'CUDA onnxruntime-gpu=1.12.1 inference result differs from onnxruntime-gpu=1.11.0',Software,open,2022-08-24T17:54:22Z,2022-08-24 17:58:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12706
12715,"b""[react native] ORT file; Can't load a model: Can't create InferenceSession""",Software,open,2022-08-25T00:47:34Z,2022-08-25 17:49:56+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12715
12718,"b'[win7 dlls]Failure to run ORT on win7 64-bit system, missing api-ms-win-core-* dlls'",Software,closed,2022-08-25T04:17:41Z,2022-08-25 04:18:47+00:00,2022-08-25T05:02:42Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12718
12719,b'link libonnxruntime_mlas run with gemmpack coredump',Software,closed,2022-08-25T04:26:33Z,2022-08-25 08:33:32+00:00,2022-08-25T08:33:32Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12719
12721,b'PHP Library',Software,closed,2022-08-25T05:06:27Z,2022-08-25 17:49:10+00:00,2022-08-27T18:36:26Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/12721
12725,b'Any difference between onnxruntime+tensorrt and tensorrt only in INT8 mode?',Software,open,2022-08-25T09:26:31Z,2022-08-25 09:27:30+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12725
12726,b'Wrong Results for FP16 Models in CUDAExecutionProvider and TensorRTExecutionProvider',Software,open,2022-08-25T12:18:31Z,2022-08-25 17:47:29+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12726
12728,"b'On a Big endian platform like AIX, KernelDef::CalculateHash() gives incorrect hash key'",Software,closed,2022-08-25T16:43:47Z,2022-08-25 17:48:15+00:00,2022-08-29T08:03:04Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/12728
12731,b'MSBuild .props copies x64 onnxruntime_providers_shared.dll to output folder when target platform is arm64',Software,open,2022-08-25T17:49:41Z,2022-08-25 20:01:15+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12731
12734,b'Cuda EP behavior with pitched data',Software,closed,2022-08-25T20:58:05Z,2022-08-25 21:09:54+00:00,2022-08-25T21:22:16Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12734
12736,b'`static inline Ort::Env onnx_env{nullptr}` easily leads to nullptr deref on app exit',Software,closed,2022-08-25T21:43:33Z,2022-08-25 21:50:54+00:00,2022-08-26T17:12:08Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/12736
12743,b'React Native .ort Operator Issue',Software,open,2022-08-26T04:28:07Z,2022-08-26 16:15:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12743
12745,b'SystemError : 13 for transformers optimizer',Software,open,2022-08-26T05:25:43Z,2022-08-26 16:16:26+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12745
12748,b'not work for OrtCUDAProviderOptionsV2 to release GPU memory in C++',Software,open,2022-08-26T09:34:13Z,2022-08-26 09:34:13+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12748
12754,b'BatchNormalization produces all zeros for 1D input',Software,open,2022-08-26T18:17:01Z,2022-08-26 21:26:38+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12754
12759,"b'Why onnxruntime-1.11.0.jar does not contain the ""linux-aarch64""'",Software,closed,2022-08-27T03:03:24Z,2022-08-29 00:02:16+00:00,2022-08-29T17:10:52Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/12759
12760,b'How to set the priority of ONNX in GPU?',Software,open,2022-08-28T07:19:37Z,2022-08-29 00:03:15+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12760
12761,"b'ONNX model fails to load on amd GPU, but loads fine on CPU'",Software,open,2022-08-28T19:46:49Z,2022-08-29 00:03:45+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12761
12763,b'torch.nn.LayerNorm mismatches in nightly.',Software,open,2022-08-28T21:03:49Z,2022-08-29 00:04:07+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12763
12766,b'onnxruntime-linux-x64-gpu-1.12.1',Software,open,2022-08-29T03:23:10Z,2022-08-29 18:27:32+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12766
12767,b'Two gathers followed by a matmul fail to load on DML',Software,open,2022-08-29T05:01:10Z,2022-08-29 18:27:42+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12767
12768,b'Asynchrononus Inference',Software,open,2022-08-29T05:17:35Z,2022-08-29 05:23:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12768
12781,b'I want to use tensorrt as the back-end of onnx',Software,open,2022-08-30T01:08:57Z,2022-08-30 02:17:39+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12781
12785,b'onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : CUDA error executing cudaSetDevice(GetDeviceId())',Software,open,2022-08-30T06:58:15Z,2022-08-30 16:36:13+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12785
12786,b'cast op not support multithread',Software,open,2022-08-30T08:01:53Z,2022-08-30 16:39:45+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12786
12793,b'NNAPIs crashes using Xiaomi 9t Pro (Snapdragon 855)',Software,open,2022-08-30T22:02:42Z,2022-08-30 23:02:33+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/12793
12800,"b""Some QlinearConv can't dequantize its int8 weight with ORT1.12""",Software,open,2022-08-31T04:28:42Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/12800
12804,b'Not able to save model when using execution providers',Software,open,2022-08-31T07:56:31Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/12804
1416,"b""The program '[30444] dotnet.exe' has exited with code -1066598274 (0xc06d007e) 'Module not found'.""",Software,closed,2019-07-16T08:14:05Z,2019-07-18 02:18:56+00:00,2019-07-29T22:10:55Z,1,13,https://api.github.com/repos/microsoft/onnxruntime/issues/1416
1417,b'Question: C# API Inferencing of Tabular Data (1D Tensors) from ML.NET',Software,closed,2019-07-16T14:05:25Z,2019-07-17 00:45:23+00:00,2019-07-17T22:59:26Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1417
1424,"b""Can't deploy ONNX model in CPU only environment""",Software,closed,2019-07-17T17:17:04Z,2019-07-18 15:19:41+00:00,2019-07-20T00:22:03Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/1424
1430,b'Exception:Only one instance of LoggingManager created with InstanceType::Default can exist at any point in time.',Software,closed,2019-07-18T06:38:29Z,2019-07-18 08:12:35+00:00,2019-07-19T02:40:37Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1430
1433,b'Compatibility issue with gcc 8.3 and/or protobuf?',Software,closed,2019-07-18T18:56:22Z,2019-07-26 17:47:05+00:00,2019-12-28T02:28:19Z,7,162,https://api.github.com/repos/microsoft/onnxruntime/issues/1433
1452,"b'TensorRT doest support opset10, onnxruntime support?'",Software,closed,2019-07-20T02:35:49Z,2019-07-20 02:39:52+00:00,2019-07-24T04:32:52Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/1452
1453,b'Wheel file not generated',Software,closed,2019-07-21T04:10:06Z,2019-07-22 18:00:25+00:00,2019-07-22T18:59:17Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1453
1454,"b""OrtRun doesn't return results unless 'output' is nullptr""",Documentation,closed,2019-07-21T04:31:30Z,2019-07-23 00:42:42+00:00,2020-02-27T18:28:55Z,1,221,https://api.github.com/repos/microsoft/onnxruntime/issues/1454
1455,b'How to extract output tensor from any layer of models',Documentation,closed,2019-07-21T07:10:55Z,2019-07-22 21:24:40+00:00,2019-07-25T00:42:04Z,1,3,https://api.github.com/repos/microsoft/onnxruntime/issues/1455
1457,b'skip unit tests after build',Documentation,closed,2019-07-22T05:37:35Z,2019-07-22 16:04:25+00:00,2019-07-22T16:04:25Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1457
1464,b'Build on master failed on PyBind11',Documentation,closed,2019-07-22T23:14:56Z,2019-07-23 00:40:12+00:00,2019-07-23T00:40:12Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1464
1467,b'Reason for Stable Performance of Nuphar EP with increasing batch size of onnx model ',Documentation,closed,2019-07-23T01:32:54Z,2019-07-23 01:32:54+00:00,2019-07-23T20:56:48Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1467
1471,"b""onnxruntime server terminate called after throwing an instance of 'boost::wrapexcept<boost::uuids::entropy_error>'   what():  getrandom""",Software,closed,2019-07-23T07:32:13Z,2019-07-23 18:05:57+00:00,2020-07-11T01:41:05Z,0,353,https://api.github.com/repos/microsoft/onnxruntime/issues/1471
1472,b'How to build and use onnxruntime static lib on windows? ',Software,closed,2019-07-23T08:50:24Z,2019-07-24 02:49:38+00:00,2019-08-09T06:11:26Z,0,16,https://api.github.com/repos/microsoft/onnxruntime/issues/1472
1473,b'Question: How can I retrieve the metadata denotations from any onnx model in Android?',Software,closed,2019-07-23T08:58:25Z,2019-07-23 10:57:38+00:00,2019-08-02T17:59:50Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/1473
1474,b'run  ./build.sh wrong',Software,closed,2019-07-23T11:26:20Z,2019-07-25 16:36:02+00:00,2019-07-30T17:37:37Z,2,7,https://api.github.com/repos/microsoft/onnxruntime/issues/1474
1481,b'there are some errors when i try to build onnxruntime with openvino',Software,closed,2019-07-24T07:24:02Z,2019-07-24 15:27:58+00:00,2019-09-09T22:46:37Z,0,47,https://api.github.com/repos/microsoft/onnxruntime/issues/1481
1487,b'DropOut fails when mask output tensor provided',Software,closed,2019-07-24T21:48:35Z,2019-07-24 22:09:02+00:00,2019-08-01T05:37:12Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/1487
1494,b'MatMul + Add -> GEMM fusion not performed for float16',Software,closed,2019-07-25T05:17:39Z,2019-07-25 05:26:34+00:00,2019-07-30T23:49:23Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/1494
1496,b'Squeeze requires axes attribute bug',Software,closed,2019-07-25T15:38:14Z,2019-07-25 19:11:56+00:00,2019-07-26T18:16:36Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1496
1510,b'Update the onnxruntime nugets for cuda10 and include Arm64v8 as target',Software,closed,2019-07-26T07:22:17Z,2019-07-26 17:40:43+00:00,2019-08-01T08:08:08Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/1510
1511,b'GENERAL ERROR : Non-zero status code returned while running Node: concat_35 Status Message: ',Software,closed,2019-07-26T11:42:32Z,2019-07-26 15:49:55+00:00,2019-08-09T02:53:35Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/1511
1515,b'No output in console after OrtCreateSession',Software,closed,2019-07-28T04:43:25Z,2019-08-13 16:43:51+00:00,2019-08-28T21:43:28Z,16,31,https://api.github.com/repos/microsoft/onnxruntime/issues/1515
1527,b'some questions about the ops of openvino and onnx',Software,closed,2019-07-31T09:58:45Z,2019-07-31 17:34:01+00:00,2020-09-20T20:40:11Z,0,417,https://api.github.com/repos/microsoft/onnxruntime/issues/1527
1533,"b""Gather doesn't seem to support negative indexing""",Software,closed,2019-07-31T23:41:48Z,2019-07-31 23:46:14+00:00,2019-08-05T22:15:12Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/1533
1535,b'Can you support GCC4.8?',Software,closed,2019-08-01T02:44:30Z,2019-08-01 23:34:32+00:00,2019-08-17T17:12:34Z,0,16,https://api.github.com/repos/microsoft/onnxruntime/issues/1535
1537,"b'Got ""NOT_IMPLEMENTED"" error on OneHot with int32'",Software,closed,2019-08-01T07:03:42Z,2019-08-01 07:19:32+00:00,2019-08-07T00:45:43Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/1537
1538,"b""Error when loading with C#: An unhandled exception of type 'System.AccessViolationException' occurred in Microsoft.ML.OnnxRuntime.dll""",Software,closed,2019-08-01T08:00:43Z,2019-08-02 03:09:19+00:00,2019-09-09T22:56:55Z,0,39,https://api.github.com/repos/microsoft/onnxruntime/issues/1538
1541,b'import paddle.fluid & import onnxruntime  will be core_dump',Software,closed,2019-08-01T13:20:35Z,2019-08-01 23:42:11+00:00,2019-09-20T00:44:35Z,0,49,https://api.github.com/repos/microsoft/onnxruntime/issues/1541
1542,b'RuntimeError: [ONNXRuntimeError] : 1 : GENERAL ERROR : Load model from waveglow.onnx failed:Type Error: Type parameter (T) bound to different types (tensor(int64) and tensor(float) in node ().',Software,closed,2019-08-01T15:01:05Z,2019-08-01 16:36:28+00:00,2019-08-01T22:18:17Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1542
1543,b'Error running quantized onnx model',Software,closed,2019-08-01T15:42:42Z,2019-08-01 16:30:27+00:00,2019-11-06T19:34:08Z,0,97,https://api.github.com/repos/microsoft/onnxruntime/issues/1543
1545,b'Examples and support custom ops in C#',Software,closed,2019-08-01T20:33:02Z,2019-08-01 23:19:55+00:00,2020-03-10T23:29:38Z,0,222,https://api.github.com/repos/microsoft/onnxruntime/issues/1545
1549,b'Memory Leak with ortcreateenv',Software,closed,2019-08-02T05:10:51Z,2019-08-02 05:23:36+00:00,2019-08-08T18:29:04Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/1549
1550,b'Official c api build dll and lib do not include function of OrtGetDimensions',Software,closed,2019-08-02T05:15:43Z,2019-08-02 05:59:23+00:00,2019-08-02T05:59:23Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1550
1557,b'some questions about cross compiling on Linux (without Docker)',Software,closed,2019-08-05T01:20:30Z,2019-08-05 16:39:34+00:00,2019-08-06T10:56:10Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1557
1558,b'use onnxruntime by pypi',Documentation,closed,2019-08-05T09:01:09Z,2019-08-05 18:21:58+00:00,2019-08-28T21:46:52Z,0,23,https://api.github.com/repos/microsoft/onnxruntime/issues/1558
1559,b'with reference to #1542 ',Software,closed,2019-08-05T10:59:05Z,2019-08-05 10:59:05+00:00,2019-09-18T00:17:38Z,0,43,https://api.github.com/repos/microsoft/onnxruntime/issues/1559
1567,b'some questions about cross compiling on Linux (without Docker) ',Software,closed,2019-08-06T10:56:17Z,2019-08-06 16:48:08+00:00,2020-02-27T18:28:40Z,0,205,https://api.github.com/repos/microsoft/onnxruntime/issues/1567
1568,b'Question about the onnx model output ',Software,closed,2019-08-06T12:20:16Z,2019-08-06 16:48:28+00:00,2019-08-08T18:54:11Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/1568
1569,b'Question about load sklearn converted onnx model',Software,closed,2019-08-06T14:10:43Z,2019-08-06 22:41:46+00:00,2019-08-09T02:07:19Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/1569
1574,b'ARM32v7 Cross Compile Broken due to protobuf Bug',Software,closed,2019-08-06T21:52:51Z,2019-08-06 22:21:44+00:00,2019-08-06T23:21:18Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1574
1579,b'How to use batch predict using v0.5',Software,closed,2019-08-07T09:06:06Z,2019-08-13 20:34:33+00:00,2019-11-11T23:03:31Z,6,96,https://api.github.com/repos/microsoft/onnxruntime/issues/1579
1583,"b'""Less"" op does not support int64 input type'",Software,closed,2019-08-07T22:21:38Z,2019-08-09 16:53:19+00:00,2019-08-12T20:52:21Z,1,4,https://api.github.com/repos/microsoft/onnxruntime/issues/1583
1584,b'pip3 install failed onnxruntime_gpu==0.5.0',Software,closed,2019-08-07T22:42:29Z,2019-08-07 22:43:13+00:00,2019-08-08T16:28:16Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1584
1585,b'Different results with xgboost and onnxruntime when n_estimators > 1',Software,closed,2019-08-08T01:49:52Z,2019-08-08 19:48:41+00:00,2019-09-20T08:49:29Z,0,43,https://api.github.com/repos/microsoft/onnxruntime/issues/1585
1591,b'ONNXRuntime_GPU illegal memory access error',Software,closed,2019-08-08T18:16:54Z,2019-08-14 20:44:35+00:00,2019-10-01T19:03:05Z,6,54,https://api.github.com/repos/microsoft/onnxruntime/issues/1591
1592,"b'multi-GPU ""alloc failed"" error arises after updating to rel-0.5.0'",Software,closed,2019-08-08T18:34:48Z,2019-08-14 20:43:56+00:00,2019-09-16T18:59:27Z,6,39,https://api.github.com/repos/microsoft/onnxruntime/issues/1592
1596,b'Official build version 5.0 for Linux does not include cxx_api.h and cxx_inline.h?',Software,closed,2019-08-09T02:09:51Z,2019-08-09 02:51:56+00:00,2019-08-14T20:51:30Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/1596
1597,"b'I run the onnx model , the program is coredump directly, is there is some flags to open, then I could see more detail'",Software,closed,2019-08-09T03:47:35Z,2019-08-14 18:29:47+00:00,2019-08-28T21:46:15Z,5,19,https://api.github.com/repos/microsoft/onnxruntime/issues/1597
1601,b'Source codes can not access inside China',Software,closed,2019-08-09T11:29:13Z,2019-08-09 16:42:12+00:00,2019-12-27T23:22:05Z,0,140,https://api.github.com/repos/microsoft/onnxruntime/issues/1601
1606,b'Run Google DeepLabV3 semantic segmentation model fail',Software,closed,2019-08-12T16:24:59Z,2019-08-12 16:30:40+00:00,2019-08-13T07:40:23Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1606
1607,b'Bidirectional RNN with initial hidden state does not return the expected results',Software,closed,2019-08-12T20:52:44Z,2019-08-14 05:21:06+00:00,2019-08-16T17:12:47Z,1,3,https://api.github.com/repos/microsoft/onnxruntime/issues/1607
1608,b'90% CPU Usage when running ONNX GPU release',Software,closed,2019-08-12T21:53:11Z,2019-08-14 20:34:27+00:00,2019-08-20T18:03:22Z,1,7,https://api.github.com/repos/microsoft/onnxruntime/issues/1608
1610,"b'In case of batch_index>0, NonMaxSuppression returns unexpected results.'",Software,closed,2019-08-13T07:14:17Z,2019-08-13 21:57:57+00:00,2019-08-15T18:41:12Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/1610
1612,b'onnruntime_gpu python lib need libcudart.so.10.1',Software,closed,2019-08-13T10:50:02Z,2019-08-14 02:28:10+00:00,2019-08-15T02:55:19Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1612
1613,"b""pip install onxxruntime==0.5.0 on linux doesn't find the package""",Software,closed,2019-08-13T17:23:01Z,2019-08-13 17:25:16+00:00,2019-08-13T17:25:16Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1613
1616,b'There was an error linking dynamic libraries during cross compilation(without docker)',Software,closed,2019-08-14T02:35:20Z,2019-08-14 20:29:43+00:00,2019-10-17T22:22:37Z,0,64,https://api.github.com/repos/microsoft/onnxruntime/issues/1616
1618,b'Use the op ReduceMax error',Software,closed,2019-08-14T13:35:05Z,2019-08-14 18:15:49+00:00,2019-08-15T21:49:00Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1618
1619,b'run mask-rcnn from model zoo crashed',Software,closed,2019-08-14T13:56:29Z,2019-08-14 20:28:25+00:00,2019-08-16T17:15:37Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/1619
1620,b'onnx model 50x slower than in pytorch',Software,closed,2019-08-14T14:29:49Z,2019-08-14 20:29:21+00:00,2019-12-17T18:21:49Z,0,125,https://api.github.com/repos/microsoft/onnxruntime/issues/1620
1621,b'Question about putting inputs / outputs in GPU memory',Software,closed,2019-08-14T15:49:11Z,2019-08-14 16:49:35+00:00,2020-07-25T07:40:25Z,0,345,https://api.github.com/repos/microsoft/onnxruntime/issues/1621
1627,b'Question about multiple dimension string tensor using CXX api',Software,closed,2019-08-15T07:28:56Z,2019-08-15 20:34:08+00:00,2019-08-21T03:31:26Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/1627
1628,b'[Need Info][ONNXRUNTIME-SERVER] - Input JSON format for onnxruntime server',Software,closed,2019-08-15T18:55:34Z,2019-08-15 20:35:05+00:00,2019-08-28T21:42:47Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/1628
1629,b'Request to add output for model load from protobuf',Software,closed,2019-08-15T21:27:11Z,2019-08-19 02:59:23+00:00,2019-10-11T22:33:44Z,3,57,https://api.github.com/repos/microsoft/onnxruntime/issues/1629
1632,b'Questions on Batch sizes and how onnxruntime treats them',Software,closed,2019-08-16T01:11:03Z,2019-08-16 03:27:40+00:00,2019-09-24T19:32:32Z,0,39,https://api.github.com/repos/microsoft/onnxruntime/issues/1632
1634,b'Load model failed - invalid model?',Software,closed,2019-08-16T13:09:25Z,2019-08-16 18:48:06+00:00,2019-08-16T19:12:26Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1634
1640,b'OrtTensorProtoToOrtValue deleter',Software,closed,2019-08-17T01:58:09Z,2019-08-17 02:26:06+00:00,2019-08-17T02:26:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1640
1641,b'Resize operator fails with 2D tensors',Software,closed,2019-08-17T02:47:47Z,2019-08-21 18:23:20+00:00,2019-08-29T18:34:32Z,4,12,https://api.github.com/repos/microsoft/onnxruntime/issues/1641
1645,b'Using Experimental operators (such as ATen) over C/C++ API.',Software,closed,2019-08-18T20:34:50Z,2019-08-19 02:55:50+00:00,2019-09-25T18:54:33Z,0,37,https://api.github.com/repos/microsoft/onnxruntime/issues/1645
1652,b'C# Avoid boxing every single float in ArrayTensorExtensions.ToTensor<T>(T[]) ',Software,closed,2019-08-20T00:37:46Z,2019-09-10 16:40:42+00:00,2020-07-25T07:40:19Z,21,340,https://api.github.com/repos/microsoft/onnxruntime/issues/1652
1657,b'ReduceSum node not implemented',Software,closed,2019-08-20T07:03:56Z,2019-08-21 07:30:38+00:00,2019-08-21T07:30:38Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1657
1658,b'onnxruntime test fail after successful model conversion',Software,closed,2019-08-20T15:18:38Z,2019-08-20 20:57:24+00:00,2019-10-14T09:00:17Z,0,54,https://api.github.com/repos/microsoft/onnxruntime/issues/1658
1659,b'[LSTM Inference] C++ API Scoring with internal state update',Software,closed,2019-08-20T15:43:52Z,2019-08-28 18:47:35+00:00,2019-09-25T18:53:43Z,8,36,https://api.github.com/repos/microsoft/onnxruntime/issues/1659
1662,b'GENERAL ERROR : The node is not placed on any Execution Provider',Software,closed,2019-08-21T08:10:04Z,2019-08-23 03:49:43+00:00,2019-08-23T03:49:43Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1662
1669,b'Misleading error on TensorRT batching ',Software,closed,2019-08-22T02:27:06Z,2019-08-27 17:47:41+00:00,2019-09-05T01:44:24Z,5,13,https://api.github.com/repos/microsoft/onnxruntime/issues/1669
1670,b'mask rcnn model failed with onnx runtime',Software,closed,2019-08-22T02:30:59Z,2019-08-26 05:12:09+00:00,2019-08-27T21:05:10Z,4,5,https://api.github.com/repos/microsoft/onnxruntime/issues/1670
1675,b'ONNX model gets much slower on rel-0.5.0 compared to rel-0.4.0',Software,closed,2019-08-22T20:42:11Z,2019-08-27 21:55:08+00:00,2019-09-04T16:32:49Z,5,12,https://api.github.com/repos/microsoft/onnxruntime/issues/1675
1681,b'Runtime Exception for TensorRT ',Software,closed,2019-08-23T06:13:42Z,2019-08-23 20:39:22+00:00,2020-07-11T04:39:50Z,0,322,https://api.github.com/repos/microsoft/onnxruntime/issues/1681
1683,b'Support for Winograd Conv with MKLDNN',Software,closed,2019-08-23T10:27:44Z,2019-08-23 20:29:15+00:00,2020-07-11T04:40:02Z,0,322,https://api.github.com/repos/microsoft/onnxruntime/issues/1683
1685,b'CNTK generated ONNX File fails to load',Software,closed,2019-08-23T17:17:01Z,2019-08-23 18:50:25+00:00,2020-07-11T02:40:00Z,0,322,https://api.github.com/repos/microsoft/onnxruntime/issues/1685
1689,b'Shape inference fails in per channel quantize model',Software,closed,2019-08-23T23:14:31Z,2019-08-27 17:50:44+00:00,2020-07-25T07:40:30Z,3,336,https://api.github.com/repos/microsoft/onnxruntime/issues/1689
1691,b'[Python Interface] How to dump every node shape info.(including input and output )',Software,closed,2019-08-26T12:17:59Z,2019-09-09 22:35:26+00:00,2019-10-23T21:41:11Z,14,58,https://api.github.com/repos/microsoft/onnxruntime/issues/1691
1696,b'Tag ORT server images with version_number',Software,closed,2019-08-27T00:29:00Z,2019-08-27 00:29:37+00:00,2019-08-30T01:19:17Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/1696
1698,b'NonMaxSuppression confirm shape of Boxes Parameter? does it include Class as Index?',Software,closed,2019-08-27T02:36:44Z,2019-08-27 03:18:57+00:00,2019-08-27T03:18:56Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1698
1699,b'Onnxruntime.dll not copied to build output directory when project is a class library',Software,closed,2019-08-27T09:06:51Z,2019-08-29 06:22:44+00:00,2019-09-18T03:10:28Z,1,21,https://api.github.com/repos/microsoft/onnxruntime/issues/1699
1700,b'Add support for Less in GNMT',Software,closed,2019-08-27T12:37:48Z,2019-08-28 01:14:55+00:00,2019-10-11T22:38:41Z,0,45,https://api.github.com/repos/microsoft/onnxruntime/issues/1700
1702,b'Ruby Library',Software,closed,2019-08-27T22:07:14Z,2019-08-27 22:07:36+00:00,2019-08-27T22:07:36Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1702
1703,b'brew install onnxruntime',Software,closed,2019-08-27T22:15:17Z,2019-08-28 01:14:23+00:00,2019-08-29T02:18:49Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1703
1706,b'Unable to inference style model using ORT server',Software,closed,2019-08-28T05:56:00Z,2019-08-28 17:52:08+00:00,2019-09-03T02:59:03Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/1706
1708,b'failed to variable input',Software,closed,2019-08-28T07:08:26Z,2019-08-28 16:43:11+00:00,2019-11-05T19:36:50Z,0,69,https://api.github.com/repos/microsoft/onnxruntime/issues/1708
1709,b'Get internal featuremaps',Software,closed,2019-08-28T09:46:02Z,2019-08-28 16:44:39+00:00,2019-08-29T04:31:35Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1709
1717,b'Question about Onnx model input',Software,closed,2019-08-29T01:55:05Z,2019-08-29 04:38:56+00:00,2019-08-30T04:56:09Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1717
1719,b'Output shape of resize op is not correct.',Software,closed,2019-08-29T05:15:59Z,2019-09-04 21:52:22+00:00,2019-09-09T18:22:14Z,6,11,https://api.github.com/repos/microsoft/onnxruntime/issues/1719
1720,b'Allow 64 bit floating point number types',Software,closed,2019-08-29T11:55:25Z,2019-08-29 11:55:40+00:00,2020-07-25T07:40:31Z,0,330,https://api.github.com/repos/microsoft/onnxruntime/issues/1720
1721,b'ONNX export for Pytorch ScriptModule including for loop and mixed types cannot be loaded in onnxruntime',Software,closed,2019-08-29T12:01:37Z,2019-08-30 15:36:20+00:00,2019-08-30T15:36:31Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1721
1725,b'Model inference consumes too much memory',Software,closed,2019-08-29T17:58:36Z,2019-09-10 18:09:18+00:00,2020-07-11T02:40:11Z,12,316,https://api.github.com/repos/microsoft/onnxruntime/issues/1725
1726,b'GENERAL ERROR : Load model from tagger.onnx failed:Model input (data) does not have type information.',Software,closed,2019-08-29T18:10:39Z,2019-09-10 16:45:15+00:00,2020-01-28T19:26:23Z,11,152,https://api.github.com/repos/microsoft/onnxruntime/issues/1726
1737,"b""error: package directory 'onnxruntime/backend' does not exist on Jetson TX2 when installing from source""",Software,closed,2019-08-30T07:13:08Z,2019-09-19 20:25:21+00:00,2019-09-25T18:53:34Z,20,26,https://api.github.com/repos/microsoft/onnxruntime/issues/1737
1744,b'View Activations during Inferencing',Software,closed,2019-08-31T00:59:47Z,2019-09-11 04:24:54+00:00,2019-10-11T22:55:39Z,11,41,https://api.github.com/repos/microsoft/onnxruntime/issues/1744
1745,b'Floating point exception\xef\xbc\x88core dumped\xef\xbc\x89',Software,closed,2019-09-02T06:12:07Z,2019-09-04 02:08:15+00:00,2019-09-09T18:16:39Z,1,7,https://api.github.com/repos/microsoft/onnxruntime/issues/1745
1747,b'Question about sequence/map input onnx type from model',Software,closed,2019-09-02T14:56:44Z,2019-09-10 17:16:33+00:00,2020-07-25T07:40:32Z,8,326,https://api.github.com/repos/microsoft/onnxruntime/issues/1747
1754,b'Unable to convert function return value to a Python type after creating inference session',Software,closed,2019-09-04T18:51:55Z,2019-09-09 04:56:37+00:00,2019-10-17T22:22:48Z,4,43,https://api.github.com/repos/microsoft/onnxruntime/issues/1754
1760,b' Inference Time Error ([ONNXRuntimeError] : 10 : INVALID_GRAPH )',Software,closed,2019-09-05T06:44:13Z,2019-09-05 17:29:22+00:00,2019-09-05T17:29:22Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1760
1764,b'RuntimeError: [ONNXRuntimeError] : 1 : GENERAL ERROR : Load model from encoder.onnx failed:Type Error: Type parameter (T) bound to different types (tensor(double) and tensor(float) in node ().',Software,closed,2019-09-06T04:07:05Z,2019-09-09 18:51:13+00:00,2019-09-09T20:48:40Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/1764
1765,b'onnxruntime in c++ to predict output using .onnx model',Software,closed,2019-09-06T04:25:47Z,2019-09-06 05:47:26+00:00,2019-09-23T16:46:24Z,0,17,https://api.github.com/repos/microsoft/onnxruntime/issues/1765
1767,b'floating point exception',Software,closed,2019-09-06T07:29:35Z,2019-09-09 14:18:36+00:00,2019-09-09T14:18:36Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/1767
1769,b'read model output from c++',Software,closed,2019-09-06T11:01:18Z,2019-09-06 17:35:52+00:00,2019-10-21T21:19:05Z,0,45,https://api.github.com/repos/microsoft/onnxruntime/issues/1769
1770,b'C# Inference fails with YOLOv3 model',Software,closed,2019-09-06T16:35:57Z,2019-09-06 17:58:31+00:00,2019-09-12T00:06:44Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/1770
1774,b'RuntimeError: [ONNXRuntimeError] : 1 : GENERAL ERROR : Load model from xxxxxxxxx.onnx failed:Type Error: Type parameter (T) bound to different types (tensor(float16) and tensor(float) in node ().',Software,closed,2019-09-07T03:40:56Z,2019-09-09 01:18:13+00:00,2019-09-11T18:45:05Z,1,4,https://api.github.com/repos/microsoft/onnxruntime/issues/1774
1775,b'Some third party lib can not fetch in China since the GFC',Software,closed,2019-09-07T07:14:31Z,2019-09-09 22:42:36+00:00,2019-12-27T23:21:35Z,2,111,https://api.github.com/repos/microsoft/onnxruntime/issues/1775
1776,"b""python3 setup.py bdist_wheel  running bdist_wheel running build running build_py error: package directory 'onnxruntime/backend' does not exist""",Software,closed,2019-09-07T07:34:47Z,2019-09-09 02:36:46+00:00,2019-09-09T15:26:06Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/1776
1777,b'Hard to build',Software,closed,2019-09-07T07:42:10Z,2019-09-09 07:10:19+00:00,2019-09-11T06:29:28Z,1,3,https://api.github.com/repos/microsoft/onnxruntime/issues/1777
1780,b'how to use the runtime-release',Software,closed,2019-09-08T10:10:23Z,2019-09-09 22:42:57+00:00,2019-09-19T17:30:07Z,1,11,https://api.github.com/repos/microsoft/onnxruntime/issues/1780
1782,b'how to run fp16 model using ort c api?',Software,closed,2019-09-09T04:04:37Z,2019-09-09 04:43:23+00:00,2019-09-10T05:52:00Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1782
1783,b' 29873 floating point exception  python3 demo_onnxrt_maskrcnn.py',Software,closed,2019-09-09T08:06:10Z,2019-09-09 14:19:29+00:00,2019-10-20T06:14:13Z,0,40,https://api.github.com/repos/microsoft/onnxruntime/issues/1783
1785,b'How to convert the format when using relative paths',Software,closed,2019-09-09T12:03:55Z,2019-09-10 16:37:42+00:00,2019-11-18T12:41:46Z,1,70,https://api.github.com/repos/microsoft/onnxruntime/issues/1785
1786,b'onnxruntime infer failed on GPU (build against with TensorRT',Software,closed,2019-09-09T15:20:49Z,2019-09-11 17:20:42+00:00,2019-11-17T13:09:12Z,2,68,https://api.github.com/repos/microsoft/onnxruntime/issues/1786
1788,b'Make version optional for ONNX server predict REST interface',Software,closed,2019-09-09T18:42:57Z,2019-09-09 18:43:12+00:00,2020-07-25T07:40:33Z,0,319,https://api.github.com/repos/microsoft/onnxruntime/issues/1788
1789,b'Support for executing custom subgraphs compiled AOT ',Software,closed,2019-09-09T19:02:43Z,2019-09-09 21:26:11+00:00,2020-07-25T07:40:34Z,0,319,https://api.github.com/repos/microsoft/onnxruntime/issues/1789
1791,b'cast to string not implemented in onnxruntime',Software,closed,2019-09-09T20:52:29Z,2019-09-09 21:12:57+00:00,2019-09-09T22:01:24Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1791
1795,b'CUDA10.1 build error',Software,closed,2019-09-10T07:27:24Z,2019-09-11 05:47:56+00:00,2019-09-11T05:47:56Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1795
1798,b'C# ONNX batch prediction only returns a single prediction',Software,closed,2019-09-10T20:59:50Z,2019-09-10 22:58:58+00:00,2019-09-11T07:07:01Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1798
1800,b'Track Memory Consumption',Software,closed,2019-09-10T22:26:52Z,2019-09-11 17:19:01+00:00,2020-07-11T01:41:06Z,0,304,https://api.github.com/repos/microsoft/onnxruntime/issues/1800
1803,b'Is TensorRT EP not included in rel-0.4.0?',Software,closed,2019-09-11T01:33:28Z,2019-09-11 17:20:22+00:00,2019-10-21T21:55:46Z,0,40,https://api.github.com/repos/microsoft/onnxruntime/issues/1803
1805,"b'bool onnxruntime::TransformerMemcpyImpl::ProcessInitializers(const onnxruntime::KernelRegistryManager&, const InitializedTensorSet&) status.IsOK() was false. Failed to find kernel for MemcpyFromHost (node Memcpy_1)'",Software,closed,2019-09-11T06:33:16Z,2019-09-11 07:53:10+00:00,2019-09-26T21:49:25Z,0,15,https://api.github.com/repos/microsoft/onnxruntime/issues/1805
1807,"b""RuntimeError: [ONNXRuntimeError] : 10 : INVALID_GRAPH : Load model from output/gr/logo/logo.onnx failed:Type Error: Type 'tensor(bool)' of input parameter (253) of operator (Gather) in node () is invalid.""",Software,closed,2019-09-11T17:43:05Z,2019-09-11 18:23:23+00:00,2019-09-11T18:43:32Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1807
1809,"b'Could not find an implementation for the node ReduceMin(1), Neg(6)'",Software,closed,2019-09-11T19:13:33Z,2019-09-12 18:58:10+00:00,2019-09-12T18:58:10Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1809
1810,"b""RuntimeError: Method run failed due to: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Non-zero status code returned while running Node:  Status Message: 'axes' has an out of range axis""",Software,closed,2019-09-11T19:51:38Z,2019-09-11 20:45:57+00:00,2019-09-11T20:59:10Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1810
1811,"b'element_wise_ops.h:332 void onnxruntime::BroadcastIterator::Append(int64_t, int64_t) axis == 1 || axis == largest was false'",Software,closed,2019-09-11T20:15:36Z,2019-09-12 21:41:37+00:00,2019-09-12T21:41:37Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1811
1813,b'ONNXRuntimerServer PredictionServiceImplTests.HappyPath unittest SegFaults',Software,closed,2019-09-11T21:24:44Z,2019-09-11 21:24:44+00:00,2019-09-19T16:04:13Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/1813
1814,b'HardMax/LpNormalization fail with negative axis',Software,closed,2019-09-11T21:56:25Z,2019-09-11 22:06:28+00:00,2019-09-17T04:51:27Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/1814
1818,"b'Failure for running the test file ""C_Api_Sample.cpp""'",Software,closed,2019-09-12T08:54:20Z,2019-09-12 10:24:22+00:00,2019-09-12T20:48:15Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1818
1820,b'Gather the common statistics from the ONNX models',Software,closed,2019-09-12T11:49:47Z,2019-09-12 18:48:31+00:00,2019-10-01T23:51:47Z,0,19,https://api.github.com/repos/microsoft/onnxruntime/issues/1820
1822,b'Building onnxruntime from source and run .onnx model in c++ using onnx c++ api',Software,closed,2019-09-12T15:07:51Z,2019-09-13 18:15:02+00:00,2019-09-15T04:34:19Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/1822
1828,"b""MeanVarianceNormalization v9 CPU kernel doesn't honor axes attribute""",Software,open,2019-09-12T22:06:40Z,2019-09-14 00:33:57+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/1828
1830,b'TopK is at best 30 times slower in ONNX than it is in Pytorch',Software,closed,2019-09-13T01:19:53Z,2019-09-13 21:39:45+00:00,2020-01-21T21:42:40Z,0,130,https://api.github.com/repos/microsoft/onnxruntime/issues/1830
1832,b'How to get the model structure and parameters',Software,closed,2019-09-13T09:38:59Z,2019-09-16 23:25:55+00:00,2019-09-23T21:08:04Z,3,10,https://api.github.com/repos/microsoft/onnxruntime/issues/1832
1837,b'TensorRT EP not falling back to lower priority EP',Software,closed,2019-09-13T21:44:07Z,2019-09-14 00:31:13+00:00,2020-02-27T16:56:50Z,0,166,https://api.github.com/repos/microsoft/onnxruntime/issues/1837
1838,b'Add verbose option for InferenceSession',Software,closed,2019-09-13T21:54:40Z,2019-09-14 00:30:07+00:00,2020-07-25T07:40:20Z,0,315,https://api.github.com/repos/microsoft/onnxruntime/issues/1838
1840,b'Expand fails with -1 in the size',Software,closed,2019-09-13T22:41:51Z,2019-09-14 00:28:38+00:00,2019-09-14T00:28:38Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1840
1843,b'C API sample not compilable',Documentation,closed,2019-09-14T17:23:34Z,2019-09-16 09:28:05+00:00,2020-07-25T07:40:16Z,1,314,https://api.github.com/repos/microsoft/onnxruntime/issues/1843
1844,b'Memory leak backend rep.run(input_data)',Documentation,closed,2019-09-15T13:04:15Z,2019-09-24 05:15:58+00:00,2019-09-24T05:15:58Z,8,8,https://api.github.com/repos/microsoft/onnxruntime/issues/1844
1845,b'Is tensor_info.GetShape() return -1 a bug?',Documentation,closed,2019-09-15T22:52:01Z,2019-09-15 23:39:48+00:00,2019-09-15T23:39:48Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1845
1848,b'The input of ONNX Runtime Server',Documentation,closed,2019-09-16T12:18:57Z,2019-09-19 16:32:31+00:00,2019-09-22T12:24:10Z,3,6,https://api.github.com/repos/microsoft/onnxruntime/issues/1848
1850,b'Ways to verify what execution provider is used',Software,closed,2019-09-16T19:55:45Z,2019-09-16 20:28:59+00:00,2020-03-02T22:35:05Z,0,168,https://api.github.com/repos/microsoft/onnxruntime/issues/1850
1857,b'Add NonZero() to CUDA',Software,closed,2019-09-17T05:34:49Z,2019-09-18 00:22:41+00:00,2019-11-11T22:12:57Z,0,55,https://api.github.com/repos/microsoft/onnxruntime/issues/1857
1858,"b'core/providers/tensorrt/tensorrt_provider_factory.h:4:31: fatal error: onnxruntime_c_api.h: No such file or directory  #include ""onnxruntime_c_api.h""'",Software,closed,2019-09-17T06:27:48Z,2019-09-17 06:48:24+00:00,2019-09-17T06:48:24Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1858
1859,b'CMake Error at CMakeLists.txt:582 (enable_language):   No CMAKE_CUDA_COMPILER could be found.',Software,closed,2019-09-17T06:39:18Z,2019-09-20 00:29:53+00:00,2019-11-25T22:45:16Z,2,69,https://api.github.com/repos/microsoft/onnxruntime/issues/1859
1860,b'Graph resolve function was fail at vgg19 model',Software,closed,2019-09-17T16:25:51Z,2019-09-17 16:26:20+00:00,2019-10-10T07:16:45Z,0,22,https://api.github.com/repos/microsoft/onnxruntime/issues/1860
1861,b'OpenVINO EP is not portable',Software,closed,2019-09-17T17:34:54Z,2019-09-18 16:19:06+00:00,2019-09-20T03:07:10Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/1861
1870,b'Build error with TensorRT 6.0 due to deprecations',Software,closed,2019-09-18T04:41:33Z,2019-09-18 16:17:31+00:00,2019-10-09T00:24:01Z,0,20,https://api.github.com/repos/microsoft/onnxruntime/issues/1870
1871,"b'when i transform unet from paddle to onnx ,it cause this error'",Software,closed,2019-09-18T04:42:33Z,2019-09-18 09:26:17+00:00,2019-09-18T09:26:17Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1871
1879,b'Segmentation fault with zero-batch intermediate tensor',Software,closed,2019-09-19T23:01:35Z,2019-09-20 00:30:58+00:00,2019-10-25T19:39:21Z,0,35,https://api.github.com/repos/microsoft/onnxruntime/issues/1879
1881,"b""TensorRT EP can't be set on device other than GPU 0""",Software,closed,2019-09-20T03:18:18Z,2019-09-20 16:08:06+00:00,2019-10-12T06:24:37Z,0,22,https://api.github.com/repos/microsoft/onnxruntime/issues/1881
1882,b'MKLDNN subgraph Error',Software,closed,2019-09-20T03:32:09Z,2019-09-20 03:33:52+00:00,2019-11-04T08:01:39Z,0,45,https://api.github.com/repos/microsoft/onnxruntime/issues/1882
1897,"b""undefined reference to `Ort::g_api'""",Software,closed,2019-09-24T08:39:17Z,2019-09-25 02:15:31+00:00,2019-09-25T02:15:31Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1897
1898,b'Onnxruntime Error in libcublas.so.10',Software,closed,2019-09-24T11:32:31Z,2019-09-24 11:32:43+00:00,2019-11-20T05:01:11Z,0,56,https://api.github.com/repos/microsoft/onnxruntime/issues/1898
1899,b'Removing initializer warning when using converted pytorch models',Software,closed,2019-09-24T11:38:06Z,2019-09-30 16:37:38+00:00,2019-09-30T16:37:37Z,6,6,https://api.github.com/repos/microsoft/onnxruntime/issues/1899
1909,b'Segmentation fault for generic model',Software,closed,2019-09-24T23:15:02Z,2019-09-24 23:39:54+00:00,2019-09-24T23:39:54Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1909
1915,"b'Build from source, cannot past test'",Software,closed,2019-09-25T07:11:01Z,2019-09-25 17:18:29+00:00,2019-09-25T17:18:29Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1915
1916,b'Log which node caused dimension error',Software,closed,2019-09-25T08:26:18Z,2019-09-26 02:26:00+00:00,2019-09-27T02:18:14Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1916
1918,b'Using Onnxruntime on python and with C++ API give different ouput results',Software,closed,2019-09-25T12:42:04Z,2019-09-25 18:50:59+00:00,2019-12-05T20:02:28Z,0,71,https://api.github.com/repos/microsoft/onnxruntime/issues/1918
1938,b'Flag to skip all tests in build',Software,closed,2019-09-26T22:08:47Z,2019-09-26 22:48:31+00:00,2019-09-26T22:48:31Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1938
1942,b'How to inference only use cpu',Software,closed,2019-09-27T05:47:50Z,2019-09-30 16:36:30+00:00,2019-10-08T03:08:52Z,3,10,https://api.github.com/repos/microsoft/onnxruntime/issues/1942
1943,b'Cannot build tensorrt-version from source',Software,closed,2019-09-27T10:23:25Z,2019-10-01 23:54:58+00:00,2019-10-09T08:08:12Z,4,11,https://api.github.com/repos/microsoft/onnxruntime/issues/1943
1944,b'Example of batch inferenece',Software,closed,2019-09-27T11:20:28Z,2019-09-30 18:25:47+00:00,2019-09-30T18:25:47Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/1944
1950,b'quantized model can not be loaded.',Software,closed,2019-09-28T15:22:13Z,2019-09-30 16:53:44+00:00,2019-11-18T12:42:18Z,2,50,https://api.github.com/repos/microsoft/onnxruntime/issues/1950
1955,b'I want to accelerate inference process using onnxruntime.',Software,closed,2019-09-30T06:44:58Z,2019-10-08 00:34:36+00:00,2019-10-08T00:34:36Z,7,7,https://api.github.com/repos/microsoft/onnxruntime/issues/1955
1958,b'Incorrect behaviour using resnet18v1/resnet50v1 and onnxruntime: extremely low accuracy.',Software,closed,2019-09-30T15:42:39Z,2019-09-30 15:45:46+00:00,2020-02-27T18:12:14Z,0,150,https://api.github.com/repos/microsoft/onnxruntime/issues/1958
1961,b'Yolo v3 inference 100x slower than expected',Software,closed,2019-09-30T22:55:01Z,2019-10-01 16:57:00+00:00,2020-02-27T18:23:53Z,0,149,https://api.github.com/repos/microsoft/onnxruntime/issues/1961
1964,b'Error parsing onnx::range inputs',Software,closed,2019-10-01T07:46:04Z,2019-10-01 07:46:22+00:00,2019-10-10T23:07:43Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/1964
1973,"b'C#: Add new InferenceSession(byte[] modelData, SessionOptions options) ctors'",Software,closed,2019-10-02T08:46:45Z,2019-10-02 16:40:39+00:00,2019-10-02T16:40:39Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1973
1974,b'Including ONNX file  in windows form application c#',Software,closed,2019-10-02T10:04:36Z,2019-10-02 16:38:55+00:00,2019-10-09T19:27:55Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/1974
1975,b'Inference fails when running Faster RCNN model from ONNX model zoo',Software,closed,2019-10-02T16:19:25Z,2019-10-02 19:39:33+00:00,2019-10-19T21:02:04Z,0,17,https://api.github.com/repos/microsoft/onnxruntime/issues/1975
1987,b'mean file from caffe model',Software,closed,2019-10-03T02:40:28Z,2019-10-03 17:02:58+00:00,2019-10-18T11:58:24Z,0,15,https://api.github.com/repos/microsoft/onnxruntime/issues/1987
1989,b'./onnxruntime_server: No such file or directory',Software,closed,2019-10-03T13:00:42Z,2019-10-04 04:44:52+00:00,2019-10-04T04:44:57Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1989
1993,b'Nuphar tutorial - Incorporate rnn_benchmark.py script to allow comparisons to other configurations ',Documentation,closed,2019-10-03T19:05:28Z,2019-10-08 17:16:09+00:00,2019-12-23T06:42:04Z,4,80,https://api.github.com/repos/microsoft/onnxruntime/issues/1993
1994,b'Nuphar tutorial - minimize the amount of steps needed to compare a users RNN/LSTM model with Nuphar and CPU EP',Software,closed,2019-10-03T19:16:54Z,2019-10-09 19:36:55+00:00,2020-03-10T23:43:35Z,6,159,https://api.github.com/repos/microsoft/onnxruntime/issues/1994
2007,"b""error undefined reference to `OrtGetApi' in C++ when run on g++""",Software,closed,2019-10-04T07:11:34Z,2019-10-09 19:16:59+00:00,2019-10-19T02:02:58Z,5,14,https://api.github.com/repos/microsoft/onnxruntime/issues/2007
2008,b'Upper-bound the memory consumption of mkl-dnn primitive pool',Software,closed,2019-10-04T07:22:09Z,2019-10-04 20:33:35+00:00,2020-07-25T07:40:22Z,0,295,https://api.github.com/repos/microsoft/onnxruntime/issues/2008
2013,b'Incompatability in C# with NuGet packages OnnxRuntime.GPU and OnnxTransformer ',Software,closed,2019-10-04T19:17:43Z,2019-10-05 16:58:00+00:00,2019-10-08T22:28:50Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/2013
2030,b'files are modified immediately after cloning',Software,closed,2019-10-07T17:30:36Z,2019-10-07 19:31:40+00:00,2019-10-18T20:25:05Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/2030
2041,b'how to build python wrapper?',Software,closed,2019-10-08T08:43:19Z,2019-10-08 08:47:59+00:00,2019-10-08T08:47:59Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2041
2042,b'How to switch onnxruntime or onnxruntime-gpu-tensorrt?',Software,closed,2019-10-08T08:54:35Z,2019-10-08 17:18:14+00:00,2019-10-23T06:49:40Z,0,14,https://api.github.com/repos/microsoft/onnxruntime/issues/2042
2043,b'onnxruntime tensorrt python test failed',Software,closed,2019-10-08T09:02:43Z,2019-10-08 17:17:43+00:00,2019-10-09T02:49:15Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2043
2044,b'could not find OpenMP_C when I build ',Software,closed,2019-10-08T10:31:13Z,2019-10-21 21:18:46+00:00,2019-10-22T07:51:32Z,13,13,https://api.github.com/repos/microsoft/onnxruntime/issues/2044
2045,"b'Error ""failed:[ShapeInferenceError] First input does not have rank 2""'",Software,closed,2019-10-08T14:31:52Z,2019-10-08 17:20:36+00:00,2019-10-11T19:34:14Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/2045
2046,b'build with --build_wheel but still I cannot use it.',Software,closed,2019-10-08T15:42:50Z,2019-10-09 05:17:01+00:00,2019-10-30T22:33:19Z,0,22,https://api.github.com/repos/microsoft/onnxruntime/issues/2046
2049,b'building from source on Ubuntu 14.04',Software,closed,2019-10-08T21:32:22Z,2019-10-08 21:45:04+00:00,2019-10-30T22:33:40Z,0,22,https://api.github.com/repos/microsoft/onnxruntime/issues/2049
2058,"b'build from source successfully, but can not import in python'",Software,closed,2019-10-09T02:12:44Z,2019-10-21 21:20:17+00:00,2019-10-21T21:20:17Z,12,12,https://api.github.com/repos/microsoft/onnxruntime/issues/2058
2060,b'build from source but hit a core dump error',Software,closed,2019-10-09T02:36:53Z,2019-10-09 05:06:38+00:00,2019-11-25T22:39:25Z,0,47,https://api.github.com/repos/microsoft/onnxruntime/issues/2060
2065,b'Bilinear Interpolate support?',Software,closed,2019-10-09T06:38:40Z,2019-10-09 07:02:25+00:00,2019-11-05T10:37:22Z,0,27,https://api.github.com/repos/microsoft/onnxruntime/issues/2065
2066,b'[onnxruntime server] multiple models in a single container',Software,closed,2019-10-09T06:53:37Z,2019-10-09 19:08:36+00:00,2020-07-25T07:40:35Z,0,290,https://api.github.com/repos/microsoft/onnxruntime/issues/2066
2067,b'Cannot infer model exported from pytorch',Software,closed,2019-10-09T08:17:46Z,2019-10-09 19:07:58+00:00,2020-07-11T01:41:07Z,0,275,https://api.github.com/repos/microsoft/onnxruntime/issues/2067
2068,"b""AttributeError: module 'onnxruntime' has no attribute 'InferenceSession'""",Software,closed,2019-10-09T10:13:28Z,2019-10-10 02:58:20+00:00,2019-10-13T03:31:54Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/2068
2078,b'onnxruntime with TensorRT performance issue',Software,closed,2019-10-10T02:56:31Z,2019-10-10 03:04:29+00:00,2020-07-11T02:40:06Z,0,274,https://api.github.com/repos/microsoft/onnxruntime/issues/2078
2080,b'indices element out of data bounds',Software,closed,2019-10-10T08:50:19Z,2019-10-18 21:09:07+00:00,2019-10-18T21:09:07Z,8,8,https://api.github.com/repos/microsoft/onnxruntime/issues/2080
2081,"b'Error in c_cxx samples: unresolved external symbol ""struct OrtApi const * const Ort::g_api""'",Software,closed,2019-10-10T10:01:55Z,2019-10-10 10:01:58+00:00,2019-10-14T02:20:59Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/2081
2084,b'Empty MobileNet Inference',Software,closed,2019-10-10T20:17:51Z,2019-10-18 21:10:31+00:00,2019-10-31T20:43:49Z,8,21,https://api.github.com/repos/microsoft/onnxruntime/issues/2084
2090,b'ReduceMin NOT_IMPLEMENTED ',Software,closed,2019-10-10T23:22:58Z,2019-10-11 00:18:18+00:00,2019-10-11T00:18:18Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2090
2111,b'[Announcement] Onnxruntime available on Nixpkgs',Software,closed,2019-10-12T00:37:58Z,2019-10-21 21:22:48+00:00,2020-01-13T19:16:19Z,9,93,https://api.github.com/repos/microsoft/onnxruntime/issues/2111
317,b'Snap package support',Software,closed,2019-01-11T22:12:37Z,2019-01-11 22:35:26+00:00,2019-02-21T08:21:40Z,0,40,https://api.github.com/repos/microsoft/onnxruntime/issues/317
319,b'roi_pool operator implementation error about FLT_MIN',Software,closed,2019-01-14T19:31:32Z,2019-01-14 23:27:08+00:00,2019-01-14T23:27:08Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/319
329,b'[Q] how to run test_file with onnxruntime_exec ?',Software,closed,2019-01-15T04:28:06Z,2019-01-15 04:36:49+00:00,2019-01-16T19:33:52Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/329
331,b'How to choose CPU/GPU as the onnxruntime engine?',Software,closed,2019-01-15T11:56:39Z,2019-01-15 18:46:49+00:00,2019-06-28T20:42:48Z,0,164,https://api.github.com/repos/microsoft/onnxruntime/issues/331
338,"b""Unable to find an entry point named 'ReleaseOrtAllocatorInfo' in DLL 'onnxruntime.dll""",Software,closed,2019-01-16T03:49:08Z,2019-01-17 00:53:07+00:00,2019-01-17T00:53:07Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/338
345,"b'op ""Div"" not supports double input while double is said to be supported in onnx'",Software,closed,2019-01-17T09:16:15Z,2019-01-17 19:15:38+00:00,2019-01-17T19:15:38Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/345
348,b'Missing boundary case in GEMM: zero size input',Software,closed,2019-01-17T20:38:22Z,2019-02-08 15:23:24+00:00,2019-02-08T15:23:24Z,21,21,https://api.github.com/repos/microsoft/onnxruntime/issues/348
349,b'Inconsistency of Squeeze spec between Ort and ONNX',Software,closed,2019-01-17T22:31:28Z,2019-01-21 20:29:07+00:00,2019-01-21T20:29:07Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/349
357,b'Test failure',Software,closed,2019-01-21T20:43:11Z,2019-02-20 21:54:06+00:00,2019-03-01T17:57:46Z,30,38,https://api.github.com/repos/microsoft/onnxruntime/issues/357
359,"b""What's the next step after build the onnxruntime from source code""",Software,closed,2019-01-22T07:12:08Z,2019-01-24 08:26:41+00:00,2019-01-24T08:26:41Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/359
360,b'onnxruntime python package conflicts with pytorch',Software,closed,2019-01-22T09:22:23Z,2019-01-22 19:11:53+00:00,2019-03-13T20:10:27Z,0,50,https://api.github.com/repos/microsoft/onnxruntime/issues/360
380,b'ONNXRuntime Issue: Output:Y [ShapeInferenceError] Mismatch between number of source and target dimensions',Software,closed,2019-01-25T08:01:25Z,2019-02-21 03:44:31+00:00,2019-03-14T21:10:52Z,26,48,https://api.github.com/repos/microsoft/onnxruntime/issues/380
396,b'Few newbie questions',Software,closed,2019-01-28T23:31:09Z,2019-01-30 01:20:22+00:00,2019-01-30T01:20:22Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/396
402,b'Errors while using docker build',Software,closed,2019-01-29T19:38:35Z,2019-02-01 03:02:30+00:00,2019-02-01T03:02:30Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/402
404,b'Wrong model prediction for keras application models NASNetMobile and NASNetLarge',Software,closed,2019-01-29T20:30:18Z,2019-02-21 03:54:22+00:00,2019-03-14T21:11:28Z,22,44,https://api.github.com/repos/microsoft/onnxruntime/issues/404
2118,b'[C++] How to predict fast?',Software,closed,2019-10-13T05:41:35Z,2019-10-18 02:58:54+00:00,2019-10-18T07:09:44Z,4,5,https://api.github.com/repos/microsoft/onnxruntime/issues/2118
2119,b'python API to get intermediate layer output',Software,closed,2019-10-14T03:41:49Z,2019-10-14 22:41:11+00:00,2019-10-15T01:32:31Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2119
2120,"b'build from source code, get ""OSError: [Errno 12] Cannot allocate memory""'",Software,closed,2019-10-14T09:32:16Z,2019-10-21 21:22:11+00:00,2019-11-18T12:44:03Z,7,35,https://api.github.com/repos/microsoft/onnxruntime/issues/2120
2121,b'is onnxruntime support Intel MKL Sparse BLAS?',Software,closed,2019-10-14T10:06:29Z,2019-10-14 21:52:56+00:00,2019-10-14T21:52:56Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2121
2125,b'Opset 11 support?',Software,closed,2019-10-14T22:06:57Z,2019-10-14 22:40:49+00:00,2019-10-14T22:44:26Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2125
2132,b'Pytorch model cannot be served by ORT 0.5.0 + ONNX 1.6.0',Software,closed,2019-10-15T04:08:59Z,2019-10-16 08:59:33+00:00,2020-07-11T01:41:20Z,1,269,https://api.github.com/repos/microsoft/onnxruntime/issues/2132
2133,"b""mklml python wheel - No module named 'onnxruntime.capi'""",Software,closed,2019-10-15T05:17:32Z,2019-10-21 21:49:23+00:00,2019-10-31T01:47:08Z,6,15,https://api.github.com/repos/microsoft/onnxruntime/issues/2133
2135,b'ONNX backend test failed with core dumped (OnnxBackendNodeModelTest::test_compress_negative_axis_cpu)',Software,closed,2019-10-15T06:54:04Z,2019-10-15 07:36:03+00:00,2019-10-15T22:44:24Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2135
2136,b'Qustion about the tensor type',Software,closed,2019-10-15T07:59:27Z,2019-10-15 08:13:26+00:00,2019-10-15T08:13:26Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2136
2143,b'how to get multi output layers when run once?',Software,closed,2019-10-16T11:53:39Z,2019-10-17 02:02:38+00:00,2019-10-18T04:23:59Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/2143
2150,b'Mobilenetv2 classification result is wrong',Software,closed,2019-10-17T02:41:10Z,2019-10-17 07:30:48+00:00,2020-07-11T01:41:21Z,0,267,https://api.github.com/repos/microsoft/onnxruntime/issues/2150
2151,b'When will NMS and RoIAlign op TensorRT version will be support?',Software,closed,2019-10-17T03:52:03Z,2019-10-18 17:38:06+00:00,2020-02-27T18:22:14Z,1,133,https://api.github.com/repos/microsoft/onnxruntime/issues/2151
2152,b'qmath.cc error when building from source on Raspberry',Software,closed,2019-10-17T07:19:22Z,2019-10-18 20:02:50+00:00,2019-10-21T11:41:43Z,1,4,https://api.github.com/repos/microsoft/onnxruntime/issues/2152
2153,b'Is it possible to install onnxruntime for Python2?',Software,closed,2019-10-17T07:20:42Z,2019-10-18 08:08:59+00:00,2019-10-18T08:08:59Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/2153
2154,b'GENERAL ERROR : GSL: Precondition failure at /onnxruntime_src/cmake/external/gsl/include/gsl/span: 475',Software,closed,2019-10-17T17:51:20Z,2019-10-18 13:47:57+00:00,2019-10-24T18:39:21Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/2154
2157,b'Recommendation to improve MNIST example',Software,closed,2019-10-17T18:43:06Z,2019-10-17 20:26:27+00:00,2020-10-04T03:56:33Z,0,352,https://api.github.com/repos/microsoft/onnxruntime/issues/2157
2166,b'fail to run the MaskRCNN model',Software,closed,2019-10-18T02:06:19Z,2019-10-18 02:30:06+00:00,2019-10-18T02:30:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2166
2169,b'OpenVINO Execution Provider is broken?',Software,closed,2019-10-18T03:23:44Z,2019-10-18 17:34:18+00:00,2019-10-21T22:01:37Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/2169
2170,b'RuntimeError: [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for the node ATen(1)',Software,closed,2019-10-18T03:50:01Z,2019-10-18 17:37:37+00:00,2019-10-18T17:37:37Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2170
2174,b'[C++] How to change symbolic dimension?',Software,closed,2019-10-18T07:32:52Z,2019-10-18 09:10:43+00:00,2019-10-18T09:15:56Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2174
2175,"b'Error ""Name:\'bn_data\' Status Message: Invalid input scale: NumDimensions() != 3""'",Software,closed,2019-10-18T09:11:45Z,2019-10-18 20:53:28+00:00,2019-10-18T20:53:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2175
2176,b'Can  release onnxruntime-gpu on Cuda 9?',Software,closed,2019-10-18T09:52:41Z,2019-10-20 04:57:04+00:00,2019-10-20T04:57:04Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/2176
2177,b'[C++] How to limit the cpu num to 1',Software,closed,2019-10-18T12:29:29Z,2019-10-18 21:20:20+00:00,2019-10-18T21:20:20Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2177
2184,"b""It isn't possible for a .NET package to use OnnxRuntime and have the application pick CPU or GPU""",Software,closed,2019-10-18T21:38:44Z,2019-10-21 21:22:27+00:00,2020-02-28T02:00:18Z,2,132,https://api.github.com/repos/microsoft/onnxruntime/issues/2184
2192,b'Option to dump only every node shape info',Software,closed,2019-10-19T01:12:06Z,2019-10-21 02:11:35+00:00,2019-10-21T17:23:25Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/2192
2197,b'Execution provider mismatch. Expected: CUDAExecutionProvider Actual: CPUExecutionProvider',Software,closed,2019-10-20T01:07:42Z,2019-10-20 01:17:06+00:00,2019-10-22T18:26:51Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/2197
2205,b'How to dump the intermediate result of the onnxruntime operator operation?',Software,closed,2019-10-21T07:00:15Z,2019-10-21 17:22:57+00:00,2019-10-25T21:02:20Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/2205
2207,b'BitShift Not Implemented for uint8',Software,closed,2019-10-21T16:34:51Z,2019-10-21 16:36:28+00:00,2019-10-22T04:10:30Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2207
2232,b'Graph initializer inconsistencies',Software,closed,2019-10-22T21:23:35Z,2019-10-28 23:36:57+00:00,2019-10-29T20:50:42Z,6,6,https://api.github.com/repos/microsoft/onnxruntime/issues/2232
2247,b'ReduceMin/ReduceMax do not reduce axes on Cuda provider',Software,closed,2019-10-24T03:54:16Z,2019-10-25 20:58:48+00:00,2019-10-31T17:12:00Z,1,7,https://api.github.com/repos/microsoft/onnxruntime/issues/2247
2250,b'[C++ API] How to do onnxruntime inference with multi input?',Software,closed,2019-10-24T10:17:44Z,2019-10-25 21:20:38+00:00,2019-10-30T19:11:26Z,1,6,https://api.github.com/repos/microsoft/onnxruntime/issues/2250
2263,"b""0.5.1 fails to build: error: package directory 'onnxruntime/backend' does not exist""",Software,closed,2019-10-25T17:06:19Z,2019-10-25 19:07:42+00:00,2019-10-31T20:53:05Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/2263
2264,b'Improve error message from shape inference',Software,closed,2019-10-25T19:19:58Z,2019-10-25 21:18:24+00:00,2019-10-30T19:35:18Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/2264
2265,b'The repository is mislabeled: git describes the master branch as v0.1.4-1400-gc7599d07 while the releases page shows that the latest release is 0.5.1',Software,closed,2019-10-25T20:03:03Z,2019-11-05 19:39:11+00:00,2019-11-05T19:39:11Z,10,10,https://api.github.com/repos/microsoft/onnxruntime/issues/2265
2266,"b'Build fails on FreeBSD: undefined symbol: MlasSgemmTransposePackB16x4Sse, etc'",Software,closed,2019-10-25T20:22:50Z,2019-10-30 17:50:14+00:00,2019-10-30T17:50:14Z,4,4,https://api.github.com/repos/microsoft/onnxruntime/issues/2266
2267,"b'import onnxruntime fails: ""Error: \'dynamic module does not define init function""'",Software,closed,2019-10-25T20:36:43Z,2019-10-25 22:19:44+00:00,2020-03-10T23:45:56Z,0,137,https://api.github.com/repos/microsoft/onnxruntime/issues/2267
2271,"b""NodeArg class has a move constructor but doesn't have a move assignment operator""",Software,closed,2019-10-26T00:23:26Z,2019-10-26 00:49:49+00:00,2019-10-31T17:29:55Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/2271
2272,b'Slice test for reverse',Software,closed,2019-10-26T08:06:00Z,2019-10-26 08:06:00+00:00,2019-11-05T20:05:26Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/2272
2284,b'FillStringTensor() should also require length of each string element',Software,closed,2019-10-30T01:03:52Z,2019-12-17 23:16:15+00:00,2020-07-25T07:40:23Z,48,269,https://api.github.com/repos/microsoft/onnxruntime/issues/2284
2295,b'Tests fail on FreeBSD',Software,closed,2019-10-31T21:02:31Z,2019-10-31 21:23:32+00:00,2020-07-25T07:40:21Z,0,267,https://api.github.com/repos/microsoft/onnxruntime/issues/2295
2296,"b""error: package directory 'onnxruntime/backend' does not exist""",Software,closed,2019-10-31T23:27:08Z,2019-11-20 18:59:58+00:00,2020-02-27T18:25:41Z,19,118,https://api.github.com/repos/microsoft/onnxruntime/issues/2296
2297,b'Global<void>::api_ was nullptr',Software,closed,2019-10-31T23:56:34Z,2019-11-01 05:01:05+00:00,2019-11-01T05:53:51Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2297
2298,"b""session.set_providers failed to call 'OpenVINOExecutionProvider'""",Software,closed,2019-11-01T02:52:45Z,2019-11-04 11:49:54+00:00,2019-11-07T02:47:34Z,3,5,https://api.github.com/repos/microsoft/onnxruntime/issues/2298
2313,b'[C#] CUDA kernel not supported for some conv2d layers',Software,closed,2019-11-04T08:34:28Z,2019-11-05 10:03:22+00:00,2019-11-05T10:03:22Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/2313
2314,b'Unable to import onnxruntime using the the pre-built container',Software,closed,2019-11-04T15:31:26Z,2019-11-04 16:36:17+00:00,2019-11-05T09:07:38Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2314
2315,b'String variable in onnx model built in python are interpreted as bytes in C# onnxruntime',Software,closed,2019-11-04T17:04:18Z,2019-11-04 17:06:54+00:00,2019-11-09T03:12:51Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/2315
2316,b'[ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running Squeeze node.',Software,closed,2019-11-04T20:55:46Z,2019-11-05 03:00:32+00:00,2020-07-11T01:41:14Z,0,249,https://api.github.com/repos/microsoft/onnxruntime/issues/2316
2318,"b""[C#] cannot convert from 'System.Numerics.Tensors.Tensor<T>' to 'Microsoft.ML.OnnxRuntime.Tensors.Tensor<T>'""",Software,closed,2019-11-04T22:55:11Z,2019-11-05 00:01:35+00:00,2019-11-05T00:02:00Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2318
2323,"b""Python documentation doesn't load style""",Software,closed,2019-11-05T16:46:46Z,2019-11-05 17:47:31+00:00,2019-11-08T19:06:14Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/2323
2331,b'Are there any plans to support mobile GPU? ',Software,closed,2019-11-06T09:43:21Z,2019-11-06 17:09:26+00:00,2020-07-11T01:41:10Z,0,247,https://api.github.com/repos/microsoft/onnxruntime/issues/2331
2334,b'Describe outputs sequence / map',Software,closed,2019-11-06T16:11:38Z,2019-11-11 20:25:50+00:00,2019-11-14T06:49:22Z,5,7,https://api.github.com/repos/microsoft/onnxruntime/issues/2334
2338,"b'ORT -  segmentation fault on Linux, when using Cast(to=string) operator'",Software,closed,2019-11-07T01:57:37Z,2019-11-11 22:15:42+00:00,2019-11-14T06:51:13Z,4,7,https://api.github.com/repos/microsoft/onnxruntime/issues/2338
2339,b'expand Matmulinteger and ConvInteger to support int8*int8',Software,closed,2019-11-07T09:14:42Z,2019-11-11 20:38:07+00:00,2020-08-15T20:00:25Z,4,282,https://api.github.com/repos/microsoft/onnxruntime/issues/2339
2340,b'expand to support \xe2\x80\x98gemm\xe2\x80\x99 quantization',Software,closed,2019-11-07T09:17:29Z,2019-11-11 20:37:50+00:00,2020-07-11T01:41:08Z,4,246,https://api.github.com/repos/microsoft/onnxruntime/issues/2340
2341,b'How do I input a variable sequence feature into the LSTM network in c++ onnxruntime?',Software,closed,2019-11-07T09:34:08Z,2019-11-12 02:04:44+00:00,2019-11-25T07:30:21Z,4,17,https://api.github.com/repos/microsoft/onnxruntime/issues/2341
2342,b'Does the Nuphar Execution Provider support arm or aarch64 cpu?',Software,closed,2019-11-07T09:57:33Z,2019-11-07 18:59:23+00:00,2020-02-27T18:21:35Z,0,112,https://api.github.com/repos/microsoft/onnxruntime/issues/2342
2343,b'Help: dealing with uint8 and int64 types in java for inference',Software,closed,2019-11-07T12:15:44Z,2019-11-11 21:59:03+00:00,2020-07-11T01:41:11Z,4,246,https://api.github.com/repos/microsoft/onnxruntime/issues/2343
2344,b'How to output the middle layer?',Software,closed,2019-11-07T12:51:06Z,2019-11-07 18:54:40+00:00,2019-11-08T02:32:26Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2344
2345,b'DEBUG_NODE_INPUTS_OUTPUTS build broken',Software,closed,2019-11-07T19:13:55Z,2019-11-07 21:23:45+00:00,2019-11-11T23:26:19Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/2345
2353,b'resnet50 sample over openvino VPU caused numpy assertion error',Software,closed,2019-11-08T09:23:59Z,2019-11-08 17:13:45+00:00,2019-11-19T02:42:29Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/2353
2354,b'Mac OSX build in PyPi targets OSX 10.14',Software,closed,2019-11-08T16:50:49Z,2019-11-08 17:50:59+00:00,2020-05-12T21:43:33Z,0,186,https://api.github.com/repos/microsoft/onnxruntime/issues/2354
2367,b'OSError: libcublas.so.10.0: cannot open shared object file: No such file or directory',Software,closed,2019-11-11T21:04:49Z,2019-11-12 00:25:08+00:00,2019-11-12T00:25:08Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2367
2371,"b'ORT loads future opsets, silently substituting old operator versions and returning potentially incorrect results'",Software,closed,2019-11-11T23:44:49Z,2019-11-11 23:49:56+00:00,2020-03-10T23:48:50Z,0,120,https://api.github.com/repos/microsoft/onnxruntime/issues/2371
2373,b'ONNXRuntime Using GPU Slower Than Using CPU?',Software,closed,2019-11-11T23:59:06Z,2019-11-12 16:47:19+00:00,2019-11-18T17:06:48Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/2373
2378,b'[DirectML] Access violation writing location',Software,closed,2019-11-12T14:22:28Z,2019-11-12 19:49:54+00:00,2020-06-02T18:52:36Z,0,203,https://api.github.com/repos/microsoft/onnxruntime/issues/2378
2384,b'Invalid ORT_ENFORCE check in nn pool op provider',Software,closed,2019-11-13T03:37:56Z,2019-11-15 17:32:16+00:00,2019-11-18T02:51:41Z,2,4,https://api.github.com/repos/microsoft/onnxruntime/issues/2384
2385,b'Support non-tensor output type in onnxruntime server',Software,closed,2019-11-13T04:34:40Z,2019-11-13 18:21:18+00:00,2020-07-25T06:40:33Z,0,255,https://api.github.com/repos/microsoft/onnxruntime/issues/2385
2386,b'load model error: CUBLAS failure 1: CUBLAS_STATUS_NOT_INITIALIZED',Software,closed,2019-11-13T06:56:16Z,2019-11-18 06:35:47+00:00,2019-11-18T06:35:47Z,4,4,https://api.github.com/repos/microsoft/onnxruntime/issues/2386
2394,b'ConvTranspose does not support input rank other than 4',Software,closed,2019-11-14T01:21:17Z,2019-11-14 19:14:24+00:00,2019-12-10T18:39:35Z,0,26,https://api.github.com/repos/microsoft/onnxruntime/issues/2394
2397,"b'[C++, Linux] Segmentation fault when creating Ort::Session'",Software,closed,2019-11-14T09:11:43Z,2019-11-14 18:28:59+00:00,2019-11-15T08:18:36Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2397
2404,b'onnxruntime is 1.5~2x slow than pytorch on GPU',Software,closed,2019-11-15T06:38:56Z,2019-11-15 10:42:32+00:00,2019-11-19T01:40:50Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/2404
2418,b'what is a scoring engine in short? differ from a score function?',Software,closed,2019-11-16T12:54:41Z,2019-11-16 12:55:08+00:00,2019-12-04T19:59:10Z,0,18,https://api.github.com/repos/microsoft/onnxruntime/issues/2418
2419,b'OrtRun infer time not stable',Software,closed,2019-11-16T13:02:39Z,2019-11-18 10:07:16+00:00,2019-12-13T10:24:35Z,1,26,https://api.github.com/repos/microsoft/onnxruntime/issues/2419
2421,b'Question about faster-rcnn inference of Onnx model with undefined input and output size',Software,closed,2019-11-18T07:33:11Z,2019-11-18 20:52:24+00:00,2020-07-11T02:40:09Z,0,235,https://api.github.com/repos/microsoft/onnxruntime/issues/2421
2422,b'Does ACL Execution Provider support Arm GPUs?',Software,closed,2019-11-18T08:39:25Z,2019-11-18 12:44:58+00:00,2020-02-25T19:31:22Z,0,99,https://api.github.com/repos/microsoft/onnxruntime/issues/2422
2427,b'Eigen conflict with system version',Software,closed,2019-11-19T03:53:32Z,2019-11-20 05:08:53+00:00,2019-11-20T05:08:53Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/2427
2428,"b' fatal error: Eigen/src/Core/arch/Default/Half.h: No such file or directory  #include ""Eigen/src/Core/arch/Default/Half.h""                                               ^'",Software,closed,2019-11-19T06:31:13Z,2019-11-20 05:08:45+00:00,2019-11-20T05:08:45Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2428
2429,b'[BUG] A model crashes on squeeze op',Software,closed,2019-11-19T07:00:06Z,2019-11-19 07:01:05+00:00,2019-11-20T10:01:50Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/2429
2430,b'<command-line>:0:16: error: \xe2\x80\x98UnionShapeInfo\xe2\x80\x99 is not a member of \xe2\x80\x98onnx\xe2\x80\x99',Software,closed,2019-11-19T07:16:19Z,2019-11-19 07:16:45+00:00,2019-12-06T20:05:44Z,0,17,https://api.github.com/repos/microsoft/onnxruntime/issues/2430
2432,b'performance question: how multiple inference on execution provider(MyriadX VPU)',Software,closed,2019-11-19T08:25:24Z,2019-11-19 17:16:31+00:00,2020-07-11T01:41:10Z,0,234,https://api.github.com/repos/microsoft/onnxruntime/issues/2432
2433,b'Pad operator: Negative pads value not supported.',Software,closed,2019-11-19T08:26:19Z,2019-11-19 17:23:17+00:00,2019-12-05T19:29:46Z,0,16,https://api.github.com/repos/microsoft/onnxruntime/issues/2433
2434,b'TopK is incredibly slower than Pytorch on GPU',Software,closed,2019-11-19T08:43:05Z,2019-11-19 19:44:00+00:00,2020-01-10T08:03:15Z,0,51,https://api.github.com/repos/microsoft/onnxruntime/issues/2434
2435,b'Transpose CPU performance is very poor',Software,closed,2019-11-19T13:08:45Z,2019-11-19 19:43:48+00:00,2019-12-16T00:58:56Z,0,26,https://api.github.com/repos/microsoft/onnxruntime/issues/2435
2436,"b'ONNX Runtime Test Dependency, Unable to Skip Tests'",Software,closed,2019-11-19T18:37:10Z,2019-11-19 19:07:06+00:00,2019-12-03T00:31:34Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/2436
2441,b'Type of output argument does not match expected type ',Software,closed,2019-11-20T00:27:59Z,2019-11-22 11:52:56+00:00,2020-03-05T18:16:23Z,2,106,https://api.github.com/repos/microsoft/onnxruntime/issues/2441
2442,b'onnx runtime server docker ',Software,closed,2019-11-20T04:15:39Z,2019-11-20 12:04:10+00:00,2019-12-13T02:19:57Z,0,22,https://api.github.com/repos/microsoft/onnxruntime/issues/2442
2443,b'onnxruntime.dll not being pulled in Release Mode',Software,closed,2019-11-20T08:07:41Z,2019-11-20 23:40:05+00:00,2019-11-20T23:40:05Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2443
2447,b'[ONNXModelZoo] Arcface model fails during ONNX runtime session run',Software,closed,2019-11-21T01:36:58Z,2019-11-21 01:40:19+00:00,2019-11-21T01:40:19Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2447
2459,b'How to install onnxruntime in Python by compiling',Software,closed,2019-11-22T06:49:36Z,2019-11-22 07:02:17+00:00,2019-11-22T07:02:17Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2459
2462,b'When installing onnxruntime',Software,closed,2019-11-22T08:57:21Z,2019-11-22 11:48:47+00:00,2019-11-28T05:51:10Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/2462
2463,b'Resize operator need to support 4-D inputs with more than 1 batch and 1 channel',Software,closed,2019-11-22T09:04:39Z,2019-12-16 08:51:00+00:00,2020-07-11T02:40:10Z,23,231,https://api.github.com/repos/microsoft/onnxruntime/issues/2463
2468,b'Batch inference in Python with onnxruntime 1.0.0',Software,closed,2019-11-22T21:33:51Z,2019-11-28 20:37:35+00:00,2019-11-28T20:37:35Z,5,5,https://api.github.com/repos/microsoft/onnxruntime/issues/2468
2474,b'An ONNX model that worked in 0.5.1 now fails in 1.0.0',Software,closed,2019-11-25T22:40:56Z,2019-11-25 22:45:51+00:00,2019-12-03T06:28:45Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/2474
2482,b'Slow Inference onnx runtime?',Software,closed,2019-11-26T15:26:18Z,2019-11-27 02:21:44+00:00,2020-03-05T18:15:17Z,0,100,https://api.github.com/repos/microsoft/onnxruntime/issues/2482
2494,"b'CPU with MKLDNN using OpenMP cause CPU loading high, maybe OMP_WAIT_POLICY is ACTIVE by default.'",Software,closed,2019-11-27T08:16:22Z,2019-11-27 17:22:15+00:00,2019-11-27T17:23:13Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2494
2498,b'Building from source fails with python 3.8 and 3.9',Software,closed,2019-11-27T14:50:27Z,2019-11-27 17:20:22+00:00,2019-12-27T23:30:19Z,0,30,https://api.github.com/repos/microsoft/onnxruntime/issues/2498
2512,b'The performance of multithreading parallel inference deteriorates rapidly as the number of threads increases',Software,closed,2019-11-29T07:10:23Z,2019-12-01 10:58:30+00:00,2019-12-08T05:51:21Z,2,8,https://api.github.com/repos/microsoft/onnxruntime/issues/2512
2513,b'OrtCustomOp for CUDA Execution provider ?',Software,closed,2019-11-29T08:42:04Z,2019-12-02 21:04:37+00:00,2020-04-01T19:26:30Z,3,124,https://api.github.com/repos/microsoft/onnxruntime/issues/2513
2518,b'Unexpected Shape with ConvTranspose with Dilation !=1',Software,closed,2019-12-02T22:05:19Z,2019-12-10 23:29:42+00:00,2020-01-29T23:42:44Z,8,58,https://api.github.com/repos/microsoft/onnxruntime/issues/2518
2524,b'CUBLAS failure 1: CUBLAS_STATUS_NOT_INITIALIZED ',Software,closed,2019-12-03T02:27:44Z,2019-12-05 19:42:25+00:00,2019-12-05T19:42:25Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/2524
2525,b'Any plan to support dynamic input size in onnxruntime build with tensorrt?',Software,closed,2019-12-03T02:47:20Z,2019-12-04 03:40:58+00:00,2019-12-04T03:40:58Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/2525
2537,b'No such flag DNNL_PRODUCT_BUILD_MODE in dnnl v1.1.0',Software,closed,2019-12-04T03:10:58Z,2019-12-04 13:28:59+00:00,2019-12-09T03:08:33Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/2537
2541,b'error of /usr/bin/ld: can not find -ltinfo when building',Software,closed,2019-12-04T12:06:51Z,2019-12-09 18:18:11+00:00,2019-12-09T18:18:11Z,5,5,https://api.github.com/repos/microsoft/onnxruntime/issues/2541
2552,b'Error: c++: internal compiler error: killed (program cc1plus) when building from source',Software,closed,2019-12-05T01:17:46Z,2019-12-05 19:41:52+00:00,2019-12-05T19:41:52Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2552
2555,b'ONNX on Windows x86',Software,closed,2019-12-05T17:22:30Z,2019-12-05 18:39:28+00:00,2020-02-27T18:01:36Z,0,84,https://api.github.com/repos/microsoft/onnxruntime/issues/2555
2571,"b""What's the difference between ORT with TensorRT execution provider and onnx with Tensor RT backend?""",Software,closed,2019-12-06T06:01:19Z,2019-12-09 19:34:34+00:00,2019-12-24T07:40:58Z,3,18,https://api.github.com/repos/microsoft/onnxruntime/issues/2571
2572,"b""import onnxruntime Error:cannot import name 'get_all_providers' """,Software,closed,2019-12-06T08:09:34Z,2019-12-09 18:17:18+00:00,2019-12-09T18:17:18Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/2572
2573,"b""Can't inference model that has input with dynamic axises using DirectML provider""",Software,closed,2019-12-06T14:16:03Z,2019-12-06 18:07:01+00:00,2020-07-11T02:40:08Z,0,217,https://api.github.com/repos/microsoft/onnxruntime/issues/2573
2576,"b""building with --cmake_extra_defines doesn't work properly with multiple items""",Software,closed,2019-12-06T19:44:37Z,2019-12-06 20:00:49+00:00,2020-01-17T04:15:16Z,0,41,https://api.github.com/repos/microsoft/onnxruntime/issues/2576
2585,b'Unable to build onnxruntime with docker build for ARM32',Software,closed,2019-12-08T09:54:12Z,2019-12-10 00:41:08+00:00,2019-12-12T11:56:24Z,1,4,https://api.github.com/repos/microsoft/onnxruntime/issues/2585
2587,b'Unable to build on Windows 10 x64 using Visual Studio 16.4 with TensorRT',Software,closed,2019-12-09T13:24:27Z,2019-12-09 18:13:29+00:00,2020-02-07T10:12:31Z,0,59,https://api.github.com/repos/microsoft/onnxruntime/issues/2587
2591,"b'Missing assembly when using ""Produce single file""'",Software,closed,2019-12-09T21:46:29Z,2019-12-13 03:00:24+00:00,2019-12-17T23:53:31Z,3,8,https://api.github.com/repos/microsoft/onnxruntime/issues/2591
2600,"b""import onnxruntime error:'libiomp5.so: cannot open shared object file: No such file or directory'""",Software,closed,2019-12-10T02:16:57Z,2020-02-27 18:13:36+00:00,2020-03-05T18:15:27Z,79,86,https://api.github.com/repos/microsoft/onnxruntime/issues/2600
2602,b'Dump C code to run inference on different device',Software,closed,2019-12-10T10:55:29Z,2019-12-13 00:43:55+00:00,2020-02-27T18:14:38Z,2,79,https://api.github.com/repos/microsoft/onnxruntime/issues/2602
2603,b'Unsupported onnx data type uint8?',Software,closed,2019-12-10T15:07:21Z,2019-12-10 18:38:00+00:00,2019-12-13T07:25:59Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/2603
2609,b'tensorrt backend: Not using dynamic axes from PyTorch?',Software,closed,2019-12-10T20:58:57Z,2019-12-10 20:59:08+00:00,2019-12-13T00:43:00Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/2609
2618,b'Is there a ok onnxruntime_perf_test demo  there?',Software,closed,2019-12-11T08:23:42Z,2019-12-11 20:08:56+00:00,2019-12-12T18:27:40Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/2618
2619,b'In quantization tool there is one module quantize i am not able to install',Software,closed,2019-12-11T10:43:57Z,2019-12-11 11:40:13+00:00,2019-12-11T11:40:12Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2619
2620,b'During Quantization output model has 0 dimesion',Software,closed,2019-12-11T11:49:38Z,2019-12-16 21:40:04+00:00,2020-07-11T01:41:13Z,5,212,https://api.github.com/repos/microsoft/onnxruntime/issues/2620
2622,b'Failed shape infernence for batch size > 1 with NUPHAR execution provider',Software,closed,2019-12-11T17:06:56Z,2019-12-13 00:47:00+00:00,2020-02-27T18:15:22Z,1,78,https://api.github.com/repos/microsoft/onnxruntime/issues/2622
2637,"b""Underscores shouldn't be used in googletest test names""",Software,closed,2019-12-12T01:30:09Z,2019-12-12 23:39:01+00:00,2020-01-28T18:50:56Z,0,47,https://api.github.com/repos/microsoft/onnxruntime/issues/2637
2642,"b""onnxruntime-gpu: ImportError: cannot import name 'RunOptions'""",Software,closed,2019-12-12T11:41:55Z,2019-12-12 18:44:25+00:00,2019-12-12T18:44:25Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2642
2649,"b""question: package directory 'onnxruntime\\backend' does not exist""",Software,closed,2019-12-13T07:46:18Z,2019-12-13 17:34:45+00:00,2020-07-11T01:41:15Z,0,210,https://api.github.com/repos/microsoft/onnxruntime/issues/2649
2657,b'Do you have any documents about C++ interface loading model?',Software,closed,2019-12-14T07:50:26Z,2019-12-16 21:34:46+00:00,2019-12-24T00:25:51Z,2,9,https://api.github.com/repos/microsoft/onnxruntime/issues/2657
2658,b'Deploying the converted R-CNN Detector from Matlabto ONNX TO raspberry ',Software,closed,2019-12-14T12:04:22Z,2019-12-14 12:11:13+00:00,2020-07-11T01:41:12Z,0,209,https://api.github.com/repos/microsoft/onnxruntime/issues/2658
2659,b'is there an elegant way to set openmp envs?',Software,closed,2019-12-15T04:00:53Z,2019-12-15 06:56:18+00:00,2019-12-15T06:56:18Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2659
2662,"b'About ""Removing initializer""'",Software,closed,2019-12-16T06:25:26Z,2019-12-16 21:26:21+00:00,2019-12-17T06:37:42Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/2662
2664,b'Python 3.8 support',Software,closed,2019-12-16T09:57:54Z,2019-12-16 18:50:53+00:00,2020-10-04T03:56:30Z,0,292,https://api.github.com/repos/microsoft/onnxruntime/issues/2664
2665,b'Enable `pip install` from source',Software,closed,2019-12-16T10:04:01Z,2019-12-16 18:50:21+00:00,2020-07-25T06:40:26Z,0,221,https://api.github.com/repos/microsoft/onnxruntime/issues/2665
2666,b'Support more dnnl(mkldnn) operators',Software,closed,2019-12-16T10:11:46Z,2019-12-16 18:44:30+00:00,2020-07-25T07:40:36Z,0,221,https://api.github.com/repos/microsoft/onnxruntime/issues/2666
2667,"b'is there any performance comparison between mlas, dnnl, openvino ?'",Software,closed,2019-12-16T10:50:30Z,2019-12-16 18:44:09+00:00,2019-12-16T18:44:09Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2667
2668,"b'At compile time, the subprocess.run function reports an error.'",Software,closed,2019-12-16T11:14:20Z,2019-12-16 21:36:26+00:00,2019-12-17T16:21:07Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/2668
2669,b'How to build/create Python module from source?',Software,closed,2019-12-16T15:27:45Z,2019-12-16 21:36:55+00:00,2019-12-17T09:01:13Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2669
2675,b'Java maven snapshots and releases',Software,closed,2019-12-16T22:03:37Z,2019-12-17 01:25:35+00:00,2020-06-17T03:15:23Z,0,183,https://api.github.com/repos/microsoft/onnxruntime/issues/2675
2683,b'Memory initialization of CreateTensorAsOrtValue',Software,closed,2019-12-17T13:36:19Z,2019-12-17 17:34:20+00:00,2019-12-18T22:37:39Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/2683
2684,b'Instructions to build for ARM 64bit',Software,closed,2019-12-17T18:42:55Z,2019-12-20 19:59:38+00:00,2019-12-23T18:34:39Z,3,5,https://api.github.com/repos/microsoft/onnxruntime/issues/2684
2687,b'Resize bilinear + NHWC layout requires scales to be specified',Software,closed,2019-12-17T22:27:05Z,2019-12-18 00:28:24+00:00,2019-12-18T02:19:59Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2687
2690,b'C# - Unicode characters in string input tensors not translated correctly',Software,closed,2019-12-18T01:27:49Z,2019-12-19 19:56:17+00:00,2019-12-20T05:02:55Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/2690
2699,b'the gather OP with some problem',Software,closed,2019-12-19T10:17:07Z,2019-12-19 20:10:16+00:00,2019-12-21T01:23:09Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/2699
2700,b'Multiple Inferences in the same session - Cpp',Software,closed,2019-12-19T17:57:34Z,2019-12-19 20:44:42+00:00,2020-07-11T02:40:07Z,0,204,https://api.github.com/repos/microsoft/onnxruntime/issues/2700
2709,b'Mismatch results for inception_v2 in C_Api_Sample.cpp',Software,closed,2019-12-20T14:00:22Z,2019-12-20 23:54:29+00:00,2020-01-07T21:48:32Z,0,18,https://api.github.com/repos/microsoft/onnxruntime/issues/2709
2722,b'Why does my model throw an exception when it contains nn.ConvTranspose3d(deconvolution)?',Software,closed,2019-12-23T08:10:06Z,2019-12-23 10:49:19+00:00,2020-03-10T23:51:43Z,0,78,https://api.github.com/repos/microsoft/onnxruntime/issues/2722
2723,b'Quantize the GRU model from pytorch',Software,closed,2019-12-23T10:23:52Z,2019-12-24 06:15:30+00:00,2019-12-24T06:15:30Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2723
2724,b'Dead link in ONNX Runtime Samples and Tutorials',Documentation,closed,2019-12-23T12:06:03Z,2019-12-23 18:00:46+00:00,2019-12-26T01:38:17Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/2724
2725,b'Batch processing support for Inference',Software,closed,2019-12-23T19:07:04Z,2019-12-23 19:48:05+00:00,2019-12-29T03:36:15Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/2725
2732,b'Support s3 file paths',Software,closed,2019-12-24T07:57:28Z,2019-12-24 07:58:56+00:00,2020-07-25T07:40:24Z,0,213,https://api.github.com/repos/microsoft/onnxruntime/issues/2732
2733,b'Passing a python scalar list throws off `input_def_list`',Software,closed,2019-12-24T13:30:25Z,2019-12-24 13:30:57+00:00,2020-01-19T23:45:11Z,0,26,https://api.github.com/repos/microsoft/onnxruntime/issues/2733
2735,b'Build error in CentOS',Software,closed,2019-12-25T05:53:33Z,2019-12-26 00:40:41+00:00,2020-07-11T01:41:24Z,0,198,https://api.github.com/repos/microsoft/onnxruntime/issues/2735
2741,b'Abnormal performance of SetIntraOpNumThreads(1)',Software,closed,2019-12-26T11:24:54Z,2019-12-29 03:06:53+00:00,2020-07-11T04:39:46Z,2,197,https://api.github.com/repos/microsoft/onnxruntime/issues/2741
2742,b'Nuget PDB files should not be included in the nuget',Software,closed,2019-12-26T14:26:11Z,2019-12-26 17:12:52+00:00,2021-09-07T17:49:17Z,0,621,https://api.github.com/repos/microsoft/onnxruntime/issues/2742
2743,b'Unable to perform inference with converted Insightface resnet 100 model. ',Software,closed,2019-12-26T18:51:20Z,2019-12-29 03:11:03+00:00,2020-01-13T18:25:48Z,2,17,https://api.github.com/repos/microsoft/onnxruntime/issues/2743
2746,b'C API Features',Software,closed,2019-12-27T01:18:29Z,2019-12-29 03:06:16+00:00,2020-03-09T22:40:59Z,2,73,https://api.github.com/repos/microsoft/onnxruntime/issues/2746
2750,b'Is python onnxruntime-gpu  slower than pytorch cuda ?',Software,closed,2019-12-27T09:24:21Z,2019-12-27 19:08:52+00:00,2020-01-09T01:40:08Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/2750
2751,b'64-bit dll is 100% faster than 32-bit dll',Software,closed,2019-12-27T10:14:24Z,2019-12-27 19:08:07+00:00,2020-07-11T01:41:16Z,0,196,https://api.github.com/repos/microsoft/onnxruntime/issues/2751
2752,b'How to Create Tensor from other types use c++ API ?',Software,closed,2019-12-27T13:01:26Z,2019-12-29 03:07:32+00:00,2020-07-11T01:41:17Z,1,196,https://api.github.com/repos/microsoft/onnxruntime/issues/2752
2754,b'C# API Direct GPU transfer',Software,closed,2019-12-28T00:44:26Z,2019-12-29 03:22:14+00:00,2020-07-26T05:31:07Z,1,211,https://api.github.com/repos/microsoft/onnxruntime/issues/2754
2756,b'Shape mismatch warnings when using dynamic axis for time dimension',Software,closed,2019-12-28T15:00:05Z,2019-12-30 04:39:50+00:00,2020-01-31T00:48:32Z,1,33,https://api.github.com/repos/microsoft/onnxruntime/issues/2756
2757,b'[C++] How to batch predict using 1.x',Software,closed,2019-12-30T02:52:31Z,2019-12-30 04:40:27+00:00,2019-12-30T05:47:33Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2757
2761,b'Error Build --use_dml',Software,closed,2019-12-31T11:30:31Z,2020-01-02 10:03:31+00:00,2020-01-07T09:58:24Z,1,6,https://api.github.com/repos/microsoft/onnxruntime/issues/2761
2762,b'Using onnxruntime perf test',Software,closed,2019-12-31T13:26:21Z,2020-01-02 10:03:48+00:00,2020-01-03T11:04:44Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/2762
2763,b'Huge amount of managed allocations in C# API',Software,closed,2019-12-31T13:30:43Z,2019-12-31 13:30:43+00:00,2020-07-11T02:39:55Z,0,192,https://api.github.com/repos/microsoft/onnxruntime/issues/2763
2764,b'Raspberry Pi Zero W',Documentation,closed,2019-12-31T14:31:29Z,2020-01-02 10:14:29+00:00,2020-06-24T05:43:53Z,1,175,https://api.github.com/repos/microsoft/onnxruntime/issues/2764
2765,b'onnxruntime-gpu installing 0.4.0 instead of latest 1.1.0 version on ubuntu 16.04',Documentation,closed,2020-01-01T10:31:07Z,2020-01-02 10:23:48+00:00,2020-02-27T18:10:33Z,0,57,https://api.github.com/repos/microsoft/onnxruntime/issues/2765
2767,b'Packaging with 1.1.0 Releases',Documentation,closed,2020-01-02T03:24:06Z,2020-01-02 03:45:08+00:00,2020-01-08T19:48:49Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/2767
2769,b'static library',Documentation,closed,2020-01-02T09:36:19Z,2020-01-02 10:26:53+00:00,2020-01-04T20:15:19Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/2769
2773,b'Native memory leak in `OrtRun` using TensorRT',Documentation,closed,2020-01-03T11:23:29Z,2020-01-03 11:39:03+00:00,2020-01-24T13:16:14Z,0,21,https://api.github.com/repos/microsoft/onnxruntime/issues/2773
2779,b'The input tensor cannot be reshaped to the requested shape',Software,closed,2020-01-06T08:10:48Z,2020-01-06 11:50:34+00:00,2020-01-07T11:08:12Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/2779
2787,b'Howto: Support of CUDA/CPU using one DLL',Software,closed,2020-01-07T18:20:52Z,2020-01-07 22:14:44+00:00,2020-08-01T08:44:02Z,0,206,https://api.github.com/repos/microsoft/onnxruntime/issues/2787
2788,b'build error in MacOS with OpenVINO 2019R3.1',Software,closed,2020-01-07T18:32:19Z,2020-01-10 06:19:29+00:00,2020-09-18T04:00:56Z,2,254,https://api.github.com/repos/microsoft/onnxruntime/issues/2788
2793,b'How to enumerate the tensors and operators in the onnx model from C++?',Software,closed,2020-01-08T00:49:01Z,2020-01-21 22:51:23+00:00,2020-07-11T01:41:19Z,13,185,https://api.github.com/repos/microsoft/onnxruntime/issues/2793
2795,b'DML SessionGetInputCount != CPU  SessionGetInputCount (C-Api)',Software,closed,2020-01-08T09:47:08Z,2020-01-08 10:07:07+00:00,2020-07-11T01:41:18Z,0,184,https://api.github.com/repos/microsoft/onnxruntime/issues/2795
2796,b'Inference time of onnxruntime vs pytorch',Software,closed,2020-01-08T11:33:38Z,2020-01-14 00:43:54+00:00,2020-01-22T08:19:15Z,5,13,https://api.github.com/repos/microsoft/onnxruntime/issues/2796
2797,b'Segmentation fault (core dumped)',Software,closed,2020-01-08T13:10:56Z,2020-01-08 18:47:44+00:00,2020-09-18T04:00:47Z,0,253,https://api.github.com/repos/microsoft/onnxruntime/issues/2797
2799,b'Transpose Utility Layer',Software,closed,2020-01-08T20:29:54Z,2020-01-08 21:20:34+00:00,2021-03-19T00:10:33Z,0,435,https://api.github.com/repos/microsoft/onnxruntime/issues/2799
2803,b'BERT performance slower than default pytorch on CPU',Software,closed,2020-01-08T23:43:18Z,2020-01-12 04:56:50+00:00,2020-01-24T17:33:50Z,3,15,https://api.github.com/repos/microsoft/onnxruntime/issues/2803
2804,b'Runtime eror before my code return',Software,closed,2020-01-09T09:24:34Z,2020-01-28 18:39:38+00:00,2020-02-27T18:12:34Z,19,49,https://api.github.com/repos/microsoft/onnxruntime/issues/2804
2806,b'Cannot start inference session with tf.keras model converted to onnx',Software,closed,2020-01-09T11:59:20Z,2020-01-14 01:21:25+00:00,2020-03-10T23:59:03Z,4,61,https://api.github.com/repos/microsoft/onnxruntime/issues/2806
2812,b'Not compatible with latest Eigen preinstalled in system',Software,closed,2020-01-10T17:56:17Z,2020-01-11 09:57:39+00:00,2020-07-07T04:55:07Z,0,178,https://api.github.com/repos/microsoft/onnxruntime/issues/2812
2814,b'Missing integer input type for TopK (CPU)',Software,closed,2020-01-10T19:04:35Z,2020-01-10 19:04:55+00:00,2020-01-14T06:46:01Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/2814
2818,b'Adding execution providers as shared library?',Software,closed,2020-01-11T00:38:45Z,2020-01-11 01:20:25+00:00,2020-10-04T03:56:31Z,0,267,https://api.github.com/repos/microsoft/onnxruntime/issues/2818
2821,b'how to install onnxruntime',Software,closed,2020-01-11T12:54:15Z,2020-01-11 14:53:06+00:00,2020-01-11T14:53:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2821
2822,b'Onnx Model scores widely inaccurate',Software,closed,2020-01-13T04:28:46Z,2020-01-13 06:56:44+00:00,2020-01-13T06:56:44Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2822
2825,b'How to properly add execution provider and use it?',Software,closed,2020-01-13T18:32:41Z,2020-01-13 22:51:37+00:00,2020-01-13T22:51:37Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2825
2828,b'[Linux] CApiTest.dim_param fails with mutex error',Software,closed,2020-01-13T21:43:20Z,2020-01-13 21:47:01+00:00,2020-07-16T00:09:31Z,0,184,https://api.github.com/repos/microsoft/onnxruntime/issues/2828
2832,b'How to properly format OpenCV Mat data (image) to work with onnxruntime inference? ',Software,closed,2020-01-13T23:54:18Z,2020-01-14 23:22:09+00:00,2020-01-14T23:22:09Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2832
2839,b'Which framework can export quantization model to onnx?',Software,closed,2020-01-15T03:59:57Z,2020-01-16 01:45:48+00:00,2020-01-20T07:47:59Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/2839
2840,b'failed to start inference session with ShapeInferenceError',Software,closed,2020-01-15T07:31:10Z,2020-01-16 01:55:53+00:00,2020-01-16T01:55:53Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2840
2848,"b"" Type Error: Type 'tensor(bool)' of input parameter (1203) of operator (ReduceSum) in node () is invalid.""",Software,closed,2020-01-16T08:15:09Z,2020-01-24 17:07:32+00:00,2020-01-24T17:07:32Z,8,8,https://api.github.com/repos/microsoft/onnxruntime/issues/2848
2849,b'TopK not supported?',Software,closed,2020-01-16T09:34:24Z,2020-01-17 03:13:09+00:00,2020-03-02T02:03:25Z,0,45,https://api.github.com/repos/microsoft/onnxruntime/issues/2849
2860,b'Jetson nano - building from source - problem ',Software,closed,2020-01-17T08:19:22Z,2020-01-20 10:15:39+00:00,2020-01-22T18:47:05Z,3,5,https://api.github.com/repos/microsoft/onnxruntime/issues/2860
2861,b'Fail to run onnxruntime-gpu ImportError',Software,closed,2020-01-17T08:23:27Z,2020-01-22 02:04:44+00:00,2020-01-22T02:04:44Z,4,4,https://api.github.com/repos/microsoft/onnxruntime/issues/2861
2871,b'No performance improvement using fp16 model',Software,closed,2020-01-19T10:13:10Z,2020-01-21 07:10:07+00:00,2020-07-11T01:41:22Z,1,173,https://api.github.com/repos/microsoft/onnxruntime/issues/2871
2872,"b""Reshape 's requested shape is incorrect""",Software,closed,2020-01-20T07:41:01Z,2020-02-01 06:48:24+00:00,2020-02-27T18:35:02Z,11,38,https://api.github.com/repos/microsoft/onnxruntime/issues/2872
2874,b'BatchNormalization implementation for float64.',Software,closed,2020-01-20T09:46:34Z,2020-01-22 00:39:38+00:00,2020-01-30T21:55:20Z,1,10,https://api.github.com/repos/microsoft/onnxruntime/issues/2874
2875,b'Runtime error on Inference session ',Software,closed,2020-01-20T21:49:16Z,2020-02-02 21:02:14+00:00,2020-02-02T21:02:14Z,12,12,https://api.github.com/repos/microsoft/onnxruntime/issues/2875
2876,b'How to set provider in python api',Software,closed,2020-01-21T11:39:00Z,2020-01-22 02:56:19+00:00,2020-01-22T02:56:19Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2876
2877,b'Android build is failing both on Windows and Linux',Software,closed,2020-01-21T12:12:24Z,2020-01-21 18:38:24+00:00,2020-09-20T04:40:28Z,0,242,https://api.github.com/repos/microsoft/onnxruntime/issues/2877
2878,b'Providing fewer tensor inputs to Java API than model declares as inputs',Software,closed,2020-01-21T15:15:24Z,2020-01-21 18:36:55+00:00,2020-02-21T21:13:03Z,0,31,https://api.github.com/repos/microsoft/onnxruntime/issues/2878
2880,b'Shared Library noexecstack flag',Software,closed,2020-01-21T21:32:31Z,2020-01-21 21:33:10+00:00,2020-01-28T18:28:57Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/2880
2885,b'MLAS rewrite (#2844) causes performance issues on CPUs with high core count',Software,closed,2020-01-21T23:54:09Z,2020-01-22 00:07:37+00:00,2020-02-26T18:31:58Z,0,35,https://api.github.com/repos/microsoft/onnxruntime/issues/2885
2889,b'Weird requested input shape after running `bert_model_optimization.py`',Software,closed,2020-01-22T15:00:57Z,2020-01-22 23:34:47+00:00,2020-07-11T02:39:59Z,0,170,https://api.github.com/repos/microsoft/onnxruntime/issues/2889
2892,b'java runtime UnsatisfiedLinkError when loading jni dll from jar',Software,closed,2020-01-22T21:54:32Z,2020-01-24 01:31:14+00:00,2020-07-11T02:40:17Z,1,170,https://api.github.com/repos/microsoft/onnxruntime/issues/2892
2894,b'Fail to run onnxruntime-gpu ImportError #2861',Software,closed,2020-01-22T23:39:33Z,2020-01-27 17:18:12+00:00,2020-01-28T03:02:00Z,4,5,https://api.github.com/repos/microsoft/onnxruntime/issues/2894
2897,b'Inference using a LabelEncoder with input type int64 ',Software,closed,2020-01-23T14:57:53Z,2020-01-23 19:05:25+00:00,2020-01-30T22:56:47Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/2897
2899,b' building ONNXruntime with DNNL cause an error',Software,closed,2020-01-23T22:17:50Z,2020-01-27 17:18:30+00:00,2020-01-27T17:18:30Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/2899
2900,b'Add section for distro installations',Documentation,closed,2020-01-23T22:24:43Z,2020-01-23 22:31:57+00:00,2020-02-23T20:51:14Z,0,30,https://api.github.com/repos/microsoft/onnxruntime/issues/2900
2909,b'Alpine Linux support',Software,closed,2020-01-25T18:48:21Z,2020-01-28 16:42:11+00:00,2020-03-03T00:43:08Z,2,37,https://api.github.com/repos/microsoft/onnxruntime/issues/2909
2921,b'ppc64le support',Software,closed,2020-01-28T11:24:12Z,2020-01-28 16:42:21+00:00,2020-04-26T02:45:26Z,0,88,https://api.github.com/repos/microsoft/onnxruntime/issues/2921
2922,b'Compile error: relocation R_X86_64_32S against _Py_NotImplementedStruct',Software,closed,2020-01-28T12:04:10Z,2020-01-28 13:50:58+00:00,2020-01-28T13:50:58Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2922
2923,b'multiple Output  C-Api ',Software,closed,2020-01-28T13:28:01Z,2020-01-29 10:06:31+00:00,2020-01-29T10:06:30Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2923
2924,b'ONNX Runtime crashes when inferring this model',Software,closed,2020-01-28T16:38:15Z,2020-01-28 18:38:11+00:00,2020-01-29T17:08:28Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/2924
2925,b'JNI version seems too high for Android',Software,closed,2020-01-28T16:49:09Z,2020-01-28 16:49:09+00:00,2020-01-30T00:09:41Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/2925
2940,b'Crash in onnx::OpSchema::TypeConstraint()',Software,closed,2020-01-29T22:11:06Z,2020-01-31 18:21:04+00:00,2020-01-31T18:21:04Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/2940
2960,b'[LSTM] C# saving internal states for scoring and usage of tensor sequences as inputs',Software,closed,2020-01-31T14:17:11Z,2020-07-03 04:58:47+00:00,2020-07-11T01:41:23Z,153,161,https://api.github.com/repos/microsoft/onnxruntime/issues/2960
2962,b'Support for grid_sample layer in both ONNX and ORT',Software,closed,2020-02-01T16:31:17Z,2020-02-04 01:25:02+00:00,2020-03-11T00:00:35Z,2,38,https://api.github.com/repos/microsoft/onnxruntime/issues/2962
2963,b'ONNXRuntime_GPU illegal memory access error',Software,closed,2020-02-02T07:03:30Z,2020-02-03 19:30:34+00:00,2020-04-17T21:56:57Z,1,75,https://api.github.com/repos/microsoft/onnxruntime/issues/2963
2964,b'Error with QLinearConv and INT8 datatype',Software,closed,2020-02-02T10:08:46Z,2020-02-03 19:29:39+00:00,2020-07-25T06:40:18Z,1,173,https://api.github.com/repos/microsoft/onnxruntime/issues/2964
2965,b' docker build fails when pip installing on onnx:   Protobuf compiler not found   ',Software,closed,2020-02-03T03:55:41Z,2020-02-03 05:06:10+00:00,2020-02-14T19:43:19Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/2965
2967,b'Using TensorRT at fp16 precision',Software,closed,2020-02-03T15:40:27Z,2020-02-03 18:21:54+00:00,2020-02-20T00:16:40Z,0,16,https://api.github.com/repos/microsoft/onnxruntime/issues/2967
2968,"b'ORT with IntelOpenVino EP, examples fail!'",Software,closed,2020-02-03T16:59:32Z,2020-02-03 22:41:40+00:00,2020-07-11T02:39:57Z,0,158,https://api.github.com/repos/microsoft/onnxruntime/issues/2968
2969,b'Quantized model runs slower',Software,closed,2020-02-03T20:17:37Z,2020-02-04 01:04:19+00:00,2020-05-06T19:20:49Z,0,92,https://api.github.com/repos/microsoft/onnxruntime/issues/2969
2974,b'Does CAST node support INT64 to FLOAT16?',Software,closed,2020-02-05T05:44:12Z,2020-03-18 12:58:49+00:00,2020-03-18T19:21:29Z,42,42,https://api.github.com/repos/microsoft/onnxruntime/issues/2974
2982,b'No Op registered for Shape with domain_version of 12',Software,closed,2020-02-06T09:35:48Z,2020-02-06 18:10:51+00:00,2020-02-06T18:10:50Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2982
2983,b'Error using output of one model as input for another',Software,closed,2020-02-06T13:47:49Z,2020-02-28 01:00:06+00:00,2020-03-24T01:36:13Z,21,46,https://api.github.com/repos/microsoft/onnxruntime/issues/2983
2984,b'Loading onnx model from memory',Software,closed,2020-02-06T16:10:17Z,2020-02-06 17:44:28+00:00,2020-02-06T17:44:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/2984
2990,b'Upload torch model in C#',Software,closed,2020-02-07T09:17:26Z,2020-02-27 20:04:28+00:00,2020-07-11T02:40:05Z,20,154,https://api.github.com/repos/microsoft/onnxruntime/issues/2990
2994,b'ResNet-50 has unsupported operations with OpenVino',Software,closed,2020-02-08T00:35:21Z,2020-02-08 02:07:49+00:00,2020-08-30T23:46:40Z,0,204,https://api.github.com/repos/microsoft/onnxruntime/issues/2994
2995,b'error when loading onnxruntime-gpu and  pytorch library',Software,closed,2020-02-08T01:02:23Z,2020-02-09 23:03:05+00:00,2020-02-09T23:03:05Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/2995
2996,b'Is static quantization working?',Software,closed,2020-02-10T10:23:12Z,2020-02-11 23:49:08+00:00,2020-03-18T17:29:29Z,1,37,https://api.github.com/repos/microsoft/onnxruntime/issues/2996
2997,"b'Proto field is not repeating, cannot start list.'",Software,closed,2020-02-10T10:24:14Z,2020-02-10 19:01:18+00:00,2020-07-11T02:39:58Z,0,151,https://api.github.com/repos/microsoft/onnxruntime/issues/2997
2998,b'Cannot build onnxruntime with python 3.8',Software,closed,2020-02-10T18:10:21Z,2020-02-10 19:01:04+00:00,2020-02-23T17:21:01Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/2998
3004,"b'after using the BertOnnxModelTF.py to optimize the onnx bert model, only support batch_size==1? '",Software,closed,2020-02-11T07:11:23Z,2020-02-13 22:10:02+00:00,2020-07-11T02:40:16Z,2,150,https://api.github.com/repos/microsoft/onnxruntime/issues/3004
3007,b'Onnxruntime build with TensorRT faillure on Jetson Nano.',Software,closed,2020-02-11T20:28:09Z,2020-02-11 23:48:05+00:00,2020-07-11T02:39:56Z,0,150,https://api.github.com/repos/microsoft/onnxruntime/issues/3007
3015,b'Improve error message when tensor type does not match node input type',Software,closed,2020-02-13T17:03:54Z,2020-02-17 04:40:09+00:00,2020-02-25T19:21:41Z,3,12,https://api.github.com/repos/microsoft/onnxruntime/issues/3015
3024,b'Jetson Xavier - building from source',Software,closed,2020-02-14T19:38:15Z,2020-02-17 07:42:19+00:00,2020-07-11T02:40:01Z,2,147,https://api.github.com/repos/microsoft/onnxruntime/issues/3024
3029,"b""v1.1.1 cant' load certain onnx file""",Software,closed,2020-02-17T04:59:53Z,2020-02-17 08:58:24+00:00,2020-02-17T22:56:07Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3029
3032,b'Problem building onnxruntime with OpenVino on Windows',Software,closed,2020-02-17T12:58:29Z,2020-02-22 19:14:21+00:00,2020-06-23T15:11:24Z,5,127,https://api.github.com/repos/microsoft/onnxruntime/issues/3032
3034,"b'TensorRT EP  failing on dynamic input shape, but CPU/GPU EP passing OK.'",Software,closed,2020-02-18T00:17:01Z,2020-02-22 19:14:47+00:00,2020-09-20T20:40:06Z,4,215,https://api.github.com/repos/microsoft/onnxruntime/issues/3034
3036,b'OpenVINO Execution Provider samples C++ and python',Software,closed,2020-02-18T22:11:17Z,2020-02-25 19:22:06+00:00,2020-07-25T07:40:26Z,6,157,https://api.github.com/repos/microsoft/onnxruntime/issues/3036
3041,b'torchvision MaskRCNN export to ONNX throws error; onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Node (ConstantOfShape_1966) Op (ConstantOfShape) [ShapeInferenceError] Invalid shape value: 0',Software,closed,2020-02-19T10:36:49Z,2020-02-19 14:26:05+00:00,2020-07-11T16:39:26Z,0,143,https://api.github.com/repos/microsoft/onnxruntime/issues/3041
3042,b'Question about adding new optimization ',Software,closed,2020-02-19T17:02:06Z,2020-02-25 19:24:05+00:00,2020-07-11T02:40:14Z,6,142,https://api.github.com/repos/microsoft/onnxruntime/issues/3042
3044,b'cannot create sequence of string tensor',Software,closed,2020-02-19T22:15:30Z,2020-02-19 22:17:51+00:00,2020-02-20T19:27:43Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3044
3055,b'Source ZIPs/tarballs are missing submodules',Software,closed,2020-02-20T16:29:09Z,2020-02-20 20:17:29+00:00,2020-03-11T00:03:24Z,0,19,https://api.github.com/repos/microsoft/onnxruntime/issues/3055
3063,"b'Could not reproduce the inference time results of tutorial ""Inference-PyTorch-Bert-Model-for-High-Performance-in-ONNX-Runtime""'",Software,closed,2020-02-21T13:45:42Z,2020-02-28 18:08:02+00:00,2020-07-25T06:40:41Z,7,154,https://api.github.com/repos/microsoft/onnxruntime/issues/3063
3067,b'Rel-1.1.1 C++ API unable to run Op Set 11 on GPU',Software,closed,2020-02-21T18:30:15Z,2020-02-25 19:27:06+00:00,2020-02-27T18:40:30Z,4,6,https://api.github.com/repos/microsoft/onnxruntime/issues/3067
3071,b'Using Java library with DNNL ',Software,closed,2020-02-22T00:55:15Z,2020-02-22 01:10:21+00:00,2020-02-25T18:43:11Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/3071
3076,b'BERT performance slower with Intel(R) Xeon(R)',Software,closed,2020-02-22T05:37:47Z,2020-02-22 06:36:20+00:00,2020-03-02T10:27:10Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/3076
3077,b'Can not open the website in ONNX Tutorial page',Documentation,closed,2020-02-22T12:56:17Z,2020-02-25 19:20:44+00:00,2020-02-26T18:48:47Z,3,4,https://api.github.com/repos/microsoft/onnxruntime/issues/3077
3087,"b'building ONNX fail with error ""undefined""'",Documentation,closed,2020-02-25T04:37:11Z,2020-02-26 01:35:56+00:00,2020-02-26T06:26:18Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/3087
3092,b'2020 year topK still not support?',Documentation,closed,2020-02-26T04:08:27Z,2020-02-27 03:34:54+00:00,2020-03-01T09:13:45Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/3092
3095,"b""undefined reference to `OrtGetApiBase' collect2: error: ld returned 1 exit status""",Documentation,closed,2020-02-26T20:50:10Z,2020-02-27 04:10:38+00:00,2020-02-27T07:30:53Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3095
3096,"b""Attribute 'alpha' appeared multiple times""",Documentation,closed,2020-02-26T22:47:52Z,2020-02-27 00:40:50+00:00,2020-04-21T05:06:42Z,0,54,https://api.github.com/repos/microsoft/onnxruntime/issues/3096
3099,b'About the threads used',Documentation,closed,2020-02-27T10:13:43Z,2020-02-27 10:13:53+00:00,2020-03-03T08:13:58Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/3099
3100,b'c# api depends on cuda 10.0 but documentation lists 10.1 as requirement',Documentation,closed,2020-02-27T16:22:23Z,2020-02-27 18:45:05+00:00,2020-03-02T23:56:56Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/3100
3101,"b'When using another package manager than NuGet (like paket), onnxruntime.dll is not copied to build directory'",Software,closed,2020-02-27T17:07:34Z,2020-03-01 09:23:19+00:00,2020-08-03T22:27:51Z,2,158,https://api.github.com/repos/microsoft/onnxruntime/issues/3101
3107,b'Question: how to build/test opset 12 / ir_version v7',Software,closed,2020-02-28T17:33:33Z,2020-02-28 20:11:48+00:00,2020-10-04T03:56:32Z,0,218,https://api.github.com/repos/microsoft/onnxruntime/issues/3107
3113,b'GPU bug with Unpooling layer and large size inputs',Software,open,2020-03-01T06:48:13Z,2020-03-05 07:19:26+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/3113
3114,b'RUNTIME_EXCEPTION : Non-zero status code returned while running ReorderInput node.',Software,closed,2020-03-01T10:25:53Z,2020-03-01 16:47:01+00:00,2020-07-11T02:40:02Z,0,131,https://api.github.com/repos/microsoft/onnxruntime/issues/3114
3115,b'Onnxruntime.gpu operation speed is as slow as cpu mode.',Software,closed,2020-03-01T14:22:08Z,2020-03-05 07:11:08+00:00,2020-03-05T07:11:08Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/3115
425,b'Microsoft.ML.OnnxRuntime libraries fails to load (dotnet-aspnetcore linux container usage)',Software,closed,2019-02-01T14:07:52Z,2019-02-21 03:58:32+00:00,2019-03-08T04:10:00Z,19,34,https://api.github.com/repos/microsoft/onnxruntime/issues/425
433,"b'when there are few cast connected, the result might be wrong'",Software,closed,2019-02-02T04:33:04Z,2019-02-08 19:20:11+00:00,2019-03-13T21:46:23Z,6,39,https://api.github.com/repos/microsoft/onnxruntime/issues/433
434,"b'Build error ""Could not copy the file ...""'",Software,closed,2019-02-02T22:46:56Z,2019-02-04 18:20:14+00:00,2019-02-04T20:17:09Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/434
438,b'Windows x86 support CPU (and GPU?)',Software,closed,2019-02-05T12:06:53Z,2019-02-19 19:17:00+00:00,2019-02-21T04:00:20Z,14,15,https://api.github.com/repos/microsoft/onnxruntime/issues/438
441,b'InferenceSession without ONNX Files',Software,closed,2019-02-05T23:17:04Z,2019-02-08 19:29:20+00:00,2019-06-04T22:30:10Z,2,118,https://api.github.com/repos/microsoft/onnxruntime/issues/441
453,b'SIGSEGV',Software,closed,2019-02-07T11:46:04Z,2019-02-21 04:04:11+00:00,2019-03-22T03:42:05Z,13,42,https://api.github.com/repos/microsoft/onnxruntime/issues/453
458,b'Missing opset in the model',Software,closed,2019-02-08T14:20:09Z,2019-02-08 14:44:29+00:00,2019-02-08T14:44:29Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/458
462,b'OnnxRuntime csharp Inference example',Software,closed,2019-02-11T08:50:23Z,2019-02-11 17:41:26+00:00,2019-02-11T18:13:55Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/462
463,b'Segfault with scikit-learn LogisticRegression model',Software,closed,2019-02-11T10:10:43Z,2019-02-11 10:11:16+00:00,2019-03-13T21:45:10Z,0,30,https://api.github.com/repos/microsoft/onnxruntime/issues/463
486,b'Switch between providers',Software,closed,2019-02-17T08:46:36Z,2019-02-21 04:05:22+00:00,2019-10-11T21:52:40Z,3,236,https://api.github.com/repos/microsoft/onnxruntime/issues/486
487,b'Wrong predict results on onnx model 1.2 from customvision.ai',Software,closed,2019-02-17T14:52:53Z,2019-02-20 12:27:26+00:00,2019-02-22T01:02:08Z,2,4,https://api.github.com/repos/microsoft/onnxruntime/issues/487
488,b'CUDA 10 Support',Software,closed,2019-02-18T03:02:52Z,2019-02-18 06:29:39+00:00,2019-02-18T06:29:39Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/488
492,"b'Got ""No suitable kernel definition found for op BatchNormalization(9)""'",Software,closed,2019-02-20T04:00:15Z,2019-02-20 04:01:55+00:00,2019-02-20T04:07:47Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/492
494,b'Official build for Linux',Software,closed,2019-02-20T13:57:39Z,2019-02-20 23:04:47+00:00,2019-02-20T23:04:47Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/494
495,"b'Conv with auto_pad=""SAME_UPPER"" does not work as expected.'",Software,closed,2019-02-20T14:36:16Z,2019-02-21 04:08:53+00:00,2019-04-10T03:14:23Z,0,48,https://api.github.com/repos/microsoft/onnxruntime/issues/495
504,b'Doc page with list of supported ops ?',Software,closed,2019-02-21T18:02:53Z,2019-02-21 22:41:33+00:00,2019-02-23T03:30:22Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/504
508,b'Score computation in TreeEnsembleRegressor implementation is wrong',Software,closed,2019-02-21T23:52:47Z,2019-02-22 00:56:35+00:00,2019-05-15T17:19:26Z,0,82,https://api.github.com/repos/microsoft/onnxruntime/issues/508
510,"b""ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'""",Software,closed,2019-02-22T02:04:16Z,2019-02-22 19:31:48+00:00,2019-03-08T04:11:18Z,0,14,https://api.github.com/repos/microsoft/onnxruntime/issues/510
513,b'PROBIT score transform is ignored in TreeEnsembleRegressor',Software,closed,2019-02-22T23:59:12Z,2019-02-26 18:44:29+00:00,2019-03-20T00:55:26Z,3,25,https://api.github.com/repos/microsoft/onnxruntime/issues/513
3117,b'CUDA error cudaErrorNoKernelImageForDevice:no kernel image is available for execution on the device',Software,closed,2020-03-02T07:25:48Z,2020-03-02 07:26:30+00:00,2021-03-19T00:10:09Z,0,381,https://api.github.com/repos/microsoft/onnxruntime/issues/3117
3118,b'InferenceSession from I/O Stream',Software,closed,2020-03-02T10:51:19Z,2020-03-02 12:46:59+00:00,2020-03-02T12:46:59Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3118
3119,b'MissingMethodException during Predict',Software,closed,2020-03-02T15:52:18Z,2020-03-03 19:38:21+00:00,2020-04-08T05:42:51Z,1,36,https://api.github.com/repos/microsoft/onnxruntime/issues/3119
3121,b'GPU inference time of first image',Software,closed,2020-03-02T16:16:50Z,2020-03-05 19:56:50+00:00,2020-07-11T02:40:04Z,3,130,https://api.github.com/repos/microsoft/onnxruntime/issues/3121
3122,"b'""This is an invalid model"" error related to float type and Equal operator'",Software,closed,2020-03-02T18:45:26Z,2020-03-02 19:51:35+00:00,2020-03-05T13:52:22Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/3122
3124,b'Can you guys provide a clear CMakeLists.txt example on how to include onnxruntime for a C++ project?',Documentation,closed,2020-03-02T22:32:02Z,2020-03-02 23:01:25+00:00,2020-07-25T06:40:40Z,0,144,https://api.github.com/repos/microsoft/onnxruntime/issues/3124
3127,b'PreProcessing step in  yolov3',Documentation,closed,2020-03-03T04:33:44Z,2020-03-05 19:13:37+00:00,2020-03-05T19:13:37Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/3127
3128,b'How to only compute a partial graph?',Software,closed,2020-03-03T04:41:01Z,2020-03-03 18:55:58+00:00,2020-07-25T06:40:19Z,0,144,https://api.github.com/repos/microsoft/onnxruntime/issues/3128
3129,b'cublas64_100.dll  got  exception after return from main',Software,closed,2020-03-03T08:03:24Z,2020-03-03 23:45:00+00:00,2020-03-05T22:40:23Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/3129
3130,b'onnxruntime.capi.onnxruntime_pybind11_state.NotImplemented: [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for the node ConvInteger(10)',Software,closed,2020-03-03T18:26:35Z,2020-03-03 18:54:26+00:00,2020-07-25T06:40:23Z,0,143,https://api.github.com/repos/microsoft/onnxruntime/issues/3130
3132,b'GetTensorShapeElementCount return wrong result if tensor shape has unknown',Software,closed,2020-03-03T21:35:27Z,2020-03-03 23:17:42+00:00,2020-07-11T04:39:55Z,0,129,https://api.github.com/repos/microsoft/onnxruntime/issues/3132
3138,"b""CUDAExecutionProvider doesn't respect kernels defined in custom op C API""",Software,closed,2020-03-04T18:08:03Z,2020-03-07 00:39:32+00:00,2020-03-11T07:49:02Z,2,6,https://api.github.com/repos/microsoft/onnxruntime/issues/3138
3141,b'ONNX BERTModel produces different number of outputs  between Python and C#',Software,closed,2020-03-04T23:49:16Z,2020-03-05 00:35:04+00:00,2020-07-11T02:40:03Z,0,128,https://api.github.com/repos/microsoft/onnxruntime/issues/3141
3143,b'onnx + weight_norm',Software,closed,2020-03-05T11:12:25Z,2020-08-29 11:04:44+00:00,2020-09-05T19:32:37Z,176,184,https://api.github.com/repos/microsoft/onnxruntime/issues/3143
3144,b'Adding sparse matrix support (or failing them)',Software,closed,2020-03-05T13:08:42Z,2020-03-19 11:29:02+00:00,2020-07-11T02:40:15Z,13,127,https://api.github.com/repos/microsoft/onnxruntime/issues/3144
3145,b'raspberry4 build with docker ',Software,closed,2020-03-05T16:55:28Z,2020-03-12 15:17:34+00:00,2020-08-08T23:16:56Z,6,156,https://api.github.com/repos/microsoft/onnxruntime/issues/3145
3156,b'ONNXRUNTIME C++ API ROI-Align Sampling Ratio < 0 Support',Software,closed,2020-03-06T09:00:38Z,2020-03-06 19:10:42+00:00,2020-03-07T01:13:02Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3156
3157,b'OnnxTensor.createTensor should support Nd4j Objects',Software,closed,2020-03-06T10:40:33Z,2020-03-06 19:04:06+00:00,2020-03-06T19:04:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3157
3164,b'Segmentation Fault when inference with PyOp',Software,closed,2020-03-07T02:21:26Z,2020-03-12 00:10:05+00:00,2020-11-16T03:47:58Z,4,254,https://api.github.com/repos/microsoft/onnxruntime/issues/3164
3166,b'onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running BatchNormalization node',Software,closed,2020-03-07T12:50:06Z,2020-03-09 22:17:01+00:00,2020-04-17T21:50:55Z,2,41,https://api.github.com/repos/microsoft/onnxruntime/issues/3166
3167,b'ShapeInferenceError on a very simple network with resize only',Software,closed,2020-03-07T18:31:00Z,2020-03-08 07:58:09+00:00,2020-03-08T07:58:09Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3167
3168,b'Inference Maskrcnn model via Onnxruntime(c++) and got bugs',Software,closed,2020-03-08T08:59:18Z,2020-03-08 09:02:34+00:00,2020-06-02T08:37:48Z,0,85,https://api.github.com/repos/microsoft/onnxruntime/issues/3168
3169,b'Cannot build ORT with Visual Studio 2017 Version 15.9.20 and CUDA 10.1',Software,closed,2020-03-09T13:25:20Z,2020-06-03 07:53:47+00:00,2020-06-03T07:53:46Z,85,85,https://api.github.com/repos/microsoft/onnxruntime/issues/3169
3170,b'How to get more than one outputs using onnxruntime?',Software,closed,2020-03-09T14:28:33Z,2020-03-09 15:30:56+00:00,2020-07-11T02:40:19Z,0,123,https://api.github.com/repos/microsoft/onnxruntime/issues/3170
3172,b'Delay-loading of onnxruntime.dll fails',Software,closed,2020-03-10T09:08:51Z,2020-06-02 20:11:08+00:00,2020-08-08T23:16:57Z,84,151,https://api.github.com/repos/microsoft/onnxruntime/issues/3172
3179,b'onnxruntime.dll is built differently for the releases page compared to the nuget.org version',Software,closed,2020-03-11T19:30:25Z,2020-03-13 00:52:40+00:00,2020-07-25T06:40:22Z,1,135,https://api.github.com/repos/microsoft/onnxruntime/issues/3179
3181,b'C# DisposableOnnxValue seems to incorrectly accumulate tensors in a SequenceTensor',Software,closed,2020-03-11T23:22:13Z,2020-03-11 23:22:49+00:00,2020-05-18T18:10:14Z,0,67,https://api.github.com/repos/microsoft/onnxruntime/issues/3181
3184,b'How to put more than one inputs using onnxruntime?',Software,closed,2020-03-12T04:18:19Z,2020-03-13 01:03:36+00:00,2020-03-13T01:03:36Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3184
3185,b'PyPy support',Software,closed,2020-03-12T05:09:05Z,2020-03-13 06:53:35+00:00,2020-07-25T06:40:20Z,1,135,https://api.github.com/repos/microsoft/onnxruntime/issues/3185
3188,b'quantize.py error(s) static quantization',Software,closed,2020-03-12T07:56:21Z,2020-03-12 21:42:35+00:00,2020-03-13T16:32:37Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/3188
3189,b'Support for constant op with sparse tensor value',Software,closed,2020-03-12T10:25:53Z,2020-03-13 07:06:34+00:00,2020-07-25T06:40:21Z,0,134,https://api.github.com/repos/microsoft/onnxruntime/issues/3189
3190,"b'inference 4096 Images, GPU, small modell'",Software,closed,2020-03-12T11:09:09Z,2020-03-13 00:53:30+00:00,2020-07-11T02:40:13Z,0,120,https://api.github.com/repos/microsoft/onnxruntime/issues/3190
3191,b'No Op registered',Software,closed,2020-03-12T13:22:59Z,2020-03-12 19:22:50+00:00,2020-03-12T19:22:50Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3191
3192,b'Support OpenVino 2020.1',Software,closed,2020-03-12T13:43:06Z,2020-03-13 00:54:10+00:00,2020-07-11T02:40:12Z,0,120,https://api.github.com/repos/microsoft/onnxruntime/issues/3192
3195,b'Is runtime CPU and GPU support available from one lib in C++?',Software,closed,2020-03-12T20:30:51Z,2020-03-13 00:55:15+00:00,2020-03-13T20:25:48Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3195
3202,b'How can I get the value of the multiple layer as output?',Software,closed,2020-03-13T05:29:29Z,2020-03-16 00:10:45+00:00,2020-07-11T02:40:21Z,2,119,https://api.github.com/repos/microsoft/onnxruntime/issues/3202
3203,b'Can i run model with custom op at the python environment using onnruntime? ',Software,closed,2020-03-13T05:31:25Z,2020-03-16 03:04:10+00:00,2020-03-16T03:04:10Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/3203
3205,b'[ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running PRelu node',Software,closed,2020-03-13T11:41:41Z,2020-03-13 17:58:21+00:00,2020-03-13T17:58:21Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3205
3208,b'Segfault when reducing a 0D Tensor',Software,closed,2020-03-13T18:19:01Z,2020-03-13 23:47:42+00:00,2020-07-11T02:40:20Z,0,119,https://api.github.com/repos/microsoft/onnxruntime/issues/3208
3218,b'How to run a onnx model on GPU in c++?',Software,closed,2020-03-15T03:46:13Z,2020-03-16 00:20:19+00:00,2020-04-05T14:10:57Z,0,21,https://api.github.com/repos/microsoft/onnxruntime/issues/3218
3220,b'Error when quantizing Squeezenet',Software,closed,2020-03-15T11:34:17Z,2020-03-16 18:36:57+00:00,2020-03-20T18:36:48Z,1,5,https://api.github.com/repos/microsoft/onnxruntime/issues/3220
3221,b'CPUExecutionProvider and CUDAExecutionProvider switching during runtime',Software,closed,2020-03-15T11:51:10Z,2020-03-15 12:40:42+00:00,2020-03-22T13:46:20Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/3221
3222,b'Create Session fails....',Software,closed,2020-03-15T23:37:08Z,2020-03-17 17:58:07+00:00,2020-07-11T04:39:47Z,1,117,https://api.github.com/repos/microsoft/onnxruntime/issues/3222
3223,b'Build error when onnxruntime_BUILD_FOR_NATIVE_MACHINE is ON',Software,closed,2020-03-16T01:47:29Z,2020-03-16 03:18:28+00:00,2020-03-16T04:51:22Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3223
3224,b'What package should java install from maven',Software,closed,2020-03-16T05:33:07Z,2020-03-16 07:12:03+00:00,2020-07-15T19:56:49Z,0,121,https://api.github.com/repos/microsoft/onnxruntime/issues/3224
3225,b'where id ai.onnxruntime?',Software,closed,2020-03-16T05:42:55Z,2020-03-23 04:48:51+00:00,2020-03-23T04:48:51Z,6,6,https://api.github.com/repos/microsoft/onnxruntime/issues/3225
3226,b'How can i make inputs?',Software,closed,2020-03-16T07:29:37Z,2020-03-17 07:50:41+00:00,2020-03-21T13:17:26Z,1,5,https://api.github.com/repos/microsoft/onnxruntime/issues/3226
3227,b'Lack of Output Data when running Tiny Yolo v3',Software,closed,2020-03-16T08:23:34Z,2020-03-17 10:01:10+00:00,2020-03-18T13:57:54Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/3227
3229,b'Error running inference on converted tensorflow model',Software,closed,2020-03-16T15:45:18Z,2020-03-17 12:52:38+00:00,2020-03-17T14:49:16Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3229
3233,b'Cannot force to single threaded execution',Software,closed,2020-03-16T20:26:14Z,2020-03-19 18:11:47+00:00,2020-03-19T18:11:46Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/3233
3236,b'ReduceSumSquare op much slower than a combination of Mul and ReduceSum.',Software,closed,2020-03-17T09:38:50Z,2020-03-17 09:39:26+00:00,2020-03-19T23:59:26Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/3236
3239,b'topK error',Software,closed,2020-03-17T16:01:39Z,2020-03-19 00:55:04+00:00,2020-07-11T02:40:18Z,1,115,https://api.github.com/repos/microsoft/onnxruntime/issues/3239
3240,b'Error loading model with ONNX Runtime with TensorRT on Jetson devices',Software,closed,2020-03-17T16:53:16Z,2020-03-17 17:57:34+00:00,2020-09-20T20:40:05Z,0,187,https://api.github.com/repos/microsoft/onnxruntime/issues/3240
3242,b'How can I run an LSTM model with negative shape for batch size?',Software,closed,2020-03-17T18:27:23Z,2020-03-18 19:01:53+00:00,2020-03-18T19:01:56Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/3242
3247,b'ONNX instability output on onnxruntime',Software,closed,2020-03-18T08:40:11Z,2020-03-18 08:40:33+00:00,2020-03-20T00:38:12Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/3247
3248,b'num_dims does not match for input',Software,closed,2020-03-18T10:22:01Z,2020-03-19 07:19:45+00:00,2020-03-19T07:19:45Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3248
3250,b'ios support',Software,closed,2020-03-18T12:28:58Z,2020-03-18 18:34:58+00:00,2020-07-25T06:40:38Z,0,128,https://api.github.com/repos/microsoft/onnxruntime/issues/3250
3251,b'Reproducing the release builds',Software,closed,2020-03-18T16:41:09Z,2020-03-19 06:28:10+00:00,2020-03-19T06:28:10Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3251
3254,b'Inference speed ONNX vs. PB',Software,closed,2020-03-18T17:52:39Z,2020-03-18 20:50:04+00:00,2020-07-11T04:39:44Z,0,114,https://api.github.com/repos/microsoft/onnxruntime/issues/3254
3261,b'Maintain Ort::Session opened',Software,closed,2020-03-19T03:31:03Z,2020-03-22 16:48:35+00:00,2020-03-22T16:48:35Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/3261
3262,b'TensorRT 7.0 build error',Software,closed,2020-03-19T03:44:15Z,2020-03-19 03:50:39+00:00,2020-03-19T03:50:39Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3262
3263,b'CPU and GPU different behaviour',Software,closed,2020-03-19T06:29:33Z,2020-03-24 18:30:16+00:00,2020-09-14T12:20:30Z,5,179,https://api.github.com/repos/microsoft/onnxruntime/issues/3263
3264,b'DLL version number of current release is 0.0.0.0',Software,closed,2020-03-19T10:24:49Z,2020-03-19 17:41:45+00:00,2020-03-19T19:22:18Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3264
3266,b'add dimension for input_tensor_values',Software,closed,2020-03-19T14:53:41Z,2020-03-24 18:28:33+00:00,2020-06-02T19:14:08Z,5,75,https://api.github.com/repos/microsoft/onnxruntime/issues/3266
3279,b'Building python binding without enabling unit tests',Software,closed,2020-03-20T16:15:30Z,2020-03-24 18:30:00+00:00,2020-07-25T06:40:25Z,4,126,https://api.github.com/repos/microsoft/onnxruntime/issues/3279
3288,b'Release source distribution is unusable',Software,closed,2020-03-21T06:53:23Z,2020-03-23 05:44:15+00:00,2020-07-25T06:40:25Z,1,125,https://api.github.com/repos/microsoft/onnxruntime/issues/3288
3289,b'Question about input dimensions using C++ API',Software,closed,2020-03-21T09:45:25Z,2020-03-22 09:12:52+00:00,2020-03-23T10:36:31Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/3289
3290,b'Run time for web(browser)',Software,open,2020-03-21T16:34:47Z,2020-03-23 04:01:30+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/3290
3292,b'pytorch Upsampling with align_corners = True',Software,closed,2020-03-22T10:45:57Z,2020-03-24 18:26:17+00:00,2020-07-11T01:41:02Z,2,110,https://api.github.com/repos/microsoft/onnxruntime/issues/3292
3293,b'Problems with TensorRT onnxruntime and symbolic_shape_infer.py ',Software,closed,2020-03-22T17:36:31Z,2020-03-22 17:36:51+00:00,2020-04-01T11:46:48Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/3293
3294,b'How to run a quantization model on GPU\xef\xbc\x9f',Software,closed,2020-03-23T09:06:58Z,2020-03-23 22:50:48+00:00,2020-03-27T05:46:36Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/3294
3296,b'Segmentation Fault when running on Raspberry Pi 3B+',Software,closed,2020-03-23T11:08:32Z,2020-03-24 18:25:27+00:00,2020-07-11T04:39:48Z,1,109,https://api.github.com/repos/microsoft/onnxruntime/issues/3296
3297,b'Nearest neighbour upsampling very slow with opset11',Software,closed,2020-03-23T13:42:18Z,2020-03-24 18:24:37+00:00,2020-05-20T00:14:04Z,1,57,https://api.github.com/repos/microsoft/onnxruntime/issues/3297
3299,b'Model with multiple inputs in ONNXRuntime C++',Software,closed,2020-03-23T16:16:28Z,2020-03-24 18:15:22+00:00,2020-03-27T17:53:11Z,1,4,https://api.github.com/repos/microsoft/onnxruntime/issues/3299
3307,b'Build onnxruntime on AGX',Software,closed,2020-03-24T07:49:01Z,2020-03-24 18:14:25+00:00,2020-03-30T07:30:52Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/3307
3308,b'Differences between mlas/lib/aarch64 and mlas/lib/arm64',Software,closed,2020-03-24T08:34:01Z,2020-03-24 18:13:15+00:00,2020-03-25T03:54:30Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3308
3309,b'Yolov3 from Model Zoo Unsupported by OpenVino EP',Software,closed,2020-03-24T16:17:26Z,2020-03-24 16:27:31+00:00,2020-07-11T02:40:22Z,0,108,https://api.github.com/repos/microsoft/onnxruntime/issues/3309
3310,"b""Outputs from C/Python APIs don't match - how to properly load image data?""",Software,closed,2020-03-24T20:29:01Z,2020-03-24 22:55:50+00:00,2020-04-21T05:04:48Z,0,27,https://api.github.com/repos/microsoft/onnxruntime/issues/3310
3313,b'Build from source failed on Mac',Software,closed,2020-03-25T05:32:08Z,2020-03-25 05:34:16+00:00,2020-04-23T15:26:04Z,0,29,https://api.github.com/repos/microsoft/onnxruntime/issues/3313
3325,b'difference between yolo3.weights and yolo3.onnx',Software,closed,2020-03-26T01:43:26Z,2020-04-08 09:42:08+00:00,2020-04-08T09:42:08Z,13,13,https://api.github.com/repos/microsoft/onnxruntime/issues/3325
3326,b'Install onnxruntime gpu version',Software,closed,2020-03-26T01:44:20Z,2020-03-26 02:20:49+00:00,2020-03-26T02:20:49Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3326
3335,b'Web tooling for model conversion for newcomers/quick start?',Software,closed,2020-03-26T17:28:07Z,2020-03-26 17:30:21+00:00,2020-07-11T02:40:24Z,0,106,https://api.github.com/repos/microsoft/onnxruntime/issues/3335
3340,b'Runtime_Exception with nGraph',Software,closed,2020-03-26T20:58:56Z,2020-03-27 21:54:31+00:00,2020-03-30T16:22:38Z,1,3,https://api.github.com/repos/microsoft/onnxruntime/issues/3340
3342,b'Request for C++ API documentation',Documentation,closed,2020-03-27T03:23:45Z,2020-03-27 21:54:01+00:00,2020-08-03T05:08:45Z,0,129,https://api.github.com/repos/microsoft/onnxruntime/issues/3342
3344,b'Unable to use onnxruntime.dll for GPU',Documentation,closed,2020-03-27T13:03:16Z,2020-03-27 21:56:10+00:00,2020-06-02T22:07:54Z,0,67,https://api.github.com/repos/microsoft/onnxruntime/issues/3344
3345,b'DirectML: Non-zero status code returned while running FusedConv node.',Software,closed,2020-03-27T15:41:56Z,2020-03-27 21:51:01+00:00,2020-07-11T02:40:23Z,0,105,https://api.github.com/repos/microsoft/onnxruntime/issues/3345
3346,b'CUDA support with C++',Software,closed,2020-03-27T18:06:04Z,2020-03-27 18:40:36+00:00,2020-03-27T18:40:36Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3346
3353,b'RUNTIME_EXCEPTION:  Attribute not found: pads',Software,closed,2020-03-28T11:31:38Z,2020-03-28 11:45:09+00:00,2020-07-11T04:39:45Z,0,104,https://api.github.com/repos/microsoft/onnxruntime/issues/3353
3354,b'Python 3.6 not found by FindPythonInterp',Software,closed,2020-03-28T15:22:39Z,2020-03-28 15:24:27+00:00,2020-08-31T12:46:34Z,0,155,https://api.github.com/repos/microsoft/onnxruntime/issues/3354
3355,b'Cannot build with CUDA in CMake 3.17.0',Software,closed,2020-03-28T21:29:07Z,2020-03-28 21:37:39+00:00,2020-03-30T07:38:58Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/3355
3357,"b""onnxruntime c/c++ api don't support windows xp""",Software,closed,2020-03-29T11:57:23Z,2020-03-30 21:42:56+00:00,2020-07-25T06:40:28Z,1,117,https://api.github.com/repos/microsoft/onnxruntime/issues/3357
3358,b'How to use DirectML execution provider from Python?',Software,closed,2020-03-29T16:19:48Z,2020-03-30 23:42:13+00:00,2020-08-31T02:46:33Z,1,154,https://api.github.com/repos/microsoft/onnxruntime/issues/3358
3360,b'Creating DirectML Device crashes at `DMLCreateDevice1`',Software,closed,2020-03-29T21:52:26Z,2020-03-31 23:30:03+00:00,2020-04-01T19:20:28Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/3360
3361,b'Long load time when using Grouped convolutions',Software,closed,2020-03-30T02:03:00Z,2020-03-30 23:40:33+00:00,2020-07-11T04:39:58Z,0,103,https://api.github.com/repos/microsoft/onnxruntime/issues/3361
3364,b'ONNXRUNTIME needs to support Opset version 11 and 12 of the Clip Operation',Software,closed,2020-03-30T13:05:15Z,2020-03-30 23:40:15+00:00,2020-07-25T06:40:30Z,0,116,https://api.github.com/repos/microsoft/onnxruntime/issues/3364
3366,b'No support for double Sum',Software,closed,2020-03-30T17:07:00Z,2020-03-30 19:01:52+00:00,2020-07-25T06:40:27Z,0,116,https://api.github.com/repos/microsoft/onnxruntime/issues/3366
3371,b'Build onnxruntime-tensorRT  on Jetson Xavier failed',Software,closed,2020-03-31T03:22:04Z,2020-04-01 07:33:56+00:00,2020-04-01T07:33:55Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/3371
3372,"b'use onnx shape_inference.infer_shapes check model success,but use onnxruntime-gpu InferenceSession check model fail'",Software,closed,2020-03-31T03:36:40Z,2020-03-31 23:28:56+00:00,2020-04-08T05:58:33Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/3372
3377,b'opset11 equal ops doesnt support float (onnxruntime-gpu)',Software,closed,2020-03-31T08:19:56Z,2020-03-31 23:30:26+00:00,2020-07-25T06:40:29Z,0,115,https://api.github.com/repos/microsoft/onnxruntime/issues/3377
3391,b'GPU topk may get different results with same input',Software,closed,2020-04-01T10:14:26Z,2020-04-06 22:31:12+00:00,2020-04-30T21:17:10Z,5,29,https://api.github.com/repos/microsoft/onnxruntime/issues/3391
3394,b'Custom ops with same name and different Execution Provider',Software,closed,2020-04-01T13:57:18Z,2020-04-02 19:58:15+00:00,2020-04-02T22:38:52Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/3394
3402,b'Predict gets slower and slower over time',Software,closed,2020-04-02T00:23:17Z,2020-04-04 01:00:44+00:00,2020-04-04T01:00:43Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/3402
3406,b'bad sample for cuda',Documentation,closed,2020-04-02T11:02:53Z,2020-04-03 00:47:19+00:00,2020-07-20T16:31:45Z,0,109,https://api.github.com/repos/microsoft/onnxruntime/issues/3406
3409,b'C# Verbose levels not working',Software,closed,2020-04-02T23:09:05Z,2020-04-06 22:30:41+00:00,2020-05-08T21:47:10Z,3,35,https://api.github.com/repos/microsoft/onnxruntime/issues/3409
3414,b'[ONNXRuntimeError] TensorRT EP could not build Engine for fused node',Software,closed,2020-04-03T06:44:52Z,2020-04-06 22:30:20+00:00,2020-09-20T20:40:07Z,3,170,https://api.github.com/repos/microsoft/onnxruntime/issues/3414
3417,b'Segmentation fault on loading quantized model',Software,closed,2020-04-03T11:41:07Z,2020-04-03 16:57:43+00:00,2020-04-13T22:02:19Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/3417
3418,"b""CPUExecutionProvider's Conv1D is 3 times slower than tf.keras""",Software,closed,2020-04-03T15:10:22Z,2020-04-03 17:50:07+00:00,2020-09-11T04:15:53Z,0,160,https://api.github.com/repos/microsoft/onnxruntime/issues/3418
3420,b'Model shape inference failed for Nuphar with onnxruntime-1.2.0',Software,closed,2020-04-03T18:30:01Z,2020-04-03 19:18:56+00:00,2020-09-20T04:40:30Z,0,169,https://api.github.com/repos/microsoft/onnxruntime/issues/3420
3427,b'Memory use with GPU in C++ API',Software,closed,2020-04-05T15:56:34Z,2020-04-06 22:29:37+00:00,2020-08-09T01:16:53Z,1,125,https://api.github.com/repos/microsoft/onnxruntime/issues/3427
3428,b'CNTK to ONNX converter bug - inception-v3 model',Software,closed,2020-04-05T23:38:11Z,2020-04-06 22:29:12+00:00,2020-09-20T04:40:31Z,0,167,https://api.github.com/repos/microsoft/onnxruntime/issues/3428
3430,b'Segfault when serializing a model that contains value_info for an edge not present in graph ',Software,closed,2020-04-06T09:45:51Z,2020-04-06 22:31:45+00:00,2020-04-10T02:25:12Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/3430
3436,b'Onnxruntime profiler  produces empty log in C# under certain circumstances',Software,closed,2020-04-06T19:43:53Z,2020-04-06 22:28:19+00:00,2020-05-19T02:47:53Z,0,42,https://api.github.com/repos/microsoft/onnxruntime/issues/3436
3440,b'Flatten Op with Negative Axis Not supported?',Software,closed,2020-04-07T03:13:16Z,2020-04-07 03:26:10+00:00,2020-04-07T03:26:10Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3440
3442,b'QuantizeLinear saturates to wrong range for int8',Software,closed,2020-04-07T04:05:54Z,2020-04-07 20:35:51+00:00,2020-04-08T05:40:18Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/3442
3443,"b'Definition of Im2col<T, StorageOrder::NHWC> does not take into account groups attribute'",Software,closed,2020-04-07T05:22:09Z,2020-07-03 02:59:40+00:00,2020-07-11T04:39:49Z,86,94,https://api.github.com/repos/microsoft/onnxruntime/issues/3443
3444,b'Example for Handling ONNXType other than ONNX_TYPE_TENSOR',Software,closed,2020-04-07T19:59:16Z,2020-04-08 17:04:23+00:00,2020-04-08T17:04:23Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3444
3451,"b'Excuse me, is there an example of GPU loading model and testing?'",Software,closed,2020-04-08T07:26:26Z,2020-04-08 08:44:48+00:00,2020-04-08T08:44:48Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3451
3452,b'the inference speed of onnx model is slower than the pytorch model',Software,closed,2020-04-08T09:25:09Z,2020-04-08 09:50:07+00:00,2020-07-11T04:39:51Z,0,93,https://api.github.com/repos/microsoft/onnxruntime/issues/3452
3453,b'Execution error running 3D convolutions with ONNX runtime',Software,closed,2020-04-08T12:02:57Z,2020-04-17 21:00:09+00:00,2020-05-15T02:23:13Z,9,36,https://api.github.com/repos/microsoft/onnxruntime/issues/3453
3464,b'How to get objects scores from output in Yolov3',Software,closed,2020-04-09T09:14:16Z,2020-04-13 00:21:26+00:00,2020-04-13T10:27:41Z,3,4,https://api.github.com/repos/microsoft/onnxruntime/issues/3464
3467,b'C# API Convert inference output to array',Software,closed,2020-04-09T15:40:05Z,2020-04-17 21:48:17+00:00,2020-07-11T04:39:57Z,8,92,https://api.github.com/repos/microsoft/onnxruntime/issues/3467
3478,b'QlinearConv  support for per channel and  int8?',Software,closed,2020-04-10T01:42:00Z,2020-04-13 21:57:59+00:00,2020-07-11T04:39:52Z,3,92,https://api.github.com/repos/microsoft/onnxruntime/issues/3478
3479,b'Cannot build the onnxruntime from source on TX2',Software,closed,2020-04-10T01:53:31Z,2020-04-10 02:36:24+00:00,2020-04-10T03:50:04Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3479
3502,b'ONNX produces different output in Python and C#',Software,closed,2020-04-12T12:43:05Z,2020-04-13 15:01:56+00:00,2020-04-13T15:01:56Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/3502
3505,b'SKlearn KNeighborsRegressor ONNX model run problem',Software,closed,2020-04-13T12:55:50Z,2020-04-13 18:23:59+00:00,2020-07-25T06:40:31Z,0,102,https://api.github.com/repos/microsoft/onnxruntime/issues/3505
3506,b'Error in Trying to Use TensorRT Backend with ONNX Model',Software,closed,2020-04-13T15:45:32Z,2020-04-13 18:23:16+00:00,2020-07-11T04:39:53Z,0,88,https://api.github.com/repos/microsoft/onnxruntime/issues/3506
3517,b'C++ API: Missing features in comparison to C API',Software,closed,2020-04-14T06:48:49Z,2020-04-14 07:20:19+00:00,2020-07-25T06:40:32Z,0,101,https://api.github.com/repos/microsoft/onnxruntime/issues/3517
3521,b'ONNX Runtime Build Issues on Win10 x64 Visual Studio 2019',Software,closed,2020-04-14T17:30:27Z,2020-04-28 17:39:40+00:00,2020-05-21T23:57:03Z,14,37,https://api.github.com/repos/microsoft/onnxruntime/issues/3521
3534,b'qmath.cc:24:6: error: unused parameter \xe2\x80\x98thread_pool\xe2\x80\x99 [-Werror=unused-parameter](void QGemmu8s8_s32)',Software,closed,2020-04-15T05:52:29Z,2020-04-15 06:39:25+00:00,2020-04-15T06:39:25Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3534
3537,b'Cuda Dependency still required in Windows even when running only the CPU mode',Software,closed,2020-04-15T19:03:51Z,2020-04-16 02:49:04+00:00,2020-04-16T02:49:04Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3537
3547,b'PRelu kernel is not supported in CUDAExecutionProvider',Software,closed,2020-04-16T02:29:50Z,2020-04-16 06:16:34+00:00,2020-07-25T06:40:34Z,0,100,https://api.github.com/repos/microsoft/onnxruntime/issues/3547
3548,b'MaxPooling is much slower than tf.keras when pool_size is large even with DNNL EP',Software,closed,2020-04-16T07:38:16Z,2020-04-16 07:38:45+00:00,2020-11-16T03:48:11Z,0,213,https://api.github.com/repos/microsoft/onnxruntime/issues/3548
3552,b'quantization modes(bert) not work on cpu',Software,closed,2020-04-16T15:46:35Z,2020-04-16 19:05:19+00:00,2020-07-11T01:41:01Z,0,85,https://api.github.com/repos/microsoft/onnxruntime/issues/3552
3553,b'C++ API',Software,closed,2020-04-16T16:12:48Z,2020-04-28 03:26:29+00:00,2020-07-11T04:40:00Z,11,85,https://api.github.com/repos/microsoft/onnxruntime/issues/3553
3556,b'Need a way to secure (encrypt) our models',Software,closed,2020-04-17T00:05:07Z,2020-04-17 05:40:35+00:00,2020-04-17T05:40:35Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3556
3562,b'Do you have an example of GPU?',Software,closed,2020-04-17T06:13:14Z,2020-04-17 06:35:43+00:00,2020-04-17T06:36:45Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3562
3563,b'[ONNXRuntimeError] : 1 : FAIL : This is an invalid model. Error: Duplicate definition of name ',Software,closed,2020-04-17T06:19:26Z,2020-04-17 21:47:46+00:00,2020-04-17T21:47:46Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3563
3565,b'Build ARM32v7 Error: /code/onnxruntime/onnxruntime/core/mlas/lib/quantize.cpp:259:28: error: \xe2\x80\x98nearbyintf\xe2\x80\x99 is not a member of \xe2\x80\x98std\xe2\x80\x99',Software,closed,2020-04-17T09:03:16Z,2020-04-17 16:35:48+00:00,2020-04-17T19:03:36Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3565
3566,b'how can i use Microsoft.ML.OnnxRuntime.Gpu for onnx gpu inferecne',Software,closed,2020-04-17T09:09:00Z,2020-04-21 04:56:01+00:00,2020-04-21T04:56:01Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/3566
3571,b'Static build fails to register ops',Software,closed,2020-04-17T16:32:32Z,2020-04-17 21:46:03+00:00,2020-04-17T21:46:03Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3571
3576,b'Non-File Constructor for Session',Software,closed,2020-04-17T21:41:06Z,2020-04-18 15:53:07+00:00,2020-04-18T15:53:07Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3576
3589,b'ONNX Runtime support for NVDLA\xef\xbc\x9f',Software,closed,2020-04-19T04:37:22Z,2020-05-04 22:52:46+00:00,2020-07-25T06:40:37Z,15,97,https://api.github.com/repos/microsoft/onnxruntime/issues/3589
3592,b'C++cuda api',Software,closed,2020-04-20T07:46:54Z,2020-04-21 01:56:02+00:00,2020-04-29T06:41:54Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/3592
3593,b'Torchvision Mask-RCNN CUDA support',Software,closed,2020-04-20T09:58:25Z,2020-04-28 03:27:25+00:00,2020-07-11T04:39:59Z,7,81,https://api.github.com/repos/microsoft/onnxruntime/issues/3593
3594,"b""'release' on Ort::Session""",Software,closed,2020-04-20T16:35:53Z,2020-04-22 05:17:17+00:00,2020-04-22T05:17:17Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/3594
3600,"b'E2E_example_model for quantization expects NHWC, not NCHW format?'",Software,closed,2020-04-20T21:56:47Z,2020-05-04 22:06:59+00:00,2020-07-11T01:41:00Z,14,81,https://api.github.com/repos/microsoft/onnxruntime/issues/3600
3605,b'Build ARM32v7 error: call of overloaded \xe2\x80\x98abs(__gnu_cxx::__alloc_traits<std::allocator<float> >::value_type)\xe2\x80\x99 is ambiguous',Software,closed,2020-04-21T01:13:12Z,2020-04-21 02:40:41+00:00,2020-05-05T09:08:15Z,0,14,https://api.github.com/repos/microsoft/onnxruntime/issues/3605
3611,b'Example of using DirectML with onnxruntime and D3D12 inputs and outputs',Software,closed,2020-04-21T09:50:15Z,2020-04-28 17:27:27+00:00,2020-07-11T01:40:59Z,7,80,https://api.github.com/repos/microsoft/onnxruntime/issues/3611
3614,b'onnxruntime-gpu-1.2.0 gives `ImportError`',Software,closed,2020-04-21T20:39:03Z,2020-04-21 20:42:19+00:00,2020-04-22T15:15:14Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3614
3624,b'Depreciated Dockerfile keywords',Software,closed,2020-04-22T01:36:43Z,2020-05-04 22:08:15+00:00,2020-07-25T06:40:42Z,12,94,https://api.github.com/repos/microsoft/onnxruntime/issues/3624
3625,b'Keras Mask RCNN: Fatal error: CropAndResize is not a registered function/op',Software,closed,2020-04-22T02:32:23Z,2020-04-24 06:47:47+00:00,2020-04-24T06:47:47Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/3625
3629,b'Yolo V3 with tensorrt provider inside Docker',Software,closed,2020-04-22T10:04:57Z,2020-07-03 02:59:32+00:00,2020-07-11T04:39:54Z,71,79,https://api.github.com/repos/microsoft/onnxruntime/issues/3629
3630,"b""build doesn't work on windows""",Software,closed,2020-04-22T10:49:33Z,2020-04-23 06:32:25+00:00,2020-04-27T11:09:25Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/3630
3631,b'Have you guys consider another scenario of upsample?',Software,closed,2020-04-22T12:46:16Z,2020-04-22 17:43:28+00:00,2020-05-04T22:10:01Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/3631
3632,b'OSError: libcudnn.so.7: cannot open shared object file: No such file or directory',Software,closed,2020-04-22T15:57:55Z,2020-07-03 02:59:30+00:00,2020-07-11T04:39:56Z,71,79,https://api.github.com/repos/microsoft/onnxruntime/issues/3632
3633,b'Is there a way to save engine like tensorrt?',Software,closed,2020-04-22T16:18:35Z,2020-04-22 16:18:46+00:00,2020-07-25T06:40:36Z,0,93,https://api.github.com/repos/microsoft/onnxruntime/issues/3633
3647,b'Problems selecting the cuda version when installing nuget',Software,closed,2020-04-23T04:45:10Z,2020-08-01 20:43:56+00:00,2020-08-08T23:16:58Z,100,107,https://api.github.com/repos/microsoft/onnxruntime/issues/3647
3654,b'the inference result of onnx model with onnxruntime is big different with the pytorch model ',Software,closed,2020-04-23T08:07:26Z,2020-04-23 08:21:52+00:00,2021-03-19T00:10:25Z,0,329,https://api.github.com/repos/microsoft/onnxruntime/issues/3654
3656,b'Create Ort::Value from const data pointer',Software,closed,2020-04-23T12:59:38Z,2020-04-23 18:25:23+00:00,2020-05-06T09:33:15Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/3656
3676,"b'qmin, qmax undeclared'",Software,closed,2020-04-24T00:34:27Z,2020-04-28 21:36:04+00:00,2020-04-28T21:36:04Z,4,4,https://api.github.com/repos/microsoft/onnxruntime/issues/3676
3685,b'Missing file version for onnxruntime.dll in C# nuget package',Software,closed,2020-04-24T11:32:12Z,2020-04-28 18:40:53+00:00,2020-04-28T18:53:21Z,4,4,https://api.github.com/repos/microsoft/onnxruntime/issues/3685
3686,"b'Onnxruntime fail to run Fasterrcnn_resnet50_fpn test ""Cannot split using values in \'split\' attribute""'",Software,open,2020-04-24T13:34:59Z,2020-05-04 21:53:00+00:00,,10,,https://api.github.com/repos/microsoft/onnxruntime/issues/3686
3687,b'PrepareForReduce in_dim != 0 was false -- unsure how to approach fixing this',Software,closed,2020-04-24T13:46:26Z,2020-05-04 21:49:17+00:00,2020-05-04T21:49:17Z,10,10,https://api.github.com/repos/microsoft/onnxruntime/issues/3687
3689,b'Error Creating a bool Tensor using C++ API',Software,closed,2020-04-24T16:07:23Z,2020-04-27 09:26:04+00:00,2020-04-27T09:26:04Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/3689
3704,b'How is bench.in built?',Software,closed,2020-04-25T22:20:35Z,2020-05-04 21:41:19+00:00,2020-05-04T21:49:53Z,8,8,https://api.github.com/repos/microsoft/onnxruntime/issues/3704
3706,b'ORT Training: Training mnist using provided sample?',Software,closed,2020-04-26T19:29:52Z,2020-04-26 19:36:31+00:00,2020-05-01T20:07:38Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/3706
3712,b'Dependency issues with Windows.AI.MachineLearning.pdb',Software,closed,2020-04-27T11:21:02Z,2020-04-27 18:43:27+00:00,2020-07-11T04:40:01Z,0,74,https://api.github.com/repos/microsoft/onnxruntime/issues/3712
3713,b'OnnxRuntime multithreading efficiency is poor',Software,closed,2020-04-27T15:58:47Z,2020-04-28 01:59:20+00:00,2020-12-24T11:39:32Z,0,240,https://api.github.com/repos/microsoft/onnxruntime/issues/3713
3735,b'Loading float16 model fails',Software,closed,2020-04-28T14:49:56Z,2020-05-04 21:23:10+00:00,2020-05-11T02:08:38Z,6,12,https://api.github.com/repos/microsoft/onnxruntime/issues/3735
3736,b'Trouble running model with float64 input',Software,closed,2020-04-28T14:54:52Z,2020-04-29 07:13:34+00:00,2020-05-04T20:40:01Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/3736
3737,b'Build problem with NNAPI Execution Provider ',Software,closed,2020-04-28T17:04:40Z,2020-05-04 20:38:24+00:00,2020-07-15T03:51:41Z,6,77,https://api.github.com/repos/microsoft/onnxruntime/issues/3737
3740,"b""Resize operator runtime exception when using torch.nn.functional.interpolate mode='trilinear'""",Software,closed,2020-04-28T20:39:05Z,2020-05-04 20:35:07+00:00,2020-07-25T06:40:39Z,5,87,https://api.github.com/repos/microsoft/onnxruntime/issues/3740
3746,b'[C# API] InferenceSession throws CUDA exception when used in a different thread',Software,closed,2020-04-29T08:44:52Z,2020-05-04 20:31:52+00:00,2020-07-11T01:41:03Z,5,72,https://api.github.com/repos/microsoft/onnxruntime/issues/3746
3755,b'Error creating onnxruntime session',Software,closed,2020-04-29T21:44:11Z,2020-05-04 20:30:25+00:00,2020-07-25T08:41:02Z,4,86,https://api.github.com/repos/microsoft/onnxruntime/issues/3755
3763,b'Implement OnnxRuntime in MagicLeap using Unity',Software,closed,2020-04-30T06:11:25Z,2020-05-04 20:28:47+00:00,2020-07-21T12:20:57Z,4,82,https://api.github.com/repos/microsoft/onnxruntime/issues/3763
3764,"b""ORT throws GEMM error, but there's no GEMM operator in  model""",Software,closed,2020-04-30T11:34:32Z,2020-04-30 20:34:42+00:00,2020-05-01T21:36:22Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/3764
3787,b'Onnxruntime not running on GPU in python environment',Software,closed,2020-05-01T10:27:45Z,2020-05-04 20:28:27+00:00,2020-05-04T20:28:27Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/3787
3794,b'Loop outputs are incorrect when TRIP_COUNT is the input for the subgraph',Software,closed,2020-05-01T23:10:57Z,2020-05-04 20:27:49+00:00,2020-09-08T18:16:19Z,2,129,https://api.github.com/repos/microsoft/onnxruntime/issues/3794
3802,b'ONNX runtime takes much time and memory to load model',Software,closed,2020-05-02T17:12:33Z,2020-05-04 20:27:12+00:00,2020-07-13T02:15:39Z,2,71,https://api.github.com/repos/microsoft/onnxruntime/issues/3802
3804,b'FixedBufferOnnxValue',Software,closed,2020-05-03T06:49:13Z,2020-05-04 20:26:16+00:00,2020-05-04T20:26:16Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/3804
3808,b'value info is not updating',Software,closed,2020-05-04T16:27:22Z,2020-05-04 20:25:52+00:00,2020-09-20T04:40:32Z,0,138,https://api.github.com/repos/microsoft/onnxruntime/issues/3808
3810,b'Install fail in python3.8 (onnx has same error in python3.8 and does not support python3.8)',Software,closed,2020-05-04T21:08:11Z,2020-05-04 21:09:05+00:00,2020-05-09T12:21:59Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/3810
3820,b'QuantizeLinear fails without optional zero point input',Software,closed,2020-05-05T11:24:11Z,2020-05-06 02:00:01+00:00,2020-07-17T08:36:37Z,0,72,https://api.github.com/repos/microsoft/onnxruntime/issues/3820
3821,"b'Error in TensorRT inference: ""One or more weights outside the range of INT32 was clamped""'",Software,closed,2020-05-05T13:04:38Z,2020-05-06 01:59:48+00:00,2020-09-20T20:40:08Z,0,138,https://api.github.com/repos/microsoft/onnxruntime/issues/3821
3822,b'Inference session output with null _nativeMemoryManager (C#)',Software,closed,2020-05-05T14:58:22Z,2020-05-06 02:00:45+00:00,2020-05-14T06:32:19Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/3822
3828,b'cuDNN error when running multi-thread evaluation',Software,closed,2020-05-05T20:10:52Z,2020-05-05 22:22:12+00:00,2020-05-06T07:05:16Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3828
3843,b'Support pathlib.Path when paths are required in python module',Software,open,2020-05-06T16:46:02Z,2020-05-06 19:48:25+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/3843
3862,b'onnxruntime model slower on gpu than pytorch implementation',Software,closed,2020-05-07T15:52:00Z,2020-05-07 20:24:05+00:00,2020-08-01T08:44:03Z,0,85,https://api.github.com/repos/microsoft/onnxruntime/issues/3862
3864,b'I am new to onnx. ',Software,closed,2020-05-07T17:39:44Z,2020-05-07 17:55:07+00:00,2020-05-07T17:55:07Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3864
3865,"b'I am looking for something similar to doing what tensorflow_session.get_tensor_by_name(""intermediate_node"").shape() does'",Software,closed,2020-05-07T17:40:06Z,2020-05-07 17:40:21+00:00,2020-05-12T01:06:40Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/3865
3873,b'the big different of outputs between the .pth model and the according onnx model with the BatchNorm2d layer',Software,open,2020-05-08T03:33:57Z,2020-05-21 06:34:01+00:00,,13,,https://api.github.com/repos/microsoft/onnxruntime/issues/3873
3878,b'[ONNXRuntimeError] Fatal error: adaptive_max_pool2d is not a registered function/op',Software,closed,2020-05-08T17:44:12Z,2020-05-08 18:27:06+00:00,2020-05-08T18:27:05Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3878
3879,b'Simplify the C++ samples',Documentation,closed,2020-05-08T20:38:52Z,2020-05-09 00:48:30+00:00,2020-07-09T06:17:51Z,0,61,https://api.github.com/repos/microsoft/onnxruntime/issues/3879
3887,b'Inference for a intermedia tensor. (Python API)',Documentation,closed,2020-05-09T06:13:56Z,2020-05-10 07:25:06+00:00,2020-05-10T07:25:06Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/3887
3889,b'Slow compilation of dockerfiles/Dockerfile.cuda',Software,closed,2020-05-10T16:05:59Z,2020-05-13 20:36:12+00:00,2020-08-02T05:43:57Z,3,83,https://api.github.com/repos/microsoft/onnxruntime/issues/3889
3890,"b'InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Unexpected input data type. Actual: (N11onnxruntime17PrimitiveDataTypeINS_9MLFloat16EEE) , expected: (N11onnxruntime17PrimitiveDataTypeIfEE)'",Software,closed,2020-05-10T19:54:07Z,2020-05-11 06:41:01+00:00,2020-05-12T16:56:33Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/3890
3891,b'dockerfiles/Dockerfile.nuphar',Software,closed,2020-05-11T00:37:35Z,2020-05-13 20:35:58+00:00,2020-08-02T05:43:58Z,2,83,https://api.github.com/repos/microsoft/onnxruntime/issues/3891
3894,b'how could i can run batchsize >1 in test',Software,closed,2020-05-11T10:53:50Z,2020-05-12 09:58:22+00:00,2020-05-12T09:58:22Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3894
3895,b'dockerfiles',Software,closed,2020-05-11T11:55:46Z,2020-05-13 20:35:43+00:00,2020-09-20T04:40:34Z,2,131,https://api.github.com/repos/microsoft/onnxruntime/issues/3895
3897,b'Step to step guid to build onnxruntime on win32',Software,closed,2020-05-11T14:10:23Z,2020-07-11 01:40:29+00:00,2020-07-17T11:37:01Z,60,66,https://api.github.com/repos/microsoft/onnxruntime/issues/3897
3898,b'Privacy / telemetry policy clarification',Software,closed,2020-05-11T15:10:14Z,2020-05-13 20:34:58+00:00,2020-05-15T18:05:07Z,2,4,https://api.github.com/repos/microsoft/onnxruntime/issues/3898
3900,b'Wrong result with `If` node',Software,closed,2020-05-11T15:36:35Z,2020-05-14 19:48:19+00:00,2020-05-14T19:50:10Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/3900
3913,b'Error when trying to build ONNXRuntime in Jetson Nano',Software,closed,2020-05-12T07:59:22Z,2020-08-08 14:16:52+00:00,2020-08-15T20:00:19Z,88,95,https://api.github.com/repos/microsoft/onnxruntime/issues/3913
3922,b'onnxrt fails at no-op squeeze',Software,closed,2020-05-13T06:52:00Z,2020-05-13 19:58:51+00:00,2020-05-13T19:58:50Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3922
3924,b'How to build custom nuget package on linux',Software,closed,2020-05-13T11:23:41Z,2020-05-13 18:27:02+00:00,2020-07-18T06:57:46Z,0,65,https://api.github.com/repos/microsoft/onnxruntime/issues/3924
3940,b'Symbolic dimensions are not replaced with 1',Software,closed,2020-05-14T14:27:14Z,2020-05-15 22:11:25+00:00,2020-05-18T06:51:10Z,1,3,https://api.github.com/repos/microsoft/onnxruntime/issues/3940
3943,"b""import onnxruntime Error:cannot import name 'get_all_providers'""",Software,closed,2020-05-14T16:56:37Z,2020-05-15 02:42:17+00:00,2020-06-03T07:12:25Z,0,19,https://api.github.com/repos/microsoft/onnxruntime/issues/3943
3958,b'Registering Custom via python interface',Software,closed,2020-05-15T18:39:04Z,2020-05-16 07:40:22+00:00,2020-08-28T20:24:31Z,0,105,https://api.github.com/repos/microsoft/onnxruntime/issues/3958
3973,b'Expected storage order for Ort tensors',Software,closed,2020-05-18T14:49:50Z,2020-05-23 08:29:20+00:00,2020-10-11T11:41:32Z,4,145,https://api.github.com/repos/microsoft/onnxruntime/issues/3973
3977,b'INVALID_GRAPH after running `optimize_model`',Software,closed,2020-05-18T19:33:22Z,2020-05-19 18:39:17+00:00,2020-06-18T06:53:51Z,0,30,https://api.github.com/repos/microsoft/onnxruntime/issues/3977
3984,b'Precompiled zip-binaries  1.3',Software,closed,2020-05-19T09:07:32Z,2020-05-19 10:27:07+00:00,2020-05-19T10:27:07Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/3984
3986,b'Help regarding input data format in onnx runtime in c++.',Software,closed,2020-05-19T14:09:12Z,2020-05-20 00:18:21+00:00,2020-06-18T14:05:10Z,0,29,https://api.github.com/repos/microsoft/onnxruntime/issues/3986
3987,b'Yolov3 quantization model is slower\xef\xbc\x9f',Software,closed,2020-05-19T14:53:18Z,2020-05-19 18:24:53+00:00,2020-07-27T18:50:11Z,0,69,https://api.github.com/repos/microsoft/onnxruntime/issues/3987
3991,b'TensorRT Execution Provider - Issue with Tinny yolo v2 and v3 models',Software,closed,2020-05-19T17:31:51Z,2020-05-19 18:37:05+00:00,2020-11-16T03:48:09Z,0,180,https://api.github.com/repos/microsoft/onnxruntime/issues/3991
3994,b'Python has stopped working message pops up when using onnxruntime-gpu',Software,closed,2020-05-19T18:46:28Z,2020-07-20 04:49:11+00:00,2020-07-27T04:50:14Z,61,68,https://api.github.com/repos/microsoft/onnxruntime/issues/3994
4002,b'orttraining: Is there or will there be a C API? (for C# etc.)',Software,open,2020-05-20T08:33:45Z,2020-05-20 16:48:44+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/4002
4005,b'python and C++ libs use OpenVino? ',Software,closed,2020-05-20T10:53:51Z,2020-05-20 11:03:59+00:00,2020-08-15T20:00:21Z,0,87,https://api.github.com/repos/microsoft/onnxruntime/issues/4005
4006,b'Java native loader failing on Mac OSX',Software,closed,2020-05-20T13:37:04Z,2020-05-20 13:57:11+00:00,2020-05-20T13:57:11Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4006
4007,b'ONNX runtime nuget package built in release mode',Software,closed,2020-05-20T15:00:02Z,2020-05-20 19:49:18+00:00,2020-07-27T12:50:12Z,0,67,https://api.github.com/repos/microsoft/onnxruntime/issues/4007
4008,b'CUDA error executing cudaMemcpy for large batch size',Software,closed,2020-05-20T21:20:59Z,2020-07-26 09:31:00+00:00,2020-08-02T17:08:46Z,66,73,https://api.github.com/repos/microsoft/onnxruntime/issues/4008
4009,b'NuGet package onnxruntime.dll error',Software,closed,2020-05-21T00:11:40Z,2020-05-21 01:19:04+00:00,2021-03-19T00:27:03Z,0,302,https://api.github.com/repos/microsoft/onnxruntime/issues/4009
4014,b'The output is different with the same input on CUDA',Software,closed,2020-05-21T10:13:03Z,2020-05-23 08:33:44+00:00,2020-06-29T10:10:02Z,1,38,https://api.github.com/repos/microsoft/onnxruntime/issues/4014
4015,b'Onnx training in c#',Software,closed,2020-05-21T19:50:33Z,2020-05-21 23:09:00+00:00,2020-08-15T20:00:25Z,0,86,https://api.github.com/repos/microsoft/onnxruntime/issues/4015
4018,b'Significant loading time with TensorRT compared to not',Software,closed,2020-05-22T00:21:29Z,2020-05-23 08:28:55+00:00,2020-09-20T20:40:09Z,1,121,https://api.github.com/repos/microsoft/onnxruntime/issues/4018
4023,b'Reduce libraries disk footprint on mobile device',Software,closed,2020-05-25T07:40:11Z,2020-05-25 21:59:24+00:00,2020-07-23T11:38:14Z,0,59,https://api.github.com/repos/microsoft/onnxruntime/issues/4023
4024,b'MaskRCNN model fails on GPU if there are no predictions',Software,closed,2020-05-25T12:31:09Z,2020-07-26 05:31:04+00:00,2020-08-02T05:43:56Z,61,68,https://api.github.com/repos/microsoft/onnxruntime/issues/4024
4026,b'Possibility to change protobuf version',Software,closed,2020-05-25T17:31:32Z,2020-05-25 22:01:29+00:00,2020-05-25T22:01:29Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4026
4027,b'Convert Python build script to CMake',Software,closed,2020-05-25T18:41:59Z,2020-06-02 18:37:47+00:00,2020-06-22T23:57:49Z,7,28,https://api.github.com/repos/microsoft/onnxruntime/issues/4027
4028,"b'when I install onnxruntime in a virtual  windows system, there is always a ""import error""   '",Software,closed,2020-05-26T02:43:05Z,2020-05-26 11:17:43+00:00,2020-05-26T11:17:43Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4028
4029,b'onnxruntime openvino docker inference very slow',Software,closed,2020-05-26T06:15:36Z,2020-05-26 14:20:57+00:00,2020-05-31T14:46:35Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/4029
4032,b'DequantizeLinear crash in Compute',Software,closed,2020-05-26T08:56:39Z,2020-05-28 00:11:57+00:00,2020-06-04T03:21:42Z,1,8,https://api.github.com/repos/microsoft/onnxruntime/issues/4032
4033,b'Initializer appears in graph inputs and will not be treated as constant value/weight.',Software,closed,2020-05-26T10:08:15Z,2020-05-26 10:19:06+00:00,2020-05-26T10:19:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4033
4034,b'ONNX RNN op activations attribute not supported.',Software,closed,2020-05-26T12:15:25Z,2020-05-27 18:43:09+00:00,2020-05-27T22:11:48Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/4034
4035,b'Not able to install onnxruntime_gpu on windows server 2019',Software,closed,2020-05-26T15:10:23Z,2020-05-27 06:40:55+00:00,2020-05-27T06:40:55Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4035
4036,b'Error in c_cxx samples: error: \xe2\x80\x98OrtGetApi\xe2\x80\x99 was not declared in this scope',Software,closed,2020-05-26T15:25:10Z,2020-05-27 06:07:50+00:00,2020-05-27T06:07:50Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4036
4037,b'QLinearConv support in any of the providers',Software,closed,2020-05-26T15:33:39Z,2020-05-26 23:31:37+00:00,2020-08-02T01:43:54Z,0,67,https://api.github.com/repos/microsoft/onnxruntime/issues/4037
4039,b'The issue on Cast elimination in fusion',Software,closed,2020-05-26T16:32:06Z,2020-05-27 00:12:07+00:00,2020-08-02T22:08:45Z,0,68,https://api.github.com/repos/microsoft/onnxruntime/issues/4039
4048,b'Building a dynamic library without dependency',Software,closed,2020-05-27T03:08:48Z,2020-05-28 17:15:09+00:00,2020-10-11T11:41:35Z,1,137,https://api.github.com/repos/microsoft/onnxruntime/issues/4048
4050,b'Usage example of CreateMap API in C++. ',Software,closed,2020-05-27T07:56:36Z,2020-06-18 14:08:47+00:00,2020-06-18T14:08:47Z,22,22,https://api.github.com/repos/microsoft/onnxruntime/issues/4050
4051,"b' tensor_info.GetShape() gives [-1, 1 ] as shape.'",Software,closed,2020-05-27T09:15:25Z,2020-06-18 14:07:34+00:00,2020-06-18T14:07:34Z,22,22,https://api.github.com/repos/microsoft/onnxruntime/issues/4051
4053,b'DropoutGrad input size error',Software,closed,2020-05-27T17:53:56Z,2020-05-27 17:53:57+00:00,2020-06-04T22:00:03Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/4053
4054,b'onnxruntime.capi_pybind_state on windows exe',Software,closed,2020-05-27T18:15:05Z,2020-05-28 17:06:32+00:00,2020-05-28T17:06:32Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4054
4060,b'C and C++ API examples should not be located under csharp dir',Documentation,closed,2020-05-28T00:06:59Z,2020-05-28 00:06:59+00:00,2020-06-02T20:25:03Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/4060
4070,b'Managed API: NativeMethods.OrtSetIntraOpNumThreads Crashes Application',Documentation,closed,2020-05-28T08:50:45Z,2020-05-29 01:20:54+00:00,2020-06-01T22:28:07Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/4070
4071,"b'INVALID_ARGUMENT : Non-zero status code returned while running Conv node. Invalid input shape: {0,0} after successful convertation'",Documentation,closed,2020-05-28T10:53:23Z,2020-07-27 12:50:09+00:00,2020-08-08T02:57:28Z,60,71,https://api.github.com/repos/microsoft/onnxruntime/issues/4071
4072,b'dead link in /README.md',Documentation,closed,2020-05-28T13:30:49Z,2020-05-28 13:31:51+00:00,2020-06-01T22:25:28Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/4072
4077,b'Not able to build ONNX Runtime Server image',Software,closed,2020-05-28T22:41:59Z,2020-05-29 00:47:07+00:00,2020-08-09T01:16:54Z,0,72,https://api.github.com/repos/microsoft/onnxruntime/issues/4077
4081,"b""AttributeError: 'InferenceSession' object has no attribute 'get_providers'""",Software,closed,2020-05-29T09:40:28Z,2020-05-31 18:33:02+00:00,2020-06-01T14:46:18Z,2,3,https://api.github.com/repos/microsoft/onnxruntime/issues/4081
4082,b'rel-1.3.0 Eigen revision is invalid',Software,closed,2020-05-29T13:49:23Z,2020-05-29 17:36:50+00:00,2020-05-29T17:36:50Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4082
4086,b'ConvTranspose auto_pad=SAME_UPPER/SAME_LOWER not working properly',Software,closed,2020-05-29T20:37:01Z,2020-06-05 04:51:17+00:00,2020-10-11T11:41:41Z,6,134,https://api.github.com/repos/microsoft/onnxruntime/issues/4086
4093,b'Memory leak and thread pools not closing',Software,closed,2020-05-30T17:28:37Z,2020-06-01 07:21:07+00:00,2020-06-04T17:04:16Z,1,4,https://api.github.com/repos/microsoft/onnxruntime/issues/4093
4094,b'Improve C++ API with support for modern C++ standards',Software,closed,2020-05-31T20:28:49Z,2020-05-31 20:29:28+00:00,2020-10-11T11:41:36Z,0,132,https://api.github.com/repos/microsoft/onnxruntime/issues/4094
4096,b'directml provider and yolov3',Software,closed,2020-06-01T07:30:13Z,2020-06-02 18:32:55+00:00,2020-09-05T19:32:40Z,1,96,https://api.github.com/repos/microsoft/onnxruntime/issues/4096
4098,b'Build with TensorRT : onnxruntime_test_all fails',Software,closed,2020-06-01T16:25:25Z,2020-06-01 20:43:15+00:00,2020-06-04T03:19:59Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/4098
4103,b'Crash with bus error on Android (arm-v7a) when creating InferenceSession with SSD model',Software,closed,2020-06-01T21:15:14Z,2020-08-03 10:08:45+00:00,2020-08-15T20:00:26Z,62,74,https://api.github.com/repos/microsoft/onnxruntime/issues/4103
4110,b'Graph optimization break correctness',Software,closed,2020-06-02T09:29:29Z,2020-06-02 09:31:37+00:00,2020-06-13T22:09:37Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/4110
521,b'Dangerous naming',Software,closed,2019-02-26T23:01:16Z,2019-02-26 23:38:50+00:00,2019-03-09T08:23:06Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/521
528,b'BatchNorm and InstanceNormalization tests fail with CUDA 10.1/CUDNN 7.5',Software,closed,2019-02-28T18:44:58Z,2019-02-28 19:16:15+00:00,2019-03-07T21:05:27Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/528
530,b'Support linking with full MKL instead of MKLML',Software,closed,2019-02-28T22:04:42Z,2019-03-05 23:19:58+00:00,2019-03-05T23:19:58Z,5,5,https://api.github.com/repos/microsoft/onnxruntime/issues/530
540,b'Integrate with the CoreFX Tensor proposal',Software,closed,2019-03-04T23:35:43Z,2019-03-04 23:36:13+00:00,2019-04-22T23:58:18Z,0,49,https://api.github.com/repos/microsoft/onnxruntime/issues/540
543,b'Import onnxruntime failed in windows docker image without CUDA',Software,closed,2019-03-05T03:09:28Z,2019-03-05 18:53:07+00:00,2019-04-01T18:52:36Z,0,27,https://api.github.com/repos/microsoft/onnxruntime/issues/543
552,"b'""Kernel died, restarting"" everytime the session.run([], {input:value}) function from onnx runtime is called'",Software,closed,2019-03-06T10:28:30Z,2019-03-08 05:12:16+00:00,2019-03-08T05:12:16Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/552
553,b'Make numpy version optional not hardcoded',Software,closed,2019-03-06T10:38:58Z,2019-03-06 20:37:09+00:00,2019-03-08T04:55:13Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/553
577,b'C api Package Url invalid. (https://aka.ms/onnxruntime-release)',Software,closed,2019-03-08T01:53:42Z,2019-03-08 03:24:23+00:00,2019-03-08T03:24:23Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/577
581,b'Error when Loading with C#',Software,closed,2019-03-08T19:51:04Z,2019-03-08 23:18:21+00:00,2019-03-09T08:20:39Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/581
589,b'Download Link for C Version Files broken',Software,closed,2019-03-10T10:05:37Z,2019-03-10 12:01:25+00:00,2019-03-10T12:01:25Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/589
590,b'x86 Python Wheel shows error message',Software,closed,2019-03-10T12:00:32Z,2019-03-11 07:48:37+00:00,2020-03-10T23:07:30Z,0,366,https://api.github.com/repos/microsoft/onnxruntime/issues/590
591,b'Slower than caffe in GPU mode.',Software,closed,2019-03-11T17:56:47Z,2019-03-13 19:19:56+00:00,2019-04-22T23:43:41Z,2,42,https://api.github.com/repos/microsoft/onnxruntime/issues/591
599,b'Support GraphTransformer in C API',Software,closed,2019-03-12T01:29:57Z,2019-03-13 19:31:06+00:00,2019-04-05T00:47:19Z,1,23,https://api.github.com/repos/microsoft/onnxruntime/issues/599
612,b'TfidfVectorizer fails with empty strings',Software,closed,2019-03-13T15:33:45Z,2019-03-13 16:54:09+00:00,2019-04-09T17:55:32Z,0,27,https://api.github.com/repos/microsoft/onnxruntime/issues/612
613,"b""Installation on Raspbian doesn't work""",Software,closed,2019-03-13T16:21:48Z,2019-03-13 18:42:24+00:00,2019-03-13T18:42:24Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/613
4118,b'Build from source fails when building horovod',Software,closed,2020-06-03T03:35:59Z,2020-06-08 19:39:06+00:00,2020-09-20T20:40:13Z,5,109,https://api.github.com/repos/microsoft/onnxruntime/issues/4118
4122,b'TensorRT Inference gives different result',Software,closed,2020-06-03T14:18:13Z,2020-06-05 04:48:54+00:00,2020-09-20T20:40:11Z,1,109,https://api.github.com/repos/microsoft/onnxruntime/issues/4122
4130,b'Predictions do not match for RandomForestRegressor',Software,closed,2020-06-04T06:09:11Z,2020-06-04 08:13:57+00:00,2020-11-16T03:48:02Z,0,164,https://api.github.com/repos/microsoft/onnxruntime/issues/4130
4131,b'More constructor options for Ort::Session',Software,closed,2020-06-04T16:11:08Z,2020-06-05 04:48:36+00:00,2020-06-12T19:37:40Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/4131
4132,"b'Facing ""ImportError: cannot import name \'get_all_providers\''",Software,closed,2020-06-04T16:20:00Z,2020-06-05 11:14:02+00:00,2020-08-15T20:00:24Z,0,72,https://api.github.com/repos/microsoft/onnxruntime/issues/4132
4134,b'Add GetAvailableProviders to the C API',Software,closed,2020-06-04T22:10:44Z,2020-06-05 04:49:54+00:00,2020-06-23T10:58:42Z,0,18,https://api.github.com/repos/microsoft/onnxruntime/issues/4134
4136,b'x86 onnxruntime_perf_text.exe fails to load vgg16 with bad allocation',Software,closed,2020-06-04T23:35:32Z,2020-06-05 01:25:33+00:00,2020-06-05T01:25:32Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4136
4138,b'Can we please expose DisposableList as public',Software,closed,2020-06-05T01:11:20Z,2020-06-05 04:50:55+00:00,2020-12-24T11:39:33Z,0,202,https://api.github.com/repos/microsoft/onnxruntime/issues/4138
4139,b'Python issue to use the right Execution Provider for a specific model',Software,closed,2020-06-05T08:13:16Z,2020-06-09 07:20:13+00:00,2020-08-15T20:00:19Z,3,71,https://api.github.com/repos/microsoft/onnxruntime/issues/4139
4140,b'How to get the current provider used in C++ inference stage?',Software,closed,2020-06-05T10:30:50Z,2020-06-08 03:28:27+00:00,2020-06-22T10:20:23Z,2,16,https://api.github.com/repos/microsoft/onnxruntime/issues/4140
4141,b'Build Faillure on Jetson Nano:',Software,closed,2020-06-05T14:14:35Z,2020-06-06 12:58:55+00:00,2020-06-06T12:58:55Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4141
4147,b'cumsum and topk float16 support',Software,closed,2020-06-05T23:38:25Z,2020-06-06 03:38:45+00:00,2021-03-04T00:54:57Z,0,271,https://api.github.com/repos/microsoft/onnxruntime/issues/4147
4152,b'Build failure on redundant move statement',Software,closed,2020-06-06T05:18:52Z,2020-06-08 19:24:01+00:00,2020-06-10T23:02:54Z,2,4,https://api.github.com/repos/microsoft/onnxruntime/issues/4152
4154,b'How to install cuDNN on Jetson Nano?',Software,closed,2020-06-06T13:20:32Z,2020-06-09 06:30:04+00:00,2020-06-09T06:30:04Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/4154
4158,"b'linux build from source error:  no instance of overloaded function ""atomicAdd"" matches the argument list'",Software,closed,2020-06-08T10:03:46Z,2020-06-08 19:23:30+00:00,2020-06-09T10:13:28Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/4158
4162,b'dlpack support for ONNX runtime',Software,closed,2020-06-08T19:17:09Z,2020-06-08 19:21:54+00:00,2021-11-08T16:11:15Z,0,517,https://api.github.com/repos/microsoft/onnxruntime/issues/4162
4169,b'Not able to run onnx model',Software,closed,2020-06-09T10:52:51Z,2020-06-09 18:07:55+00:00,2020-08-23T01:44:51Z,0,74,https://api.github.com/repos/microsoft/onnxruntime/issues/4169
4175,b'Support multiple learning rates for training',Software,closed,2020-06-09T17:22:07Z,2020-06-09 17:22:34+00:00,2020-08-15T20:00:17Z,0,67,https://api.github.com/repos/microsoft/onnxruntime/issues/4175
4176,b'[WIP] New PyTorch frontend API',Software,closed,2020-06-09T17:27:54Z,2020-06-09 17:27:54+00:00,2020-09-09T16:46:07Z,0,91,https://api.github.com/repos/microsoft/onnxruntime/issues/4176
4184,b'onnxruntime-gpu-tensorrt consumes too much memory',Software,closed,2020-06-10T05:45:38Z,2020-09-14 00:20:29+00:00,2020-09-21T04:33:30Z,95,102,https://api.github.com/repos/microsoft/onnxruntime/issues/4184
4187,b'Backward LSTM results mismatch between TF and ONNXRuntime',Software,closed,2020-06-10T06:32:11Z,2020-06-24 06:38:20+00:00,2020-07-16T20:51:19Z,14,36,https://api.github.com/repos/microsoft/onnxruntime/issues/4187
4189,b'Build on RaspberryPi4b failed: requested alignment 16 is larger than 8',Software,closed,2020-06-10T08:08:50Z,2020-06-11 09:25:26+00:00,2020-06-11T09:25:26Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/4189
4191,b'Is there a programmatic way to get max supported ONNX version and opset',Software,closed,2020-06-10T16:53:31Z,2020-06-10 17:56:46+00:00,2020-12-24T11:39:34Z,0,196,https://api.github.com/repos/microsoft/onnxruntime/issues/4191
4192,b'When will the new experimental API for customOps be stable?',Software,closed,2020-06-10T19:19:09Z,2020-06-10 20:22:11+00:00,2020-06-10T22:07:46Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4192
4196,"b""ImportError: cannot import name 'get_all_providers' from 'onnxruntime.capi._pybind_state' """,Software,closed,2020-06-10T22:34:34Z,2020-06-11 06:33:50+00:00,2020-06-12T20:54:00Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/4196
4199,b'Error when build with --use_armnn: could not find armnn/armnn.hpp',Software,closed,2020-06-11T06:30:20Z,2020-06-14 08:47:27+00:00,2020-08-30T23:46:39Z,3,80,https://api.github.com/repos/microsoft/onnxruntime/issues/4199
4200,"b""ONNX Runtime only *guarantees* support for models stamped with opset version 7 or above for opset domain 'ai.onnx'. Please upgrade your model to opset 7 or higher.""",Software,closed,2020-06-11T07:01:57Z,2020-06-12 19:42:25+00:00,2020-06-12T19:42:25Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/4200
4201,b'StringNormalizer+Tokenizer misses n-grams',Software,open,2020-06-11T10:03:13Z,2020-06-11 10:03:29+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/4201
4202,b'pytorch to onnx discrepancies',Software,closed,2020-06-11T12:58:54Z,2020-06-12 02:13:36+00:00,2020-06-14T09:16:36Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/4202
4203,b'Citing ONNX Runtime in an academic publication',Software,closed,2020-06-11T13:47:27Z,2020-06-22 20:35:03+00:00,2020-08-29T20:04:37Z,11,79,https://api.github.com/repos/microsoft/onnxruntime/issues/4203
4209,b'Bug in onnxruntime\\onnxruntime\\core\\providers\\acl\\nn\\conv.cc?',Software,closed,2020-06-12T00:48:07Z,2020-06-13 07:24:14+00:00,2020-06-18T14:54:15Z,1,6,https://api.github.com/repos/microsoft/onnxruntime/issues/4209
4211,b'Operator Greater is not available for double but Less is',Software,closed,2020-06-12T08:54:01Z,2020-06-12 18:10:09+00:00,2020-06-12T18:10:09Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4211
4223,b'How do I disable onnxruntime logging in python?',Software,closed,2020-06-13T06:32:19Z,2020-06-13 16:18:14+00:00,2020-06-13T16:18:14Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4223
4225,b'support running inference on CPU machine with lib built on GPU machine?',Software,closed,2020-06-13T15:00:18Z,2020-06-15 18:22:41+00:00,2020-06-22T08:17:44Z,2,8,https://api.github.com/repos/microsoft/onnxruntime/issues/4225
4226,b'Build on Raspberry Pi4 failed ',Software,closed,2020-06-13T15:39:07Z,2020-08-15 20:00:01+00:00,2021-02-23T02:41:58Z,63,254,https://api.github.com/repos/microsoft/onnxruntime/issues/4226
4234,"b""Building from source fails due to undefined reference to 'libiconv'""",Software,closed,2020-06-15T09:18:44Z,2020-06-16 18:21:19+00:00,2020-09-20T20:40:12Z,1,97,https://api.github.com/repos/microsoft/onnxruntime/issues/4234
4235,b'How to build C++ api for Nvidia Jetson TX2',Software,closed,2020-06-15T13:01:24Z,2020-07-15 19:58:24+00:00,2020-07-16T01:23:24Z,30,30,https://api.github.com/repos/microsoft/onnxruntime/issues/4235
4244,"b""error: package directory 'onnxruntime/backend' does not exist""",Software,closed,2020-06-16T07:20:08Z,2020-07-17 05:25:42+00:00,2021-03-19T00:27:02Z,30,275,https://api.github.com/repos/microsoft/onnxruntime/issues/4244
4245,b'running a model cause bus error',Software,closed,2020-06-16T08:48:35Z,2020-06-16 08:48:56+00:00,2020-06-17T05:46:46Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4245
4249,b'Samples for ORTTraining lack instructions and data',Software,closed,2020-06-16T17:29:34Z,2020-06-16 18:07:17+00:00,2020-09-11T04:15:52Z,0,86,https://api.github.com/repos/microsoft/onnxruntime/issues/4249
4251,b'Locking seems to be taking the share of the time',Software,closed,2020-06-16T18:11:51Z,2020-06-16 21:22:43+00:00,2020-12-24T11:39:36Z,0,190,https://api.github.com/repos/microsoft/onnxruntime/issues/4251
4252,b'Unable to compile UWP project using .NET native with OnnxRuntime reference',Software,closed,2020-06-16T18:14:25Z,2020-07-15 19:50:12+00:00,2020-12-24T11:39:29Z,29,190,https://api.github.com/repos/microsoft/onnxruntime/issues/4252
4253,b'trainning_runner spins up hundreds of threads',Software,closed,2020-06-16T18:41:53Z,2020-06-16 18:50:36+00:00,2020-10-05T17:42:10Z,0,110,https://api.github.com/repos/microsoft/onnxruntime/issues/4253
4258,b'Cannot build from source',Software,closed,2020-06-17T02:10:37Z,2020-06-17 02:10:37+00:00,2020-06-22T09:29:23Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/4258
4259,b'How to reduce the memory usage by CUDA?',Software,closed,2020-06-17T02:15:30Z,2020-08-22 19:17:23+00:00,2020-08-29T20:04:36Z,66,73,https://api.github.com/repos/microsoft/onnxruntime/issues/4259
4262,b'OpenVINO EP inferencing issue for some combinations of model/platforms/device',Software,open,2020-06-17T17:31:52Z,2020-06-18 15:40:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/4262
4264,b'TVM HOME?',Software,closed,2020-06-17T18:48:03Z,2020-06-17 23:18:09+00:00,2020-09-05T19:32:38Z,0,80,https://api.github.com/repos/microsoft/onnxruntime/issues/4264
4267,b'Memory management overhead in CPU/Inference mode',Software,closed,2020-06-18T03:53:56Z,2020-06-18 18:44:27+00:00,2020-08-29T11:04:47Z,0,72,https://api.github.com/repos/microsoft/onnxruntime/issues/4267
4269,b'pytorch to onnx discrepancies',Software,closed,2020-06-18T05:36:06Z,2020-06-18 12:05:20+00:00,2020-06-18T12:05:20Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4269
4273,b'undefined reference to `onnxruntime::Env::Default()',Software,closed,2020-06-18T09:59:42Z,2020-06-19 00:34:02+00:00,2020-06-19T00:34:02Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4273
4282,b'Does it support TensorRT in new release 1.3.1-java-gpu',Software,closed,2020-06-19T06:15:38Z,2020-06-21 05:43:43+00:00,2020-06-21T05:43:43Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/4282
4286,"b""Unable to build, getting error: package directory 'onnxruntime/backend' does not exist""",Software,closed,2020-06-19T22:52:11Z,2020-06-22 17:23:27+00:00,2020-07-01T21:36:15Z,2,11,https://api.github.com/repos/microsoft/onnxruntime/issues/4286
4288,b'Softmax op has different result from keras.layers.Softmax and numpy when axis != -1',Software,closed,2020-06-20T00:34:15Z,2020-06-20 06:04:23+00:00,2020-06-20T16:39:50Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4288
4289,b'Support for Binary Convolutional Neural Networks for ACL/ArmNN EPs',Software,closed,2020-06-20T12:53:22Z,2020-06-20 12:53:22+00:00,2020-09-20T04:40:33Z,0,91,https://api.github.com/repos/microsoft/onnxruntime/issues/4289
4292,b'Onnx works when CUDAExecutionProvider but crash with CPUExecutionProvider',Software,closed,2020-06-21T09:04:06Z,2020-06-23 23:34:19+00:00,2020-06-23T23:34:18Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/4292
4293,b'FusionLayerNormalization change output significantly on Transformers',Software,closed,2020-06-21T21:37:20Z,2020-06-22 20:08:17+00:00,2020-06-25T11:12:21Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/4293
4294,"b""Doesn't support non-tensor output with sklearn-onnx in onnxruntime server""",Software,open,2020-06-22T06:16:52Z,2020-06-22 20:32:57+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/4294
4296,b'Add better error message when creating tensors with negative-valued shape',Software,closed,2020-06-22T07:19:33Z,2020-06-25 01:56:15+00:00,2020-06-25T01:56:15Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/4296
4298,b'How to access multidimensional output in C++?',Software,closed,2020-06-22T10:04:41Z,2020-06-24 07:19:32+00:00,2020-06-24T07:19:32Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/4298
4299,b'Unable to clone repository from github',Software,closed,2020-06-22T17:48:13Z,2020-06-24 06:00:14+00:00,2020-08-31T01:46:33Z,1,69,https://api.github.com/repos/microsoft/onnxruntime/issues/4299
4302,b'Resize operator missing INT64 support',Software,closed,2020-06-22T20:39:55Z,2020-06-30 01:15:33+00:00,2020-09-05T19:32:41Z,7,74,https://api.github.com/repos/microsoft/onnxruntime/issues/4302
4307,"b""Can't suppress warning when build with OpenMP""",Software,closed,2020-06-23T03:29:23Z,2020-06-23 03:29:44+00:00,2020-06-23T09:34:00Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4307
4308,b'Increasing memory usage with TensorRT',Software,closed,2020-06-23T06:57:41Z,2020-07-11 02:00:19+00:00,2021-03-19T00:27:01Z,17,268,https://api.github.com/repos/microsoft/onnxruntime/issues/4308
4309,"b""NameError: name 'onnx' is not defined""",Software,closed,2020-06-23T07:22:52Z,2020-06-24 05:37:42+00:00,2020-06-24T05:37:42Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4309
4310,"b'run(output_names, input_feed, run_options)'",Software,closed,2020-06-23T10:13:10Z,2020-08-29 17:04:34+00:00,2020-09-05T19:32:36Z,67,74,https://api.github.com/repos/microsoft/onnxruntime/issues/4310
4311,b'Missing Csharp language when building with --build_csharp option on Linux',Software,closed,2020-06-23T11:39:44Z,2020-06-28 10:14:40+00:00,2020-06-28T10:14:40Z,4,4,https://api.github.com/repos/microsoft/onnxruntime/issues/4311
4325,b'error with tensorrt',Software,closed,2020-06-24T09:12:55Z,2020-07-15 19:57:59+00:00,2020-09-20T20:40:17Z,21,88,https://api.github.com/repos/microsoft/onnxruntime/issues/4325
4326,b'CMake possible features: making the install an option and modify deprecated Python handling',Software,closed,2020-06-24T13:50:10Z,2020-08-29 11:04:41+00:00,2020-09-05T19:32:39Z,65,73,https://api.github.com/repos/microsoft/onnxruntime/issues/4326
4331,b'Using onnxruntime_perf_test for testdata/squeezenet/model.onnx',Software,closed,2020-06-24T23:38:49Z,2020-06-25 18:36:21+00:00,2020-06-25T18:36:21Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4331
4339,b'arm/arm64 builds are broken',Software,closed,2020-06-25T19:58:50Z,2020-06-25 19:59:32+00:00,2020-06-26T04:41:19Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4339
4349,b'Model with missing type information causes a SIGSEGV',Software,closed,2020-06-26T20:34:39Z,2020-06-29 21:44:24+00:00,2020-07-10T10:27:07Z,3,13,https://api.github.com/repos/microsoft/onnxruntime/issues/4349
4352,b'Maven Java Artifacts Performance Degradation Questions',Software,closed,2020-06-26T23:27:33Z,2020-06-29 20:40:30+00:00,2020-12-24T11:39:30Z,2,180,https://api.github.com/repos/microsoft/onnxruntime/issues/4352
4355,b'Add more C++ examples to demonstrate the experimental C++ API',Documentation,closed,2020-06-27T00:38:32Z,2020-07-06 21:57:32+00:00,2020-07-09T06:17:51Z,9,12,https://api.github.com/repos/microsoft/onnxruntime/issues/4355
4359,"b""Includes of onnxruntime_c_api.h don't have path starting with onnxruntime""",Software,closed,2020-06-27T19:38:38Z,2020-06-29 23:53:30+00:00,2020-09-11T04:15:54Z,2,75,https://api.github.com/repos/microsoft/onnxruntime/issues/4359
4361,b'With openvino EP\xef\xbc\x8c how to set the cpu number used\xef\xbc\x9f',Software,closed,2020-06-28T08:01:19Z,2020-06-30 05:56:35+00:00,2020-06-30T05:56:35Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/4361
4363,b'DllNotFound exception on android',Software,open,2020-06-29T11:38:47Z,2020-07-06 21:38:32+00:00,,7,,https://api.github.com/repos/microsoft/onnxruntime/issues/4363
4364,b'build error ',Software,closed,2020-06-29T14:46:51Z,2020-06-30 12:13:53+00:00,2020-09-05T19:32:35Z,0,68,https://api.github.com/repos/microsoft/onnxruntime/issues/4364
4365,b'onnxruntime/cmake/external',Software,closed,2020-06-29T15:11:52Z,2020-11-01 07:42:08+00:00,2020-11-16T03:48:08Z,124,139,https://api.github.com/repos/microsoft/onnxruntime/issues/4365
4368,b'onnxruntime fails to compile with c++20 compiler mode (VS2019)',Software,closed,2020-06-29T22:31:24Z,2020-08-11 18:08:10+00:00,2020-10-22T04:26:40Z,42,114,https://api.github.com/repos/microsoft/onnxruntime/issues/4368
4369,b'ArgumentException: Dimensions must contain elements',Software,closed,2020-06-29T22:34:47Z,2020-06-29 23:56:44+00:00,2020-08-25T18:00:34Z,0,56,https://api.github.com/repos/microsoft/onnxruntime/issues/4369
4370,b'Is ORT supporting custom backward functions in PyTorch?',Software,closed,2020-06-29T22:44:06Z,2020-07-06 19:25:36+00:00,2020-09-13T00:16:00Z,6,75,https://api.github.com/repos/microsoft/onnxruntime/issues/4370
4378,b'build errors',Software,closed,2020-06-30T12:59:54Z,2020-07-07 05:31:26+00:00,2020-09-20T20:40:14Z,6,82,https://api.github.com/repos/microsoft/onnxruntime/issues/4378
4379,b'compile errors',Software,closed,2020-06-30T13:53:42Z,2020-06-30 22:25:03+00:00,2020-07-01T10:20:20Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4379
4390,b'[Advice] GPU memory transfer optimizations',Software,closed,2020-07-01T07:24:46Z,2020-09-02 18:11:33+00:00,2020-09-11T04:15:51Z,63,71,https://api.github.com/repos/microsoft/onnxruntime/issues/4390
4393,b'Build for ARM | error: call of overloaded \xe2\x80\x98abs(__gnu_cxx::__alloc_traits<std::allocator<float> >::value_type)\xe2\x80\x99 is ambiguous   ',Software,closed,2020-07-01T08:55:27Z,2020-07-01 18:29:02+00:00,2020-09-02T03:45:39Z,0,62,https://api.github.com/repos/microsoft/onnxruntime/issues/4393
4405,"b""Can't load model that converts input to float16, runs inner model in float16, converts output to float32 """,Software,closed,2020-07-02T12:08:43Z,2020-07-02 21:36:26+00:00,2020-07-17T04:59:15Z,0,14,https://api.github.com/repos/microsoft/onnxruntime/issues/4405
4409,b'CudaContext changes',Software,closed,2020-07-02T16:59:34Z,2020-07-07 05:26:45+00:00,2021-03-19T00:09:43Z,4,259,https://api.github.com/repos/microsoft/onnxruntime/issues/4409
4417,b'Java API documentation has broken links',Documentation,closed,2020-07-03T01:41:08Z,2020-07-07 05:20:30+00:00,2020-08-13T19:06:44Z,4,41,https://api.github.com/repos/microsoft/onnxruntime/issues/4417
4419,b'Confuse about Resize(opset 10)  calculation method ',Software,closed,2020-07-03T09:48:08Z,2020-07-06 21:34:12+00:00,2020-10-04T03:56:36Z,3,92,https://api.github.com/repos/microsoft/onnxruntime/issues/4419
4420,b'Functional encryption models',Software,closed,2020-07-03T14:51:21Z,2020-07-07 04:58:07+00:00,2020-09-13T00:16:01Z,3,71,https://api.github.com/repos/microsoft/onnxruntime/issues/4420
4421,b'Severe performance degradation with 1.3.0',Software,closed,2020-07-03T16:03:32Z,2020-07-07 12:39:18+00:00,2020-08-01T22:49:00Z,3,29,https://api.github.com/repos/microsoft/onnxruntime/issues/4421
4422,b'Improve support for tensor element access (C/C++ API)',Software,closed,2020-07-03T17:20:09Z,2020-07-06 20:40:44+00:00,2020-08-12T01:34:05Z,3,39,https://api.github.com/repos/microsoft/onnxruntime/issues/4422
4423,b'Unable to Perform Inference using ONNX RUNTIME. Invalid Argument Error',Software,closed,2020-07-03T18:10:05Z,2020-07-06 21:23:25+00:00,2020-07-09T11:35:59Z,3,5,https://api.github.com/repos/microsoft/onnxruntime/issues/4423
4424,b'Session load fails with Protobuf serialization failed',Software,closed,2020-07-03T19:03:00Z,2020-07-06 21:12:44+00:00,2020-07-20T22:18:35Z,3,17,https://api.github.com/repos/microsoft/onnxruntime/issues/4424
4425,b'Session.Run(inputs) returns null result',Software,closed,2020-07-03T22:17:56Z,2020-07-06 20:08:23+00:00,2020-07-07T02:26:01Z,2,3,https://api.github.com/repos/microsoft/onnxruntime/issues/4425
4427,b'Segmentation fault (core dumped) CUDAExecutionProvider',Software,closed,2020-07-04T11:35:10Z,2020-07-06 21:16:38+00:00,2021-03-19T00:09:10Z,2,257,https://api.github.com/repos/microsoft/onnxruntime/issues/4427
4428,b'specify install location using build.sh',Software,closed,2020-07-05T16:52:44Z,2020-07-05 21:52:00+00:00,2020-07-07T16:01:08Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/4428
4429,b'Display all input types on type error',Software,open,2020-07-06T08:13:11Z,2020-07-06 19:20:32+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/4429
4430,b'ARMNN build failed due to signature change of CPUAllocator introduced by PR2850',Software,closed,2020-07-06T08:43:36Z,2020-07-06 21:03:48+00:00,2020-07-13T23:07:41Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/4430
4431,b'Why is the onnx version down to 1.2 in the document docs/version.md that chapter is compatibility/version matrix?',Documentation,closed,2020-07-06T11:03:41Z,2020-07-06 18:29:26+00:00,2020-07-07T02:17:26Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4431
4441,b'Porting the controller in C/C++ imagenet example to Linux ',Software,closed,2020-07-07T04:29:11Z,2020-07-07 18:18:07+00:00,2020-12-24T11:39:26Z,0,170,https://api.github.com/repos/microsoft/onnxruntime/issues/4441
4445,b'Build with OpenVINO',Software,closed,2020-07-07T17:42:21Z,2020-07-07 18:13:41+00:00,2020-09-07T23:26:37Z,0,62,https://api.github.com/repos/microsoft/onnxruntime/issues/4445
4449,b'Longformer Optimization',Software,closed,2020-07-08T07:14:38Z,2020-07-08 20:12:01+00:00,2021-02-22T06:14:30Z,0,228,https://api.github.com/repos/microsoft/onnxruntime/issues/4449
4450,b'How to import  onnxruntime when I build from source?',Software,closed,2020-07-08T08:28:23Z,2020-07-08 08:28:57+00:00,2020-07-09T02:21:38Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4450
4463,"b'onnxruntime_test_all --gtest_filter=ActivationOpTest.Relu fails, cross-compile onnxruntime v1.3.1 against ACL v19.08'",Software,closed,2020-07-09T03:04:17Z,2020-07-09 09:15:23+00:00,2020-09-14T18:58:44Z,0,67,https://api.github.com/repos/microsoft/onnxruntime/issues/4463
4464,b'Direct GPU Inference',Software,closed,2020-07-09T03:55:40Z,2020-07-09 19:00:56+00:00,2020-11-16T03:48:06Z,0,129,https://api.github.com/repos/microsoft/onnxruntime/issues/4464
4466,b'Running models with dynamic output shapes (C++)',Software,closed,2020-07-09T16:29:48Z,2020-07-09 16:29:57+00:00,2020-07-09T19:56:38Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4466
4473,b'Support for ACL v20.05',Software,closed,2020-07-09T22:41:33Z,2020-07-10 21:34:54+00:00,2020-09-14T19:00:41Z,0,66,https://api.github.com/repos/microsoft/onnxruntime/issues/4473
4477,b'Question about default multi-thread of mlas',Software,closed,2020-07-10T08:52:01Z,2020-07-10 20:57:13+00:00,2020-07-13T22:45:22Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/4477
4478,b'Assertion failed: f.pitches[i] >= s',Software,closed,2020-07-10T11:30:08Z,2020-07-10 21:17:20+00:00,2020-08-10T09:07:13Z,0,30,https://api.github.com/repos/microsoft/onnxruntime/issues/4478
4484,b'[Question] graph early exiting',Software,closed,2020-07-10T22:20:50Z,2020-07-11 01:41:43+00:00,2020-10-04T03:56:34Z,0,85,https://api.github.com/repos/microsoft/onnxruntime/issues/4484
4486,b' RUNTIME_EXCEPTION : Exception during initialization',Software,closed,2020-07-11T05:19:34Z,2020-07-11 19:23:25+00:00,2021-02-10T01:07:58Z,0,213,https://api.github.com/repos/microsoft/onnxruntime/issues/4486
4488,b'Different Output when Inference on CPU / GPU in some case',Software,closed,2020-07-11T05:29:14Z,2020-07-13 23:04:36+00:00,2020-08-18T09:09:32Z,2,38,https://api.github.com/repos/microsoft/onnxruntime/issues/4488
4489,b'Suggestion: add python wheels of various providers to each release',Software,open,2020-07-11T11:50:33Z,2020-07-11 19:15:42+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/4489
4491,b'ONNXRuntime C++ Documentation',Software,closed,2020-07-13T12:34:40Z,2020-07-13 12:38:59+00:00,2020-10-22T04:26:38Z,0,100,https://api.github.com/repos/microsoft/onnxruntime/issues/4491
4492,b'How can I get a reference to an already running environment on the same thread?',Software,closed,2020-07-13T12:36:12Z,2020-07-13 18:52:27+00:00,2020-07-22T19:29:56Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/4492
4502,"b'Aggregate Operators (""functions"") should favor primary EP over secondary EP'",Software,closed,2020-07-14T06:43:44Z,2020-07-14 06:45:50+00:00,2020-10-11T11:41:34Z,0,89,https://api.github.com/repos/microsoft/onnxruntime/issues/4502
4505,"b'TX2 - Jetpack 4.4 - Network has dynamic or shape inputs, but no optimization profile has been defined.'",Software,closed,2020-07-14T10:36:26Z,2020-07-14 19:24:01+00:00,2020-09-20T04:40:29Z,0,67,https://api.github.com/repos/microsoft/onnxruntime/issues/4505
4506,b'GPU Memory Release Problem ONNRuntime C++',Software,closed,2020-07-14T13:27:05Z,2020-07-14 13:29:35+00:00,2020-08-19T06:42:15Z,0,35,https://api.github.com/repos/microsoft/onnxruntime/issues/4506
4507,b'remove_initializer_from_input.py not removing all ininitializers from inputs',Software,closed,2020-07-14T14:45:23Z,2020-07-14 19:12:48+00:00,2020-07-16T09:50:23Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/4507
4508,b'use shared library for onnx',Software,closed,2020-07-14T15:00:03Z,2020-07-15 20:44:12+00:00,2020-11-16T03:48:04Z,1,124,https://api.github.com/repos/microsoft/onnxruntime/issues/4508
4513,b'Question about Tensorflow_Keras_Bert-Squad_OnnxRuntime_CPU.ipynb',Software,closed,2020-07-14T22:08:33Z,2020-07-15 08:02:44+00:00,2020-08-25T18:39:16Z,0,41,https://api.github.com/repos/microsoft/onnxruntime/issues/4513
4515,b'How to register a new domain?',Software,closed,2020-07-15T05:37:47Z,2020-07-15 07:12:51+00:00,2020-07-15T07:12:51Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4515
4516,b'loading a model in ort throws error: onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Node (Reshape_46) Op (Reshape) [ShapeInferenceError] Invalid position of 0 ',Software,closed,2020-07-15T13:50:52Z,2020-07-15 20:44:47+00:00,2020-07-20T15:08:34Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/4516
4528,b'Tensor Creation from data',Software,closed,2020-07-16T06:11:01Z,2020-07-16 18:24:25+00:00,2020-07-25T16:05:41Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/4528
4534,b'A Test Failed Randomly',Software,closed,2020-07-16T21:19:10Z,2020-07-16 23:37:32+00:00,2020-09-21T16:49:15Z,0,66,https://api.github.com/repos/microsoft/onnxruntime/issues/4534
4539,"b""In function __cxx_global_var_init undefined reference to `OrtGetApiBase'""",Software,closed,2020-07-17T08:43:11Z,2020-07-17 18:22:29+00:00,2020-07-19T22:40:49Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/4539
4540,b'Impossible to Compile an source code to run onnx with Arm Compute Library',Software,closed,2020-07-17T09:51:29Z,2020-07-17 18:28:52+00:00,2020-08-01T05:57:29Z,0,14,https://api.github.com/repos/microsoft/onnxruntime/issues/4540
4553,"b""NNAPI build doesn't provide libonnxruntime library""",Software,closed,2020-07-19T08:25:30Z,2020-07-20 00:32:38+00:00,2020-07-21T03:58:30Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/4553
4554,b'Unable to build Onnxruntime 1.4.0 with OpenVINO 2020.3 on Windows 10',Software,closed,2020-07-19T19:02:28Z,2020-07-20 00:33:43+00:00,2020-07-28T00:08:23Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/4554
4555,b'Unable to Get the StartTime in the Profiler',Software,closed,2020-07-20T00:22:39Z,2020-07-20 00:33:31+00:00,2020-09-22T22:30:17Z,0,64,https://api.github.com/repos/microsoft/onnxruntime/issues/4555
4559,b'Segmentation fault with zero-dim tensor',Software,closed,2020-07-20T21:34:54Z,2020-07-20 21:46:50+00:00,2020-07-22T00:57:48Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/4559
4563,b'Unknown model file format version with example dataset in Python',Software,closed,2020-07-21T04:23:55Z,2020-07-21 23:01:17+00:00,2020-07-22T06:51:18Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/4563
4565,b'Add `optimizer_cli` support for `gpt2-medium`',Software,closed,2020-07-21T07:44:38Z,2020-07-21 11:47:34+00:00,2020-07-21T11:47:33Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4565
4566,b'onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running BatchNormalization node. ',Software,closed,2020-07-21T08:12:00Z,2020-07-21 08:12:12+00:00,2020-10-04T03:56:35Z,0,74,https://api.github.com/repos/microsoft/onnxruntime/issues/4566
4568,b'Access to custom metadata of an .onnx model when creating an InferenceSession in a C# WPF application.',Software,closed,2020-07-21T12:16:18Z,2020-07-21 23:02:37+00:00,2020-08-25T18:13:50Z,0,35,https://api.github.com/repos/microsoft/onnxruntime/issues/4568
4569,b'onnxruntime compilation with --enable_nvtx_profile fails.',Software,closed,2020-07-21T14:45:34Z,2020-07-21 23:03:02+00:00,2020-12-24T11:39:31Z,0,155,https://api.github.com/repos/microsoft/onnxruntime/issues/4569
4570,"b' there is always a ""import error"" in a new win7 system: ""ImportError: cannot import name \'get_all_providers\'""'",Software,closed,2020-07-21T15:29:13Z,2020-07-21 23:03:24+00:00,2020-07-23T17:49:58Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/4570
4585,b'Fuzzed model takes down the runtime with a SIGSEGV',Software,closed,2020-07-22T15:53:20Z,2020-07-22 17:08:54+00:00,2021-04-09T22:36:47Z,0,261,https://api.github.com/repos/microsoft/onnxruntime/issues/4585
4589,b'ONNXRuntime outputs are different from PyTorch outputs',Software,closed,2020-07-22T21:05:09Z,2020-07-23 09:22:55+00:00,2020-07-23T09:22:55Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4589
4594,b'Export data preprocessing logic built upon featurizers_ops and PyTorch model into one ONNX file for model serving.',Software,closed,2020-07-23T00:44:25Z,2020-07-23 09:30:14+00:00,2020-10-11T11:41:33Z,0,80,https://api.github.com/repos/microsoft/onnxruntime/issues/4594
4598,b'Incompatibility Openvino-vadm Model  Error',Software,closed,2020-07-23T10:44:29Z,2020-07-23 16:54:20+00:00,2020-07-29T08:38:28Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/4598
4609,b'Cmakelist.txt  in samples',Software,closed,2020-07-24T07:51:02Z,2020-07-24 08:38:41+00:00,2020-07-24T08:38:41Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4609
4611,b'Inference on GPU is not deterministic',Software,closed,2020-07-24T15:53:51Z,2020-07-24 15:58:18+00:00,2020-07-24T15:58:18Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4611
4617,b'Cmake fail to create symbolic link',Software,closed,2020-07-24T22:53:09Z,2020-07-27 07:46:29+00:00,2020-08-02T22:38:21Z,2,8,https://api.github.com/repos/microsoft/onnxruntime/issues/4617
4620,b'Input and output tensors data info',Software,closed,2020-07-25T16:53:13Z,2020-07-27 07:44:33+00:00,2020-08-02T22:38:37Z,1,8,https://api.github.com/repos/microsoft/onnxruntime/issues/4620
4621,b'Worse performance of onnxruntime v-1.4.0 compared to v-1.2.0 on armv8 (aarch64) device',Software,closed,2020-07-25T20:48:46Z,2020-07-25 20:49:00+00:00,2020-10-11T11:41:39Z,0,77,https://api.github.com/repos/microsoft/onnxruntime/issues/4621
4622,b'Does onnxruntime use data parallelism or model parallelism?',Software,closed,2020-07-26T09:20:44Z,2020-07-26 23:47:09+00:00,2020-07-28T16:45:48Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/4622
4623,b'Test failure on Windows',Software,closed,2020-07-26T22:27:48Z,2020-07-27 06:47:05+00:00,2020-08-02T22:39:14Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/4623
4624,b'Error using output of one model as input for another C#',Software,closed,2020-07-26T23:06:46Z,2020-07-27 06:30:53+00:00,2020-08-02T22:39:53Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/4624
4625,b'TensorRT build failed.',Software,closed,2020-07-26T23:23:43Z,2020-07-27 06:29:02+00:00,2020-12-09T04:02:59Z,0,135,https://api.github.com/repos/microsoft/onnxruntime/issues/4625
4628,"b'when input shape  too big, the result of GRU is different with Numpy.'",Software,closed,2020-07-27T08:48:31Z,2020-07-27 08:59:25+00:00,2020-07-31T09:10:34Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/4628
4635,b'C API Error in model input dimensions with yolov4 model',Software,closed,2020-07-27T23:08:02Z,2020-07-28 01:10:37+00:00,2020-08-02T23:02:42Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/4635
4641,"b""Non-zero status code returned while running Concat node. Name:'Concat_582'. Axis 0 has mismatched dimensions of 5 and 24""",Software,closed,2020-07-28T06:17:26Z,2020-07-28 06:23:23+00:00,2020-07-31T02:24:20Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/4641
4642,b'Error while building release 1.3.1 from given source code.',Software,closed,2020-07-28T13:51:19Z,2020-07-28 13:52:27+00:00,2020-10-11T11:41:38Z,0,74,https://api.github.com/repos/microsoft/onnxruntime/issues/4642
4643,b'cmake error',Software,closed,2020-07-28T14:40:13Z,2020-07-29 09:46:01+00:00,2020-07-30T23:34:37Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/4643
4644,b'Multinomial float16 is broken since a recent change to the Cast transformer',Software,closed,2020-07-28T20:05:12Z,2020-07-28 20:41:12+00:00,2020-07-30T06:32:02Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/4644
4647,b'ACL performance with onnxruntime_perf_test',Software,closed,2020-07-28T22:39:19Z,2020-07-29 09:56:24+00:00,2020-09-30T19:27:29Z,0,63,https://api.github.com/repos/microsoft/onnxruntime/issues/4647
4652,b'onnxruntime_perf_test core dumped with rel-1.4.0 ',Software,closed,2020-07-29T07:30:21Z,2020-07-29 10:09:35+00:00,2020-10-11T11:41:37Z,0,74,https://api.github.com/repos/microsoft/onnxruntime/issues/4652
4653,"b""loading a model in ort throws error: onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running Reshape node. Name:'Reshape_62' Status Message: /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/reshape_helper.h:43 onnxruntime::ReshapeHelper::ReshapeHelper(const onnxruntime::TensorShape&, std::vector<long int>&) gsl::narrow_cast<int64_t>(input_shape.Size()) == size was false. The input tensor cannot be reshaped to the requested shape. Input shape:{22,256}, requested shape:{56,1,256}""",Software,closed,2020-07-29T08:51:06Z,2020-07-29 10:33:31+00:00,2020-07-31T07:40:28Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/4653
4654,b'ONNX Runtime performing worse than PyTorch on BERT CPU Inference',Software,open,2020-07-29T09:28:20Z,2020-07-29 09:33:48+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/4654
4655,b'Windows Version Requirements',Software,closed,2020-07-29T10:36:12Z,2020-07-29 10:50:36+00:00,2020-07-29T10:51:35Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4655
4656,b'CUDA test hang without GPU.',Software,closed,2020-07-29T10:49:01Z,2020-07-30 00:09:12+00:00,2020-12-21T01:56:54Z,0,144,https://api.github.com/repos/microsoft/onnxruntime/issues/4656
4662,b'Nuget package including 253mb libonnxruntime.dylib file on OSX64',Software,closed,2020-07-30T04:30:31Z,2020-07-31 07:32:35+00:00,2021-08-21T08:15:58Z,1,387,https://api.github.com/repos/microsoft/onnxruntime/issues/4662
4665,b'Failed to build ORT 1.4.0 with CUDA provider',Software,closed,2020-07-30T05:20:16Z,2020-07-30 20:47:24+00:00,2020-07-30T20:47:24Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4665
4667,b'experimental_onnxruntime_cxx_api.h errors',Software,closed,2020-07-30T14:44:46Z,2020-07-30 23:34:56+00:00,2020-10-11T11:41:40Z,0,72,https://api.github.com/repos/microsoft/onnxruntime/issues/4667
4683,"b""C# how to mock Run's result""",Software,closed,2020-08-01T00:50:12Z,2020-08-02 22:00:24+00:00,2020-08-06T04:53:27Z,1,5,https://api.github.com/repos/microsoft/onnxruntime/issues/4683
4685,b'PyTorch FPN segmentation model differs in inference between C++ in Windows and Python on Linux',Software,closed,2020-08-01T10:24:38Z,2020-08-02 22:29:52+00:00,2020-08-03T02:08:04Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/4685
4686,b'Microsoft.AI.MachineLearning cannot be used in UWP app on on Windows 10 ARM64',Software,open,2020-08-01T18:26:16Z,2020-08-01 18:28:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/4686
4688,b'Hardcoded CPU Allocator in TreeEnsembleCommon',Software,closed,2020-08-03T07:29:02Z,2020-08-03 09:30:06+00:00,2020-10-09T09:26:10Z,0,67,https://api.github.com/repos/microsoft/onnxruntime/issues/4688
4689,b'SetOutputs of graph in transformer not working as expected',Software,closed,2020-08-03T09:32:55Z,2020-08-03 15:49:31+00:00,2020-09-04T08:51:20Z,0,31,https://api.github.com/repos/microsoft/onnxruntime/issues/4689
4692,b'TEST_SRC_DIR not defined if unittests are not enabled',Software,closed,2020-08-03T16:40:17Z,2020-08-03 17:59:23+00:00,2021-03-19T00:26:59Z,0,227,https://api.github.com/repos/microsoft/onnxruntime/issues/4692
4698,b'ConvTranspose output shape incorrect when auto_pad attribute is set.',Software,closed,2020-08-03T23:00:49Z,2020-08-03 23:13:44+00:00,2020-08-04T22:33:58Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4698
4707,"b""Can't export GPT2-XL to ONNX: ModelProto exceeds maximum protobuf size of 2GB""",Software,closed,2020-08-04T23:11:52Z,2020-08-05 20:29:40+00:00,2020-08-08T15:06:29Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/4707
4709,b'Concrete C# samples',Software,closed,2020-08-05T07:10:45Z,2020-08-05 07:49:34+00:00,2020-08-07T20:36:37Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/4709
4711,b'Onnxruntimeserver Jupiter notebook has missing dependencies ',Software,closed,2020-08-05T12:54:22Z,2020-08-05 16:58:31+00:00,2020-08-05T16:58:31Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4711
4720,b'openvino performance test',Software,closed,2020-08-06T06:20:51Z,2020-08-06 16:35:39+00:00,2021-02-10T01:32:51Z,0,187,https://api.github.com/repos/microsoft/onnxruntime/issues/4720
4723,b'Building onnxruntime on Jetson TX2 with python 3.7.8 and jetpack 4.4',Software,closed,2020-08-06T06:59:42Z,2020-08-06 16:33:38+00:00,2020-08-18T03:05:56Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/4723
4724,b'Some output shapes become fixed numbers when using onnxruntime to load the model',Software,closed,2020-08-06T10:31:01Z,2020-08-06 16:29:44+00:00,2020-09-17T05:51:00Z,0,41,https://api.github.com/repos/microsoft/onnxruntime/issues/4724
4725,b'How to correctly (make) install onnxruntime on a Linux machine?',Software,closed,2020-08-06T13:28:50Z,2020-08-06 16:16:44+00:00,2020-10-22T04:26:41Z,0,76,https://api.github.com/repos/microsoft/onnxruntime/issues/4725
4729,b'libonnxruntime_providers_dnnl.so not installed by CMake',Software,closed,2020-08-07T00:07:35Z,2020-08-07 00:08:43+00:00,2020-11-03T16:40:23Z,0,88,https://api.github.com/repos/microsoft/onnxruntime/issues/4729
4735,b'ONNXRuntime fails to build on MAC ',Software,closed,2020-08-07T10:48:00Z,2020-08-07 16:00:06+00:00,2020-08-11T10:00:46Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/4735
4740,b'Mem pattern should be disabled when using DML execution provider.',Software,closed,2020-08-10T06:37:49Z,2020-08-10 19:12:34+00:00,2020-08-14T08:22:37Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/4740
4741,b'Failed to build onnxruntime with TensorRT on Windows 10',Software,closed,2020-08-10T10:36:51Z,2020-08-10 18:41:15+00:00,2020-08-20T06:33:00Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/4741
4742,b'Error in Float16 inference',Software,closed,2020-08-10T13:16:28Z,2020-08-10 18:48:41+00:00,2020-10-22T04:26:39Z,0,72,https://api.github.com/repos/microsoft/onnxruntime/issues/4742
4745,b'InferenceSession(GraphOptimizationLevel.ORT_ENABLE_BASIC) inserts Cast nodes with hard-coded name cause name conflict',Software,closed,2020-08-10T18:55:34Z,2020-08-10 18:57:38+00:00,2020-08-27T19:38:42Z,0,17,https://api.github.com/repos/microsoft/onnxruntime/issues/4745
4754,b'Segmentation Fault when trying to run my own custom op with default EP.',Software,closed,2020-08-11T09:29:09Z,2020-08-11 09:29:52+00:00,2021-03-19T00:26:58Z,0,219,https://api.github.com/repos/microsoft/onnxruntime/issues/4754
4755,b'ONNXRuntime JAVA JNI build failure ',Software,closed,2020-08-11T11:07:08Z,2020-08-11 17:08:15+00:00,2020-08-11T17:54:24Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4755
4756,"b""Can't make GPT2 working with past state""",Software,closed,2020-08-11T18:22:30Z,2020-08-11 20:59:10+00:00,2020-09-16T14:14:00Z,0,35,https://api.github.com/repos/microsoft/onnxruntime/issues/4756
4762,b'ORT Training: Training mnist using provided sample using a convolution model',Software,closed,2020-08-11T23:34:09Z,2020-08-11 23:34:09+00:00,2021-10-14T18:12:20Z,0,428,https://api.github.com/repos/microsoft/onnxruntime/issues/4762
4766,b'Error when buliding sample MNIST with visual studio 2019',Software,closed,2020-08-12T08:48:51Z,2020-08-12 22:36:34+00:00,2020-08-13T04:46:12Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4766
4769,b'FP16 model is not faster than full precision',Software,closed,2020-08-12T14:10:20Z,2020-08-12 18:21:05+00:00,2020-12-24T11:39:25Z,0,133,https://api.github.com/repos/microsoft/onnxruntime/issues/4769
4770,b'Document what are the defaults',Documentation,closed,2020-08-12T20:12:03Z,2020-08-12 20:44:39+00:00,2020-08-12T21:30:03Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4770
4779,b'[ONNXRuntimeError]  Non-zero status code returned while running SkipLayerNormalization node.',Software,open,2020-08-13T04:36:21Z,2020-08-13 07:54:44+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/4779
4782,b'Error when buliding sample MNIST with visual studio 2019',Software,closed,2020-08-13T13:30:07Z,2020-08-13 13:30:07+00:00,2020-08-14T03:36:36Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4782
4785,b'Huge performance difference Intel CPU vs. Ryzen CPU',Software,closed,2020-08-13T14:41:38Z,2020-08-13 14:45:52+00:00,2021-02-10T01:31:39Z,0,180,https://api.github.com/repos/microsoft/onnxruntime/issues/4785
4787,"b'unclear error message: INVALID_ARGUMENT : Unexpected input data type. Actual: (N11onnxruntime17PrimitiveDataTypeIlEE) , expected: (N11onnxruntime17PrimitiveDataTypeIiEE)'",Documentation,closed,2020-08-13T15:28:26Z,2020-08-13 19:04:09+00:00,2020-08-17T09:13:43Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/4787
4796,"b'Quantized tiny_yolov4 model ,inference speed from 47ms to 83ms.What should I do speed up inference speed? '",Software,closed,2020-08-14T02:43:29Z,2020-08-14 21:48:00+00:00,2020-08-24T06:40:21Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/4796
4798,b'add new op but register test failed',Software,closed,2020-08-14T07:59:06Z,2020-08-14 10:49:26+00:00,2020-08-20T09:37:53Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/4798
4801,b'How to use yolov5 onnx file in C#',Software,closed,2020-08-14T09:57:29Z,2020-08-14 21:55:07+00:00,2020-08-14T21:55:27Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4801
4802,b'A question on DispatchOnTensorType()',Software,closed,2020-08-14T10:03:27Z,2020-08-14 18:06:41+00:00,2020-08-15T14:25:50Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/4802
4803,b'Bad node spec for onnx model after using the calibration/quantization tool',Software,closed,2020-08-14T10:05:25Z,2020-08-14 17:59:42+00:00,2020-11-04T05:35:34Z,0,81,https://api.github.com/repos/microsoft/onnxruntime/issues/4803
4805,b'Build Failure with CUDA device with QAttentionTest and  MatmulIntegerOpTest',Software,closed,2020-08-14T15:27:04Z,2020-08-14 18:09:58+00:00,2020-11-16T03:48:05Z,0,93,https://api.github.com/repos/microsoft/onnxruntime/issues/4805
4806,"b""onnxruntime-gpu ImportError: cannot import name 'get_all_providers'""",Documentation,closed,2020-08-14T16:56:10Z,2020-08-14 17:57:59+00:00,2020-08-18T19:59:48Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/4806
4809,b'CUDAExecutionProvider',Documentation,closed,2020-08-14T18:52:15Z,2020-08-14 20:14:01+00:00,2020-08-14T20:14:01Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4809
4812,b'Debugging capability of onnxruntime in Visual Studio 2019 incapacitated',Documentation,open,2020-08-14T23:58:27Z,2020-08-15 01:24:03+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/4812
4816,b'No performance different between ORT_ENABLE_ALL and ORT_DISABLE_ALL ',Documentation,closed,2020-08-15T03:26:16Z,2020-08-15 05:30:18+00:00,2020-08-18T13:22:39Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/4816
4818,b'Got error onnxruntime c++ api with two inputs',Documentation,closed,2020-08-17T09:32:06Z,2020-08-17 12:58:51+00:00,2020-08-17T12:58:51Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4818
4819,b'replace onnx model output with all conv node input/output name can not infer once to get all results shape',Software,closed,2020-08-17T09:37:18Z,2020-08-18 21:44:26+00:00,2020-11-16T03:48:12Z,1,90,https://api.github.com/repos/microsoft/onnxruntime/issues/4819
4820,b'Ort::Env cannot be static',Software,closed,2020-08-17T10:39:37Z,2020-08-17 17:10:09+00:00,2020-08-17T17:10:09Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4820
4821,"b'""Segmentation fault"" (core dumped) '",Software,closed,2020-08-17T13:14:59Z,2020-08-17 23:24:07+00:00,2020-08-18T03:25:14Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4821
4824,b'Qunatization and calibration end-to-end example does not work',Software,closed,2020-08-17T17:02:26Z,2020-08-18 15:29:42+00:00,2020-10-21T17:25:31Z,0,65,https://api.github.com/repos/microsoft/onnxruntime/issues/4824
4829,b'Wrong requested shape after a few thousand inference steps when using CUDA',Software,closed,2020-08-17T19:00:49Z,2020-08-18 21:46:00+00:00,2020-10-13T05:12:06Z,1,56,https://api.github.com/repos/microsoft/onnxruntime/issues/4829
4839,b'No Op registered for ArrayFeatureExtractor with domain_version of 11',Software,closed,2020-08-18T10:35:09Z,2020-08-18 12:00:11+00:00,2020-08-18T12:00:11Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4839
4840,b'Segmentationfault when using ACL (32bit)',Software,closed,2020-08-18T11:59:35Z,2020-08-18 19:54:51+00:00,2021-03-19T00:26:58Z,0,212,https://api.github.com/repos/microsoft/onnxruntime/issues/4840
4841,b'TensorRT 7.1.3 / Cuda11 / CuDNN 8 - supported yet?',Software,closed,2020-08-18T18:45:11Z,2020-08-18 19:53:37+00:00,2020-11-18T00:32:01Z,0,91,https://api.github.com/repos/microsoft/onnxruntime/issues/4841
4843,b'C++ API - add ability to use global threadpools AND custom logging',Software,closed,2020-08-18T19:13:45Z,2020-08-19 22:34:10+00:00,2020-10-27T20:23:11Z,1,70,https://api.github.com/repos/microsoft/onnxruntime/issues/4843
4853,"b"" INVALID_ARGUMENT : Non-zero status code returned while running ScatterElements node. Name:'ScatterElements_102' Status Message: Indices dim=24 at pos=0 is greater than input dim=2""",Software,closed,2020-08-19T00:59:51Z,2020-08-19 19:29:42+00:00,2020-08-19T19:29:42Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4853
4862,b'BERT performance on ONNX runtime on Linux CPU much worse than Windows',Software,closed,2020-08-19T22:13:42Z,2020-08-21 22:17:29+00:00,2020-09-24T19:15:52Z,2,35,https://api.github.com/repos/microsoft/onnxruntime/issues/4862
4869,b'About hyperthreading and openmp on the CPU',Software,closed,2020-08-20T03:14:46Z,2020-08-21 04:13:45+00:00,2021-02-23T02:56:46Z,1,186,https://api.github.com/repos/microsoft/onnxruntime/issues/4869
4876,b'Separate Nugets for different execution providers',Software,closed,2020-08-20T20:42:04Z,2020-08-20 21:13:04+00:00,2020-08-20T23:27:22Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4876
4882,"b'Failed to build on ARM device (Terminal on Android), with saying ""No target ""protobuf::protoc""""'",Software,closed,2020-08-21T08:48:59Z,2020-08-21 17:18:13+00:00,2020-11-16T03:48:10Z,0,86,https://api.github.com/repos/microsoft/onnxruntime/issues/4882
4883,b'ONNXRuntime StandardScaler distinctions',Software,closed,2020-08-21T12:27:57Z,2020-08-21 17:19:32+00:00,2020-08-27T10:41:47Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/4883
4893,b'Performance between onnxruntime vs tensorflow serving.',Software,closed,2020-08-24T02:33:31Z,2020-08-24 17:10:23+00:00,2020-11-16T03:48:03Z,0,84,https://api.github.com/repos/microsoft/onnxruntime/issues/4893
4896,"b'Getting ""Unable to load DLL \'onnxruntime\'"" when using ML.NET on Azure Cloud Service'",Software,closed,2020-08-24T09:50:06Z,2020-08-24 16:57:59+00:00,2021-04-04T16:08:33Z,0,223,https://api.github.com/repos/microsoft/onnxruntime/issues/4896
4897,b'Unspecified error by using DirectXHighPerformance with Microsoft.AI.MachineLearning package',Software,closed,2020-08-24T13:58:39Z,2020-08-24 17:31:49+00:00,2020-11-16T03:48:01Z,0,83,https://api.github.com/repos/microsoft/onnxruntime/issues/4897
4898,b'Optimizer changes dynamic shape to constant',Software,closed,2020-08-24T20:56:57Z,2020-08-25 00:16:51+00:00,2020-08-31T20:14:03Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/4898
4909,b'Install onnxruntime via pip on raspberry pi 3 fails',Software,closed,2020-08-25T11:15:02Z,2020-08-25 20:47:00+00:00,2020-08-25T20:47:00Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4909
4910,b'Raspberry Pi OnnxRuntime error: call of overloaded \xe2\x80\x98abs(__gnu_cxx::__alloc_traits<std::allocator<float> >::value_type)\xe2\x80\x99 is ambiguous ASSERT_TRUE(std::abs(values_y[i] - f[i]) < 1e-6)',Software,closed,2020-08-25T12:47:16Z,2020-08-25 20:39:41+00:00,2020-09-02T03:45:23Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/4910
4922,b'Unable to load pytorch model exported to onnx using use_external_data_format=True Flag',Software,closed,2020-08-26T05:28:32Z,2020-08-26 05:34:00+00:00,2020-11-16T03:48:07Z,0,81,https://api.github.com/repos/microsoft/onnxruntime/issues/4922
4923,b'Feature request : pre-built binaries for Android',Software,closed,2020-08-26T09:26:02Z,2020-08-26 17:28:12+00:00,2020-11-16T03:48:13Z,0,81,https://api.github.com/repos/microsoft/onnxruntime/issues/4923
4929,b'Onnx input size',Software,closed,2020-08-26T22:30:23Z,2020-08-27 00:51:08+00:00,2020-08-27T00:51:08Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4929
4934,b'Documentation and examples for onnxruntime_perf_test',Documentation,open,2020-08-27T01:39:36Z,2020-08-27 01:49:07+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/4934
4935,b'CUDA 11 still supports 3.5/3.7',Software,closed,2020-08-27T07:16:11Z,2020-08-27 07:28:27+00:00,2021-03-19T00:26:57Z,0,203,https://api.github.com/repos/microsoft/onnxruntime/issues/4935
4941,b'Expose DirectML to C#',Software,closed,2020-08-27T20:01:46Z,2020-08-28 03:49:57+00:00,2020-08-29T22:18:51Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/4941
4944,"b'EinSum CPU provider rejects equation ZY,YX->ZX'",Software,closed,2020-08-27T20:52:11Z,2020-08-27 20:52:39+00:00,2020-08-29T22:18:22Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/4944
4945,b'Unable to build C# API for OpenVINO  Execution Provider With VS2019',Software,open,2020-08-27T21:52:30Z,2020-08-27 22:39:43+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/4945
4947,b'Java API OnnxTensor.createTensor() uses buffer incorrectly',Software,closed,2020-08-27T22:55:22Z,2020-08-28 00:40:15+00:00,2020-10-05T17:50:39Z,0,38,https://api.github.com/repos/microsoft/onnxruntime/issues/4947
4952,b'GPT2 quantization',Software,closed,2020-08-28T03:13:24Z,2020-08-28 06:36:22+00:00,2020-09-08T23:17:47Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/4952
4956,"b""Build by source, import onnxruntime, ModuleNotFoundError: No module named 'onnxruntime.capi'""",Software,closed,2020-08-28T07:29:35Z,2020-08-28 18:19:51+00:00,2020-08-28T18:19:51Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4956
4962,b'Add support for sessions to share a global threadpool',Software,closed,2020-08-28T20:07:10Z,2020-08-28 20:38:25+00:00,2020-08-28T21:20:11Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4962
4971,b'[WinML] [C++/WinRT] Clarify how to share Ort::Env environments with WinRT/WinML instances',Software,open,2020-08-29T08:56:18Z,2020-09-01 03:04:35+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/4971
4972,b'/usr/bin/ld: cannot find -lonnxruntime',Software,closed,2020-08-29T13:25:15Z,2020-08-29 14:16:06+00:00,2020-08-29T14:16:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4972
4974,b'onnx inferencesession load hangs with quartznet asr config. ',Software,closed,2020-08-30T13:14:01Z,2020-08-30 13:20:01+00:00,2020-08-30T13:20:01Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4974
4976,b'Using AAR on android gives java.lang.IllegalStateException: Unsupported arch:armv7l exception',Software,closed,2020-08-31T02:37:20Z,2020-08-31 03:23:33+00:00,2020-09-02T07:48:08Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/4976
4978,"b""[W:onnxruntime:, graph.cc:2709 CleanUnusedInitializers] Removing initializer 'features.6.out.8.num_batches_tracked'. It is not used by any node and should be removed from the model""",Software,closed,2020-08-31T09:02:28Z,2020-08-31 23:36:36+00:00,2020-11-16T03:48:02Z,0,76,https://api.github.com/repos/microsoft/onnxruntime/issues/4978
4980,b'onnxruntime tools + transformers + tensorflow: inference for optimized DistilBert fails',Software,closed,2020-08-31T15:37:06Z,2020-09-01 03:00:02+00:00,2020-09-11T18:46:32Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/4980
4985,b'Propagate the OrtRunOptions::training_mode value down into external providers',Software,closed,2020-08-31T22:16:59Z,2020-09-01 02:58:51+00:00,2020-11-16T03:48:14Z,0,76,https://api.github.com/repos/microsoft/onnxruntime/issues/4985
4992,b'RNN int8 support',Software,closed,2020-09-01T03:51:01Z,2020-09-01 04:09:07+00:00,2020-10-27T08:43:46Z,0,56,https://api.github.com/repos/microsoft/onnxruntime/issues/4992
4993,b'NNAPI on Android gives different output from the one that CPU gives',Software,closed,2020-09-01T03:51:54Z,2020-09-01 04:10:01+00:00,2020-09-02T03:27:39Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4993
4997,b'Unable to load model generated by tf2onnx ',Software,closed,2020-09-01T07:26:43Z,2020-09-01 08:27:19+00:00,2020-09-01T08:27:19Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4997
4998,b'Loading onnx model failed with Fatal error: max_pool2d is not a registered function/op',Software,closed,2020-09-01T08:10:49Z,2020-09-01 08:35:45+00:00,2020-09-01T08:35:53Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4998
4999,b'using float16 onnx model gives wrong predict results.',Software,closed,2020-09-01T08:13:47Z,2020-09-02 00:26:21+00:00,2020-09-02T00:26:21Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/4999
5001,b'tf_inception_v2  result mismatch',Software,closed,2020-09-01T10:47:51Z,2020-09-01 17:39:28+00:00,2021-03-19T00:17:11Z,0,198,https://api.github.com/repos/microsoft/onnxruntime/issues/5001
5003,b'ONNX Runtime Server Docker - Body Limit Issue',Software,open,2020-09-01T17:24:20Z,2020-09-01 23:50:00+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5003
5008,"b""error: 'once_flag' in namespace 'std' does not name a type""",Software,closed,2020-09-01T20:43:26Z,2020-09-02 04:01:51+00:00,2020-09-02T07:47:00Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5008
5011,"b""C Sharp API for openvino doesn't run on GPU""",Software,open,2020-09-01T21:25:29Z,2020-09-02 03:50:40+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5011
5019,"b'Build with OpenVINO Execution Provider Fails with 2020.3, 2020.4'",Software,closed,2020-09-02T04:02:53Z,2020-09-02 04:56:01+00:00,2021-03-19T00:26:56Z,0,197,https://api.github.com/repos/microsoft/onnxruntime/issues/5019
5020,b'onxruntime-gpu installation issues',Software,open,2020-09-02T05:49:10Z,2020-09-03 03:19:21+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5020
5024,"b'file INSTALL cannot find ""onnxruntime/cmake/../include/onnxruntime/core/providers/shared""'",Software,closed,2020-09-02T12:15:59Z,2020-09-02 13:40:40+00:00,2020-09-19T13:28:33Z,0,17,https://api.github.com/repos/microsoft/onnxruntime/issues/5024
5025,b'cpu float16 support',Software,closed,2020-09-02T12:42:43Z,2020-09-04 23:41:36+00:00,2020-10-27T08:43:35Z,2,54,https://api.github.com/repos/microsoft/onnxruntime/issues/5025
5029,"b'Cannot specify link options for target ""protoc"" which is not built by this project.'",Software,closed,2020-09-02T18:43:35Z,2020-09-02 19:39:15+00:00,2020-09-03T22:20:02Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/5029
5031,b'Missing plugin when building with LTO+CUDA',Software,closed,2020-09-02T19:34:38Z,2020-09-02 19:39:16+00:00,2020-11-16T03:47:57Z,0,74,https://api.github.com/repos/microsoft/onnxruntime/issues/5031
5034,b'Build nuget locally on Linux',Software,closed,2020-09-02T20:54:39Z,2020-09-02 20:57:43+00:00,2020-11-16T03:48:02Z,0,74,https://api.github.com/repos/microsoft/onnxruntime/issues/5034
5035,b'Duplicated onnx-ml',Software,open,2020-09-02T20:58:05Z,2020-09-02 22:15:30+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5035
5046,b'segmentation fault when infer with gpu',Software,closed,2020-09-03T03:23:58Z,2020-09-03 03:26:14+00:00,2020-12-24T11:39:23Z,0,112,https://api.github.com/repos/microsoft/onnxruntime/issues/5046
5047,b'Export set provider API in C++',Software,closed,2020-09-03T04:05:49Z,2020-09-03 09:34:38+00:00,2020-09-03T18:02:05Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5047
5048,b'c++ complie and run',Software,closed,2020-09-03T06:38:48Z,2020-09-03 06:59:58+00:00,2020-09-03T06:59:58Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5048
5049,b'Does custom_op_library support dynamic input of CustomOp?',Software,closed,2020-09-03T08:58:42Z,2020-09-09 01:07:30+00:00,2020-12-09T23:14:22Z,5,97,https://api.github.com/repos/microsoft/onnxruntime/issues/5049
5058,b'browserify difficulty?',Software,closed,2020-09-03T23:27:12Z,2020-09-05 00:35:14+00:00,2020-11-06T02:07:33Z,1,63,https://api.github.com/repos/microsoft/onnxruntime/issues/5058
5076,b'Inference by C++ GPU',Software,closed,2020-09-07T10:46:06Z,2020-09-08 18:54:09+00:00,2020-09-10T03:00:44Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/5076
5080,b'Read Access Violation error and application crash while inference from TreeEnsembleClassifier C++ APIs.',Software,closed,2020-09-08T10:52:58Z,2020-09-08 17:20:54+00:00,2021-02-19T04:49:02Z,0,163,https://api.github.com/repos/microsoft/onnxruntime/issues/5080
5081,b'Win10/VS2019: wil library compile error',Software,closed,2020-09-08T11:43:22Z,2020-09-08 17:24:09+00:00,2021-01-11T10:59:52Z,0,124,https://api.github.com/repos/microsoft/onnxruntime/issues/5081
5082,b'ONNXRuntime java library should include libgomp.so.1',Software,closed,2020-09-08T18:22:55Z,2020-09-08 18:54:31+00:00,2020-09-08T19:14:13Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5082
5093,b'program stucks when multi processes',Software,open,2020-09-09T08:21:57Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/5093
5099,b'Core Dump with Java API for BERT',Software,closed,2020-09-09T22:14:38Z,2020-09-09 22:52:14+00:00,2020-09-16T16:16:27Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/5099
5109,b'CalibrationDataReader does not have `datasize` field',Software,closed,2020-09-10T08:38:57Z,2020-09-12 03:56:51+00:00,2020-09-15T01:06:24Z,1,4,https://api.github.com/repos/microsoft/onnxruntime/issues/5109
5113,b' onnxruntime_tools optimize a transformer model',Software,closed,2020-09-10T11:55:06Z,2020-09-12 04:01:36+00:00,2020-12-24T11:39:24Z,1,104,https://api.github.com/repos/microsoft/onnxruntime/issues/5113
5115,b'DirectML build from source failed',Software,closed,2020-09-10T13:01:39Z,2020-09-10 18:22:18+00:00,2020-09-16T14:51:16Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/5115
5117,b'Clarity and API for flushing denormal values',Software,closed,2020-09-10T19:17:47Z,2020-09-11 00:18:08+00:00,2020-12-24T11:39:23Z,0,104,https://api.github.com/repos/microsoft/onnxruntime/issues/5117
622,b'[Performance] Any bench marking data or scripts available for ONNXRuntime ?',Software,closed,2019-03-14T04:32:39Z,2019-03-14 20:50:32+00:00,2019-04-02T03:36:43Z,0,18,https://api.github.com/repos/microsoft/onnxruntime/issues/622
624,b'unit test test_slice_default_axes_cpu from onnx is failing for the python bindings',Software,closed,2019-03-14T12:39:05Z,2019-03-14 20:52:29+00:00,2019-03-19T18:45:28Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/624
625,b'GPU performance (Was named: Cannot load onnxruntime.capi)',Software,closed,2019-03-14T15:29:03Z,2019-03-14 20:52:18+00:00,2019-04-22T23:44:17Z,0,39,https://api.github.com/repos/microsoft/onnxruntime/issues/625
626,"b'Tokenizer does not work if the regular expression includes \\b, \\w, \\d...'",Software,closed,2019-03-14T16:15:00Z,2019-03-14 20:53:03+00:00,2019-03-19T13:18:32Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/626
643,"b""python bindings: InferenceSession can't be pickled""",Software,closed,2019-03-16T21:15:53Z,2019-03-18 19:03:35+00:00,2019-12-18T18:23:41Z,1,276,https://api.github.com/repos/microsoft/onnxruntime/issues/643
648,"b""error: no matching function for call to 'OrtCreateSession'""",Software,closed,2019-03-18T12:04:20Z,2019-03-18 19:02:43+00:00,2019-03-29T07:21:12Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/648
649,b'failed:Type Error: Type parameter (T) bound to different types (tensor(float) and tensor(double) in node ().',Software,closed,2019-03-18T18:26:14Z,2019-03-18 18:34:57+00:00,2019-04-24T18:24:46Z,0,36,https://api.github.com/repos/microsoft/onnxruntime/issues/649
660,b'Which correct version of CUDA and cuDNN?',Software,closed,2019-03-20T07:12:46Z,2019-03-20 18:27:01+00:00,2019-03-25T02:56:51Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/660
661,b'CUDA 10.1 Linux Build failure: cannot call member function without object',Software,closed,2019-03-20T12:11:27Z,2019-03-20 23:19:52+00:00,2019-03-20T23:19:51Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/661
662,b'Faster way to get MKL',Software,closed,2019-03-20T13:33:17Z,2019-03-20 23:08:48+00:00,2019-06-28T20:45:20Z,0,100,https://api.github.com/repos/microsoft/onnxruntime/issues/662
663,b'Crash at the end of cmake config.',Software,closed,2019-03-20T13:43:37Z,2019-03-20 23:01:24+00:00,2019-04-22T07:22:45Z,0,32,https://api.github.com/repos/microsoft/onnxruntime/issues/663
664,"b'Nuget ""Part URI cannot start with two forward slashes.""'",Software,closed,2019-03-20T19:05:29Z,2019-03-20 22:58:33+00:00,2019-03-22T03:27:58Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/664
667,b'Support int32_t for Tile op',Software,closed,2019-03-20T23:45:05Z,2019-03-21 00:07:14+00:00,2019-03-26T05:50:17Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/667
673,b'Support different input types',Software,closed,2019-03-21T20:18:02Z,2019-03-21 22:18:30+00:00,2019-06-28T22:00:35Z,0,99,https://api.github.com/repos/microsoft/onnxruntime/issues/673
677,b'ONNX inference session consumes too much memory',Software,closed,2019-03-21T22:01:27Z,2019-03-21 22:12:11+00:00,2019-04-05T00:50:06Z,0,14,https://api.github.com/repos/microsoft/onnxruntime/issues/677
678,b'Add Transpose (Permute) operation',Software,closed,2019-03-21T22:03:36Z,2019-03-21 23:09:24+00:00,2019-03-23T02:50:25Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/678
679,b'Invalid Tracer Warning about tensor shape',Software,closed,2019-03-21T22:57:14Z,2019-03-22 22:32:21+00:00,2019-04-09T00:03:19Z,0,18,https://api.github.com/repos/microsoft/onnxruntime/issues/679
681,b'failed to concat a tensor with an empty tensor',Software,closed,2019-03-22T01:32:52Z,2019-03-26 19:09:40+00:00,2019-04-02T18:32:43Z,4,11,https://api.github.com/repos/microsoft/onnxruntime/issues/681
685,"b'What is, if any, the relationship between ONNX Runtime and ONNX IFI?'",Software,closed,2019-03-22T18:31:39Z,2019-03-22 22:16:30+00:00,2019-03-23T06:51:56Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/685
689,b'Error when build with protobuf 3.7',Software,closed,2019-03-22T21:29:31Z,2019-03-22 21:38:38+00:00,2019-03-22T21:38:38Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/689
691,b'Build error when switching off unit test.',Software,closed,2019-03-22T21:47:59Z,2019-03-22 22:27:14+00:00,2019-04-02T03:22:08Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/691
693,b'Support basic array output types',Software,closed,2019-03-22T21:57:30Z,2019-03-22 22:19:54+00:00,2019-03-27T20:54:26Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/693
697,b'Building from source Failed.',Software,closed,2019-03-23T15:16:38Z,2019-03-25 18:26:18+00:00,2019-04-26T22:08:52Z,2,34,https://api.github.com/repos/microsoft/onnxruntime/issues/697
698,b'Is TVMKernel working for onnx examples?',Software,closed,2019-03-23T21:17:33Z,2019-03-23 22:12:17+00:00,2019-03-23T22:12:17Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/698
699,b'Tests for ConvolutionTranspose3D are probably invalid.',Software,closed,2019-03-24T16:34:29Z,2019-04-05 18:53:02+00:00,2019-04-07T00:01:28Z,12,13,https://api.github.com/repos/microsoft/onnxruntime/issues/699
706,b'AsTensor is slower than AsEnumerable.ToArray',Software,closed,2019-03-26T01:12:10Z,2019-03-26 05:48:13+00:00,2019-04-05T02:02:50Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/706
709,b'cuda::Conv benchmarks convolution algorithms for every shape change',Software,closed,2019-03-26T15:14:24Z,2019-03-26 15:16:10+00:00,2019-04-16T05:15:15Z,0,20,https://api.github.com/repos/microsoft/onnxruntime/issues/709
713,b'Issue pinning large memory in C# (crash)',Software,closed,2019-03-26T19:19:34Z,2019-03-26 19:25:19+00:00,2020-09-16T20:35:24Z,0,540,https://api.github.com/repos/microsoft/onnxruntime/issues/713
5127,"b""Why CUDAExecutionProvider doesn't support ConvInteger Op?""",Software,open,2020-09-11T02:07:22Z,2020-09-11 03:46:11+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5127
5130,b'AssertionError when build python dml wheel',Software,closed,2020-09-11T13:54:53Z,2020-09-11 20:18:00+00:00,2020-09-11T23:40:04Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5130
5134,b'unable to use opencv2 with CPU image ',Software,closed,2020-09-11T19:36:48Z,2020-09-11 19:50:12+00:00,2020-09-11T19:50:12Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5134
5136,b'How to disable messages',Software,closed,2020-09-11T21:27:08Z,2020-09-11 23:30:52+00:00,2020-09-11T23:30:52Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5136
5143,b'How to load an ML model created in tensorflow model format in onnx java runtime',Software,closed,2020-09-13T08:31:03Z,2020-09-13 08:33:19+00:00,2021-03-19T00:26:54Z,0,186,https://api.github.com/repos/microsoft/onnxruntime/issues/5143
5145,b'TensorRT Windows build failed',Software,closed,2020-09-13T09:30:20Z,2020-09-14 21:29:46+00:00,2020-09-18T14:06:33Z,1,5,https://api.github.com/repos/microsoft/onnxruntime/issues/5145
5149,"b'If I have multiple GPUs, how can I choose any of them'",Software,closed,2020-09-14T09:07:20Z,2020-09-14 17:45:24+00:00,2020-10-14T09:03:51Z,0,29,https://api.github.com/repos/microsoft/onnxruntime/issues/5149
5151,"b'""Resize-11"" ops with  ""nearest neighbour"" mode have unexpected behavior'",Software,closed,2020-09-14T11:17:15Z,2020-09-14 23:27:43+00:00,2020-09-30T22:33:34Z,0,16,https://api.github.com/repos/microsoft/onnxruntime/issues/5151
5152,"b""DistilBERT: use_dynamic_axes doesn't work""",Software,open,2020-09-14T14:25:48Z,2020-09-14 14:25:49+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5152
5153,b'Ort::Session creates redundant threads when running with DirectML backend',Software,closed,2020-09-14T15:57:17Z,2020-09-14 20:47:22+00:00,2020-09-14T21:57:23Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5153
5164,b'[Feature Request] Dynamic gradient accumumaltion steps for Training',Software,closed,2020-09-14T22:50:19Z,2020-09-14 22:50:19+00:00,2020-12-24T11:39:27Z,0,100,https://api.github.com/repos/microsoft/onnxruntime/issues/5164
5165,b'[Feature Request] Optimizer parameters schedulers',Software,closed,2020-09-14T23:13:29Z,2020-09-14 23:13:30+00:00,2020-12-24T11:39:28Z,0,100,https://api.github.com/repos/microsoft/onnxruntime/issues/5165
5172,b'Java runtime with GraalVM build',Software,closed,2020-09-15T04:00:19Z,2020-09-15 04:10:27+00:00,2020-10-02T00:34:23Z,0,16,https://api.github.com/repos/microsoft/onnxruntime/issues/5172
5174,b'CPU QLinearConv supporting per-channel quantized weights',Software,closed,2020-09-15T07:02:42Z,2020-09-15 20:41:29+00:00,2020-09-15T20:41:29Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5174
5175,b'Segmentation error when using graph optimization',Software,open,2020-09-15T12:02:23Z,2020-09-15 21:36:22+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5175
5176,b'Possible Memory leak over released sessions',Software,closed,2020-09-15T14:22:03Z,2020-09-15 14:38:21+00:00,2020-10-05T01:13:30Z,0,19,https://api.github.com/repos/microsoft/onnxruntime/issues/5176
5187,b'AliasWithName is not a registered function',Software,closed,2020-09-16T01:35:09Z,2020-09-16 04:26:25+00:00,2021-03-19T00:26:53Z,0,183,https://api.github.com/repos/microsoft/onnxruntime/issues/5187
5188,b'For loop bad performance',Software,closed,2020-09-16T03:00:24Z,2020-09-16 03:27:33+00:00,2020-09-25T07:00:20Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/5188
5189,b'InvalidGraph Error onnxruntime.InferenceSession Converted from TensorFlow MobilenetV3',Software,closed,2020-09-16T05:38:42Z,2020-09-17 20:51:31+00:00,2020-09-22T18:26:23Z,1,6,https://api.github.com/repos/microsoft/onnxruntime/issues/5189
5192,b'Yolov3 wrong output from C API',Software,closed,2020-09-16T09:21:05Z,2020-09-17 08:35:47+00:00,2020-09-17T08:35:47Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5192
5193,b'Inference performances decrease with number of cpus used.',Software,closed,2020-09-16T12:10:30Z,2020-09-16 16:27:41+00:00,2021-02-10T01:30:41Z,0,146,https://api.github.com/repos/microsoft/onnxruntime/issues/5193
5195,b'Segmentation fault while training mnist',Software,closed,2020-09-16T17:20:18Z,2020-09-16 23:07:31+00:00,2020-09-17T15:14:17Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5195
5197,b'DirectML Runtime error during prediction',Software,closed,2020-09-16T20:12:25Z,2020-09-17 20:58:27+00:00,2021-02-12T03:51:58Z,1,148,https://api.github.com/repos/microsoft/onnxruntime/issues/5197
5198,b'Build using tensorrt for c# failing',Software,closed,2020-09-16T21:36:06Z,2020-09-17 20:58:48+00:00,2020-09-18T19:16:29Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/5198
5206,b'c api is about 2.3 times slower than python api',Software,closed,2020-09-17T15:26:11Z,2020-09-17 21:00:56+00:00,2021-03-19T00:11:47Z,0,182,https://api.github.com/repos/microsoft/onnxruntime/issues/5206
5211,b'INT8 inference with TensorRT provider ',Software,closed,2020-09-17T19:10:10Z,2020-09-17 21:03:20+00:00,2020-09-18T15:04:15Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5211
5212,b'TensoRT build.sh fails due to missing CMakeLists.txt',Software,closed,2020-09-17T19:54:24Z,2020-09-17 21:00:32+00:00,2020-09-18T15:04:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5212
5221,b'Build Error with OpenVINO build_shared_lib   ',Software,closed,2020-09-18T08:51:04Z,2020-09-18 12:50:38+00:00,2021-03-19T00:26:52Z,0,181,https://api.github.com/repos/microsoft/onnxruntime/issues/5221
5231,b'Cannot use dynamic quantization in nightly repo',Software,closed,2020-09-20T09:08:58Z,2020-09-20 09:18:28+00:00,2020-09-20T09:18:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5231
5232,b'OnnxRuntime_test_all fails when building with TensorRT ',Software,closed,2020-09-21T01:16:31Z,2020-09-21 16:54:30+00:00,2020-11-09T18:51:21Z,0,49,https://api.github.com/repos/microsoft/onnxruntime/issues/5232
5234,"b'\xe4\xbd\xbf\xe7\x94\xa8onnxruntime_cxx_api.\xe8\xae\xbe\xe7\xbd\xae\xe4\xba\x86\xe5\xa4\x9a\xe7\xba\xbf\xe7\xa8\x8b,\xe5\xbd\x93\xe5\x90\x8c\xe6\x97\xb6\xe4\xbd\xbf\xe7\x94\xa8fasterrcnn\xe5\x92\x8cyolov3\xe6\x97\xb6\xe5\x80\x99\xe4\xbc\x9a\xe6\x8a\xa5\xe9\x94\x99.'",Software,closed,2020-09-21T10:39:49Z,2020-09-21 15:59:47+00:00,2020-09-23T00:44:17Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/5234
5235,b'Website not working in China',Documentation,closed,2020-09-21T13:38:15Z,2020-09-21 22:06:44+00:00,2021-03-12T19:34:31Z,0,172,https://api.github.com/repos/microsoft/onnxruntime/issues/5235
5242,b'Different inference results between 1.4.0 and 1.0.0',Documentation,closed,2020-09-21T20:27:41Z,2020-09-21 21:52:21+00:00,2020-09-21T21:52:21Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5242
5243,b'Wrong Type for C.InferenceSession()',Documentation,closed,2020-09-21T23:48:27Z,2020-09-22 06:45:46+00:00,2020-10-03T00:25:47Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/5243
5247,b'lp_norm CPU operator leaves output element uninitialized when 0 norm.',Software,closed,2020-09-22T03:15:38Z,2020-09-22 18:25:17+00:00,2020-09-23T05:01:10Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/5247
5249,b'Conv transpose not supported',Software,closed,2020-09-22T07:46:10Z,2020-09-22 11:41:14+00:00,2020-09-22T11:41:14Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5249
5250,b'Exception thrown from Dispose method (When missing dependency)',Software,open,2020-09-22T13:10:41Z,2020-09-23 20:51:04+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/5250
5253,"b'Poor Performance on  bit/m-r101x1 (TF=275ms, ONNX=598ms)'",Software,closed,2020-09-22T21:26:50Z,2020-09-23 19:25:09+00:00,2021-01-13T03:08:40Z,0,112,https://api.github.com/repos/microsoft/onnxruntime/issues/5253
5260,b'NNAPI execution provider fails on Android App',Software,closed,2020-09-23T01:35:09Z,2020-09-23 01:35:33+00:00,2020-09-23T06:25:55Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5260
5267,b'Release supporting CUDA 11',Software,open,2020-09-23T08:15:21Z,2020-09-23 08:16:01+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5267
5268,b'Onnxruntime failed on the torch.mean function',Software,closed,2020-09-23T12:38:35Z,2020-10-02 00:30:33+00:00,2020-11-30T06:13:27Z,8,67,https://api.github.com/repos/microsoft/onnxruntime/issues/5268
5270,b'`make install` does not install `libonnxruntime_providers_shared.so` and `libonnxruntime_providers_tensorrt.so`',Software,closed,2020-09-23T18:06:48Z,2020-09-23 19:26:05+00:00,2020-10-07T20:06:39Z,0,14,https://api.github.com/repos/microsoft/onnxruntime/issues/5270
5271,b'C++ API Failing to create Tensor with dim =-1',Software,closed,2020-09-23T18:59:10Z,2020-09-23 21:59:33+00:00,2020-09-24T20:22:33Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/5271
5282,"b'Error ""no kernel image is available for execution on the device"" raised on Jetson axvier nx'",Software,closed,2020-09-24T07:31:30Z,2020-09-28 05:19:33+00:00,2021-03-19T00:26:52Z,3,175,https://api.github.com/repos/microsoft/onnxruntime/issues/5282
5283,b'Cannot install onnxruntime with pip/python2',Software,closed,2020-09-24T12:18:39Z,2020-10-02 00:30:15+00:00,2020-11-06T02:02:50Z,7,42,https://api.github.com/repos/microsoft/onnxruntime/issues/5283
5284,"b""Unable to load DLL 'onnxruntime'""",Software,closed,2020-09-24T14:38:21Z,2020-10-02 00:30:51+00:00,2021-03-19T00:26:51Z,7,175,https://api.github.com/repos/microsoft/onnxruntime/issues/5284
5292,b'Memory increases without limit while in an infference session.',Software,closed,2020-09-25T10:06:39Z,2020-09-25 17:29:38+00:00,2020-10-06T15:52:38Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/5292
5295,b'DLRM model failure to execute on GPU',Software,open,2020-09-25T22:03:12Z,2020-09-28 04:39:59+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/5295
5297,b'Build failure when building master branch on Windows',Software,closed,2020-09-25T22:23:35Z,2020-09-26 03:05:58+00:00,2020-09-28T16:14:11Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/5297
5299,b'Onnx GPU runtime fails to fallback to CPU when GPU is not available OR busy.',Software,closed,2020-09-25T22:51:07Z,2020-09-26 00:48:31+00:00,2020-10-05T22:09:48Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/5299
5319,b'Static quantized resnet is slower than the raw one',Software,open,2020-09-29T03:27:35Z,2020-09-29 17:43:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5319
5320,b'Segmentation fault when running a session as attribute of a class',Software,closed,2020-09-29T03:40:20Z,2020-09-29 03:50:05+00:00,2020-09-29T21:17:52Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5320
5322,"b'Conflicts between ""--minimal_build"" and ""--use_nnapi""'",Software,closed,2020-09-29T08:23:39Z,2020-09-29 22:12:58+00:00,2020-09-30T02:35:38Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5322
5329,b'Error while loading large model (protobug > 2 Gb) in C#',Software,closed,2020-09-29T22:09:57Z,2020-09-29 22:18:24+00:00,2021-03-19T00:26:48Z,0,170,https://api.github.com/repos/microsoft/onnxruntime/issues/5329
5336,"b'Build error ""No Cuda toolset found"" on Windows 10'",Software,closed,2020-09-30T12:22:55Z,2020-10-01 05:03:40+00:00,2020-10-01T20:42:00Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/5336
5337,b'onnxruntime runs inference on CPU even though GPU is available',Software,closed,2020-09-30T13:42:36Z,2020-10-01 09:01:04+00:00,2020-10-01T09:01:04Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5337
5341,b'Can no longer import onnxruntime inside of google colab.',Software,closed,2020-10-01T00:05:40Z,2020-10-01 18:05:23+00:00,2020-10-02T19:56:56Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/5341
5344,"b'""ImportError: cannot import name \'get_all_providers\'"" for macOS in TravisCI after 1.5.1 update'",Software,closed,2020-10-01T03:50:39Z,2020-10-01 05:10:50+00:00,2020-10-01T13:54:41Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5344
5347,b'Not compiling for arm7 32bit',Software,closed,2020-10-01T16:38:43Z,2020-10-01 17:26:05+00:00,2020-10-01T17:26:21Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5347
5348,b'[Dockerfile] Recommendation to remove the old way to include miniconda in PATH.',Software,open,2020-10-01T16:40:15Z,2020-10-01 18:05:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5348
5351,b'Exception error with Tensorrt Execution Provider on Windows',Software,closed,2020-10-01T19:31:32Z,2020-10-01 23:35:18+00:00,2020-10-02T08:55:22Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5351
5355,b'Suggestion: Add note about OpenMP on Mac to 1.5.1 release notes',Software,closed,2020-10-01T23:19:58Z,2020-10-01 23:33:56+00:00,2020-10-01T23:33:56Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5355
5358,b'Run onnxruntime_perf_test with different batch sizes and different precisions with TensorRT execution engine',Software,closed,2020-10-02T01:52:31Z,2020-10-02 01:53:51+00:00,2020-10-12T22:06:10Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/5358
5359,b'Running quantized models on GPU',Software,open,2020-10-02T03:06:28Z,2020-10-02 17:04:20+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5359
5363,b'Multiple Inference sessions slows down inference speed',Software,closed,2020-10-02T16:29:05Z,2020-10-02 16:29:33+00:00,2020-10-13T22:10:19Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/5363
5369,b'New libomp dependency conflicts with other libs',Software,closed,2020-10-04T09:16:04Z,2020-10-05 07:14:47+00:00,2020-10-05T19:10:20Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/5369
5379,b'failed to Load TinyYolo Onnx model in OnnxRuntime',Software,closed,2020-10-05T20:44:11Z,2020-10-05 22:26:36+00:00,2021-03-19T00:26:47Z,0,164,https://api.github.com/repos/microsoft/onnxruntime/issues/5379
5384,b'ORT 1.5.1 TensorRT EP segfault on unloading shared library',Software,closed,2020-10-06T03:20:58Z,2020-10-06 03:46:42+00:00,2020-11-09T23:39:39Z,0,34,https://api.github.com/repos/microsoft/onnxruntime/issues/5384
5387,b'Pre-built release files are missing an include',Software,closed,2020-10-06T18:20:49Z,2020-10-06 19:40:21+00:00,2020-10-08T22:00:30Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/5387
5389,b'Add DirectML support to WinML NuGet package for UWP',Software,closed,2020-10-06T19:14:27Z,2020-10-07 17:46:16+00:00,2021-06-17T20:49:32Z,0,254,https://api.github.com/repos/microsoft/onnxruntime/issues/5389
5398,"b'""error: no member named \'runtime_error\' in namespace \'std\'"" when building MLAS with MLAS_NO_ONNXRUNTIME_THREADPOOL'",Software,closed,2020-10-07T12:13:43Z,2020-10-07 15:34:49+00:00,2020-10-07T15:34:49Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5398
5409,"b""Can't find the required module in import statement""",Software,closed,2020-10-08T06:21:27Z,2020-10-08 06:29:31+00:00,2021-03-19T00:26:46Z,0,161,https://api.github.com/repos/microsoft/onnxruntime/issues/5409
5414,b'Optimizing BART: encoder/decoder attention',Software,open,2020-10-08T14:53:48Z,2020-10-08 16:12:40+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5414
5418,b'Model with External Data cannot be loaded in Windows when path has forward slash (/)',Software,open,2020-10-08T18:33:24Z,2020-10-08 21:11:18+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5418
5422,b'ONNX operator set version: 12 is unsupported. Falling back to: 11',Software,closed,2020-10-08T20:26:14Z,2020-10-08 21:10:00+00:00,2021-03-19T00:26:45Z,0,161,https://api.github.com/repos/microsoft/onnxruntime/issues/5422
5434,b'Default order of Execution Provider ',Software,closed,2020-10-09T10:18:10Z,2020-10-09 18:11:14+00:00,2020-10-14T03:30:02Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/5434
5435,b'Unsupported OpenVINO version on Windows when shortcut is used',Software,open,2020-10-09T11:51:45Z,2020-10-09 18:15:07+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5435
5447,"b""no file named 'ort_model.py' in pytorch_transformer sample""",Software,closed,2020-10-10T09:29:20Z,2020-10-12 17:32:40+00:00,2020-10-13T00:53:10Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/5447
5448,b'What is the best way to allocate cuda buffer in custom op?',Software,closed,2020-10-10T10:46:53Z,2020-10-12 17:33:01+00:00,2021-02-25T01:26:19Z,2,137,https://api.github.com/repos/microsoft/onnxruntime/issues/5448
5449,"b""C#: Unable to load DLL 'onnxruntime' on server without Visual Studio installed""",Software,closed,2020-10-11T00:03:01Z,2020-10-11 00:37:58+00:00,2020-10-11T00:37:58Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5449
5450,b'Results Mismatch between XGBoost Model and ONNX Runtime when eval_set parameter is passed in model.fit method',Software,open,2020-10-12T06:47:08Z,2020-10-12 17:35:15+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5450
5458,b'cannot replicate BERT quantization performance',Software,closed,2020-10-12T20:42:24Z,2020-10-12 22:56:40+00:00,2020-11-04T05:34:39Z,0,22,https://api.github.com/repos/microsoft/onnxruntime/issues/5458
5460,b'onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 ',Software,closed,2020-10-12T21:54:26Z,2020-10-12 22:58:18+00:00,2020-10-12T23:03:13Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5460
5467,b'Cannot install onnxruntime with pip3/python3',Software,closed,2020-10-13T03:32:50Z,2020-10-13 04:54:44+00:00,2020-10-13T04:54:44Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5467
5470,"b""KernelInfoGetAttribute doesn't support returning vector of string/float/int64_t""",Software,closed,2020-10-13T11:22:00Z,2020-10-13 18:58:47+00:00,2022-01-04T03:10:22Z,0,447,https://api.github.com/repos/microsoft/onnxruntime/issues/5470
5471,b'onnxruntime.InferenceSession gets stuck on loading a specific model',Software,closed,2020-10-13T15:08:34Z,2020-10-13 18:02:00+00:00,2021-10-27T19:04:26Z,0,379,https://api.github.com/repos/microsoft/onnxruntime/issues/5471
5472,b'PyTorch model 10x slower on CPU provider when exported with pre-trained weights',Software,closed,2020-10-13T15:14:49Z,2020-10-13 19:06:48+00:00,2020-10-13T19:45:52Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5472
5473,"b'Poor Performance on imagenet/nasnet_mobile/classification (TF=58ms, ONNX=92ms)'",Software,closed,2020-10-13T18:47:28Z,2020-10-13 19:10:17+00:00,2021-01-13T03:08:22Z,0,91,https://api.github.com/repos/microsoft/onnxruntime/issues/5473
5483,b'win7 use onnxruntime',Software,closed,2020-10-14T05:15:08Z,2020-10-14 17:46:30+00:00,2020-10-14T18:49:57Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5483
5486,b'Image Tensor conversion',Software,closed,2020-10-14T17:40:32Z,2020-10-14 17:47:37+00:00,2021-03-19T00:26:44Z,0,155,https://api.github.com/repos/microsoft/onnxruntime/issues/5486
5489,b'How to define a string input to the exported onnx model?',Software,closed,2020-10-14T20:00:12Z,2020-10-16 22:19:44+00:00,2020-10-19T21:56:37Z,2,5,https://api.github.com/repos/microsoft/onnxruntime/issues/5489
5495,"b'ORT Mobile new feature missing in v1.5.1 ""convert_onnx_model_to_ort.py""'",Software,closed,2020-10-15T02:46:24Z,2020-10-16 04:44:25+00:00,2020-10-17T00:41:19Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/5495
5496,b'IF operator get unexpected outputs',Software,closed,2020-10-15T07:27:07Z,2020-10-15 07:27:35+00:00,2020-10-16T07:16:15Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5496
5497,b'Is there a simple demo of python example about tensorRT as the execution engine of onnxruntime?',Software,closed,2020-10-15T09:27:18Z,2020-10-16 22:25:55+00:00,2020-11-11T13:06:00Z,1,27,https://api.github.com/repos/microsoft/onnxruntime/issues/5497
5498,"b'Windows 10 compilation fails, there is a problem with the path?'",Software,closed,2020-10-15T09:37:29Z,2020-10-16 02:59:43+00:00,2020-10-16T02:59:43Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5498
5499,b'Augmented nodes in calibration for static quantization returning float when something expects int64',Software,closed,2020-10-15T10:53:35Z,2020-10-16 22:26:29+00:00,2020-11-24T19:14:42Z,1,40,https://api.github.com/repos/microsoft/onnxruntime/issues/5499
5512,"b'[C++]In 1.5.1, is there any way to set cuda/cpu?'",Software,closed,2020-10-16T08:05:32Z,2020-10-16 22:27:20+00:00,2021-03-19T00:26:42Z,0,153,https://api.github.com/repos/microsoft/onnxruntime/issues/5512
5522,b'Convert to mobile Error: Onnxruntime_test_all (Failed) - Tests Fail',Software,closed,2020-10-17T00:52:02Z,2020-10-17 13:03:28+00:00,2020-10-22T02:03:28Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/5522
5526,b'Core dumped error',Software,closed,2020-10-17T15:25:21Z,2020-10-17 18:02:35+00:00,2020-10-17T22:26:15Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5526
5528,b'Set provider with openvino',Software,closed,2020-10-18T02:11:00Z,2020-10-19 17:18:55+00:00,2021-01-05T09:34:56Z,1,79,https://api.github.com/repos/microsoft/onnxruntime/issues/5528
5532,b'Is there a problem with the python onnxruntime-gpu installation package?',Software,closed,2020-10-19T02:05:13Z,2020-10-19 17:21:45+00:00,2020-10-20T13:52:49Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/5532
5533,"b""ImportError: cannot import name 'get_all_providers' from 'onnxruntime.capi._pybind_state' on win10""",Software,closed,2020-10-19T02:44:37Z,2020-10-19 08:04:54+00:00,2020-10-19T18:44:25Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5533
5534,b'Fail: [ONNXRuntimeError] : 1 : FAIL : Type Error: Type parameter (T) bound to different types (tensor(float) and tensor(int64) in node (742_zero_point_Sub).',Software,closed,2020-10-19T05:08:36Z,2020-10-19 08:05:35+00:00,2020-10-23T18:52:49Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/5534
5538,"b'Poor Performance on nq model (TF=3434ms, ONNX=6226ms)'",Software,closed,2020-10-19T19:14:54Z,2020-10-19 21:22:26+00:00,2021-01-13T03:08:12Z,0,85,https://api.github.com/repos/microsoft/onnxruntime/issues/5538
5539,b'Unsupported Squeeze node',Software,closed,2020-10-19T22:02:59Z,2020-10-19 22:50:51+00:00,2021-03-19T00:26:40Z,0,150,https://api.github.com/repos/microsoft/onnxruntime/issues/5539
5548,b'UpsampleBase const scale >= 1 was false. Scale value should be greater than or equal to 1.',Software,closed,2020-10-20T10:55:22Z,2020-10-20 11:22:42+00:00,2020-10-21T17:42:19Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/5548
5549,b'Python inference with dropout',Software,closed,2020-10-20T11:49:49Z,2020-10-21 17:54:51+00:00,2021-03-19T00:26:38Z,1,149,https://api.github.com/repos/microsoft/onnxruntime/issues/5549
5552,"b'Advertized compatibility with Tensorflow, Keras, Caffe, etc'",Software,closed,2020-10-20T17:51:14Z,2020-10-21 16:55:57+00:00,2021-03-19T00:26:38Z,0,149,https://api.github.com/repos/microsoft/onnxruntime/issues/5552
5555,b'Cuda Memory Allocation throws error on Session->Run',Software,closed,2020-10-20T21:39:33Z,2020-10-21 18:09:13+00:00,2020-10-26T08:26:26Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/5555
5558,b'Can Session::Run be const?',Software,open,2020-10-21T01:38:28Z,2020-10-22 04:35:55+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/5558
5560,b'For weight input',Software,closed,2020-10-21T08:56:30Z,2020-10-22 04:38:35+00:00,2020-10-22T07:59:23Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5560
5561,b'Android Build Failed',Software,closed,2020-10-21T12:42:45Z,2020-10-22 04:39:55+00:00,2020-10-27T18:07:55Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/5561
5565,b'cuda error with docker',Software,closed,2020-10-22T05:49:02Z,2020-10-22 09:00:50+00:00,2020-10-22T09:00:50Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5565
5577,b'How to use batchsize in onnxruntime?',Software,closed,2020-10-23T03:03:54Z,2020-10-23 03:31:06+00:00,2021-03-19T00:07:31Z,0,146,https://api.github.com/repos/microsoft/onnxruntime/issues/5577
5578,b'Is OnnxRt support sparse tensor input?',Software,open,2020-10-23T03:12:24Z,2020-10-23 07:24:22+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5578
5581,b'onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Load model from fastwave.onnx failed:Type Error: Type parameter (T) bound to different types (tensor(double) and tensor(float) in node ().',Software,closed,2020-10-23T06:56:14Z,2020-10-26 18:51:29+00:00,2021-03-19T00:26:37Z,3,146,https://api.github.com/repos/microsoft/onnxruntime/issues/5581
5582,b'How to set the input of multi input network\xef\xbc\x9f',Documentation,closed,2020-10-23T06:56:42Z,2020-10-23 22:58:14+00:00,2020-10-26T07:26:54Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/5582
5585,b'`constant_subexpression_elimination` not comparing initializer values',Software,closed,2020-10-24T06:10:03Z,2020-10-26 18:35:13+00:00,2021-03-19T00:26:36Z,2,145,https://api.github.com/repos/microsoft/onnxruntime/issues/5585
5586,b'Static quantization of a model fails while accessing attributes of a Clip node',Software,closed,2020-10-25T13:42:37Z,2020-10-25 16:27:25+00:00,2021-02-09T02:51:11Z,0,106,https://api.github.com/repos/microsoft/onnxruntime/issues/5586
5587,b'example on loading an ONNX File as embeded Resource on C#.',Software,open,2020-10-25T15:51:04Z,2020-10-26 16:36:18+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/5587
5593,b'ML.NET issue while Using yolov4 onnx model',Software,open,2020-10-26T19:06:17Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/5593
5597,b'Passing Non-Const pointer to Session::Run() using CPP Api',Software,open,2020-10-26T22:44:24Z,2020-10-26 23:07:19+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5597
5600,b'Unstable inference results with c++',Software,closed,2020-10-27T08:39:24Z,2020-10-29 04:25:30+00:00,2020-11-13T08:43:11Z,1,17,https://api.github.com/repos/microsoft/onnxruntime/issues/5600
5601,b'TensorRT engine file model is slower than onnx',Software,closed,2020-10-27T09:01:00Z,2020-10-28 16:59:22+00:00,2020-11-03T08:09:33Z,1,6,https://api.github.com/repos/microsoft/onnxruntime/issues/5601
5615,b'Using DNNL is slower',Software,closed,2020-10-28T10:24:06Z,2020-10-28 16:58:42+00:00,2020-10-29T02:09:15Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5615
5617,"b""ValueError: DmlExecutionProvider does not contain a subset of available providers ['CPUExecutionProvider', 'DmlExecutionProvider']""",Software,closed,2020-10-28T13:00:30Z,2020-10-28 16:57:11+00:00,2021-02-10T01:31:10Z,0,104,https://api.github.com/repos/microsoft/onnxruntime/issues/5617
5618,b'[Java] Cannot create large OnnxTensor ',Software,closed,2020-10-28T17:16:38Z,2020-10-28 17:30:27+00:00,2020-11-05T23:02:42Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/5618
5625,"b""cmake/external/eigen @ d10b27f  doesn't exist""",Software,closed,2020-10-29T02:59:01Z,2020-10-29 03:05:29+00:00,2020-10-29T03:05:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5625
5629,b'Prerequisites on building on Jetson devices',Software,open,2020-10-29T14:50:48Z,2020-10-29 15:07:33+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5629
5630,b'Segmentation Fault on session.Run() with custom model on c++ API',Software,closed,2020-10-29T16:39:44Z,2020-10-29 19:55:10+00:00,2020-10-30T01:23:15Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5630
5638,b'tacotron2/waveglow onnx model can not inference with onnxruntime',Software,closed,2020-10-30T03:19:42Z,2020-10-30 07:52:11+00:00,2020-10-30T07:52:10Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5638
5643,"b'  When using onnxruntime to load the ONNX model, the following error is reported:'",Software,closed,2020-10-30T07:26:36Z,2020-11-02 19:01:43+00:00,2020-11-02T19:01:43Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/5643
5644,b'Quantize bert sample code seem to be wrong.',Software,open,2020-10-30T08:57:56Z,2020-11-02 19:00:48+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/5644
5645,b'Can not build with TensorRT 7.2.1 and 7.1.3 on Windows',Software,closed,2020-10-30T10:20:05Z,2020-10-30 17:18:09+00:00,2020-10-30T20:43:45Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5645
5646,b'Runtime error when converting T5 decoder with multiple dynamic axes inputs',Software,closed,2020-10-30T12:01:10Z,2020-11-03 00:22:29+00:00,2020-11-30T20:13:37Z,3,31,https://api.github.com/repos/microsoft/onnxruntime/issues/5646
5657,b'Getting wrong results with the C++ API; Where did I make a mistake?',Software,closed,2020-11-01T20:53:31Z,2020-11-03 00:21:57+00:00,2020-11-03T09:53:38Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/5657
5667,b'Different results on different computers.',Software,closed,2020-11-02T19:37:59Z,2020-11-02 19:50:42+00:00,2020-11-02T19:50:42Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5667
5670,b'error C2014: preprocessor command must start as first nonwhite space',Software,closed,2020-11-03T00:18:03Z,2020-11-03 14:22:19+00:00,2020-11-03T14:22:19Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5670
5672,b'quantized gpt2 model output seem to be wrong when batch size > 1',Software,closed,2020-11-03T01:32:54Z,2020-11-03 06:15:32+00:00,2020-11-04T05:34:00Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/5672
5673,b'Compile error in C++ API header',Software,closed,2020-11-03T02:18:42Z,2020-11-03 06:15:13+00:00,2021-06-30T17:02:08Z,0,239,https://api.github.com/repos/microsoft/onnxruntime/issues/5673
5674,b'Different inference results with c++ & python (gpu)',Software,closed,2020-11-03T02:25:45Z,2020-11-03 06:15:25+00:00,2020-11-05T09:51:19Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/5674
5679,b'What datatype should be used for float16 in C++?',Software,closed,2020-11-03T13:53:43Z,2020-11-03 20:36:04+00:00,2020-11-06T20:45:05Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/5679
5681,b'The README file in this repo has a bad link - [404:NotFound]',Documentation,closed,2020-11-03T18:00:28Z,2020-11-03 22:20:59+00:00,2020-11-06T02:01:10Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/5681
5696,b'Pow operator fails to support mixed types for base and power for opset 11',Documentation,closed,2020-11-04T14:29:03Z,2020-11-04 14:31:56+00:00,2020-11-04T14:33:20Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5696
5697,b'Lack of support for Windows/CUDA in Python 3.8 and 3.9',Software,closed,2020-11-04T16:08:07Z,2020-11-04 16:25:40+00:00,2021-02-21T23:11:28Z,0,109,https://api.github.com/repos/microsoft/onnxruntime/issues/5697
5708,b'onnxruntime inference quantized-onnx model is very slow?',Software,closed,2020-11-05T07:43:10Z,2020-11-06 01:56:55+00:00,2020-11-09T14:36:07Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/5708
5709,"b'TRT FP16 compilation fails on SSD model ""could not build engine for fused node""'",Software,closed,2020-11-05T08:52:35Z,2020-11-09 20:34:12+00:00,2022-04-19T14:56:11Z,4,530,https://api.github.com/repos/microsoft/onnxruntime/issues/5709
5711,b'How to reduce memory used?',Software,open,2020-11-05T09:16:16Z,2020-11-09 20:33:29+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/5711
5712,"b'Build onnxruntime on Raspberry Pi2 (x86, armv7l)!'",Software,closed,2020-11-05T10:42:21Z,2020-11-06 01:38:54+00:00,2020-11-06T01:38:54Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5712
5715,b'Op in first training step is much slower',Software,closed,2020-11-05T22:08:12Z,2020-11-05 23:18:29+00:00,2021-02-10T01:32:33Z,0,96,https://api.github.com/repos/microsoft/onnxruntime/issues/5715
5723,b'How graph partition based on provider and assign execution to provider implemented in source code?',Software,closed,2020-11-06T12:05:54Z,2020-11-06 12:06:17+00:00,2020-11-11T00:40:56Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/5723
5726,b'Please help us improve ONNX Runtime by participating in our survey',Software,closed,2020-11-06T19:30:05Z,2020-11-06 19:30:27+00:00,2021-02-10T01:17:25Z,0,95,https://api.github.com/repos/microsoft/onnxruntime/issues/5726
5735,b'coding bug',Software,closed,2020-11-09T02:20:53Z,2020-11-09 19:17:27+00:00,2021-02-12T04:02:23Z,0,95,https://api.github.com/repos/microsoft/onnxruntime/issues/5735
5747,b'Quantization for LSTM',Software,closed,2020-11-10T07:35:56Z,2020-11-10 18:11:22+00:00,2020-11-24T19:13:58Z,0,14,https://api.github.com/repos/microsoft/onnxruntime/issues/5747
5749,b'openvino build failed nuget',Software,open,2020-11-10T09:05:14Z,2020-11-10 09:05:14+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5749
5754,b'U8S8 QLinearMatMul NOT_IMPLEMENTED',Software,closed,2020-11-10T17:28:37Z,2020-11-10 18:28:10+00:00,2020-11-23T20:04:33Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/5754
5765,b'Complete example to use yolov3.onnx model for inference',Software,closed,2020-11-11T02:31:28Z,2020-11-11 18:27:48+00:00,2021-03-19T00:06:55Z,0,127,https://api.github.com/repos/microsoft/onnxruntime/issues/5765
5769,"b'The same input, sometimes the output is different'",Software,closed,2020-11-11T10:39:36Z,2020-11-11 18:34:14+00:00,2020-12-29T12:41:50Z,0,48,https://api.github.com/repos/microsoft/onnxruntime/issues/5769
5780,b'IR_VERSION and Opset Versions support via C API',Software,open,2020-11-12T07:11:31Z,2020-11-12 07:13:38+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5780
5781,"b'How to loading a pytorch model with input shape of (None, 32) using the C# inference ? '",Software,open,2020-11-12T07:14:20Z,2020-11-12 07:18:07+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5781
5782,b'Any support for double type tensor when loading pytorch onnx model ?',Software,open,2020-11-12T07:39:08Z,2020-11-12 18:39:40+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5782
5783,"b'Build with DNNL execution provider failing on macOS, but working on Linux'",Software,open,2020-11-12T08:01:26Z,2020-11-12 18:48:36+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5783
5784,b'Any suggestions to speed up onnx model inference speed ?',Software,closed,2020-11-12T08:27:15Z,2020-11-12 18:50:34+00:00,2020-11-17T09:10:36Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/5784
5785,b'Inputs with UINT8 should fallback to CUDA instead of failing to compile with TRT execution provider',Software,open,2020-11-12T12:49:48Z,2020-11-12 18:53:03+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5785
5786,"b'Building with ""--minimal_build"" fails'",Software,closed,2020-11-12T13:28:12Z,2020-11-12 19:08:23+00:00,2021-05-01T00:31:49Z,0,169,https://api.github.com/repos/microsoft/onnxruntime/issues/5786
5796,b'memory keep increasing with dynamic input shape of network',Software,open,2020-11-13T03:28:11Z,2020-11-13 19:13:55+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5796
5797,"b'There is a vulnerability in mysql-connector-java 8.0.16,upgrade recommended'",Software,closed,2020-11-13T06:06:46Z,2020-11-13 17:46:22+00:00,2020-11-16T22:09:22Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/5797
5798,b'Different output when running on CUDA (compared to CPU and keras)',Software,open,2020-11-13T08:01:12Z,2020-11-13 18:47:39+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5798
5801,b'Memory usage with Cuda ExecutionProvider',Software,open,2020-11-13T13:16:55Z,2020-11-13 19:16:30+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5801
5819,b' index: 1 Got: 3 Expected: 416  index: 3 Got: 416 Expected: 3  Please fix either the inputs or the model.',Software,closed,2020-11-16T03:51:04Z,2020-11-16 18:02:18+00:00,2020-11-23T21:51:00Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/5819
5825,b'onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : The node is not placed on any Execution Provider. OneHot(11) (node while/cond_5/one_hot). ',Software,open,2020-11-17T02:25:10Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/5825
5829,"b'""npm install"" throws an error. Can not install onnxruntime for nodejs'",Software,closed,2020-11-17T06:56:45Z,2020-11-17 07:08:34+00:00,2021-02-05T01:07:06Z,0,79,https://api.github.com/repos/microsoft/onnxruntime/issues/5829
5830,b'Non-zero status code returned while running Div node',Software,open,2020-11-17T08:11:58Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/5830
5832,b'arm64v8-cuda dockerfiles',Software,closed,2020-11-17T12:19:22Z,2020-11-20 14:59:59+00:00,2020-11-20T14:59:59Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/5832
5834,b'Performance comparison',Software,open,2020-11-17T14:02:06Z,2020-11-23 21:29:15+00:00,,6,,https://api.github.com/repos/microsoft/onnxruntime/issues/5834
5839,b'No longer able to run onnxruntime_training_mnist sample',Software,closed,2020-11-18T01:14:20Z,2020-11-18 01:14:20+00:00,2020-11-19T17:34:39Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/5839
5844,b'ONNX model inferencing issue - numpy array vs tensor',Software,closed,2020-11-18T07:56:38Z,2020-11-19 01:26:46+00:00,2020-11-19T01:26:46Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5844
5845,b'onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Fatal error: adaptive_avg_pool2d is not a registered function/op',Software,closed,2020-11-18T08:36:01Z,2020-11-19 04:56:32+00:00,2020-11-19T04:56:32Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5845
5846,b'Question: C# API Inferencing of Tabular Data (1D Tensors) with Different Dimensions',Software,closed,2020-11-18T12:34:25Z,2020-11-19 09:46:17+00:00,2020-11-24T05:57:00Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/5846
5847,b'No matching distribution found for onnxruntime (pip3 install onnxruntime)',Software,closed,2020-11-18T13:42:08Z,2020-11-18 18:26:12+00:00,2020-11-18T18:26:25Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5847
5848,b'Calculation error of reduction operator when axis has duplicate value',Software,open,2020-11-18T14:36:54Z,2020-11-19 19:27:48+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/5848
5849,b'Qauntized distilbert model is not working well on different machines',Software,closed,2020-11-18T16:24:00Z,2020-11-23 21:35:18+00:00,2020-11-26T08:55:24Z,5,7,https://api.github.com/repos/microsoft/onnxruntime/issues/5849
5851,b'ORT 1.5.3 should be able to build with OpenVINO 2021.1',Software,open,2020-11-18T18:52:13Z,2020-11-18 22:57:36+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5851
5857,b'IOBindings in C++ API are missing a way to SynchronizeInputs.',Software,open,2020-11-19T02:52:26Z,2020-11-19 18:43:02+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5857
5859,"b'How to compile with vs2019, with the platform tool set ""Visual Studio 2015 - Windows XP (v140_xp)""\xef\xbc\x8c i want use it in xp system'",Software,open,2020-11-19T03:36:28Z,2020-11-23 21:38:38+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/5859
5860,b'Calculating variance uses ~2x more memory compared to tensorflow (CPU)',Software,open,2020-11-19T06:25:51Z,2020-11-23 21:46:26+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/5860
5865,b'Quantized model much slower than full precision model',Software,open,2020-11-19T15:38:04Z,2020-11-23 21:47:11+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/5865
5872,"b'""Windows fatal exception: access violation"" when trying to run custom ONNX model.'",Software,open,2020-11-20T00:33:14Z,2020-11-23 21:49:48+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/5872
5876,b'provider tensorrt crashes (Segmentation fault)',Software,open,2020-11-20T02:42:34Z,2020-11-20 18:54:51+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5876
5896,b'Performance issue with operator Where on CPU',Software,open,2020-11-23T13:20:15Z,2020-11-23 22:03:06+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5896
5897,b'Performance issue with operator Einsum on CPU',Software,open,2020-11-23T14:38:27Z,2020-11-23 16:54:37+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5897
5898,b'Performance issue with operators SVMRegressor and SVMClassifier for RBF kernel on CPU',Software,open,2020-11-23T16:58:40Z,2020-11-23 16:59:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5898
5905,b'failed:/onnxruntime_src/onnxruntime/core/graph/model_load_utils.h:47 void onnxruntime::model_load_utils::ValidateOpsetForDomain',Software,open,2020-11-24T01:23:27Z,2020-11-24 19:05:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5905
5908,"b'Error ""Unsupported tensor type of (unknown type)"" when running Unique on int32 type'",Software,open,2020-11-24T03:05:37Z,2020-11-24 19:03:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5908
5909,b'Would KernelInfoGetAttribute function return more friendly output?',Software,open,2020-11-24T03:40:23Z,2020-11-24 19:02:52+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5909
5910,b'Support GCN ',Software,open,2020-11-24T04:54:34Z,2020-11-24 19:02:08+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5910
5914,b'Tests failing on P100s ',Software,closed,2020-11-24T10:40:43Z,2020-11-24 19:00:16+00:00,2020-12-01T23:45:00Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/5914
5917,b'EyeLike with dynamic shape results in error',Software,open,2020-11-24T19:50:10Z,2020-11-25 18:29:27+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5917
5918,"b""Can't train mnist in parallel""",Software,open,2020-11-24T20:47:28Z,2020-11-24 22:52:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5918
5925,"b'could not open ""tensorrt_provider_factory.h"", ""mkldnn_provider_factory.h""'",Software,open,2020-11-25T01:55:13Z,2020-11-25 18:24:59+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5925
5928,b'Dynamic shape got wrong output',Software,open,2020-11-25T08:29:27Z,2020-11-25 18:24:13+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5928
5931,b'Windows 7 support',Software,closed,2020-11-25T11:55:09Z,2020-11-25 18:22:13+00:00,2020-11-25T18:22:29Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5931
5933,b'OrtSessionOptionsAppendExecutionProvider_DML interface is not robust',Software,open,2020-11-25T14:09:06Z,2020-11-25 18:20:41+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5933
5934,b'would you mind exchange the order of max and min while compute clip',Software,open,2020-11-25T14:44:32Z,2020-11-25 18:18:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5934
5939,b'Issue with Multi-GPU and GPU memory limit',Software,open,2020-11-25T17:00:25Z,2020-11-25 18:11:22+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5939
5951,b'ONNX Runtime and Execution Providers',Software,closed,2020-11-26T06:09:10Z,2020-11-26 06:09:10+00:00,2020-12-02T04:47:24Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/5951
5952,"b'Hello, how to limit the number of CPU cores to 1'",Software,closed,2020-11-26T08:48:14Z,2020-11-26 08:48:46+00:00,2020-11-26T09:36:15Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5952
5953,b'can not get expected speed in onnxruntime',Software,open,2020-11-26T12:39:41Z,2020-11-30 06:12:18+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/5953
5955,b'Error using onnx model containing Bidirectional layer with MatMulAddFusion',Software,open,2020-11-26T17:53:30Z,2020-11-30 06:13:26+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/5955
5957,b'Model loading is too slow with onnxruntime-gpu',Software,closed,2020-11-26T21:53:50Z,2020-11-30 06:14:07+00:00,2021-02-12T04:02:07Z,3,77,https://api.github.com/repos/microsoft/onnxruntime/issues/5957
5958,b'Add support for ScatterND on CUDA.',Software,closed,2020-11-27T01:24:27Z,2020-11-30 06:14:45+00:00,2020-12-22T08:04:21Z,3,25,https://api.github.com/repos/microsoft/onnxruntime/issues/5958
5959,b'Does onnxruntime support AMD GPU?',Software,closed,2020-11-27T01:35:15Z,2020-11-30 06:16:11+00:00,2021-04-07T23:41:42Z,3,131,https://api.github.com/repos/microsoft/onnxruntime/issues/5959
5960,"b'scikit-learn,lgbm,xgb model loading in C#?'",Software,closed,2020-11-27T03:51:45Z,2020-11-30 06:16:45+00:00,2020-12-01T02:02:37Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/5960
5961,b'Drop support for Python 3.5',Software,open,2020-11-27T07:15:10Z,2020-11-30 06:17:22+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/5961
5962,"b""onnxruntime-gpu built for Python 3.8/Windows doesn't support CUDA versions other than 10.2""",Software,closed,2020-11-27T07:44:21Z,2020-11-30 06:18:21+00:00,2021-01-25T18:43:53Z,2,59,https://api.github.com/repos/microsoft/onnxruntime/issues/5962
5963,b'onnxruntime-gpu package not available for Python 3.8 on Windows',Software,closed,2020-11-27T08:04:12Z,2020-11-30 06:21:18+00:00,2020-12-01T01:17:30Z,2,3,https://api.github.com/repos/microsoft/onnxruntime/issues/5963
5964,b'Possible reversed functions in winml compute shaders',Software,open,2020-11-27T18:57:12Z,2020-11-30 06:18:55+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/5964
5966,b'Be able to build onnxruntime without submodules',Software,closed,2020-11-28T20:12:33Z,2020-11-30 06:19:37+00:00,2021-01-28T07:19:21Z,1,60,https://api.github.com/repos/microsoft/onnxruntime/issues/5966
5967,b'Use git-lfs for large testing dependencies',Software,closed,2020-11-28T20:18:30Z,2020-11-30 06:20:27+00:00,2021-01-28T07:19:30Z,1,60,https://api.github.com/repos/microsoft/onnxruntime/issues/5967
5971,"b""No opset import for domain 'com.microsoft'""",Software,open,2020-11-30T09:01:52Z,2020-12-01 19:46:48+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/5971
5972,b'Python3.5 nightly builds failing',Software,closed,2020-11-30T16:41:28Z,2020-11-30 16:43:51+00:00,2020-11-30T21:55:45Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5972
5980,b'Build error in build.py',Software,open,2020-12-01T03:54:56Z,2020-12-01 03:55:42+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5980
5984,"b'""undefined symbol"" error occured, when I use ort.SessionOptions.register_custom_ops_library'",Software,open,2020-12-01T07:26:32Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/5984
5985,b'Kindly ask you to delete this issue',Software,closed,2020-12-01T17:32:50Z,2020-12-01 21:14:31+00:00,2020-12-01T21:14:30Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/5985
5987,b'Error during compiling rel-1.5.3 natively on ARM64 (Ubuntu 20.10 aarch64)',Software,closed,2020-12-01T19:18:36Z,2020-12-01 21:15:38+00:00,2021-08-18T07:59:41Z,0,259,https://api.github.com/repos/microsoft/onnxruntime/issues/5987
5991,b'Bug with control flow op in ORT: Graph output does not exist in the graph.',Software,closed,2020-12-01T22:30:22Z,2020-12-02 19:23:53+00:00,2022-01-21T22:52:22Z,0,416,https://api.github.com/repos/microsoft/onnxruntime/issues/5991
5999,b'build params --build_shared_lib and --enable_language_interop_ops',Software,open,2020-12-02T01:43:50Z,2020-12-02 02:35:11+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/5999
6000,b'How to build onnxruntime CPU on ubuntu14.04 docker?',Software,closed,2020-12-02T08:43:16Z,2020-12-03 04:11:49+00:00,2020-12-04T07:26:44Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/6000
6002,"b'Under TRT EP, custom op cannot fall back to CUDA EP'",Software,open,2020-12-02T12:13:27Z,2020-12-03 18:55:59+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/6002
6003,b'Consecutive calls to Session::Run() with DML EP crashing',Software,open,2020-12-02T16:51:41Z,2020-12-02 19:03:43+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6003
6004,b'Incorrect INT8 quantized BERT model prediction on AVX2 only CPU',Software,closed,2020-12-02T17:24:26Z,2020-12-02 17:36:12+00:00,2020-12-04T08:42:07Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/6004
6013,"b'Onnx can inference on Linux-CPU by only using pip-install to convert the model, without any other so-file to install on Linux, Am I right?'",Software,closed,2020-12-03T01:51:29Z,2020-12-03 01:56:32+00:00,2020-12-03T02:20:04Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6013
6016,b'Moving from v1.5.1-cuda10.2-cudnn8 to v1.5.2-cuda10.2-cudnn8 downgrades Python and removes nvcc',Software,closed,2020-12-03T05:25:29Z,2020-12-03 06:47:43+00:00,2020-12-03T06:47:43Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6016
6018,b'The test data format for ScoreMNIST.java',Software,closed,2020-12-03T07:53:33Z,2020-12-03 08:35:45+00:00,2020-12-03T08:35:45Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6018
6019,b'Need a libsvm format version of MNIST for ScoreMNIST.java',Software,closed,2020-12-03T08:39:03Z,2020-12-03 08:55:43+00:00,2020-12-03T08:55:43Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6019
6020,b'How to install libgomp.so.1 on CentOS by yum?',Software,closed,2020-12-03T08:52:11Z,2020-12-03 10:16:13+00:00,2020-12-03T10:16:13Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6020
6021,"b""/lib64/libc.so.6: version `GLIBC_2.14' not found""",Software,closed,2020-12-03T11:39:19Z,2020-12-03 14:37:29+00:00,2020-12-04T01:06:49Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6021
6022,"b'OpenVino provider, inference in one cpu thread.'",Software,closed,2020-12-03T11:59:35Z,2020-12-03 18:53:19+00:00,2020-12-07T20:24:52Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/6022
6025,b'Inconsistent inference time between C Python API [Megatron-LM]',Software,open,2020-12-03T17:49:10Z,2020-12-04 04:58:03+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6025
6026,b'Support AARCH64 for Java',Software,closed,2020-12-03T21:10:41Z,2020-12-05 23:47:40+00:00,2020-12-12T01:23:16Z,2,8,https://api.github.com/repos/microsoft/onnxruntime/issues/6026
6030,b'Linux nightly build for training package fails',Software,closed,2020-12-04T04:44:24Z,2020-12-04 04:45:05+00:00,2020-12-04T15:58:38Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6030
6031,b'Java CPU inference very slow',Software,closed,2020-12-04T09:52:05Z,2020-12-04 16:12:20+00:00,2020-12-12T13:24:18Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/6031
6033,b'Linux E2E GPU tests are failing',Software,open,2020-12-04T16:52:35Z,2020-12-04 19:05:31+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6033
6040,b'libgomp: Thread creation failed error',Software,closed,2020-12-04T21:54:15Z,2020-12-05 17:07:10+00:00,2020-12-07T11:57:55Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/6040
6044,b'Onnx Batch Processing',Software,open,2020-12-04T23:49:57Z,2020-12-05 17:05:44+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6044
6047,b'Cannot use --use_external_data_form and --optimize_onnx with GPT2LMHeadModel_NoPadding',Software,open,2020-12-05T01:57:15Z,2020-12-05 16:59:23+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6047
6050,"b""Unable to load DLL 'onnxruntime' in Microsoft.ML.OnnxRuntime.Gpu 1.5.2""",Software,closed,2020-12-05T15:01:27Z,2020-12-05 16:44:03+00:00,2020-12-05T17:17:33Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6050
6051,b'Nightly python packaging pipeline build fails ',Software,closed,2020-12-05T16:40:27Z,2020-12-05 17:14:26+00:00,2021-01-27T00:29:04Z,0,52,https://api.github.com/repos/microsoft/onnxruntime/issues/6051
6052,b'Nightly Training python packaging build fails',Software,closed,2020-12-05T16:42:05Z,2020-12-05 17:11:00+00:00,2020-12-08T23:17:28Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/6052
6055,b'Multiple inputs and multiple outputs of Session.Run',Software,closed,2020-12-06T08:43:56Z,2020-12-07 18:46:55+00:00,2020-12-07T18:46:55Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/6055
6056,"b""Unable to load DLL 'onnxruntime' in Microsoft.ML.OnnxRuntime.Gpu 1.5.2""",Software,closed,2020-12-06T10:52:18Z,2020-12-06 11:05:14+00:00,2020-12-06T11:05:14Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6056
6057,b'Building on Raspberry Pi 4B with OpenVINO provider does not link correctly',Software,closed,2020-12-06T15:17:20Z,2021-02-12 03:57:22+00:00,2021-09-07T14:57:47Z,67,274,https://api.github.com/repos/microsoft/onnxruntime/issues/6057
6058,b'Possible memory leak',Software,closed,2020-12-06T19:59:26Z,2020-12-10 20:55:56+00:00,2020-12-10T20:55:56Z,4,4,https://api.github.com/repos/microsoft/onnxruntime/issues/6058
6060,b'converted-bert  fp16 model is slow  ',Software,closed,2020-12-07T05:58:22Z,2020-12-08 18:36:39+00:00,2021-01-09T13:25:31Z,1,33,https://api.github.com/repos/microsoft/onnxruntime/issues/6060
6062,b'How to use onnxruntime-tensorrt in python',Software,closed,2020-12-07T10:42:58Z,2020-12-08 02:47:49+00:00,2020-12-08T02:47:49Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6062
6067,"b""ConvTranspose output_shape seems wrong for dynamic input shape when auto_pad='SAME_LOWER'""",Software,closed,2020-12-07T21:41:35Z,2020-12-07 21:46:40+00:00,2021-01-11T10:58:41Z,0,34,https://api.github.com/repos/microsoft/onnxruntime/issues/6067
6068,b'Build issue when using `--build_wheel` without CUDA',Software,closed,2020-12-07T21:50:23Z,2020-12-07 22:08:20+00:00,2020-12-07T22:08:20Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6068
6073,b'MNIST sample does not achieve expected accuracy (enable training CPU only)',Software,open,2020-12-08T02:45:03Z,2020-12-08 02:45:03+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6073
6075,b'DirectML Runtime error in GPT-2-LM-HEAD model with variable sized input.',Software,open,2020-12-08T05:33:35Z,2020-12-08 18:33:28+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6075
6077,b'How to extract the size of a map type in c++?',Software,open,2020-12-08T08:21:50Z,2020-12-08 18:38:37+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6077
6078,b'cudaErrorInvalidConfiguration in Reshape node',Software,open,2020-12-08T10:56:27Z,2020-12-08 18:24:12+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6078
6079,b'OpenVino Execution Provider - Support External Data Format',Software,open,2020-12-08T13:10:57Z,2020-12-08 18:21:26+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6079
6080,b'use_gpu : Unable to serialize model as it contains compiled nodes',Software,closed,2020-12-08T16:36:50Z,2020-12-08 18:17:33+00:00,2020-12-17T10:30:48Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/6080
6084,b'Pytorch frontend mnist training example fails to run if training built without cuda GPU',Software,closed,2020-12-08T19:32:46Z,2020-12-09 22:27:54+00:00,2020-12-17T21:32:48Z,1,9,https://api.github.com/repos/microsoft/onnxruntime/issues/6084
6087,b'Failure to create a BatchNormgrad node for Mobilenet training app',Software,closed,2020-12-09T00:30:37Z,2020-12-09 22:26:41+00:00,2021-10-14T18:29:13Z,0,309,https://api.github.com/repos/microsoft/onnxruntime/issues/6087
6089,"b""could the checkpoint of bert convert to onnx model? I have a bug that 'BertForPreTraining' object has no attribute 'layers, output'""",Software,open,2020-12-09T08:09:52Z,2020-12-09 22:25:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6089
6091,"b""RuntimeError: Input must be a list of dictionaries or a single numpy array for input 'images'.""",Software,closed,2020-12-09T09:18:05Z,2020-12-09 10:09:26+00:00,2020-12-09T10:09:26Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6091
6094,b'Gpu input when use TensorRT provider failed',Software,closed,2020-12-10T01:14:55Z,2020-12-11 17:58:35+00:00,2021-01-15T01:08:51Z,1,35,https://api.github.com/repos/microsoft/onnxruntime/issues/6094
6096,"b""AttributeError: 'BertForPreTraining' object has no attribute 'layers,outputs'""",Software,closed,2020-12-10T03:32:56Z,2020-12-10 18:44:37+00:00,2020-12-10T18:44:37Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6096
6101,b'Docker Image for ONNXRuntime TensorRT',Software,closed,2020-12-10T10:42:07Z,2020-12-10 18:41:40+00:00,2021-02-12T22:58:58Z,0,64,https://api.github.com/repos/microsoft/onnxruntime/issues/6101
6102,b'CUBLAS error executing cublasGemmHelper',Software,closed,2020-12-10T12:18:40Z,2020-12-10 23:30:50+00:00,2021-10-08T00:09:16Z,0,301,https://api.github.com/repos/microsoft/onnxruntime/issues/6102
6104,b'What is the best model to use with the orttraining models MNIST sample?',Software,open,2020-12-10T17:45:08Z,2020-12-10 23:21:43+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6104
6110,b'how to implement execution provider (EP) that allow onnx run on my hardware? ',Software,open,2020-12-11T07:38:57Z,2020-12-11 19:04:21+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6110
6113,b'Offer Nuget package without PDB',Software,closed,2020-12-11T18:41:18Z,2020-12-11 18:41:18+00:00,2021-09-07T17:49:12Z,0,269,https://api.github.com/repos/microsoft/onnxruntime/issues/6113
6114,b'Crash in onnxruntime::SequentialExecutor::Execute()',Software,closed,2020-12-11T19:24:03Z,2020-12-11 19:33:35+00:00,2020-12-11T19:33:35Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6114
6116,b'[ONNXRuntimeError] : 9 : NOT_IMPLEMENTED error on OneHot op',Software,closed,2020-12-11T21:06:07Z,2020-12-12 00:07:48+00:00,2020-12-12T04:55:10Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6116
6123,b'Add support for string to string LabelEncoder',Software,open,2020-12-13T17:57:58Z,2020-12-14 23:36:49+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/6123
6124,b'failed to install onnxruntime-gpu on Jetson Nano with the latest image (Jetpack 4.4.1)',Software,open,2020-12-13T20:48:55Z,2020-12-14 18:26:51+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6124
6125,b'pypi releases for python 3.9',Software,closed,2020-12-13T22:04:50Z,2021-01-24 22:28:46+00:00,2021-03-04T00:53:07Z,42,80,https://api.github.com/repos/microsoft/onnxruntime/issues/6125
6127,b'Unable to get the output results for Sequence of Map in C++ api',Software,closed,2020-12-14T06:47:15Z,2020-12-14 07:07:34+00:00,2020-12-14T08:33:54Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6127
6130,"b'XLNet ONNX model giving error: ""Attempting to broadcast an axis by a dimension other than 1""'",Software,closed,2020-12-14T18:26:44Z,2020-12-14 23:32:40+00:00,2021-05-25T00:09:30Z,0,161,https://api.github.com/repos/microsoft/onnxruntime/issues/6130
6133,b'Bug - Not able to build onnxruntime.',Software,closed,2020-12-14T23:11:39Z,2020-12-14 23:26:29+00:00,2020-12-14T23:59:33Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6133
6137,"b""About CUDA's version""",Software,closed,2020-12-15T06:23:22Z,2020-12-15 19:53:04+00:00,2021-03-16T10:01:17Z,0,91,https://api.github.com/repos/microsoft/onnxruntime/issues/6137
6143,b'C API question - Custom allocator',Software,open,2020-12-15T21:34:26Z,2020-12-15 21:46:01+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6143
6144,b'32bit vs 64bit when compiling or something else?',Software,open,2020-12-16T07:37:54Z,2020-12-16 18:25:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6144
6146,"b""Dubious implementation of ROIAlign in 'max' mode""",Software,open,2020-12-16T09:39:10Z,2020-12-16 18:36:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6146
6147,b'Different results with torch.jit',Software,closed,2020-12-16T10:12:54Z,2020-12-16 13:13:57+00:00,2020-12-16T13:14:42Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6147
6148,b'NCHWc optimization requirements',Software,closed,2020-12-16T11:48:21Z,2020-12-17 05:58:21+00:00,2020-12-17T08:05:13Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6148
6149,b'building model_explorer example: experimental_onnxruntime_cxx_api.h; errors',Software,closed,2020-12-16T18:42:20Z,2020-12-16 20:12:20+00:00,2020-12-17T21:53:25Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/6149
717,b'Question about disabling sequential execution on CUDA',Software,closed,2019-03-27T12:42:04Z,2019-03-27 18:33:28+00:00,2019-05-09T19:11:48Z,0,43,https://api.github.com/repos/microsoft/onnxruntime/issues/717
727,b'Prioritization with CUDA',Software,closed,2019-03-28T06:14:36Z,2019-05-09 18:51:54+00:00,2019-05-09T18:51:54Z,42,42,https://api.github.com/repos/microsoft/onnxruntime/issues/727
729,"b""Can't use parent graph's initializer in subgraphs""",Software,closed,2019-03-28T09:40:59Z,2019-03-28 09:41:14+00:00,2019-06-03T21:23:52Z,0,67,https://api.github.com/repos/microsoft/onnxruntime/issues/729
730,b' unexpected behavior for contrib op range when start equals to limit',Software,closed,2019-03-28T12:55:33Z,2019-03-28 12:57:00+00:00,2019-03-29T07:24:19Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/730
738,b'build error: narrowing conversion...',Software,closed,2019-03-29T01:05:08Z,2019-03-29 02:24:51+00:00,2019-04-22T18:41:51Z,0,24,https://api.github.com/repos/microsoft/onnxruntime/issues/738
740,b'building from source C api',Software,closed,2019-03-29T11:28:14Z,2019-03-29 15:37:46+00:00,2019-03-29T15:37:46Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/740
754,b'input_shape in inference_test_capi',Software,closed,2019-04-02T21:26:57Z,2019-04-03 10:48:55+00:00,2019-04-03T22:07:34Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/754
755,b'Support retrieving more attributes types in C API',Software,closed,2019-04-02T23:59:28Z,2019-04-05 04:31:22+00:00,2019-07-20T02:53:38Z,2,108,https://api.github.com/repos/microsoft/onnxruntime/issues/755
760,b'Fully support adaptive max/avg pooling',Software,closed,2019-04-03T18:27:28Z,2019-04-05 17:08:13+00:00,2019-04-18T00:46:26Z,1,14,https://api.github.com/repos/microsoft/onnxruntime/issues/760
774,b'Input shape Python vs C#',Software,closed,2019-04-05T13:25:52Z,2019-04-05 17:08:39+00:00,2019-04-06T00:04:00Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/774
775,b'Runtime Reporting BatchNorm not implemented.',Software,closed,2019-04-05T17:28:39Z,2019-04-05 17:47:33+00:00,2019-04-05T17:47:33Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/775
787,b'Is it possible to iterate over each node of an onnx model?',Software,closed,2019-04-06T03:55:10Z,2019-04-08 17:59:37+00:00,2019-04-08T19:12:45Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/787
791,b'Add support for loading models directly from streams',Software,closed,2019-04-08T11:32:35Z,2019-04-08 11:38:14+00:00,2019-06-12T02:38:36Z,0,64,https://api.github.com/repos/microsoft/onnxruntime/issues/791
795,b'Inconsistent Test Data URL in tensorrt pipelines',Software,closed,2019-04-09T01:46:40Z,2019-04-09 03:28:02+00:00,2019-04-09T03:53:04Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/795
796,b'ShapeInferenceError in v0.3.1',Software,closed,2019-04-09T02:34:03Z,2019-04-09 18:28:54+00:00,2019-05-02T23:09:47Z,0,23,https://api.github.com/repos/microsoft/onnxruntime/issues/796
799,b'ContribOperators.md doc issue',Documentation,closed,2019-04-09T12:23:16Z,2019-04-09 18:49:41+00:00,2019-05-03T19:12:52Z,0,24,https://api.github.com/repos/microsoft/onnxruntime/issues/799
801,"b""Bug: Pooling ops don't seem to handle explicit pads correctly """,Documentation,closed,2019-04-09T20:16:44Z,2019-04-09 20:33:29+00:00,2019-05-15T18:10:32Z,0,35,https://api.github.com/repos/microsoft/onnxruntime/issues/801
6153,b'ORT computes min/max incorrectly for negative fp16 values in opsets 12 and 13',Software,closed,2020-12-16T21:48:58Z,2020-12-17 18:43:43+00:00,2021-01-08T07:32:53Z,0,22,https://api.github.com/repos/microsoft/onnxruntime/issues/6153
6154,b'Nested namespace in experimental_onnxruntime_cxx_api.h breaks cpp14',Software,closed,2020-12-16T22:17:30Z,2020-12-17 18:49:03+00:00,2020-12-17T21:53:54Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6154
6158,"b'Initialize Ort::Session in main thread, Session->Run in another thread : possible?'",Software,closed,2020-12-17T08:49:00Z,2020-12-17 15:45:03+00:00,2020-12-17T15:45:03Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6158
6159,b'`CUDAExecutionProvider(...)` ctor hangs with 100% CPU in nvptxJitCompiler64',Software,closed,2020-12-17T12:19:06Z,2020-12-17 18:50:50+00:00,2021-02-14T17:22:13Z,0,59,https://api.github.com/repos/microsoft/onnxruntime/issues/6159
6160,b'Onnx run time shared library size on linux is 500 mb. ',Software,closed,2020-12-17T13:54:57Z,2020-12-17 13:55:35+00:00,2020-12-17T19:29:48Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6160
6168,b'Tensor manipulations in C#',Software,open,2020-12-17T23:50:06Z,2020-12-18 01:46:44+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6168
6173,"b'Opset12+fp16 runs much slower than opset10/opset11+fp16 in V100 gpu, only 1/88'",Software,closed,2020-12-18T07:35:22Z,2020-12-18 18:18:10+00:00,2020-12-31T04:42:00Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/6173
6181,b'GPU memory consumption keeps increasing with multithreading in Java',Software,open,2020-12-18T22:37:50Z,2020-12-19 07:02:39+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6181
6183,b'Cuda provider not showing up on Google Colab',Software,closed,2020-12-21T08:21:54Z,2020-12-21 08:22:14+00:00,2020-12-22T05:18:04Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6183
6185,b'Docker (server) build fails to build libonnxruntime.so.1.2.0',Software,closed,2020-12-21T19:37:15Z,2020-12-21 23:55:44+00:00,2020-12-21T23:55:44Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6185
6192,b'why onnxruntime inference slow then pytorch model',Software,closed,2020-12-22T03:24:38Z,2020-12-23 22:25:49+00:00,2020-12-31T03:18:14Z,1,8,https://api.github.com/repos/microsoft/onnxruntime/issues/6192
6194,b'ModelMetadata::GetDescription returns empty string  ',Software,closed,2020-12-22T05:39:48Z,2020-12-22 06:28:18+00:00,2021-01-06T06:18:50Z,0,15,https://api.github.com/repos/microsoft/onnxruntime/issues/6194
6195,b'Converting Tensorflow model to onnx and running using onnx runtime give totally wrong result comare to orignal model ',Software,closed,2020-12-22T14:59:02Z,2021-01-02 15:56:19+00:00,2021-01-05T10:53:07Z,11,13,https://api.github.com/repos/microsoft/onnxruntime/issues/6195
6197,"b""ORT 1.6.0 Java release isn't on Maven Central""",Software,closed,2020-12-22T17:44:41Z,2020-12-22 18:04:08+00:00,2021-01-11T17:42:41Z,0,19,https://api.github.com/repos/microsoft/onnxruntime/issues/6197
6204,b'data_ptr is 0 for io_binding in gpt2_helper',Software,closed,2020-12-23T03:29:09Z,2021-02-12 03:49:25+00:00,2021-02-12T03:58:51Z,51,51,https://api.github.com/repos/microsoft/onnxruntime/issues/6204
6206,b'Cuda availibility checker',Software,closed,2020-12-24T05:28:51Z,2021-01-07 18:44:02+00:00,2022-01-19T17:22:22Z,14,391,https://api.github.com/repos/microsoft/onnxruntime/issues/6206
6207,b'Support Yolo5 model training (GPU) - https://github.com/ultralytics/yolov5',Software,closed,2020-12-25T01:45:08Z,2020-12-25 01:46:26+00:00,2021-02-10T06:00:24Z,0,47,https://api.github.com/repos/microsoft/onnxruntime/issues/6207
6208,b'[RFC] Add torchvision/faster-rcnn inference example on cpp backend',Software,open,2020-12-25T05:36:16Z,2020-12-25 05:37:11+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6208
6209,b'how to build ti by python2.7?',Software,closed,2020-12-25T09:17:55Z,2020-12-25 21:04:00+00:00,2020-12-25T21:04:00Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6209
6213,b'Not support rtx 3000 series ',Software,open,2020-12-26T14:15:45Z,2020-12-26 14:29:08+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6213
6214,"b""ValueError: ['OpenVINOExecutionProvider'] does not contain a subset of available providers ['CPUExecutionProvider']""",Software,closed,2020-12-27T22:11:31Z,2020-12-28 01:10:23+00:00,2020-12-29T01:28:53Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/6214
6215,b'how to use cuda_mem_limit',Software,closed,2020-12-28T08:26:58Z,2021-01-04 17:39:01+00:00,2021-02-12T23:03:24Z,7,46,https://api.github.com/repos/microsoft/onnxruntime/issues/6215
6216,b'Using Multi-GPUs for inferencing',Software,open,2020-12-28T08:46:56Z,2020-12-28 20:59:59+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6216
6226,"b""cannot open file 'onnxruntime.lib'""",Software,closed,2020-12-29T03:31:33Z,2020-12-31 02:35:58+00:00,2020-12-31T04:15:58Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/6226
6227,"b"" TypeError: forward() got an unexpected keyword argument 'past' when converting gpt2 from transformers to onnx""",Software,open,2020-12-29T03:51:30Z,2021-01-04 17:36:06+00:00,,6,,https://api.github.com/repos/microsoft/onnxruntime/issues/6227
6229,b'performance of gpt2 inference with onnxruntime-gpu',Software,open,2020-12-29T07:23:00Z,2021-01-04 18:28:17+00:00,,6,,https://api.github.com/repos/microsoft/onnxruntime/issues/6229
6230,"b""build.py ImportError: wrong 'util' imported""",Software,closed,2020-12-29T16:00:45Z,2020-12-30 22:24:18+00:00,2020-12-30T22:24:18Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/6230
6232,b'Segmentfault caused by MlasGemmFloatKernel both on Avx512F and Fma3',Software,closed,2020-12-30T04:13:41Z,2020-12-30 08:35:35+00:00,2021-01-01T11:37:04Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/6232
6236,b'How to run YOLO with onnxruntime',Software,open,2020-12-31T03:26:07Z,2020-12-31 11:04:29+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6236
6243,"b'sample c++ program just print ""hello"" does not start'",Software,open,2021-01-02T10:59:27Z,2021-01-06 19:34:33+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/6243
6245,"b""gpt2 io binding inference error when 'past_sequence_length' is 0""",Software,closed,2021-01-04T06:50:21Z,2021-01-04 18:25:47+00:00,2021-02-12T03:58:23Z,0,38,https://api.github.com/repos/microsoft/onnxruntime/issues/6245
6249,b'Build error: Payload contains two or more files with the same destination path',Software,open,2021-01-04T16:18:06Z,2021-01-04 17:33:23+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6249
6258,b'Cannot convert onnx model to tensorflow pb when using onnxruntime-gpu',Software,open,2021-01-05T21:52:53Z,2021-01-06 18:43:31+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6258
6261,b'Cannot create OnnxTensor with UINT8 type. ',Software,open,2021-01-06T00:38:13Z,2021-01-06 18:43:03+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6261
6264,b'Referencing Microsoft.ML.OnnxRuntime and Microsoft.ML.OnnxRuntime.GPU in a c# project.',Software,open,2021-01-06T10:41:03Z,2021-01-06 18:44:26+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6264
6271,b'Converted Onnx model from gpt2 does not have the same input shape',Software,closed,2021-01-06T22:04:08Z,2021-01-07 17:32:36+00:00,2021-01-17T01:30:39Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/6271
6274,"b'  without Ort::Env env(ORT_LOGGING_LEVEL_WARNING, ""test"") {1, 3, 32, 620} ok {1, 3, 32, 630} crash'",Software,closed,2021-01-07T03:57:32Z,2021-01-07 04:29:09+00:00,2021-01-07T04:29:09Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6274
6275,b'Could onnxruntime be compiled into wasm using emsdk? ',Software,open,2021-01-07T05:55:48Z,2021-01-07 17:58:57+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6275
6277,"b""Import Issue -  Cannot import 'quantize_dynamic'""",Software,closed,2021-01-07T14:05:26Z,2021-01-07 17:33:57+00:00,2021-01-19T13:16:58Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/6277
6279,b'Resize OP with sizes',Software,closed,2021-01-07T19:46:35Z,2021-01-08 18:55:14+00:00,2021-02-10T06:50:03Z,0,33,https://api.github.com/repos/microsoft/onnxruntime/issues/6279
6292,b'Python tests failing',Software,open,2021-01-08T14:06:37Z,2021-01-08 18:57:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6292
6299,"b'Why does a custom OP that only supports cpu will insert memcpytohost before OP, but not insert memcpyfromhost after op, which will cause subsequent ops to run on cpu'",Software,closed,2021-01-11T03:40:04Z,2021-01-11 03:53:12+00:00,2021-01-18T07:44:10Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/6299
6300,b'CUDA kernel not found in registries for Op type: ScatterND',Software,closed,2021-01-11T06:24:58Z,2021-01-11 07:01:50+00:00,2021-01-11T07:01:50Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6300
6301,b'Performance shaking',Software,open,2021-01-11T06:46:27Z,2021-01-12 23:51:16+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/6301
6302,b'[Bug] Wrong implementation in LpPool',Software,open,2021-01-11T11:29:53Z,2021-01-12 09:39:30+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6302
6304,b'Memory corruption when using OnnxRuntime with OpenVINO on the Intel MyriadX and Raspberry Pi 4B',Software,open,2021-01-11T13:33:29Z,2021-01-13 00:09:00+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/6304
6318,b'Model-parallel inference with ONNX Runtime + HF transformers',Software,closed,2021-01-12T03:45:08Z,2021-01-12 20:19:39+00:00,2021-01-12T20:19:39Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6318
6319,b' [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Error while inferencing DLRM onnx model',Software,open,2021-01-12T06:10:39Z,2021-01-13 00:10:24+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6319
6320,b'Error: Running double precision model exported from pyTorch',Software,open,2021-01-12T08:17:31Z,2021-01-13 00:08:36+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6320
6328,b'The output for GPT is NAN when fp16=True',Software,open,2021-01-12T19:45:18Z,2021-01-13 00:07:16+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6328
6339,b'Python Segmentation fault (core dumped) on cuda11.0-runtime when built on cuda11.0-devel',Software,open,2021-01-13T07:58:01Z,2021-01-13 18:15:13+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6339
6350,b'onnxruntime no longer /delayload CUDA dlls when compiled for Windows',Software,closed,2021-01-14T15:06:42Z,2021-01-14 18:22:12+00:00,2021-09-02T17:13:23Z,0,231,https://api.github.com/repos/microsoft/onnxruntime/issues/6350
6358,b'ROCm build seems broken: `error: \xe2\x80\x98ncclComm_t\xe2\x80\x99 does not name a type`',Software,open,2021-01-15T06:33:38Z,2021-01-15 20:45:18+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6358
6360,b'Implementation of ONNX Functions',Software,open,2021-01-15T09:20:24Z,2021-01-15 20:41:06+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6360
6361,b'Difference between onnxruntime with TensorRT provider vs TensorRT standalone',Software,closed,2021-01-15T17:41:34Z,2021-01-15 17:46:37+00:00,2021-01-17T06:04:13Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/6361
6367,b'Error BadImageFormatException: An attempt was made to load a program with an incorrect format. (Exception from HRESULT: 0x8007000B) ',Software,closed,2021-01-16T07:53:16Z,2021-01-19 21:47:50+00:00,2021-03-19T05:47:11Z,3,61,https://api.github.com/repos/microsoft/onnxruntime/issues/6367
6368,b'Failing to build from Dockerfile.source',Software,closed,2021-01-16T17:50:50Z,2021-01-16 17:59:06+00:00,2021-01-16T17:59:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6368
6370,b'Incorrect TypeInferenceError on UNDEFINED tensor type',Software,open,2021-01-17T04:36:41Z,2021-01-19 21:47:25+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/6370
6371,b'Unable to find onnxruntime.dll via FFI(node js)',Software,open,2021-01-17T08:42:56Z,2021-01-19 20:06:15+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/6371
6372,b'[C-Api] Dynamic Shape Error: Non-zero status code returned while running Sigmoid node.',Software,open,2021-01-18T04:11:36Z,2021-01-19 21:45:09+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/6372
6375,b'onnxruntime v1.6.0 on Jetson Nano - Illegal Instruction (core dumped)',Software,open,2021-01-18T20:05:51Z,2021-01-19 13:32:18+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6375
6379,b'Import issues with onnxruntime-gpu',Software,closed,2021-01-19T13:15:56Z,2021-01-19 21:49:43+00:00,2021-01-25T08:06:48Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/6379
6380,b'add a ThreadingOptions class to the C++ interface',Software,open,2021-01-19T14:28:40Z,2021-01-19 20:04:28+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6380
6388,b'CUDA kernel not found in registries for Op type: CustomOpOne',Software,closed,2021-01-20T05:17:10Z,2021-01-20 09:23:46+00:00,2021-01-25T19:47:42Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/6388
6389,b' INVALID_ARGUMENT : Invalid Feed Input Name:token_type_ids',Software,closed,2021-01-20T08:26:33Z,2021-01-20 09:24:13+00:00,2021-03-19T00:12:12Z,0,57,https://api.github.com/repos/microsoft/onnxruntime/issues/6389
6396,b'How to extract dimension of inputs in onnxruntime/core/providers/cpu/math/matmul.cc',Software,open,2021-01-21T11:57:18Z,2021-01-21 19:59:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6396
6397,b'Memory Increase With Run',Software,closed,2021-01-21T13:41:14Z,2021-01-21 20:04:19+00:00,2021-03-07T21:39:00Z,0,45,https://api.github.com/repos/microsoft/onnxruntime/issues/6397
6398,b'Page for python API documentation is broken',Documentation,closed,2021-01-21T15:48:54Z,2021-01-21 19:58:37+00:00,2021-02-12T23:32:01Z,0,22,https://api.github.com/repos/microsoft/onnxruntime/issues/6398
6400,b'Which executor to build when using: Intel\xc2\xae Deep Learning Boost (Intel\xc2\xae DL Boost)',Software,open,2021-01-21T20:27:29Z,2021-01-21 21:13:34+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6400
6402,b'C API doc (badly) needs updating',Documentation,closed,2021-01-21T22:22:43Z,2021-01-21 23:30:07+00:00,2022-02-15T22:21:06Z,0,389,https://api.github.com/repos/microsoft/onnxruntime/issues/6402
6408,b'the problem of converting hrnet to onnx',Software,closed,2021-01-22T08:05:46Z,2021-01-22 20:29:40+00:00,2021-02-05T05:54:38Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/6408
6409,b'OrtCustomOp does not support all types of attributes',Software,open,2021-01-22T09:41:21Z,2021-01-22 20:28:37+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6409
6411,b'[question] Configure GPU arena with Python bindings',Software,open,2021-01-22T11:46:24Z,2021-01-22 11:46:34+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6411
6421,b'onnxruntime ArmNN Build Failing with Release Tag 1.6.0 and with master ',Software,closed,2021-01-23T10:00:02Z,2021-01-23 22:21:29+00:00,2021-01-30T23:02:08Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/6421
6422,"b""raw_data field doesn't exist when trying to quantize transformer""",Software,closed,2021-01-24T06:01:10Z,2021-01-25 19:51:53+00:00,2021-01-25T19:51:53Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/6422
6423,b'Onnxruntime error when Relu-layer follows Dense-layer without activation and biases',Software,open,2021-01-24T16:16:14Z,2021-01-24 16:16:35+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6423
6424,b'Reshape `requested_shape` forced to have leading dimension 1 when it should be -1',Software,open,2021-01-24T17:43:54Z,2021-01-25 17:31:38+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6424
6425,b'Error during onnxruntime-gpu nuget package installation',Software,open,2021-01-25T10:52:06Z,2021-01-25 18:31:13+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6425
6426,"b'ONNX runtime fails with ""Fatal program exit requested."" due to ORT_THROW when AppendExecutionProvider_* in C#'",Software,closed,2021-01-25T11:03:42Z,2021-01-25 17:58:20+00:00,2021-06-03T20:46:44Z,0,129,https://api.github.com/repos/microsoft/onnxruntime/issues/6426
6427,b'How to disable TF32 use on Ampere GPUs using TensorRT',Software,closed,2021-01-25T12:04:43Z,2021-01-25 17:56:39+00:00,2021-01-26T11:05:36Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6427
6429,b'[BERT-Squad][opset-10][models/20191107.zip] Expected values mismatch',Software,open,2021-01-25T13:04:58Z,2021-01-25 17:27:57+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6429
6430,b'Failed to run inference session on 8bit quantized onnx model',Software,open,2021-01-25T16:33:53Z,2021-01-25 17:42:28+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6430
6432,b'Dockerfile build failures for CPU and CUDA dockers',Software,closed,2021-01-25T18:09:45Z,2021-01-25 18:19:11+00:00,2021-01-25T20:57:39Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6432
6433,b'Unable to use onnxruntime-gpu package when multiple versions of CUDA are installed',Software,closed,2021-01-25T19:06:09Z,2021-01-27 19:25:15+00:00,2021-02-21T23:11:28Z,2,27,https://api.github.com/repos/microsoft/onnxruntime/issues/6433
6435,b'Cryptic message while importing CUDA version of onnxruntime Python package when one of dependencies is missing',Software,closed,2021-01-25T19:16:38Z,2021-01-27 19:26:37+00:00,2021-02-21T23:11:28Z,2,27,https://api.github.com/repos/microsoft/onnxruntime/issues/6435
6442,b'PadNode reflect mode implementation is wrong',Software,closed,2021-01-26T00:06:41Z,2021-01-27 19:27:50+00:00,2021-02-16T04:52:45Z,1,21,https://api.github.com/repos/microsoft/onnxruntime/issues/6442
6445,b'Problem in adding custom operator',Software,closed,2021-01-26T04:43:35Z,2021-01-27 19:30:26+00:00,2021-01-29T03:00:31Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/6445
6455,b'Onnxruntime TensorRT create one cache when models same structure',Software,open,2021-01-26T12:45:56Z,2021-01-27 19:36:25+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/6455
6456,b'Inconsistent values in Ort::Value from CreateTensor in C++.',Software,closed,2021-01-26T14:23:21Z,2021-01-26 17:46:06+00:00,2022-04-18T16:47:03Z,0,447,https://api.github.com/repos/microsoft/onnxruntime/issues/6456
6457,"b""DML execution provider doesn't load model while CUDA,CPU execution provider does""",Software,closed,2021-01-26T17:11:43Z,2021-01-27 19:22:33+00:00,2021-03-10T12:54:53Z,1,42,https://api.github.com/repos/microsoft/onnxruntime/issues/6457
6458,b'Python Packaging Pipeline (Training) failures',Software,closed,2021-01-26T18:57:11Z,2021-01-26 18:57:47+00:00,2021-01-27T17:09:13Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6458
6459,b'Build failure with --cmake_extra_defines onnxruntime_DEBUG_NODE_INPUTS_OUTPUTS=ON',Software,closed,2021-01-26T19:35:18Z,2021-01-27 08:34:40+00:00,2021-02-01T15:09:19Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/6459
6469,b'Does custom_op_library support Multiple dynamic inputs of CustomOp?',Software,closed,2021-01-27T02:38:34Z,2021-01-27 19:21:11+00:00,2021-02-17T04:54:31Z,0,21,https://api.github.com/repos/microsoft/onnxruntime/issues/6469
6470,b'onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Type Error: Type parameter (T) bound to different types (tensor(float) and tensor(int64) in node (Mul_11).',Software,open,2021-01-27T09:33:43Z,2021-01-27 19:18:19+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6470
6471,"b""Java's OnnxSequence::getValue leaking memory""",Software,closed,2021-01-27T18:24:58Z,2021-01-27 19:37:35+00:00,2021-01-28T19:28:57Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/6471
6475,b'Onnx/ort load model from buffer',Software,closed,2021-01-27T20:28:13Z,2021-01-27 22:48:15+00:00,2021-01-28T12:15:08Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6475
6482,b'ArgMax failure on CUDA',Software,closed,2021-01-28T05:11:14Z,2021-01-28 17:30:59+00:00,2021-02-02T17:50:17Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/6482
6486,b'ArmNN Execution Provider does not build',Software,open,2021-01-28T12:05:20Z,2021-01-28 12:11:08+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6486
6488,b'Question: how to install runtime on linux ?',Software,closed,2021-01-28T20:58:22Z,2021-01-28 21:15:29+00:00,2021-01-28T21:15:29Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6488
6497,b'onnxruntime import fails with error: libcudart.so.10.2: cannot open shared object file: No such file or directory',Software,open,2021-01-29T07:01:57Z,2021-01-29 18:03:44+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6497
6499,b'onnxinferencetime',Software,closed,2021-01-29T07:13:10Z,2021-01-29 18:34:01+00:00,2021-02-10T07:43:09Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/6499
6500,b'Graph optimization build options?',Software,closed,2021-01-29T10:58:12Z,2021-01-29 18:34:52+00:00,2021-02-10T01:37:26Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/6500
6501,b'onnxruntime_tools.optimizer_cli conversion to fp16 breaks types for adding a constant',Software,closed,2021-01-29T15:06:57Z,2021-01-29 18:23:41+00:00,2021-02-06T10:11:28Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/6501
6505,b'Op with name (StatefulPartitionedCall/sequential/conv2d/BiasAdd) and type (Conv) kernel not found in CPUExecutionProvider',Software,closed,2021-01-29T18:03:44Z,2021-01-29 18:06:42+00:00,2021-01-30T14:20:45Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6505
6511,b'Is it possible to publish a pypi package without openmp requirement?',Software,closed,2021-01-30T09:59:14Z,2021-01-31 03:33:22+00:00,2021-01-31T03:33:22Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6511
6512,b'optimization in pytorch can not work in onnx',Software,open,2021-01-30T13:09:04Z,2021-02-02 08:12:12+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/6512
6515,b'How do I load and run models that have multiple inputs and multiple  outputs using the C API?',Software,closed,2021-01-31T10:48:31Z,2021-02-01 05:30:21+00:00,2021-02-01T05:30:21Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6515
6516,b'There is a problem: GetTensorMutableData ',Software,open,2021-01-31T15:21:35Z,2021-01-31 15:21:57+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6516
6527,"b""How to use default CPU execution provider for math operations on tensors? I can't find any documentation...""",Software,closed,2021-02-01T19:04:07Z,2021-02-02 07:45:38+00:00,2021-02-02T07:45:38Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6527
6533,b'Cannot build with Snap installed cmake',Software,closed,2021-02-02T02:35:37Z,2021-02-02 05:35:03+00:00,2021-02-08T20:01:28Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/6533
6536,b'Build failure in `orttraining_pybind_state.cc` when building with `--enable_training` and `--build_wheel`',Software,open,2021-02-02T16:58:37Z,2021-02-02 18:01:26+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6536
6543,b'NaN in AveragePooling',Software,open,2021-02-03T01:41:59Z,2021-02-04 01:01:37+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6543
6545,b'per channel sym performance problem?',Software,closed,2021-02-03T03:18:20Z,2021-02-04 01:02:28+00:00,2021-02-22T07:49:30Z,0,19,https://api.github.com/repos/microsoft/onnxruntime/issues/6545
6548,b'[BERT-Squad][opset-8][Model Zoo] Inference fails on  bert/embeddings/one_hot op',Software,open,2021-02-03T12:26:29Z,2021-02-04 01:03:45+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6548
6549,b'Loss of accuracy when GPT-2 based model is exported to ONNX',Software,open,2021-02-03T13:51:56Z,2021-02-04 02:14:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6549
6553,b'[java] load shared library providers',Software,closed,2021-02-03T22:25:43Z,2021-02-03 23:13:20+00:00,2021-07-21T05:33:16Z,0,167,https://api.github.com/repos/microsoft/onnxruntime/issues/6553
6564,b'Custom Op Registration and Implementation',Software,open,2021-02-04T06:51:52Z,2021-02-04 06:51:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6564
6567,b'[c api] Why there will be about 300MB GPU memory cost when i infer on cpu ?',Software,open,2021-02-04T09:52:48Z,2021-02-08 12:17:59+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/6567
6568,b'VitisAIExecutionProvider is not shown in the available providers',Software,open,2021-02-04T10:57:23Z,2021-02-04 10:57:24+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6568
6569,b'TensorRT file operations performance issue',Software,closed,2021-02-04T13:20:54Z,2021-02-08 04:09:31+00:00,2021-02-08T04:09:31Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/6569
6571,b'Google colab crashes when trying to load the model (containing a custom operator) for inferencing using ORT.',Software,closed,2021-02-04T14:06:11Z,2021-02-04 14:06:12+00:00,2021-12-08T05:31:27Z,0,306,https://api.github.com/repos/microsoft/onnxruntime/issues/6571
6573,b'macOS: Errors when cross compiling for arm64',Software,closed,2021-02-04T16:29:39Z,2021-02-04 16:42:57+00:00,2022-04-04T16:55:43Z,0,424,https://api.github.com/repos/microsoft/onnxruntime/issues/6573
6584,b'Fix to avoid incompatibility if compile with jdk9',Software,closed,2021-02-05T16:26:30Z,2021-02-05 16:26:43+00:00,2021-02-06T06:26:18Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6584
6591,"b""ImportError: cannot import name 'get_all_providers' from 'onnxruntime.capi._pybind_state'""",Software,closed,2021-02-05T21:47:35Z,2021-02-05 21:59:11+00:00,2021-02-05T21:59:11Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6591
6600,"b""InvalidGraph: [ONNXRuntimeError] : 10 : INVALID_GRAPH : Load model from Models/onnx_mutate_2.onnx failed:This is an invalid model. Error in Node:c1 : Required attribute 'to' is missing.""",Software,closed,2021-02-06T22:29:11Z,2021-02-07 18:57:56+00:00,2021-02-07T18:57:56Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6600
6605,b'Inference error using migraohx-onnxruntime',Software,open,2021-02-08T09:26:33Z,2021-02-08 12:22:48+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6605
6606,b'How could I set dymanic input size when customizing an operator',Software,closed,2021-02-08T11:55:19Z,2021-02-08 12:24:15+00:00,2021-03-03T13:59:24Z,0,23,https://api.github.com/repos/microsoft/onnxruntime/issues/6606
6607,b'Can you provide the OnNXRuntime Windows precompiled libraries based on CUDA11 and CUDNN8',Software,closed,2021-02-08T14:29:24Z,2021-02-16 04:24:23+00:00,2021-02-16T04:24:23Z,7,7,https://api.github.com/repos/microsoft/onnxruntime/issues/6607
6608,b'onnxruntime-win-x64-gpu-1.6.0.zip can not run',Software,closed,2021-02-08T14:34:39Z,2021-02-09 12:16:09+00:00,2021-02-09T12:16:09Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6608
6618,b'Request examples for GPU inference with C API',Documentation,open,2021-02-09T10:57:28Z,2021-02-09 21:56:41+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6618
6620,b'Android arm64-v8a static libraries 1.11 GB in size',Software,closed,2021-02-09T13:04:29Z,2021-02-09 22:30:34+00:00,2021-02-12T03:47:29Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/6620
6633,b'Python MacOS arm64 release binaries',Software,open,2021-02-10T04:01:25Z,2021-02-10 04:02:03+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6633
6637,b'ONNX Runtime on Nvidia Jetson only 2FPS',Software,open,2021-02-10T08:16:38Z,2021-02-16 04:22:10+00:00,,5,,https://api.github.com/repos/microsoft/onnxruntime/issues/6637
6638,b'/onnxruntime/core/mlas/lib/quantize.cpp:50:62: error: \xe2\x80\x98vminnmq_f32\xe2\x80\x99 was not declared in this scope',Software,open,2021-02-10T09:19:18Z,2021-02-10 17:38:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6638
6639,b'Optimal CPU Configuration',Software,open,2021-02-10T14:14:13Z,2021-02-10 19:43:10+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6639
6655,b'Java runtime request: Add method that returns underlying map for OrtSession.Result',Software,closed,2021-02-11T16:27:42Z,2021-02-13 12:53:27+00:00,2021-02-13T12:53:26Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/6655
6662,b'Failed to add Microsoft.AI.MachineLearning NuGet package to .NET Framework 4.6.1 projects',Software,open,2021-02-12T03:57:04Z,2021-02-12 04:04:21+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6662
6670,b'CUDA / TensorRT - Exception during initialization: std::bad_alloc',Software,closed,2021-02-12T22:21:13Z,2021-02-15 16:38:44+00:00,2021-02-15T16:38:44Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/6670
6676,b'Lifetime of the strings inside OrtOpenVINOProviderOptions',Software,closed,2021-02-13T02:12:03Z,2021-02-16 15:41:56+00:00,2021-03-08T21:30:46Z,3,23,https://api.github.com/repos/microsoft/onnxruntime/issues/6676
6680,b'Error in Nonmaxsupression',Software,closed,2021-02-13T09:29:19Z,2021-02-16 04:36:13+00:00,2021-02-16T08:36:00Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/6680
6681,"b""LabelEncoder with NaN float key doesn't map""",Software,open,2021-02-13T16:33:30Z,2021-02-16 04:48:49+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/6681
6691,b'Incorrect ShapeInferenceError on RoiAlign op',Software,closed,2021-02-15T13:11:49Z,2021-02-16 04:37:58+00:00,2021-02-16T04:37:58Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6691
6694,b'Run ML model on GPU of an Android run system',Software,open,2021-02-15T14:28:30Z,2021-02-16 04:20:27+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6694
6695,b'Dynamic quantization slow on non-VNNI CPUs',Software,closed,2021-02-15T16:59:42Z,2021-02-16 04:19:48+00:00,2021-02-16T22:06:45Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/6695
6696,"b""ONNX runtime session can't load model with external data outside of current folder.""",Software,closed,2021-02-15T18:08:33Z,2021-02-18 18:47:19+00:00,2021-09-02T19:43:05Z,3,199,https://api.github.com/repos/microsoft/onnxruntime/issues/6696
6698,b'NodeJS samples links to 404',Documentation,closed,2021-02-15T20:38:42Z,2021-02-16 04:19:09+00:00,2021-02-19T18:56:23Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/6698
6702,b'static quantization issue with Matmul parameters',Documentation,closed,2021-02-16T08:45:22Z,2021-02-16 21:56:03+00:00,2021-02-17T10:05:43Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/6702
6703,b'Support for 3D ConvTranspose in CUDA execution provider',Software,closed,2021-02-16T15:30:52Z,2021-02-17 04:56:16+00:00,2021-02-24T19:53:32Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/6703
6706,"b'TensorRT EP API for environment variables (esp, on FP16, INT8) '",Software,open,2021-02-16T19:57:28Z,2021-02-23 02:55:26+00:00,,6,,https://api.github.com/repos/microsoft/onnxruntime/issues/6706
6710,b'typo in readme',Software,closed,2021-02-16T23:06:34Z,2021-02-16 23:38:53+00:00,2021-02-17T17:29:31Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6710
6712,b'another typo in readme',Software,closed,2021-02-16T23:23:16Z,2021-02-16 23:38:43+00:00,2021-02-17T17:06:39Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6712
6724,b'onnxruntime c++ api for getting non Tensor output',Software,closed,2021-02-17T09:46:43Z,2021-02-17 15:22:32+00:00,2021-02-17T18:45:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6724
6725,b'[WinML] Threadpool consumes all available CPU during real-time CPU inference',Software,closed,2021-02-17T10:09:37Z,2021-02-17 17:33:36+00:00,2021-10-14T21:51:11Z,0,239,https://api.github.com/repos/microsoft/onnxruntime/issues/6725
6732,b'INT8 quantized model is very slow',Software,open,2021-02-17T19:39:27Z,2021-02-18 06:42:13+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6732
6737,b'Shape inference error for Range node',Software,open,2021-02-17T22:13:24Z,2021-02-18 06:41:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6737
6744,b'onnxruntime-gpu (cudaexecutionprovider) usage of cudnn autotuner',Software,open,2021-02-18T14:33:08Z,2021-02-18 18:37:06+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6744
6749,b'Unable to compile on Linux with CUDA',Software,open,2021-02-19T00:50:53Z,2021-02-19 18:59:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6749
6752,"b'install onnxruntime  compile element_wise_ops.cc failed,error code:C2514'",Software,closed,2021-02-19T05:13:34Z,2021-02-19 18:04:11+00:00,2021-08-10T06:40:22Z,0,172,https://api.github.com/repos/microsoft/onnxruntime/issues/6752
6755,b'Onnxruntime inference with Integrated GPU Failed',Software,open,2021-02-19T11:36:54Z,2021-03-03 18:23:54+00:00,,12,,https://api.github.com/repos/microsoft/onnxruntime/issues/6755
6756,"b""Non-zero status code returned while running Unsqueeze node. Name:'Unsqueeze__892' Status Message: /onnxruntime_src/onnxruntime/core/providers/common.h:18 int64_t onnxruntime::HandleNegativeAxis(int64_t, int64_t) axis >= -tensor_rank && axis <= tensor_rank - 1 was false. axis 2 is not in valid range [-2,1]""",Software,closed,2021-02-19T15:51:52Z,2021-02-19 17:03:37+00:00,2021-02-19T17:03:37Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6756
6759,b'Quantizer does not correctly set QType in quantized_value_map for int8 input',Software,closed,2021-02-19T21:08:42Z,2021-02-22 22:27:36+00:00,2021-03-01T21:09:50Z,3,10,https://api.github.com/repos/microsoft/onnxruntime/issues/6759
6766,b'[Ignore] Test issue',Software,closed,2021-02-20T00:40:21Z,2021-02-20 00:40:31+00:00,2021-02-24T19:07:25Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/6766
6769,b'[ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for the node LinearRegressor:LinearRegressor(1)',Software,closed,2021-02-20T18:07:38Z,2021-02-24 01:05:16+00:00,2021-03-26T20:08:06Z,3,34,https://api.github.com/repos/microsoft/onnxruntime/issues/6769
6779,"b'How can I deploy, a model with ATen-based custom op, with c++ api'",Software,closed,2021-02-23T05:36:19Z,2021-02-24 01:03:27+00:00,2021-05-29T05:21:27Z,0,94,https://api.github.com/repos/microsoft/onnxruntime/issues/6779
6781,b'Can not get the same result between tensorflow model and the exported ONNX model?',Software,closed,2021-02-23T09:31:25Z,2021-02-24 01:02:27+00:00,2021-03-10T02:20:39Z,0,14,https://api.github.com/repos/microsoft/onnxruntime/issues/6781
6782,b'1 : FAIL : Type Error: Type parameter (T) bound to different types (tensor(double) and tensor(float) in node (MatMul).',Software,closed,2021-02-23T11:40:52Z,2021-02-24 01:04:21+00:00,2021-02-24T09:47:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6782
6783,b'Memcopy (Host->Device) very slow on TX2 with Jetpack 4.5',Software,open,2021-02-23T12:34:27Z,2021-02-24 01:01:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6783
6784,b'Broken link in README.md for python quantization tools',Documentation,closed,2021-02-23T18:16:10Z,2021-02-23 18:42:53+00:00,2021-02-24T17:24:35Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6784
6786,b'When will onnxRuntime be available based on cuda11 and cudnn8 and when will the next version be available?',Documentation,closed,2021-02-24T01:57:15Z,2021-02-24 02:09:40+00:00,2021-02-24T02:09:40Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6786
6787,b'/protobuf/cmake/protoc-3.11.3.0: Exec format error',Software,closed,2021-02-24T05:05:38Z,2021-03-01 18:59:28+00:00,2021-03-01T19:52:06Z,5,5,https://api.github.com/repos/microsoft/onnxruntime/issues/6787
6790,b'onnx runtime is running the whole graph',Software,closed,2021-02-24T07:41:48Z,2021-02-24 09:42:03+00:00,2021-03-19T00:05:58Z,0,22,https://api.github.com/repos/microsoft/onnxruntime/issues/6790
6792,b'Not sure if the source code in the release page should be buildable?',Software,closed,2021-02-24T08:32:38Z,2021-02-24 08:43:57+00:00,2021-02-24T12:32:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6792
6793,b'Onnxruntime fails to load a session (Operator not implemented)',Software,closed,2021-02-24T11:48:45Z,2021-02-26 19:16:25+00:00,2021-03-04T00:52:32Z,2,7,https://api.github.com/repos/microsoft/onnxruntime/issues/6793
6799,b'Onnxruntime.gpu is as slower than cpu mode ',Software,open,2021-02-25T00:11:14Z,2021-02-25 00:27:56+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6799
6800,b'running onnxruntime on alpine based image',Software,open,2021-02-25T00:40:38Z,2021-02-26 19:32:40+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/6800
6814,b'How to access DisposableList?',Software,closed,2021-02-26T00:45:51Z,2021-02-26 05:35:53+00:00,2021-02-26T05:35:53Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6814
6821,b'Multiple input and multiple output models that create tensors in loops can cause serious crashes',Software,open,2021-02-26T07:53:48Z,2021-03-01 19:20:28+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/6821
6823,b'tensorflow albert quantized',Software,closed,2021-02-26T09:16:16Z,2021-03-01 18:15:38+00:00,2021-05-25T00:11:55Z,3,87,https://api.github.com/repos/microsoft/onnxruntime/issues/6823
6824,b'Using existing cudaArray as input to model run with DirectML',Software,open,2021-02-26T15:31:53Z,2021-03-01 19:12:10+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/6824
6830,b'ONNXRuntime Inference with Finetuned BERT Model outputting odd results',Software,open,2021-02-26T21:48:40Z,2021-03-02 21:51:51+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/6830
6835,b'why do transformer onnx model perform slower than pytorch model for longer sequence length?',Software,closed,2021-02-27T01:28:05Z,2021-02-27 22:08:33+00:00,2021-03-03T15:35:43Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/6835
6839,b'how to build mlas only? I want to use mlas as my BLAS .',Software,closed,2021-02-27T07:16:17Z,2021-03-02 01:06:12+00:00,2021-03-02T01:06:12Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/6839
6841,"b'Unable to build onnxruntime with ""--build_wheel""  and ""--enable_pybind"" options'",Software,open,2021-02-27T18:21:16Z,2021-03-01 18:10:46+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/6841
6842,b'[JAVA Bindings + ARM64] ONNXRuntime build fail',Software,closed,2021-02-28T19:43:39Z,2021-03-01 01:26:07+00:00,2021-04-21T17:57:57Z,0,51,https://api.github.com/repos/microsoft/onnxruntime/issues/6842
6843,"b""Can't build against v1.6""",Software,closed,2021-02-28T22:35:05Z,2021-03-01 10:15:41+00:00,2021-03-01T18:07:57Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6843
6847,b'albert quantized ',Software,open,2021-03-01T08:06:46Z,2021-03-01 19:10:38+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6847
6851,"b'[optimization, quantization, inference] Clarification regarding docs/API'",Software,closed,2021-03-01T15:21:45Z,2021-03-02 17:47:23+00:00,2022-02-06T20:34:56Z,1,342,https://api.github.com/repos/microsoft/onnxruntime/issues/6851
6852,b'Quantized layers inference error on MacOS',Software,closed,2021-03-01T15:53:08Z,2021-03-01 18:18:05+00:00,2021-03-10T00:45:31Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/6852
6857,b'No nuget packages when building multiple EPs',Software,open,2021-03-01T19:27:55Z,2021-03-02 17:51:02+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6857
6864,b'General C# EP question',Software,closed,2021-03-02T11:11:19Z,2021-03-02 17:54:46+00:00,2022-03-02T13:59:05Z,0,365,https://api.github.com/repos/microsoft/onnxruntime/issues/6864
6865,b'same structure with different parameters run at very different speeds',Software,closed,2021-03-02T12:10:05Z,2021-03-02 12:21:18+00:00,2021-03-03T05:16:17Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6865
6874,b'TFlite model crashes in ONNX runtime',Software,closed,2021-03-03T11:00:24Z,2021-03-03 11:02:34+00:00,2021-03-11T18:24:48Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/6874
6875,b'How to call `CreateEnvWithGlobalThreadPools` in cpp program?',Software,closed,2021-03-03T13:47:33Z,2021-03-03 13:48:46+00:00,2021-03-04T00:48:55Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6875
6876,"b'onnxruntime 1.7.0 inference model crashes, but 1.6.0 can'",Software,closed,2021-03-03T14:27:19Z,2021-03-03 16:33:41+00:00,2021-03-04T08:13:17Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6876
6877,b'python API: onnxruntime.set_seed does not seem to work',Software,closed,2021-03-03T14:48:44Z,2021-03-03 18:13:59+00:00,2021-03-04T08:04:32Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6877
6884,b'Symbolic shape inference for IF operator',Software,open,2021-03-03T23:03:07Z,2021-03-04 16:18:14+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6884
6888,"b'dynamic quantization creating unnecessary parent model with ""opt"" appended to the model name.'",Software,closed,2021-03-04T00:59:21Z,2021-03-04 15:51:56+00:00,2021-03-11T05:44:55Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/6888
6900,b'iOS build with -fembed-bitcode option',Software,closed,2021-03-04T21:55:30Z,2021-03-04 23:23:15+00:00,2021-03-09T06:56:13Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/6900
6901,"b""What's the status of the session options config keys?""",Software,closed,2021-03-04T22:08:14Z,2021-03-19 00:30:02+00:00,2021-03-19T00:30:02Z,14,14,https://api.github.com/repos/microsoft/onnxruntime/issues/6901
6902,b'Unable to build the docker file for openvino on cpu',Software,closed,2021-03-05T00:43:26Z,2021-03-05 02:31:22+00:00,2021-03-10T18:58:23Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/6902
6906,b'celu get wrong result when alpha is negtive',Software,closed,2021-03-05T06:56:04Z,2021-03-05 15:03:08+00:00,2021-03-15T03:37:41Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/6906
6907,"b'Improve the way of specifying used operators when using ""--minimal_build"" option'",Software,open,2021-03-05T06:58:36Z,2021-03-05 06:59:11+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6907
6908,"b""Cannot find entry point 'OrtGetApiBase'""",Software,closed,2021-03-05T10:34:05Z,2021-03-05 12:53:58+00:00,2021-03-09T19:55:32Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/6908
6910,b'Tensor indexing issue',Software,open,2021-03-05T15:07:35Z,2021-03-05 15:09:52+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6910
6912,b'[BUILD/Visual 2017/ort1.7] compilation issue \\onnxruntime\\core\\providers\\cpu\\math\\element_wise_ops.cc error C2514 class has no constructors',Software,closed,2021-03-05T18:18:25Z,2021-03-05 18:53:17+00:00,2021-08-10T06:37:56Z,0,157,https://api.github.com/repos/microsoft/onnxruntime/issues/6912
6921,"b""RoiAlign CPU is not aligned to pixel centers (per the Mask RCNN paper and Facebook's Detectron2 implementation)""",Software,open,2021-03-06T03:03:17Z,2021-03-08 23:41:49+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/6921
6923,b'[JAVA Bindings + Android arm64-v8a] ONNXRuntime build documentation',Software,open,2021-03-07T01:01:50Z,2021-03-09 17:40:28+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/6923
6925,b'Problem of use MLAS out of onnxruntime tree',Software,closed,2021-03-07T05:35:35Z,2021-03-07 07:48:41+00:00,2021-03-07T07:48:41Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6925
6927,b'Error(s) building ORT 1.7.1 with CUDA and TensorRT from source',Software,closed,2021-03-08T00:08:31Z,2021-03-08 17:25:25+00:00,2021-03-09T20:01:54Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/6927
6928,b'onnxruntime 1.7.0 :The reference order of the header file causes a compilation error',Software,closed,2021-03-08T01:59:19Z,2021-03-08 02:03:06+00:00,2021-03-08T02:03:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6928
6931,"b'How to run a model exported with multiple input, using single input?'",Software,closed,2021-03-08T04:50:21Z,2021-03-08 17:26:35+00:00,2021-03-11T17:42:35Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/6931
6933,b'AlbertForSequenceClassification random output',Software,closed,2021-03-08T08:38:47Z,2021-03-08 18:34:39+00:00,2021-03-08T22:18:58Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6933
6934,b'Inference performances decrease as the inference thread(also process) increase',Software,closed,2021-03-08T11:48:03Z,2021-03-08 17:36:00+00:00,2021-03-08T17:36:00Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6934
6935,b'Question: how to query the ONNX opset version from headers ?',Software,closed,2021-03-08T15:05:02Z,2021-03-08 17:07:16+00:00,2021-03-12T06:47:44Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/6935
6936,b'GRU/LSTM stateful implementation or workaround guidance',Software,closed,2021-03-08T17:27:40Z,2021-03-08 18:22:31+00:00,2021-04-19T07:52:28Z,0,41,https://api.github.com/repos/microsoft/onnxruntime/issues/6936
6949,b'compile time error in samples/c_cxx/model-explorer',Software,closed,2021-03-09T04:32:47Z,2021-03-10 18:19:02+00:00,2021-03-10T18:19:02Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/6949
6952,b'customer op with cuda provider compute is error',Software,closed,2021-03-09T06:20:48Z,2021-03-09 06:24:19+00:00,2021-03-12T10:20:32Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/6952
6953,b'Error(s) building ORT 1.7.0 with TensorRT from source component',Software,closed,2021-03-09T06:38:42Z,2021-03-09 19:22:57+00:00,2021-03-10T00:59:20Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6953
6964,b'improved C++ documentation please!',Documentation,closed,2021-03-10T02:23:30Z,2021-03-10 07:16:15+00:00,2021-10-14T23:01:16Z,0,218,https://api.github.com/repos/microsoft/onnxruntime/issues/6964
6965,"b""What's the usage of OrtSessionOptionsAppendExecutionProvider_CPU function?""",Documentation,closed,2021-03-10T03:11:16Z,2021-03-10 07:30:14+00:00,2021-03-10T07:30:14Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/6965
6970,"b'in window ,onnxruntime and use_dml build,'",Software,open,2021-03-10T11:17:13Z,2021-03-10 18:29:48+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6970
6972,"b'Enable signed int8 activation type in static quantization, add option for not symmetrizing calibration data'",Software,closed,2021-03-10T18:34:31Z,2021-03-11 04:05:18+00:00,2021-06-24T21:42:23Z,0,106,https://api.github.com/repos/microsoft/onnxruntime/issues/6972
6977,b'Can Onnxruntime support quantization with AVX2 instruction?',Software,open,2021-03-11T00:06:24Z,2021-03-11 23:07:36+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6977
6978,b'dynamic shape input is much slower than fixed shape input in gpu ',Software,open,2021-03-11T03:55:29Z,2021-03-11 19:15:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/6978
6986,b'Multiple InferenceSessions lead to unspecified launch Error',Software,closed,2021-03-11T22:22:54Z,2021-03-13 08:45:43+00:00,2021-03-13T08:45:43Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/6986
6996,"b'Error when building for Android armeabi-v7a api level 16: ""use of undeclared identifier \'nftw\'""'",Software,closed,2021-03-12T11:25:29Z,2021-03-12 18:33:36+00:00,2021-03-15T07:52:41Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/6996
7003,b'create tensor of float16 as input using the Java API',Software,open,2021-03-13T00:13:51Z,2021-03-15 17:00:25+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/7003
7005,b'CUDA header requested but missing in DNNL part of ORT 1.7.1',Software,open,2021-03-14T01:21:29Z,2021-03-15 17:11:46+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/7005
7006,b'[PR] Shape Inference for Fused Nodes',Software,closed,2021-03-14T02:56:53Z,2021-03-16 00:13:31+00:00,2021-05-08T19:53:57Z,1,55,https://api.github.com/repos/microsoft/onnxruntime/issues/7006
7008,b'dream',Software,closed,2021-03-14T05:16:20Z,2021-03-14 05:16:43+00:00,2021-03-14T05:16:43Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7008
7009,"b""Failed to build ORT with option '--enable_training' and '--x86' for Windows""",Software,open,2021-03-14T08:57:20Z,2021-03-15 16:34:54+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/7009
7010,b'Support for SSE/AVX instructions',Software,closed,2021-03-15T06:52:40Z,2021-03-15 16:51:53+00:00,2021-03-16T20:34:55Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/7010
7011,b'Run ResNet50 On TensorRT Provider was failed.',Software,closed,2021-03-15T09:01:43Z,2021-03-15 16:56:48+00:00,2021-03-22T01:53:15Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/7011
7017,"b'Quantizing GPT2-XL Model leads to ""exceeds maximum protobuf""'",Software,closed,2021-03-16T00:42:23Z,2021-03-16 15:32:24+00:00,2022-04-19T20:58:09Z,0,399,https://api.github.com/repos/microsoft/onnxruntime/issues/7017
7020,b'Exception thrown in allocation planner: accessing index -1 of ort_value_info_',Software,closed,2021-03-16T04:45:31Z,2021-03-16 18:40:49+00:00,2021-05-14T00:52:24Z,0,58,https://api.github.com/repos/microsoft/onnxruntime/issues/7020
7022,b'version1.7.0 c++ use cuda not use?',Software,closed,2021-03-16T08:04:48Z,2021-03-16 17:13:27+00:00,2021-03-17T16:20:26Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/7022
7023,b'Model works in ORT python but crashes in ORT C++',Software,closed,2021-03-16T12:00:32Z,2021-03-17 08:35:32+00:00,2021-03-17T08:35:32Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7023
7024,b'Model crashes with CUDA provider / works with CPU provider',Software,closed,2021-03-16T12:47:14Z,2021-03-16 12:47:26+00:00,2021-03-16T13:44:29Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7024
7037,b'Is batch inference supported now for quantized gpt2 model with onnxruntime 1.7.0?',Software,closed,2021-03-17T01:21:41Z,2021-03-17 01:21:41+00:00,2022-01-03T18:46:23Z,0,292,https://api.github.com/repos/microsoft/onnxruntime/issues/7037
7038,"b"" Non-zero status code returned while running ScatterND node. Name:'ScatterND@1' Status Message: updates tensor should have shape equal to indices.shape[:-1] + data.shape[indices.shape[-1]:]. updates shape: {1}, indices shape: {1}, data shape: {3}""",Software,closed,2021-03-17T03:38:17Z,2021-03-17 16:26:45+00:00,2021-03-27T03:39:37Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/7038
7041,b'Feature Request: enable cmake install target',Software,closed,2021-03-17T18:18:28Z,2021-03-18 01:42:02+00:00,2021-03-20T00:29:07Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/7041
7044,b'Dynamic GPU support',Software,closed,2021-03-17T23:09:58Z,2021-07-21 05:33:16+00:00,2021-07-21T05:33:15Z,125,125,https://api.github.com/repos/microsoft/onnxruntime/issues/7044
7045,b'Enable clients to supply their own threads when inferencing on CPU',Software,open,2021-03-17T23:26:01Z,2021-03-18 00:30:48+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7045
7049,b'No Op registered for Einsum with domain_version of 12 When using onnxruntime_server',Software,closed,2021-03-18T05:04:36Z,2021-03-18 06:00:41+00:00,2021-03-18T06:00:41Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7049
7052,b'Build fail for docker on MacOS. -NO GPU.',Software,open,2021-03-18T10:17:20Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/7052
7055,"b'Error when running ""onnxruntime_tools.transformers.bert_perf_test"" on BERT-derived model'",Software,closed,2021-03-18T15:56:56Z,2021-03-18 19:48:25+00:00,2021-03-23T16:51:29Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/7055
7056,b'conda package',Software,open,2021-03-18T16:16:17Z,2021-03-18 19:38:11+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7056
7061,b'Provider fallback is broken',Software,closed,2021-03-18T20:44:33Z,2021-03-18 21:07:42+00:00,2021-03-22T20:38:59Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/7061
7066,b'AliasWithName is not a registered function(From 5187)',Software,open,2021-03-19T01:20:39Z,2021-03-21 20:37:09+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/7066
7067,b'Large Memory Allocations When Loading RandomForestRegressor Model',Software,open,2021-03-19T02:13:03Z,2021-03-21 20:46:39+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/7067
7070,b'Onnxruntime_server support CUDA backend',Software,closed,2021-03-19T08:07:35Z,2021-03-21 21:02:13+00:00,2021-04-13T02:13:54Z,2,24,https://api.github.com/repos/microsoft/onnxruntime/issues/7070
7071,b'dnnl ep segmentation fault (core dumped) with rel-1.7.1',Software,closed,2021-03-19T08:36:43Z,2021-03-21 21:03:23+00:00,2021-04-07T07:24:17Z,2,18,https://api.github.com/repos/microsoft/onnxruntime/issues/7071
7072,b'expand fails when leading shape value is -1',Software,open,2021-03-19T10:03:32Z,2021-03-21 21:54:34+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/7072
7073,b'TensorRT supports only Bert based models but not Roberta based (or anything else)',Software,closed,2021-03-19T11:09:30Z,2021-03-21 21:56:07+00:00,2021-08-09T03:47:47Z,2,142,https://api.github.com/repos/microsoft/onnxruntime/issues/7073
7074,b'Question about cmake settings',Software,closed,2021-03-19T12:17:58Z,2021-03-19 17:23:46+00:00,2021-03-19T17:23:46Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7074
7075,b'ORT crashes if second input to split node is empty string.',Software,closed,2021-03-19T18:53:15Z,2021-03-21 22:01:10+00:00,2021-04-12T17:26:09Z,2,23,https://api.github.com/repos/microsoft/onnxruntime/issues/7075
7080,b'Converting GPT2 to ONNX format does not work with `onnxruntime-tools==1.6.0`',Software,closed,2021-03-20T21:36:18Z,2021-03-21 22:03:03+00:00,2021-03-24T16:55:50Z,1,3,https://api.github.com/repos/microsoft/onnxruntime/issues/7080
7084,b'Possible Memory leak in CXX Api',Software,open,2021-03-22T02:51:00Z,2021-03-22 08:58:34+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7084
7085,"b'when python calls the sharesd lib, an error occurs in the custom cuda operator'",Software,closed,2021-03-22T04:38:27Z,2021-03-22 07:23:58+00:00,2021-03-22T07:23:58Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7085
7086,"b""Plugin [id: 'com.diffplug.spotless', version: '5.9.0'] was not found""",Software,closed,2021-03-22T12:10:29Z,2021-03-22 16:59:47+00:00,2021-03-23T02:52:31Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7086
7095,b'Non-zero status code returned while running BatchNormalization node',Software,open,2021-03-22T22:06:31Z,2021-03-22 22:27:21+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7095
7096,b'Pytorch squeeze after pad function cause CPU Fallback warning at runtime.',Software,closed,2021-03-22T22:12:37Z,2021-03-22 22:28:20+00:00,2021-03-30T07:35:41Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/7096
7097,b'CUDA kernel not found in registries for Op type: Pow ',Software,closed,2021-03-22T22:22:21Z,2021-03-22 22:28:45+00:00,2021-03-23T06:16:14Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7097
7098,b'Incompatible dimensions error in a Mul node at runtime.',Software,closed,2021-03-22T22:46:33Z,2021-03-23 01:11:22+00:00,2021-04-08T18:08:40Z,0,16,https://api.github.com/repos/microsoft/onnxruntime/issues/7098
7100,b'Failed to build MinSizeRel on Linux',Software,closed,2021-03-23T03:51:39Z,2021-03-23 04:12:22+00:00,2021-03-25T04:03:46Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/7100
7103,b'How to input/output GPU-based tensors rather than np.array  in python?',Software,closed,2021-03-23T05:57:42Z,2021-03-23 16:57:20+00:00,2021-04-05T04:49:46Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/7103
7105,b'Invalid model after quantization for onnxruntime 1.7.0',Software,closed,2021-03-23T06:42:08Z,2021-03-23 16:58:00+00:00,2021-03-23T23:40:02Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7105
7106,b'Memory and timing issue with onnxruntime python API with TensorFlow model',Software,open,2021-03-23T15:36:24Z,2021-03-23 16:39:26+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7106
7107,"b'How to run ""onnxruntime_tools.transformers.bert_perf_test"" on cloud services'",Software,closed,2021-03-23T16:59:06Z,2021-03-23 17:03:55+00:00,2021-03-24T03:58:00Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7107
7114,b'[Documentation Request] bads links on ONNX install page',Documentation,closed,2021-03-23T22:09:02Z,2021-03-24 00:47:27+00:00,2021-10-18T23:35:38Z,0,209,https://api.github.com/repos/microsoft/onnxruntime/issues/7114
7119,b'Provider OpenVINOExecutionProvider has already been registered',Software,closed,2021-03-24T01:30:28Z,2021-03-24 02:08:08+00:00,2021-04-02T02:51:36Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/7119
7122,b'why create a global Ort::Env object will raise an error \xef\xbc\x9f ',Software,closed,2021-03-24T03:51:59Z,2021-03-24 03:57:01+00:00,2021-03-24T03:57:01Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7122
7130,b'Install onnxruntime==1.7.0 on CentOS 6',Software,closed,2021-03-24T21:25:13Z,2021-03-24 21:25:24+00:00,2021-04-01T01:49:49Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/7130
7142,b'Compile error in header onnxruntime_cxx_api.h when update ONNX runtime from 1.5.2 to 1.7.1',Software,open,2021-03-26T06:15:40Z,2021-03-26 16:08:01+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7142
7143,b'Build python wheel failed',Software,closed,2021-03-26T07:54:36Z,2021-03-26 08:29:04+00:00,2021-03-27T06:59:39Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7143
7144,"b'Question about ""quantize_qat""'",Software,closed,2021-03-26T08:23:23Z,2021-03-26 16:08:54+00:00,2021-03-30T03:52:16Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/7144
7149,b'Provider ABI for IExecutionProvider OnnxRuntime extension infrastructure',Software,open,2021-03-26T21:42:41Z,2021-03-26 21:49:03+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7149
7150,b'VCPKG port for onnxruntime and modernize cmake builds',Software,open,2021-03-26T21:49:24Z,2021-03-26 23:11:57+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7150
7155,b'Building from source with DNNL -- but no DnnlExecutionProvider',Software,closed,2021-03-27T00:43:39Z,2021-03-27 00:43:51+00:00,2021-04-13T18:37:43Z,0,17,https://api.github.com/repos/microsoft/onnxruntime/issues/7155
7160,b'Error when cross-compiling for iOS',Software,closed,2021-03-28T20:05:16Z,2021-03-29 18:38:36+00:00,2021-03-30T18:52:27Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/7160
7168,b'Error while build from source: Failed to find executable path for Cmake',Software,closed,2021-03-29T20:06:39Z,2021-03-29 20:37:57+00:00,2021-03-29T20:37:57Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7168
7173,b'Build wheel  with OpenVINO  ERROR: testRegisterCustomOpsLibrary (__main__.TestInferenceSession)',Software,closed,2021-03-30T02:34:06Z,2021-03-30 02:36:50+00:00,2021-04-15T00:26:30Z,0,15,https://api.github.com/repos/microsoft/onnxruntime/issues/7173
7178,b'Batch inference',Software,open,2021-03-30T08:42:18Z,2021-03-30 20:09:56+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7178
7186,"b'Build problem in ""Using NNAPI with ONNX Runtime Mobile""'",Software,closed,2021-03-30T21:07:09Z,2021-03-30 23:57:41+00:00,2021-03-31T10:04:04Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7186
7194,b'Fix memory leak in TRT due to optimization profile with dynamic shapes',Software,closed,2021-03-31T10:47:33Z,2021-03-31 10:47:34+00:00,2021-04-05T21:17:19Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/7194
822,b'Provide a context manager to silence PyTorch exporter warning',Software,closed,2019-04-11T22:52:49Z,2019-04-16 06:37:40+00:00,2019-04-17T23:35:15Z,4,6,https://api.github.com/repos/microsoft/onnxruntime/issues/822
827,b'onnxruntime slower than scikit in batch predictions',Software,closed,2019-04-12T19:58:08Z,2019-04-15 18:28:02+00:00,2020-05-19T18:44:41Z,2,402,https://api.github.com/repos/microsoft/onnxruntime/issues/827
829,b'Why throw exception when inferring shape using onnx',Software,closed,2019-04-15T09:46:29Z,2019-04-15 09:47:32+00:00,2019-04-19T02:23:19Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/829
830,b'How to build a static link?',Software,closed,2019-04-15T10:42:00Z,2019-04-16 00:41:59+00:00,2019-04-16T00:41:59Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/830
831,b'Arcface model from onnx model zoo returns nan with CUDA',Software,closed,2019-04-15T11:49:59Z,2019-04-15 23:56:38+00:00,2019-10-11T02:21:35Z,0,178,https://api.github.com/repos/microsoft/onnxruntime/issues/831
851,b'bidirectional lstm model with sequence_lens RuntimeError: Unexpected input data type',Software,closed,2019-04-17T03:23:27Z,2019-04-18 00:53:20+00:00,2019-04-18T23:07:27Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/851
852,b'About output',Software,closed,2019-04-17T06:52:17Z,2019-04-18 00:52:26+00:00,2019-06-17T06:08:26Z,0,60,https://api.github.com/repos/microsoft/onnxruntime/issues/852
853,b'Need sample or document about batch predict',Documentation,closed,2019-04-17T07:19:25Z,2019-04-17 17:01:08+00:00,2019-07-16T21:23:47Z,0,90,https://api.github.com/repos/microsoft/onnxruntime/issues/853
856,"b'Unexpected behavior when set RunOption.run_log_verbosity_level to ""warning""'",Software,closed,2019-04-17T23:01:18Z,2019-04-22 23:28:30+00:00,2019-06-12T01:02:26Z,5,55,https://api.github.com/repos/microsoft/onnxruntime/issues/856
876,b'Undefined symbol from nsync.',Software,closed,2019-04-22T00:03:53Z,2019-04-23 18:23:50+00:00,2019-06-11T20:01:17Z,1,50,https://api.github.com/repos/microsoft/onnxruntime/issues/876
877,b'Support eigen release',Software,closed,2019-04-22T00:12:35Z,2019-04-22 07:13:29+00:00,2019-04-22T22:02:03Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/877
885,b'SliceElimination transformer causes shape inference error',Software,closed,2019-04-23T08:25:43Z,2019-04-23 18:18:22+00:00,2019-04-27T04:06:21Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/885
886,b'onnxruntime slower than xgboost & lightgbm in batch predictions',Software,closed,2019-04-23T11:38:39Z,2019-04-23 18:15:19+00:00,2020-08-08T23:16:55Z,0,473,https://api.github.com/repos/microsoft/onnxruntime/issues/886
889,"b'mlvalue default allocation warning, not stateless'",Software,closed,2019-04-23T22:06:21Z,2019-04-24 04:18:08+00:00,2019-04-27T19:54:02Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/889
892,b'C# inference is slower than Python',Software,closed,2019-04-24T01:20:13Z,2019-04-24 01:50:45+00:00,2019-07-02T02:53:23Z,0,69,https://api.github.com/repos/microsoft/onnxruntime/issues/892
897,b'runing on two cpus machine is slower than one cpu machine',Software,closed,2019-04-24T14:22:30Z,2019-04-24 17:23:23+00:00,2019-06-11T22:20:55Z,0,48,https://api.github.com/repos/microsoft/onnxruntime/issues/897
902,b'Crash on embedded protoc',Software,closed,2019-04-25T01:46:55Z,2019-04-25 01:53:44+00:00,2019-05-16T03:12:03Z,0,21,https://api.github.com/repos/microsoft/onnxruntime/issues/902
903,"b'Regression: ""ceil_mode_"" is not defined'",Software,closed,2019-04-25T07:16:59Z,2019-04-25 07:26:10+00:00,2019-04-25T19:32:29Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/903
906,b'Use CONFIGURE_DEPENDS in file(GLOB*',Software,closed,2019-04-25T10:01:38Z,2019-04-25 18:53:27+00:00,2019-04-29T19:58:21Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/906
7207,b'Segmentation fault when running onnxruntime inside docker with cpuset restrictions',Software,open,2021-04-01T17:11:12Z,2021-04-01 21:51:00+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7207
7212,b'Significant difference in the performance of pytorch and exported onnx models',Software,open,2021-04-01T22:19:56Z,2021-04-02 01:04:29+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7212
7225,b'Explain in the docs that run() or run_with_binding() always synchronizes the CUDA stream prior to returning control (or an explicit note about proper benchmarking ONNX ops versus PyTorch ops also wrt CUDA syncs)',Documentation,open,2021-04-02T20:47:13Z,2021-04-03 08:08:11+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7225
7228,b'Different inference results Python vs C++',Documentation,closed,2021-04-03T04:23:53Z,2021-04-03 08:09:31+00:00,2021-04-05T04:29:55Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/7228
7230,b'TensorrtExecutionProvider slower than CUDAExecutionProvider: Transformers',Software,open,2021-04-03T20:31:45Z,2021-04-05 04:37:55+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/7230
7231,b'Rust support',Software,open,2021-04-04T10:58:26Z,2021-04-05 04:41:45+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7231
7233,b'The speed of running the onnx model is 6x slower than the pytorch model on Jetson TX2',Software,open,2021-04-05T02:47:20Z,2021-04-05 04:42:51+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7233
7234,b'[Python API + ARM64] Running ResNet50 on ARM board using ACL Error and Performance Issue',Software,open,2021-04-05T02:52:58Z,2021-04-05 04:47:33+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7234
7236,b'Dockerfile.cuda and Dockerfile.source fail with dependency on Python 3.7',Software,closed,2021-04-05T15:56:53Z,2021-04-05 16:49:43+00:00,2021-04-05T21:18:26Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7236
7237,b'Cannot use Microsoft.ML.OnnxRuntime and WinUI 3 desktop: The target process exited without raising a CoreCLR started event',Software,open,2021-04-05T17:11:36Z,2021-04-05 22:16:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7237
7238,b'GPT-Neo: Torch CUDA 2x faster than ONNX CUDA',Software,open,2021-04-05T18:08:27Z,2021-04-05 22:15:41+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7238
7242,b'Deploy in Android App',Software,closed,2021-04-05T20:48:14Z,2021-04-05 23:19:06+00:00,2021-05-10T22:01:14Z,0,35,https://api.github.com/repos/microsoft/onnxruntime/issues/7242
7247,b'Input device type check has syntax error',Software,closed,2021-04-05T22:42:59Z,2021-04-06 01:33:18+00:00,2021-04-06T21:44:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7247
7254,"b""onnxruntime can't recognize my custom op even though onnx can!""",Software,open,2021-04-06T03:43:30Z,2021-04-06 19:57:19+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7254
7255,b'ACL (32bit) Execution Provider fails on gemm node',Software,open,2021-04-06T09:36:48Z,2021-04-06 19:47:15+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7255
7256,b'onnxruntime c++ protobuf parsing failed.',Software,closed,2021-04-06T11:56:23Z,2021-04-06 19:55:56+00:00,2021-04-07T06:49:46Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7256
7257,"b""rt.SessionOptions() AttributeError: no 'SessionOptions'""",Software,closed,2021-04-06T13:23:06Z,2021-04-06 19:53:19+00:00,2021-04-07T02:12:50Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7257
7269,b'Weights not correctly saved for model trained using level 3 optimizations',Software,closed,2021-04-07T06:16:51Z,2021-04-07 07:13:10+00:00,2021-10-12T16:09:26Z,0,188,https://api.github.com/repos/microsoft/onnxruntime/issues/7269
7270,"b""ai.onnxruntime.OrtException: This tensor is not representable in Java, it's too big""",Software,closed,2021-04-07T06:27:35Z,2021-04-07 07:14:07+00:00,2021-04-14T04:25:48Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/7270
7271,b'Memory leak of using dynamic shapes with Openvino',Software,closed,2021-04-07T07:40:44Z,2021-04-07 20:02:20+00:00,2021-04-19T07:50:21Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/7271
7272,"b""onnxruntime gpu version can't installed, how to fix it?""",Software,open,2021-04-07T09:17:20Z,2021-04-07 23:25:37+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7272
7274,"b""Couldn't install Microsoft.ML.OnnxRuntime on .net core 3.1 project with Visual Studio 2019""",Software,closed,2021-04-07T14:22:18Z,2021-04-07 23:24:53+00:00,2021-04-09T08:02:01Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/7274
7275,b'Mention nightly builds on README.md and onnxruntime.ai main page',Documentation,open,2021-04-07T14:26:36Z,2021-04-07 20:01:13+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7275
7277,b'Information in deleted BUILD.md left out onnxruntime.ai',Documentation,closed,2021-04-07T19:20:26Z,2021-04-07 19:56:47+00:00,2021-10-21T18:13:26Z,0,196,https://api.github.com/repos/microsoft/onnxruntime/issues/7277
7283,b'Question about quantization of Yolo.',Software,closed,2021-04-08T05:25:33Z,2021-04-08 16:49:59+00:00,2021-05-14T20:54:56Z,0,36,https://api.github.com/repos/microsoft/onnxruntime/issues/7283
7286,b'Memory leaks and valgrind errors when running with TensorRT',Software,open,2021-04-08T14:50:07Z,2021-04-08 16:49:19+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7286
7296,b'can I use the windows_x86 to run with gpu?',Software,closed,2021-04-09T05:59:41Z,2021-04-09 14:43:32+00:00,2021-04-09T14:43:31Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7296
7300,b'Invalid model after quantization with onnxruntime 1.7.0 ',Software,closed,2021-04-09T08:56:15Z,2021-04-09 15:01:20+00:00,2021-05-15T06:34:12Z,0,35,https://api.github.com/repos/microsoft/onnxruntime/issues/7300
7303,b'Memory leak',Software,closed,2021-04-09T14:53:06Z,2021-04-09 15:01:02+00:00,2021-10-08T19:30:12Z,0,182,https://api.github.com/repos/microsoft/onnxruntime/issues/7303
7313,b'how can i use the onnxruntime cpu version and gpu version at the same time? ',Software,closed,2021-04-10T11:41:50Z,2021-04-11 23:49:53+00:00,2021-04-14T04:53:33Z,1,3,https://api.github.com/repos/microsoft/onnxruntime/issues/7313
7314,b'Run a model containing CustomOp with TensorRT provider fails',Software,open,2021-04-12T03:35:19Z,2021-04-12 03:43:37+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7314
7316,b'cudaErrorInvalidConfiguration in FusedBatchNormV3',Software,closed,2021-04-12T14:16:39Z,2021-04-12 14:57:19+00:00,2021-05-27T21:01:09Z,0,45,https://api.github.com/repos/microsoft/onnxruntime/issues/7316
7317,b'Getting error during inference with onnx built with openvino support',Software,open,2021-04-12T14:46:50Z,2021-04-12 15:03:28+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7317
7322,b'Access violation when using TensorRT ExecutionProvider on multiple GPU',Software,open,2021-04-12T23:31:35Z,2021-04-13 01:56:48+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7322
7327,b'How to do inference with multi-GPU and multi-machines',Software,closed,2021-04-13T08:45:08Z,2021-04-13 08:52:48+00:00,2021-04-14T04:53:11Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7327
7330,b'C# console app crash upon appending OpenVino execution provider',Software,open,2021-04-13T16:08:46Z,2021-04-13 16:32:06+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7330
7338,b'Unrecognized attribute: axes for operator Squeeze/RecduceSum',Software,closed,2021-04-14T13:46:09Z,2021-04-14 14:28:31+00:00,2021-04-19T22:41:37Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/7338
7339,b'Cannot save Tensorrt .engine model in v1.7.1',Software,open,2021-04-14T15:32:11Z,2021-04-14 16:02:34+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7339
7340,b'Python version 1.7.0 crashes without exception for ndarray dtype float64',Software,closed,2021-04-14T16:18:40Z,2021-04-14 16:18:51+00:00,2021-05-05T18:07:21Z,0,21,https://api.github.com/repos/microsoft/onnxruntime/issues/7340
7346,b'openvino  continued package by pyinstaller  external dll  issue',Software,open,2021-04-15T00:34:05Z,2021-04-15 02:15:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7346
7347,"b""numactl can't bind numa node in onnxruntime1.7""",Software,open,2021-04-15T02:51:36Z,2021-04-15 07:57:52+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7347
7350,b'C/C++ API clarification on accessing arbitrary nodes',Documentation,closed,2021-04-15T14:23:47Z,2021-04-15 15:32:47+00:00,2021-04-15T18:19:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7350
7351,b'Blog post link to python notebook broken (and no notebooks)',Documentation,closed,2021-04-15T20:17:38Z,2021-04-15 21:17:43+00:00,2021-04-19T22:38:45Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/7351
7355,b'Unable to build onnxruntime 1.6.0 from source',Software,closed,2021-04-16T11:11:37Z,2021-04-16 13:46:08+00:00,2021-04-20T17:29:01Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/7355
7356,"b'Problem with  symbolic shape inference for ""Squeeze""'",Software,closed,2021-04-16T14:00:45Z,2021-04-16 15:50:19+00:00,2021-04-28T20:13:04Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/7356
7358,b'[JAVA] Cannot create an ONNXTensor of boolean scalar due to exception thrown on reshape',Software,closed,2021-04-16T15:48:17Z,2021-04-16 15:51:28+00:00,2021-06-24T20:21:36Z,0,69,https://api.github.com/repos/microsoft/onnxruntime/issues/7358
7368,b'Resize Operator rounds-down instead of round-to-even for int32/uint8',Software,open,2021-04-17T19:51:32Z,2021-04-18 17:44:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7368
7375,b'Discrepencies between onnxruntime and numpy with operator Einsum',Software,closed,2021-04-19T21:21:07Z,2021-04-19 21:21:07+00:00,2021-05-26T17:27:20Z,0,36,https://api.github.com/repos/microsoft/onnxruntime/issues/7375
7381,b'Avoid allocations and memory leak in performance critical loop',Software,closed,2021-04-20T16:08:48Z,2021-04-20 16:44:58+00:00,2021-04-26T16:46:24Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/7381
7390,b'Profiling shows that kernel time only takes a very little part of total run time ',Software,closed,2021-04-21T02:07:44Z,2021-04-21 16:33:03+00:00,2021-04-28T15:14:39Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/7390
7395,b'[C#] Feed session.Run a 2D Tensor',Software,closed,2021-04-21T11:03:08Z,2021-04-21 16:24:53+00:00,2021-04-26T06:15:45Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/7395
7400,b'Should AllReduce scaling only happen when gradient steps > 1',Software,closed,2021-04-21T16:57:21Z,2021-04-21 17:20:30+00:00,2021-04-22T14:56:02Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7400
7405,b'Example with Vitis AI execution provider ?',Software,closed,2021-04-21T21:25:02Z,2021-04-22 13:17:28+00:00,2021-04-23T12:20:52Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/7405
7428,"b""Exception has occurred: RuntimeError Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.IntTensor instead (while checking arguments for embedding)""",Software,closed,2021-04-23T03:00:40Z,2021-04-23 03:00:49+00:00,2021-04-27T22:50:44Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/7428
7432,b'Question: can session manage multiple devices ?',Software,closed,2021-04-23T12:20:15Z,2021-04-23 18:40:21+00:00,2021-04-23T18:40:21Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7432
7433,b'Question: plans for a Vulkan compute execution provider ?',Software,closed,2021-04-23T15:58:35Z,2021-04-26 20:50:45+00:00,2021-04-26T21:21:04Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/7433
7441,b'Loading onnx models from ModelProto',Software,closed,2021-04-24T08:39:21Z,2021-04-24 08:51:55+00:00,2021-05-03T14:40:10Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/7441
7444,b'How to compile the framework that can run in Windows XP\xef\xbc\x9f',Software,open,2021-04-26T02:58:29Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/7444
7446,b'Invalid graph after running bert_tf optimizer',Software,open,2021-04-26T05:59:35Z,2021-04-26 05:59:35+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7446
7447,b'Unable to access onnxruntime testdata',Software,closed,2021-04-26T06:32:43Z,2021-04-26 17:25:59+00:00,2021-04-26T17:25:59Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7447
7448,b'Poor inference performance on Intel CPU',Software,closed,2021-04-26T06:45:27Z,2021-04-26 17:10:07+00:00,2021-05-06T19:49:24Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/7448
7449,b'delay between inferences slows down inference',Software,open,2021-04-26T10:07:28Z,2021-04-26 15:52:11+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7449
7451,b'onnxruntime==1.7.0 for aarch64',Software,closed,2021-04-26T14:14:04Z,2021-04-26 22:06:44+00:00,2021-05-11T12:49:09Z,0,14,https://api.github.com/repos/microsoft/onnxruntime/issues/7451
7457,"b'Please, update the docs. Provider parameter ""cuda_mem_limit"" was renamed to ""gpu_mem_limit"" in nightly build.'",Software,open,2021-04-26T22:59:20Z,2021-04-26 23:08:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7457
7460,b'QDQ Optimization for MaxPool does not check Opset Version',Software,closed,2021-04-27T06:35:43Z,2021-04-27 06:35:44+00:00,2021-05-14T20:53:54Z,0,17,https://api.github.com/repos/microsoft/onnxruntime/issues/7460
7462,b'CUDA kernel not found in registries for Op type: Equal',Software,closed,2021-04-27T07:32:32Z,2021-04-30 01:56:54+00:00,2021-04-30T01:56:54Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/7462
7463,b'How to release gpu memory without exiting the process\xef\xbc\x9f',Software,open,2021-04-27T08:08:14Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/7463
7464,b'The input tensor cannot be reshaped to the requested shape',Software,closed,2021-04-27T09:03:33Z,2021-04-27 12:12:32+00:00,2021-04-27T12:12:32Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7464
7465,b'Cant run with model.onnx and Microsoft.ML.OnnxRuntime.DirectML.1.7.0',Software,open,2021-04-27T10:36:37Z,2021-04-27 16:53:04+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7465
7467,b'How to get the libonnxruntime.so in tar.gz  on jetson AGX Xavier when i deploy mmdetction on Xavier',Software,closed,2021-04-27T15:04:47Z,2021-04-28 06:12:19+00:00,2021-04-29T07:12:42Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/7467
7474,b'Onnxruntime - Vitis AI EP error ',Software,closed,2021-04-28T01:09:54Z,2021-04-28 06:10:41+00:00,2021-04-30T05:58:41Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/7474
7480,b'openvino python package build failed on windows with rel-1.6.0',Software,closed,2021-04-28T11:08:46Z,2021-04-29 06:38:22+00:00,2021-05-07T09:38:24Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/7480
7484,b'Running inference using GPU or TensorRT on Jetson',Software,open,2021-04-28T18:14:33Z,2021-04-29 06:38:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7484
7485,b'Failed to load library ./libonnxruntime_providers_shared.so',Software,open,2021-04-28T19:22:11Z,2021-04-28 19:35:57+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7485
7486,b'Is it possible to disable shape inference?',Software,closed,2021-04-28T20:15:05Z,2021-04-28 20:59:57+00:00,2021-04-28T20:59:57Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7486
7499,b'Very slow load of ONNX model in memory especially using TensorRT EP',Software,closed,2021-04-29T06:28:01Z,2021-04-29 06:28:10+00:00,2021-05-03T00:34:18Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/7499
7501,b'Publish optimized aar for Android Java Arm64 Default CPU to central repository.',Software,open,2021-04-29T15:15:05Z,2021-04-29 16:18:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7501
7506,b'Error running onnxruntime_training_mnist on CPU (possibly error in GemmGrad )',Software,closed,2021-04-29T21:10:08Z,2021-04-29 21:11:36+00:00,2021-09-08T21:52:00Z,0,132,https://api.github.com/repos/microsoft/onnxruntime/issues/7506
7507,b'quantize to int8:    assert (bias_name not in self.quantized_value_map)',Software,closed,2021-04-29T22:26:15Z,2021-05-01 05:03:37+00:00,2021-05-14T20:53:30Z,1,14,https://api.github.com/repos/microsoft/onnxruntime/issues/7507
7512,b'Dynamic Quantization with QLinearOps',Software,closed,2021-04-30T05:06:39Z,2021-04-30 05:06:53+00:00,2021-04-30T05:34:23Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7512
7520,b'Error when building onnxruntime on Fedora 32 for aarch64',Software,closed,2021-04-30T13:58:39Z,2021-05-01 00:32:58+00:00,2021-05-01T00:32:58Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7520
7524,b'Bug in MatMulInteger',Software,open,2021-04-30T16:43:25Z,2021-05-03 02:08:04+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/7524
7527,"b""Missing 'coloredlogs', 'sympy' when compiling from source""",Software,open,2021-04-30T17:40:52Z,2021-05-03 04:42:44+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/7527
7546,"b""'Conv' operator doesn't support Double tensor type on runtime""",Software,open,2021-05-01T21:04:43Z,2021-05-01 21:05:32+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7546
7547,b'Error : convert onnx to ort',Software,closed,2021-05-02T15:04:09Z,2021-05-03 02:02:39+00:00,2021-05-03T02:02:39Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7547
7552,b'Tests for creating NuGet package fail',Software,closed,2021-05-03T11:25:24Z,2021-05-04 00:34:59+00:00,2021-08-22T12:14:44Z,0,111,https://api.github.com/repos/microsoft/onnxruntime/issues/7552
7553,b'fail to load ORT format model',Software,closed,2021-05-03T15:22:09Z,2021-05-03 15:28:44+00:00,2021-05-04T07:42:34Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7553
7554,b'Build with MPI on Windows',Software,closed,2021-05-03T15:55:15Z,2021-05-03 17:09:31+00:00,2021-05-03T18:48:09Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7554
7562,b'Problem compiling ONNX RT with CUDA and TensorRT on Windows',Software,open,2021-05-04T07:56:43Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/7562
7563,"b'""Can\'t reduce on dim with value of 0 if \'keepdims\' is false"" in Session::Run()'",Software,closed,2021-05-04T14:26:25Z,2021-05-05 07:09:27+00:00,2021-05-05T18:03:10Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/7563
7571,b'Build Broken with cmake option onnxruntime_BUILD_UNIT_TESTS=OFF',Software,closed,2021-05-04T22:16:22Z,2021-05-05 07:29:11+00:00,2021-05-07T02:23:10Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/7571
7572,b'Use of torch InstanceNorm2d and dynamic tensor size causes crash',Software,open,2021-05-04T23:10:07Z,2021-05-06 08:06:45+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/7572
7573,b'LayerNormalization operator is not in onnx domain',Software,closed,2021-05-05T00:37:01Z,2021-05-06 00:59:20+00:00,2021-05-11T16:35:01Z,1,6,https://api.github.com/repos/microsoft/onnxruntime/issues/7573
7575,b'Failed to find kernel for Transpose(1)',Software,closed,2021-05-05T05:03:22Z,2021-05-05 07:34:24+00:00,2021-05-05T22:27:29Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7575
7578,b'CUDA nearest neighbor upsampling is 40 times slower than in Tensorflow',Software,closed,2021-05-05T11:27:53Z,2021-05-05 22:54:41+00:00,2021-08-31T21:25:43Z,0,118,https://api.github.com/repos/microsoft/onnxruntime/issues/7578
7582,b'Support for non NCCL implementations ',Software,closed,2021-05-05T16:41:53Z,2021-05-05 16:56:56+00:00,2021-05-05T19:54:38Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7582
7583,b'Build failures with GCC11 and LibStdc++11',Software,closed,2021-05-05T16:50:08Z,2021-05-05 20:35:23+00:00,2021-05-14T18:38:35Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/7583
7594,b'ORT Telemetry Event = SessionCreation unconditionally printed to std::cout',Software,closed,2021-05-06T10:43:52Z,2021-05-06 23:21:32+00:00,2021-05-06T23:21:32Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7594
7597,b'onnxruntime build is not compatible with onnx build. Protobuf loaded twice.',Software,open,2021-05-06T18:20:03Z,2021-05-07 02:57:41+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7597
7611,b'CPU memory leak using Scenario 1 of IOBinding',Software,closed,2021-05-07T08:56:51Z,2021-05-07 16:33:56+00:00,2021-05-28T07:49:38Z,0,20,https://api.github.com/repos/microsoft/onnxruntime/issues/7611
7612,b'Large GPU memory usage with EXHAUSTIVE cuDNN search',Software,open,2021-05-07T09:39:54Z,2021-05-07 20:04:31+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7612
7613,b'Enable CUDA provider option configuration in Java',Software,open,2021-05-07T09:47:08Z,2021-05-07 20:03:19+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7613
7614,b'Build fails with --use_rknpu',Software,open,2021-05-07T10:49:06Z,2021-05-08 22:50:28+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/7614
7618,b'CreateTensor() crashing within threaded function c++',Software,closed,2021-05-07T17:54:10Z,2021-05-10 16:00:24+00:00,2021-05-10T16:00:24Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/7618
7624,b'Could not install Onnxruntime using pip install on windows 10',Software,open,2021-05-09T07:59:01Z,2021-05-11 16:39:16+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/7624
7625,b'onnxruntime_test',Software,closed,2021-05-09T11:21:40Z,2021-05-10 16:43:55+00:00,2021-05-10T16:43:55Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/7625
7628,b'Publish the providers with the release build',Software,open,2021-05-10T07:13:45Z,2021-05-10 16:43:28+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7628
7629,b'Build does not support VCPKG MPI installations',Software,closed,2021-05-10T16:42:27Z,2021-05-10 16:43:05+00:00,2021-05-10T17:40:57Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7629
7633,b'EfficientDet fails on parallel executor',Software,closed,2021-05-10T18:36:17Z,2021-05-10 19:15:35+00:00,2021-05-14T14:31:35Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/7633
7634,b'int8 quantization on GPU support? (transformers)',Software,open,2021-05-10T19:43:07Z,2021-05-10 20:12:08+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7634
7641,b'Unused optional input causes error if provided',Software,closed,2021-05-11T02:20:50Z,2021-05-11 07:28:41+00:00,2021-05-11T21:04:20Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7641
7642,b'[ORT] Inconsistency output from Gemm operator',Software,closed,2021-05-11T03:30:14Z,2021-05-11 04:12:33+00:00,2021-05-21T04:10:58Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/7642
7646,"b'Non-zero status code returned while running TopK node Name:"""" status Message:type not supported for TopK  Operator'",Software,closed,2021-05-11T08:50:28Z,2021-05-11 17:03:13+00:00,2021-05-12T04:58:13Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7646
7647,b'Get Started Page gone',Documentation,closed,2021-05-11T09:34:00Z,2021-05-11 16:33:17+00:00,2021-05-12T21:30:32Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/7647
7648,b'ORT C++ API sample for model inference with multiple inputs',Documentation,closed,2021-05-11T10:14:08Z,2021-05-11 16:33:07+00:00,2021-05-11T18:27:50Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7648
7651,"b"" ..\\src\\TrackerHost\\TrackerHost.cpp (185) Find onnxruntime.dll at D:\\...\\x64\\Debug\\onnxruntime.dll but it doesn't load correctly!""",Documentation,closed,2021-05-11T12:51:46Z,2021-05-11 14:57:25+00:00,2021-05-11T14:57:25Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7651
7661,b'Find if an onnx model is already optimized',Documentation,closed,2021-05-11T22:38:16Z,2021-05-12 00:06:45+00:00,2021-05-12T00:06:45Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7661
7667,b'Ask a Question',Documentation,closed,2021-05-12T03:03:50Z,2021-05-12 03:22:30+00:00,2021-05-12T05:00:30Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7667
7668,b'Does onnxruntime support inference on a node-by-node and give the output result of each node?',Documentation,closed,2021-05-12T03:22:12Z,2021-05-12 04:55:18+00:00,2021-05-12T04:56:36Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7668
7681,b'which opset would be best?',Software,closed,2021-05-13T07:49:52Z,2021-05-13 16:04:49+00:00,2021-07-16T17:20:04Z,0,64,https://api.github.com/repos/microsoft/onnxruntime/issues/7681
7686,b'kRNN has been removed in TRT 8',Software,closed,2021-05-13T18:50:11Z,2021-05-13 18:56:23+00:00,2021-05-13T18:56:23Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7686
7713,b'Does onnxruntime support bert with relative position embedding',Software,open,2021-05-15T04:53:21Z,2021-05-18 23:59:01+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/7713
7716,b'Where could I find libonnxrutime.so after building from source?',Software,closed,2021-05-15T06:40:11Z,2021-05-18 06:01:10+00:00,2021-05-18T06:01:10Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/7716
7721,"b""Variable in dynamic axes can't be used in an if statement during the forward method in the model""",Software,closed,2021-05-16T20:03:25Z,2021-05-17 10:03:01+00:00,2021-05-17T10:03:01Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7721
7723,b'Does onnxruntime support inference on a node-by-node and give the output result of each node?',Software,closed,2021-05-17T06:09:14Z,2021-05-17 19:47:52+00:00,2021-05-25T00:39:13Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/7723
7726,b'Broken links in website',Documentation,closed,2021-05-17T09:45:25Z,2021-05-17 19:47:39+00:00,2021-06-04T14:52:48Z,0,18,https://api.github.com/repos/microsoft/onnxruntime/issues/7726
7727,b'Support arm64e arch for osx',Software,closed,2021-05-17T10:40:34Z,2021-05-17 21:23:47+00:00,2021-05-19T07:03:03Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/7727
7744,b'android app crash when use nnapi',Software,open,2021-05-18T02:25:32Z,2021-05-18 23:57:45+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7744
7745,b'quantize model can\xe2\x80\x98t run on gpu ?',Software,open,2021-05-18T11:54:05Z,2021-05-18 23:58:40+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7745
7748,b'CUDAExecutionProvider Not Available / GPU Not Visible on NVIDIA T4',Software,closed,2021-05-18T19:57:59Z,2021-05-18 20:51:44+00:00,2021-06-09T18:57:39Z,0,21,https://api.github.com/repos/microsoft/onnxruntime/issues/7748
7756,"b""onnxruntime on cuda fail to run 3d unet model due to 'ConvTranspose_31 Input X must be 3- or 4-dimensional. X: {1,384,16,16,16}""",Software,open,2021-05-19T13:36:38Z,2021-05-19 18:27:34+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7756
7757,b'TensorRT execution provider SEGFAULT',Software,open,2021-05-19T13:52:39Z,2021-05-20 00:01:56+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7757
7764,"b'""Quantize_qat"" for PyTorch QAT model'",Software,open,2021-05-20T01:42:17Z,2021-08-10 07:20:57+00:00,,82,,https://api.github.com/repos/microsoft/onnxruntime/issues/7764
7775,b'[onnxruntime-web] [JS] Support for Training Operators',Software,closed,2021-05-20T22:17:28Z,2021-05-20 22:29:14+00:00,2021-06-02T23:38:35Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/7775
7779,b'CUDA kernel not found in registries for Op type: Pad',Software,open,2021-05-20T23:51:26Z,2021-05-20 23:52:05+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7779
7782,b'Does onnxruntime support inference with only one node such as \xe2\x80\x98conv\xe2\x80\x99 or \xe2\x80\x98clip\xe2\x80\x99 in the onnx model? ',Software,closed,2021-05-21T02:39:58Z,2021-05-24 21:38:23+00:00,2021-05-24T21:38:23Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/7782
7784,b'ACL and ArmNN v21.02 EP has problem with GEMM',Software,open,2021-05-21T04:52:29Z,2021-05-26 16:10:45+00:00,,5,,https://api.github.com/repos/microsoft/onnxruntime/issues/7784
7788,b'get error when using a model with custom op',Software,open,2021-05-21T08:40:31Z,2021-05-26 16:11:29+00:00,,5,,https://api.github.com/repos/microsoft/onnxruntime/issues/7788
7790,b'[ORT][C++] How to hold Ort::Session reference as class private membership',Software,closed,2021-05-21T09:45:22Z,2021-05-24 19:21:24+00:00,2021-07-28T19:59:11Z,3,68,https://api.github.com/repos/microsoft/onnxruntime/issues/7790
7792,"b'Force fallback to CPU execution for Gather, Unsqueeze, Concat nodes - onnxruntime-gpu 1.7.0, opset 12 and 13'",Software,open,2021-05-21T13:10:41Z,2021-05-24 21:47:03+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/7792
7796,b'ONNX Exported BART Model Performance is degraded than native pytorch on T4',Software,open,2021-05-21T18:35:26Z,2021-05-21 18:37:51+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7796
7809,"b""ONNX to ORT: Error converting model.onnx: __init__() got an unexpected keyword argument 'disabled_optimizers""",Software,closed,2021-05-24T15:44:22Z,2021-05-26 16:17:34+00:00,2021-05-28T09:12:41Z,2,3,https://api.github.com/repos/microsoft/onnxruntime/issues/7809
7811,b'Pad-13 does not support bool type',Software,closed,2021-05-24T18:37:50Z,2021-05-24 19:00:00+00:00,2021-05-27T20:48:45Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/7811
7821,b'Batch mode inference for onnxruntime server',Software,closed,2021-05-25T02:15:08Z,2021-05-25 21:36:00+00:00,2021-05-25T21:36:00Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7821
7823,b'ORT Training: How to postprocess a onnx model to use ORTTrainer',Software,open,2021-05-25T07:55:40Z,2021-05-26 16:23:13+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/7823
7825,b'How to utilize TensorRT fallback',Software,closed,2021-05-25T09:25:51Z,2021-05-26 16:27:14+00:00,2021-07-20T22:28:00Z,1,56,https://api.github.com/repos/microsoft/onnxruntime/issues/7825
7828,"b'Getting ""onnxruntime::CudaCall CUDA failure 3: initialization error "" when using ML.NET with CUDA'",Software,closed,2021-05-25T14:39:42Z,2021-05-26 10:12:10+00:00,2021-05-26T10:12:10Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7828
7838,b'How to get sparse tensor input in custom op?',Software,open,2021-05-26T03:44:53Z,2021-05-26 15:50:03+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7838
7840,b'Not able to export large model',Software,closed,2021-05-26T14:28:31Z,2021-05-26 14:50:37+00:00,2021-05-29T07:20:00Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/7840
7841,b'Fix spelling errors',Software,closed,2021-05-26T14:58:51Z,2021-05-26 16:32:48+00:00,2021-05-26T16:32:48Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7841
7842,b'Memory leak in java api',Software,closed,2021-05-26T15:06:41Z,2021-05-26 16:38:28+00:00,2021-05-31T17:36:31Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/7842
7846,b'onnxruntime session with python multiprocessing',Software,closed,2021-05-26T21:58:42Z,2021-06-01 14:44:09+00:00,2021-06-26T01:30:16Z,5,30,https://api.github.com/repos/microsoft/onnxruntime/issues/7846
7853,"b""Non-zero status code returned while running FusedConv node. Name:'fused ' onnxruntime::OpKernelContext::Input Missing Input: input""",Software,open,2021-05-27T02:41:52Z,2021-05-27 02:42:47+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7853
7855,b'ONNX MODELS NOT WORKING IN WINML',Software,open,2021-05-27T05:08:27Z,2021-06-01 14:44:39+00:00,,5,,https://api.github.com/repos/microsoft/onnxruntime/issues/7855
7857,b'WinML tests have implicit dependency on `--enable_onnx_tests` being specified',Software,open,2021-05-27T06:58:51Z,2021-05-27 06:59:33+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7857
7859,b'NNAPI execution backend slower than the CPU execution backend',Software,open,2021-05-27T08:57:18Z,2021-05-27 16:42:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7859
7861,b'Cannot find the Azure DevOps pipeline for the CUDA 10.2 build',Software,closed,2021-05-27T15:10:27Z,2021-05-27 16:24:32+00:00,2021-05-27T16:24:46Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7861
7877,b'How to add the python API for my custom Execution Provider?',Software,closed,2021-05-28T10:44:32Z,2021-06-01 14:25:09+00:00,2021-07-18T04:10:42Z,4,50,https://api.github.com/repos/microsoft/onnxruntime/issues/7877
7878,b'Build failure in onnxruntime/test/featurizers_ops/truncated_svdtransformer_test.cc',Software,open,2021-05-28T14:09:01Z,2021-06-01 14:25:55+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/7878
7879,b'Building with OpenVINO on CentOS (undefined symbol: _ZN6ngraph11onnx_import23get_supported_operatorsElRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE)',Software,closed,2021-05-28T14:26:55Z,2021-05-28 14:28:45+00:00,2021-06-06T10:29:46Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/7879
7887,"b""ImportError: cannot import name 'get_all_providers' in importing onnxruntime""",Software,open,2021-05-29T09:44:05Z,2021-06-01 14:27:56+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/7887
7888,b'onnxruntime::BroadcastIterator::Init axis == 1 || axis == largest was false. Attempting to broadcast an axis by a dimension other than 1. 15 by 64',Software,open,2021-05-29T09:52:04Z,2021-06-01 14:37:52+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/7888
7895,b'GCC 4.8.2 support to build ORT?',Software,closed,2021-05-31T03:00:29Z,2021-06-01 02:11:31+00:00,2021-06-01T18:07:15Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/7895
7898,b'ONNX Runtime Inference time difference for different runs using ArmNN execution provider',Software,open,2021-05-31T14:41:55Z,2021-06-01 14:40:33+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7898
7900,b'Any server docker image for linux_x86 with cuda 10.1?',Software,closed,2021-06-01T06:47:07Z,2021-06-01 14:43:06+00:00,2021-06-03T22:59:31Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/7900
7915,b'Incorrect error message when constructing Ort::Session from array',Software,closed,2021-06-02T04:06:34Z,2021-06-02 04:20:37+00:00,2021-06-03T02:08:39Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7915
7916,b'Expand supported operations for OpenVINO',Software,closed,2021-06-02T04:08:04Z,2021-06-02 04:32:33+00:00,2021-06-02T14:44:04Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7916
7917,b'TensorRT performance issue',Software,closed,2021-06-02T04:33:19Z,2021-06-03 00:47:27+00:00,2021-06-03T00:47:27Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7917
7918,b'Build failures with GCC11 and libstdc++11',Software,closed,2021-06-02T04:44:53Z,2021-06-02 22:20:07+00:00,2021-06-07T17:07:36Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/7918
7920,b'InferenceSession causes segmentation fault on arm32 device with python 3.7',Software,closed,2021-06-02T05:55:49Z,2021-06-03 15:05:40+00:00,2021-08-18T07:55:49Z,1,77,https://api.github.com/repos/microsoft/onnxruntime/issues/7920
7922,b'Project is not fully linked when installing Microsoft.ML.OnnxRuntime.Gpu via nuget-manager',Software,closed,2021-06-02T09:46:34Z,2021-06-02 10:42:05+00:00,2021-06-02T10:42:05Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7922
7925,b'Request for parameter of max_batch for tensorRT C#',Software,closed,2021-06-03T06:00:40Z,2021-06-03 15:04:56+00:00,2021-06-15T22:17:34Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/7925
7929,"b""Can't run MATLAB exported ONNX model in Android""",Software,open,2021-06-03T12:58:53Z,2021-06-03 15:04:24+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7929
7930,b'Cannot choose between onnxruntime and onnxruntime-gpu ',Software,closed,2021-06-03T13:41:54Z,2021-06-03 13:42:16+00:00,2021-07-12T22:24:17Z,0,39,https://api.github.com/repos/microsoft/onnxruntime/issues/7930
7936,"b'windows build error ""returned non-zero exit status 1"" with VS 2017'",Software,closed,2021-06-03T19:46:10Z,2021-06-03 21:30:22+00:00,2021-08-10T06:36:52Z,0,67,https://api.github.com/repos/microsoft/onnxruntime/issues/7936
7943,b'[ORT 1.8/build issues MSVC2017] remaining error C2440 in onnxruntime/core/providers/cpu/reduction/reduction_ops',Software,closed,2021-06-04T04:05:05Z,2021-06-04 04:10:40+00:00,2021-06-04T04:15:52Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7943
7948,b'Cannot use cuda on linux',Software,closed,2021-06-04T14:06:27Z,2021-06-12 14:10:04+00:00,2021-06-12T14:10:04Z,8,8,https://api.github.com/repos/microsoft/onnxruntime/issues/7948
7949,b'New node packages ship TS source files',Software,closed,2021-06-04T16:52:16Z,2021-06-04 17:00:23+00:00,2021-06-08T23:49:06Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/7949
7951,b'C# OpenVino EP broken: OrtSessionOptionsAppendExecutionProvider_OpenVINO not exported in onnxruntime.dll',Software,closed,2021-06-04T18:52:02Z,2021-06-04 22:23:39+00:00,2021-06-07T22:52:26Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/7951
7956,b'Binding GPU Memory as Input and Output',Software,closed,2021-06-04T22:34:36Z,2021-06-07 16:35:27+00:00,2021-06-09T18:50:22Z,2,4,https://api.github.com/repos/microsoft/onnxruntime/issues/7956
7962,b'Crosscompiling using VS2017 from Windows for Raspberrypi4',Software,open,2021-06-05T08:25:01Z,2021-06-05 08:25:25+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7962
7963,b'python with DmlExecutionProvider : unable to choose device_idx',Software,closed,2021-06-05T11:27:04Z,2021-06-05 13:45:59+00:00,2021-06-05T13:45:59Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7963
7965,b'v1.8.0 raises Exception if cudnn not found in Program Files',Software,closed,2021-06-05T13:06:49Z,2021-06-07 16:38:39+00:00,2021-07-14T10:30:36Z,2,38,https://api.github.com/repos/microsoft/onnxruntime/issues/7965
7966,b'1.8.0 CUDA : inference performance almost x2 slower than 1.7.0',Software,closed,2021-06-05T13:43:32Z,2021-06-07 16:50:16+00:00,2021-07-13T11:54:30Z,2,37,https://api.github.com/repos/microsoft/onnxruntime/issues/7966
7967,b'Memory leak checker error with static debug builds on Windows',Software,closed,2021-06-05T20:57:19Z,2021-06-07 16:54:42+00:00,2021-06-07T17:23:03Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/7967
7968,b'Cannot be compiled by GCC10.3',Software,closed,2021-06-06T07:38:45Z,2021-06-07 02:28:16+00:00,2021-06-08T18:53:29Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/7968
7969,b'Will Spatial transformer operator be supported in the near future?',Software,open,2021-06-07T02:40:33Z,2021-06-07 16:57:06+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7969
7970,b'undefined reference to `onnx::optimization::GetAvailablePasses() on Nvidia Jetson NX',Software,open,2021-06-07T03:17:37Z,2021-06-07 16:58:25+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7970
7974,"b'Quantization of T5-XL Model leads to ""exceeds maximum protobuf""'",Software,open,2021-06-07T08:47:42Z,2021-06-07 17:02:54+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7974
7975,b'onnxruntime-web fails to compile when simd is enabled',Software,closed,2021-06-07T11:51:38Z,2021-06-07 17:13:33+00:00,2021-06-08T06:24:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7975
7976,b'cmake error from emscripten toolchain file',Software,open,2021-06-07T12:02:54Z,2021-06-07 17:02:13+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7976
7977,b'Quantization issue - ValueError: invalid weight name <weight name> found in the graph',Software,closed,2021-06-07T14:04:02Z,2021-06-07 17:03:15+00:00,2021-06-08T07:51:01Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7977
7981,b'FP16 loop model runs on onnxruntime 1.7 but fails on 1.8',Software,closed,2021-06-07T17:57:19Z,2021-06-08 17:49:02+00:00,2021-06-11T03:54:41Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/7981
7986,b'ONNX Runtime v1.8.0  onnxruntime-win-gpu-x64-1.8.0.zip include file loss ',Software,closed,2021-06-08T01:57:44Z,2021-06-08 01:59:49+00:00,2021-06-08T23:37:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/7986
7996,b'Example script for quantization aware training',Software,open,2021-06-08T18:48:00Z,2021-06-08 22:07:22+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/7996
8003,b're-download the jni library everytime restart the program',Software,closed,2021-06-09T02:51:23Z,2021-07-21 05:33:16+00:00,2021-07-21T05:33:16Z,42,42,https://api.github.com/repos/microsoft/onnxruntime/issues/8003
8007,"b'onnxruntime-node ""Error: Non tensor type is temporarily not supported.""'",Software,open,2021-06-09T09:54:29Z,2021-06-09 17:12:06+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8007
8008,"b'Runtime exception during initialization of SparkML model (One falsenode is pointing either to itself, either to another tree.)'",Software,open,2021-06-09T12:21:45Z,2021-06-09 17:27:57+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8008
8009,b'[1.6.0] Compilation error on Visual Studio 2019 16.10.0 / CUDA 11.1',Software,closed,2021-06-09T15:12:49Z,2021-06-09 15:13:42+00:00,2021-06-10T06:36:38Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8009
8015,"b""onnxruntime::GetProviderInfo_CUDA CUDA Provider not available, can't get interface for it""",Software,open,2021-06-10T06:24:54Z,2021-06-10 18:07:29+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8015
8019,b'Running multiple input node onnx model using onnxrntime C/C++ API',Software,open,2021-06-10T12:45:56Z,2021-06-10 18:08:41+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8019
8020,b'PrepareForCompute Non concat axis dimensions mismatch',Software,closed,2021-06-10T13:36:57Z,2021-06-10 18:19:14+00:00,2021-06-18T18:14:37Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/8020
8024,b'CUDNN failure 3: CUDNN_STATUS_BAD_PARAM for FusedConv node at inference time',Software,open,2021-06-10T19:24:45Z,2021-06-10 22:47:23+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8024
8028,b'java jni call the interface of onnxruntime  and the program crashes ',Software,closed,2021-06-11T02:48:21Z,2021-06-11 15:58:30+00:00,2021-10-31T09:18:58Z,0,142,https://api.github.com/repos/microsoft/onnxruntime/issues/8028
8030,b'How to perform Batch inferencing with RoBERTa ONNX quantized model?',Software,closed,2021-06-11T05:26:56Z,2021-06-11 16:02:40+00:00,2021-06-15T05:25:23Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/8030
8032,b'init session failed when using dll',Software,closed,2021-06-11T08:07:06Z,2021-06-11 22:39:56+00:00,2021-06-28T21:53:10Z,0,17,https://api.github.com/repos/microsoft/onnxruntime/issues/8032
8044,b'model loading error: inference_session.cc:1043 LoadOrtModel The ORT format model version [3] is not supported this build 1.8.0',Software,closed,2021-06-12T04:32:45Z,2021-06-13 08:10:02+00:00,2021-06-13T08:10:02Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8044
8045,"b'recompile error, please help'",Software,closed,2021-06-13T10:00:12Z,2021-06-15 06:58:36+00:00,2021-06-15T06:58:36Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8045
8046,b'Compile error on Ubuntu 18.04 with Only Cpu Execution Provider?',Software,closed,2021-06-13T16:48:04Z,2021-06-16 09:40:09+00:00,2021-06-16T17:44:51Z,2,3,https://api.github.com/repos/microsoft/onnxruntime/issues/8046
8047,b'Is this Memory leak in onnxruntime Python API?',Software,closed,2021-06-14T09:22:16Z,2021-06-14 20:25:44+00:00,2021-06-17T14:34:45Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/8047
8049,b'Docs: no mpivars.sh in openmpi',Software,closed,2021-06-14T20:55:30Z,2021-06-14 21:15:10+00:00,2021-06-28T21:44:51Z,0,14,https://api.github.com/repos/microsoft/onnxruntime/issues/8049
8052,b'Microsoft.ML.OnnxRuntime.Gpu 1.8.0: Failed to load library libonnxruntime_providers_shared.so',Software,closed,2021-06-15T12:59:35Z,2021-06-15 17:17:39+00:00,2021-06-23T20:24:53Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/8052
8053,b'Memory leak in free-dimention model in C++',Software,open,2021-06-15T16:44:11Z,2021-06-17 19:31:22+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/8053
8062,b'Building ONNXRuntime v1.8.0 on RPi Zero gives linking error',Software,open,2021-06-15T23:11:55Z,2021-06-16 00:55:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8062
8069,b'Cannot run correctly with x86 APP',Software,closed,2021-06-16T06:57:49Z,2021-06-16 18:29:21+00:00,2021-06-17T06:50:37Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8069
8070,b'CUDAExecutionProvider does not handle Clip on float16 tensor.',Software,open,2021-06-16T07:13:48Z,2021-06-17 00:14:19+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8070
8071,b'torch export onnx LongFormer but  cannot inference model with onnxruntime-cpu',Software,open,2021-06-16T08:47:55Z,2021-06-16 08:48:15+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8071
8072,b'session.Run() outputs wrong results if CUDA provider is used',Software,closed,2021-06-16T11:09:47Z,2021-06-17 05:26:46+00:00,2021-06-21T07:47:48Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/8072
8074,"b""[python] [ORTModule] Can't load saved training model.""",Software,closed,2021-06-16T19:27:21Z,2021-06-17 01:17:14+00:00,2021-06-18T17:04:38Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8074
8081,b'Can the input tensor be created directly with the C sharp API?',Software,closed,2021-06-17T06:04:09Z,2021-06-17 17:44:25+00:00,2021-06-23T08:54:39Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/8081
8082,b'Wrong version number',Software,closed,2021-06-17T10:59:20Z,2021-06-17 15:28:44+00:00,2021-06-17T22:16:55Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8082
8093,b'Unable to run C++ API on GPU',Software,closed,2021-06-18T01:51:04Z,2021-06-18 01:57:30+00:00,2021-06-18T01:57:30Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8093
8095,b'Porgram crash on the AVD of Android Studio when the model has multiple input nodes',Software,closed,2021-06-18T10:55:23Z,2021-06-18 18:14:50+00:00,2021-07-15T00:26:31Z,0,26,https://api.github.com/repos/microsoft/onnxruntime/issues/8095
8096,"b""[python] [ORTTrainer] Can't use ORTTrainer""",Software,open,2021-06-18T15:52:35Z,2021-06-18 18:16:55+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8096
8099,b'[ONNXRuntimeError] : Fatal error: MMCVDeformConv2d is not a registered function/op',Software,closed,2021-06-18T20:09:05Z,2021-06-21 16:56:54+00:00,2021-11-19T23:02:24Z,2,154,https://api.github.com/repos/microsoft/onnxruntime/issues/8099
8103,b'How to choose which GPU device to use in a multi gpu system?',Software,closed,2021-06-20T04:34:49Z,2021-06-20 08:39:38+00:00,2021-06-20T08:39:38Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8103
8104,b'[onnxruntime] - session.run return negative number',Software,open,2021-06-20T09:22:04Z,2021-06-21 16:56:03+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/8104
8107,b'Completely disable logging locally and instead send to a server',Software,open,2021-06-20T17:34:28Z,2021-06-21 16:46:18+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8107
8108,b'Training a fine tuned Resnet model using ORTTrainer',Software,closed,2021-06-21T10:57:51Z,2021-06-21 16:45:42+00:00,2021-10-12T01:47:19Z,0,112,https://api.github.com/repos/microsoft/onnxruntime/issues/8108
8111,b'onnxruntime_providers_shared.so missing in wheel',Software,closed,2021-06-21T20:43:34Z,2021-06-21 20:44:10+00:00,2021-06-24T20:58:11Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/8111
8115,b'ShapeInferenceError during onnxruntime update from 1.7.0 to 1.8.0',Software,closed,2021-06-22T02:22:05Z,2021-06-22 02:34:12+00:00,2021-06-24T23:03:56Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/8115
8117,b'Unable to use onnxruntime package in production environment due to few vulnerabilities.',Software,closed,2021-06-22T09:34:52Z,2021-06-22 22:13:00+00:00,2021-06-23T16:00:31Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8117
8118,"b'With directML, it claims softmax xxxxx'",Software,open,2021-06-22T11:58:20Z,2021-06-22 17:06:15+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8118
8129,b'About batch inference',Software,closed,2021-06-22T22:52:57Z,2021-06-23 00:30:57+00:00,2021-06-23T00:30:57Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8129
8133,b'Unable to run inference on GPU ',Software,closed,2021-06-23T06:43:37Z,2021-06-23 15:44:43+00:00,2021-06-25T08:41:42Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/8133
8134,b'Build 1.8.0 version with cuda fails',Software,closed,2021-06-23T07:12:20Z,2021-06-23 15:53:28+00:00,2021-06-24T09:36:44Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8134
8140,"b""[python] [build] FileNotFoundError: Unable to find 'test_execution_provider.dll'""",Software,open,2021-06-23T21:57:15Z,2021-06-23 21:57:15+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8140
8144,b'Using IObinding with variable outputsize',Software,closed,2021-06-24T05:29:47Z,2021-06-24 17:19:38+00:00,2021-06-25T00:21:18Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8144
8145,b'Can onnxruntime accepts multiple input image size? ',Software,closed,2021-06-24T12:00:22Z,2021-06-24 17:16:25+00:00,2021-06-24T17:16:25Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8145
8146,b'Why ReduceSum get shape 0 for an empty input?',Software,open,2021-06-24T12:07:34Z,2021-06-24 17:25:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8146
8147,b'System memory leak on cuda GPU backend.',Software,open,2021-06-24T14:47:32Z,2021-06-24 17:23:32+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8147
8162,b'Using ML.Net and ONNX in Alpine Docker gives library load error. ',Software,open,2021-06-26T00:22:24Z,2021-06-26 01:49:31+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8162
8164,b'A dilemma for cuda',Software,closed,2021-06-26T11:38:27Z,2021-06-28 17:07:02+00:00,2021-07-15T18:59:55Z,2,19,https://api.github.com/repos/microsoft/onnxruntime/issues/8164
8165,b'run onnx in gunicorn failure',Software,closed,2021-06-27T09:21:20Z,2021-06-28 00:41:29+00:00,2021-06-28T00:41:29Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8165
8166,b'onnxruntime gpu performance 5x worse than pytorch gpu performance ',Software,closed,2021-06-27T14:55:29Z,2021-06-28 05:50:12+00:00,2021-07-16T16:44:17Z,0,19,https://api.github.com/repos/microsoft/onnxruntime/issues/8166
8167,b'[Windows+Java+Onnxruntime] GPU Util is low and inferrencing speed is slow',Software,closed,2021-06-27T15:40:35Z,2021-06-28 17:04:40+00:00,2021-06-30T01:30:52Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/8167
8169,b'Quantized model does not support dynamic axes',Software,open,2021-06-27T18:57:12Z,2021-06-28 16:51:33+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8169
8170,b'Inference result different between cpu and gpu onnxruntime',Software,closed,2021-06-28T03:44:43Z,2021-06-28 17:21:07+00:00,2021-07-08T02:27:52Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/8170
8171,b'Onnx runtime gpu usage',Software,closed,2021-06-28T07:34:21Z,2021-06-28 16:45:38+00:00,2021-07-15T18:59:21Z,0,17,https://api.github.com/repos/microsoft/onnxruntime/issues/8171
8173,b'Does ONNX Runtime and its execution providers support FP16 inference?',Software,open,2021-06-28T12:00:31Z,2021-06-28 16:50:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8173
8174,b'Windows mmhmm customize slide dialog does not handle a PNG slide with alpha correctly',Software,closed,2021-06-28T14:47:42Z,2021-06-28 15:35:54+00:00,2021-06-28T15:35:54Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8174
8176,b'Prebuild binary for Linux arm64',Software,open,2021-06-28T17:53:52Z,2021-06-28 21:39:57+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8176
8177,b'1.8.0 failed to load cuda shared library',Software,closed,2021-06-28T20:39:51Z,2021-06-28 23:40:54+00:00,2021-06-29T08:59:17Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8177
8188,b'gpt2 greedy search or beam search (auto-regressive decoding) into one onnx graph?',Software,closed,2021-06-29T08:30:23Z,2021-06-29 08:32:25+00:00,2021-07-30T17:47:31Z,0,31,https://api.github.com/repos/microsoft/onnxruntime/issues/8188
8189,b'Does DML need a shrinkage ?',Software,open,2021-06-29T09:39:21Z,2021-06-29 17:59:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8189
8190,"b'Linker error ""ld: \'libonnxruntime_mlas.a(QgemmU8X8KernelNeon.S.o)\' does not contain bitcode."" with onnxruntime_ENABLE_BITCODE=ON'",Software,closed,2021-06-29T10:08:35Z,2021-06-29 18:00:46+00:00,2021-06-30T03:06:23Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8190
8193,b'CPU cores and threads control',Software,open,2021-06-29T16:01:46Z,2021-06-29 18:01:20+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8193
8194,"b'When I batched the data using the onnx model exported from the Yolov3_spp model, an error occurred'",Software,open,2021-06-29T17:22:46Z,2021-06-29 18:02:30+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8194
8237,b'Submit app to app store failed',Software,closed,2021-06-30T05:56:08Z,2021-06-30 06:54:35+00:00,2021-07-28T02:04:56Z,0,27,https://api.github.com/repos/microsoft/onnxruntime/issues/8237
8244,b'How to inference on multi-gpus',Software,open,2021-06-30T09:18:48Z,2021-06-30 17:04:32+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8244
8245,b'Memory leaks observed for DNNL EP',Software,open,2021-06-30T12:08:46Z,2021-06-30 17:03:08+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8245
8265,b'Reflect padding output seems incorrect when padding size larger than input dimension',Software,open,2021-07-01T03:10:57Z,2021-07-01 20:37:00+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8265
8266,b'Crashed when running iOS app',Software,closed,2021-07-01T03:25:10Z,2021-07-01 04:11:54+00:00,2021-07-02T05:55:44Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8266
8268,b'Linux CUDA performance with the C++ API',Software,closed,2021-07-01T05:56:21Z,2021-07-01 17:08:20+00:00,2021-07-09T01:17:50Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/8268
8283,b'ai.onnxruntime.OrtException: Error code - ORT_FAIL - message: OrtSessionOptionsAppendExecutionProvider_Cuda: Failed to load shared library',Software,open,2021-07-02T09:13:31Z,2021-07-02 17:37:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8283
8285,b'Raspberry Pi 4 Myriad VPU support ',Software,open,2021-07-02T12:29:23Z,2021-07-02 17:37:15+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8285
8287,b'GPU memory consumption drastically increased in onnxruntime-gpu==1.8.0',Software,closed,2021-07-02T17:20:08Z,2021-07-02 17:36:30+00:00,2021-07-08T19:09:16Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/8287
8295,b'Is it possible to run with vulkan? ',Software,open,2021-07-03T10:06:53Z,2021-07-06 19:06:49+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/8295
8296,b'Can anyone give me an example of OrtIoBinding ?',Software,closed,2021-07-03T11:39:04Z,2021-07-06 19:07:09+00:00,2021-07-08T18:22:54Z,3,5,https://api.github.com/repos/microsoft/onnxruntime/issues/8296
8297,b'Please add bucketize op',Software,open,2021-07-05T03:30:12Z,2021-07-06 19:07:44+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/8297
8298,b'onnxruntime_test_all (SEGFAULT) when building onnxruntime-gpu-tensorrt from source',Software,closed,2021-07-05T04:06:39Z,2021-07-06 19:05:08+00:00,2021-07-07T10:32:57Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/8298
915,b'[Feature] Exporter to CleanUnusedInitializers or documentation on how to clean manually after export',Software,closed,2019-04-26T01:52:30Z,2019-04-26 01:53:43+00:00,2019-05-15T23:50:20Z,0,19,https://api.github.com/repos/microsoft/onnxruntime/issues/915
919,b'Build an execution provider for Android based on NNAPI - integrating DNNLibrary into ONNX Runtime',Software,closed,2019-04-26T09:15:02Z,2019-04-26 09:15:02+00:00,2020-03-10T23:12:07Z,0,319,https://api.github.com/repos/microsoft/onnxruntime/issues/919
927,b'Split operator is not working for String type input',Software,closed,2019-04-27T00:28:35Z,2019-05-07 22:33:00+00:00,2019-05-13T18:21:56Z,10,16,https://api.github.com/repos/microsoft/onnxruntime/issues/927
929,b'Release tag in master',Software,closed,2019-04-27T03:16:39Z,2019-04-27 19:03:24+00:00,2019-05-08T23:37:13Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/929
931,b'help add this repo to vcpkg',Software,closed,2019-04-27T22:51:15Z,2019-04-28 06:46:07+00:00,2020-07-18T10:47:32Z,0,447,https://api.github.com/repos/microsoft/onnxruntime/issues/931
948,"b'""Float16"" data type are not support in C# (Which mean it will impact to use the FP16 model in Onnxruntime)'",Software,closed,2019-04-30T22:03:07Z,2019-05-01 18:49:09+00:00,2020-12-04T20:06:25Z,0,583,https://api.github.com/repos/microsoft/onnxruntime/issues/948
956,b'Docker files are just wrong',Software,closed,2019-05-02T10:18:52Z,2019-05-03 20:52:39+00:00,2019-05-08T17:40:22Z,1,6,https://api.github.com/repos/microsoft/onnxruntime/issues/956
957,b'Tokenizer fails if separators include special characters for regular expression',Software,closed,2019-05-02T14:43:53Z,2019-05-02 23:49:57+00:00,2019-06-21T19:50:17Z,0,50,https://api.github.com/repos/microsoft/onnxruntime/issues/957
965,b'Support for 3D ConvTranspose ',Software,closed,2019-05-03T13:39:15Z,2019-05-03 22:37:32+00:00,2020-07-14T02:10:24Z,0,437,https://api.github.com/repos/microsoft/onnxruntime/issues/965
967,b' [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for the node BatchNormalization(6)',Software,closed,2019-05-03T18:28:57Z,2019-05-03 18:50:00+00:00,2019-05-03T19:14:14Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/967
975,b'Does Official Build for C Work with CUDA 10?',Software,closed,2019-05-06T18:54:01Z,2019-05-06 20:24:02+00:00,2019-05-06T20:24:02Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/975
979,"b""Session::Run() function doesn't support multiple outputs""",Software,closed,2019-05-07T08:19:22Z,2019-05-07 17:01:46+00:00,2019-05-14T17:59:34Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/979
980,"b""kernel32.LoadLibrary():'cublas64_91.dll' not found""",Software,closed,2019-05-07T13:34:43Z,2019-05-07 16:59:14+00:00,2019-05-24T21:41:55Z,0,17,https://api.github.com/repos/microsoft/onnxruntime/issues/980
993,b'GPU builds with Azure Pipelines?',Software,closed,2019-05-08T22:32:37Z,2019-05-08 22:56:06+00:00,2019-05-08T22:56:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/993
995,b'Bus Error on sess.run',Software,closed,2019-05-08T23:09:56Z,2019-05-08 23:14:32+00:00,2019-05-11T15:57:26Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/995
999,b'Question on DeepCPU',Software,closed,2019-05-09T10:09:46Z,2019-05-09 18:51:00+00:00,2019-05-16T03:24:14Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/999
1001,b'Need CentOS support',Software,closed,2019-05-09T14:57:22Z,2019-05-09 18:50:39+00:00,2019-10-08T21:10:25Z,0,152,https://api.github.com/repos/microsoft/onnxruntime/issues/1001
1004,b'Running inference on a batch of tensors using the C API',Software,closed,2019-05-09T20:37:08Z,2019-05-10 17:21:59+00:00,2019-05-15T03:20:41Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/1004
1007,"b'TreeEnsembleClassifier: base_value not tested, fails for binary classification'",Software,closed,2019-05-10T17:27:54Z,2019-05-14 16:44:44+00:00,2019-09-13T12:30:36Z,3,125,https://api.github.com/repos/microsoft/onnxruntime/issues/1007
8313,"b'Eigen::ThreadPoolInterface*, const onnxruntime::ThreadOptions&) pthread_setaffinity_np failed'",Software,open,2021-07-07T05:57:29Z,2021-07-07 18:15:55+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8313
8314,b'Failed to perform symbolic shape inference on GPT2 Model Variants',Software,closed,2021-07-07T06:45:24Z,2021-07-07 18:16:41+00:00,2021-07-08T05:06:01Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8314
8315,b'Awful performance with LASER model when using TensorRT provider',Software,open,2021-07-07T08:27:45Z,2021-07-07 18:17:34+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8315
8316,b'Inference Speed is slow on GPU',Software,open,2021-07-07T09:03:56Z,2021-07-07 18:18:24+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8316
8317,b'DML not running on discrete GPU',Software,open,2021-07-07T09:29:07Z,2021-07-07 18:19:32+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8317
8319,b'Can onnxruntime use memory mapped file to minimize RAM use for loading ort model?',Software,open,2021-07-07T14:15:26Z,2021-07-07 16:45:55+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8319
8325,b'Error when loading onnxruntime_providers_tensorrt.dll',Software,closed,2021-07-08T00:20:25Z,2021-07-08 05:02:13+00:00,2021-07-08T05:02:13Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8325
8327,b'Errors when loading FP16 model with resize ops',Software,closed,2021-07-08T01:15:14Z,2021-07-08 17:29:53+00:00,2021-08-13T17:56:39Z,0,36,https://api.github.com/repos/microsoft/onnxruntime/issues/8327
8328,b'Prevent data copy in CreateSessionFromArray ',Software,open,2021-07-08T07:47:10Z,2021-07-08 17:32:20+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8328
8329,b'How Can I install onnxruntime==1.8.1 directly',Software,closed,2021-07-08T08:13:49Z,2021-07-08 17:32:55+00:00,2021-07-09T03:36:18Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8329
8330,"b'After 8bit quantization, the GPU inference speed is very slow'",Software,open,2021-07-08T08:15:36Z,2021-07-08 15:57:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8330
8332,b'Migration from vesion 1.6.0 to 1.8.1',Software,closed,2021-07-08T14:37:43Z,2021-07-08 17:35:01+00:00,2021-07-10T02:31:14Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8332
8342,"b""onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running ReduceMin node. Name:'Transformer-0-MultiHeadSelfAttention-Add/All2_reduce' Status Message:""",Software,closed,2021-07-09T02:17:47Z,2021-07-09 18:30:19+00:00,2021-08-13T17:56:21Z,0,35,https://api.github.com/repos/microsoft/onnxruntime/issues/8342
8343,"b""Gpt2OnnxModel's constructor is presumably missing underscores in declaration """,Software,closed,2021-07-09T07:55:33Z,2021-07-09 18:14:21+00:00,2021-07-15T16:30:45Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/8343
8344,b'onnxruntime-gpu 1.2.0',Software,closed,2021-07-09T09:25:56Z,2021-07-09 18:29:52+00:00,2021-08-02T18:54:54Z,0,24,https://api.github.com/repos/microsoft/onnxruntime/issues/8344
8345,b'How OnnxRuntime C# API can address the pain points of ~900 ML.NET Apr2021 survey responses?',Software,open,2021-07-09T17:36:44Z,2021-07-09 18:32:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8345
8352,b'OnnxRuntime Error : sequential_executor.cc:318 Execute] Non-zero status code returned while running Transpose node. && GPU Usage Issue',Software,closed,2021-07-12T00:39:03Z,2021-07-12 04:29:46+00:00,2021-07-12T04:29:46Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8352
8362,b'GPUs operate slower than CPUs',Software,open,2021-07-13T00:37:21Z,2021-07-13 00:37:21+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8362
8365,b'No way to install an old version 1.6.0 by pip install onnxruntime==1.6.0 [StressRNN related issue]',Software,closed,2021-07-13T04:12:05Z,2021-07-13 18:12:49+00:00,2021-07-13T18:12:49Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8365
8367,b'error using C# tensorRT EP builded from source',Software,open,2021-07-13T06:55:15Z,2021-07-13 17:27:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8367
8368,"b'int8 quantization on GPU support with transformers like bert, gpt2'",Software,open,2021-07-13T08:44:55Z,2021-07-13 17:07:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8368
8370,b'FileNotFoundError: Unable to find requirements.txt',Software,closed,2021-07-13T15:51:50Z,2021-07-13 16:21:37+00:00,2021-07-13T16:21:37Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8370
8373,b'NOT_IMPLEMENTED : Could not find an implementation for the node Imputer:Imputer(1)',Software,closed,2021-07-13T18:25:44Z,2021-07-13 20:33:50+00:00,2021-07-14T21:31:49Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8373
8378,b'Why cuda provider allocator must be threadlocal?',Software,open,2021-07-14T04:16:36Z,2021-07-14 16:14:35+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8378
8381,b'Ort::Exception of  CUDA failure 3: initialization error ',Software,closed,2021-07-14T06:41:10Z,2021-07-19 09:23:15+00:00,2021-07-19T09:23:14Z,5,5,https://api.github.com/repos/microsoft/onnxruntime/issues/8381
8382,b'Implement Split for double or float64 data type',Software,open,2021-07-14T06:56:46Z,2021-07-20 19:23:27+00:00,,6,,https://api.github.com/repos/microsoft/onnxruntime/issues/8382
8383,b'Tune performance For CUDAExecutionProvider',Software,closed,2021-07-14T07:33:33Z,2021-08-13 01:01:10+00:00,2021-08-13T01:01:10Z,29,29,https://api.github.com/repos/microsoft/onnxruntime/issues/8383
8384,"b'error ""NEON intrinsics not available with the soft-float ABI"" when building onnxruntime for arm'",Software,closed,2021-07-14T15:15:30Z,2021-07-15 07:02:48+00:00,2021-07-19T15:05:30Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/8384
8385,b'Tensorflow BERT with onnxruntime is 338x slower than vanilla tensorflow on CPU.',Software,closed,2021-07-14T16:03:41Z,2021-07-15 01:44:17+00:00,2021-07-20T21:59:26Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/8385
8393,b'detect invalid nodes and invalid graph in onnxruntime before handing them to execution providers',Software,open,2021-07-14T21:57:41Z,2021-08-10 07:15:38+00:00,,26,,https://api.github.com/repos/microsoft/onnxruntime/issues/8393
8395,b'Our nightly build python package link for ort-gpu is lost',Software,closed,2021-07-14T22:37:33Z,2021-07-15 00:57:58+00:00,2021-07-15T00:57:58Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8395
8397,b'MatrixInverse : No Op registered for MatrixInverse with domain_version of 9',Software,closed,2021-07-14T23:22:49Z,2021-07-15 00:44:22+00:00,2021-07-21T16:30:11Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/8397
8403,b'C# API come out warning when using OpenVino execution provider ',Software,closed,2021-07-15T08:54:49Z,2021-07-15 17:28:54+00:00,2021-07-16T08:34:34Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8403
8404,"b""onnxruntime-gpu 1.4  No attribute 'register_custom_ops_library'""",Software,closed,2021-07-15T09:21:45Z,2021-07-15 18:58:13+00:00,2021-07-15T18:58:13Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8404
8412,b'What does libonnxrimtime_provides_cuda.so and onnxrimtime_provides_shared.so do? Is it abandoned  libonnxrimtime.so in --use_cuda compile?',Software,closed,2021-07-16T09:51:46Z,2021-07-16 16:46:56+00:00,2021-07-27T11:18:09Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/8412
8413,b'Cross Compile Error: This file was generated by an older version of protoc which is incompatible with your Protocol Buffer headers.',Software,closed,2021-07-16T13:10:00Z,2021-07-17 00:14:10+00:00,2021-07-17T00:14:10Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8413
8420,"b'Is M1 computer supported? If so, how to install it'",Software,open,2021-07-17T10:04:10Z,2021-07-19 16:39:01+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/8420
8421,b'Dimension with zero size raises Reshape error  ',Software,closed,2021-07-17T18:22:46Z,2021-07-22 19:50:22+00:00,2021-07-22T19:50:22Z,5,5,https://api.github.com/repos/microsoft/onnxruntime/issues/8421
8422,b'Get wrong constant folding result when calling InferenceSession',Software,open,2021-07-19T02:35:18Z,2021-07-21 18:52:06+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/8422
8423,b'mingw version onnxruntime?',Software,closed,2021-07-19T10:05:34Z,2021-07-19 16:38:24+00:00,2021-07-19T16:38:24Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8423
8424,b'ERROR running model inference:Non-zero status code returned while running Cast node',Software,open,2021-07-19T13:17:19Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/8424
8425,"b""Cross Compile for ARM: undefined reference to `cpuinfo_arm_linux_init'""",Software,closed,2021-07-19T14:06:23Z,2021-07-19 16:36:34+00:00,2021-08-12T20:34:50Z,0,24,https://api.github.com/repos/microsoft/onnxruntime/issues/8425
8426,b'Failed to build onnxruntime with dockerfile.arm32v7',Software,closed,2021-07-19T14:14:59Z,2021-08-06 17:32:41+00:00,2021-08-18T07:51:47Z,18,29,https://api.github.com/repos/microsoft/onnxruntime/issues/8426
8427,b'Linking CXX executable onnxruntime_test_all fails when cross-compiling onnxruntime for arm',Software,closed,2021-07-19T15:38:43Z,2021-07-20 07:19:08+00:00,2021-07-22T01:10:43Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/8427
8435,b'RuntimeError when using DirectML as the backend on Windows 10',Software,closed,2021-07-20T05:38:35Z,2021-07-21 05:51:47+00:00,2021-07-21T05:51:47Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8435
8436,b'_DCNv2 is not a registered function/op',Software,open,2021-07-20T07:38:26Z,2022-07-19 17:53:35+00:00,,364,,https://api.github.com/repos/microsoft/onnxruntime/issues/8436
8437,b'Cmake could not find python and numpy. Build python wheel for armv7l',Software,closed,2021-07-20T13:07:27Z,2021-07-20 15:40:20+00:00,2021-08-18T12:06:54Z,0,28,https://api.github.com/repos/microsoft/onnxruntime/issues/8437
8439,b'[BREAKING CHANGE] bert_tf transformers optimizations now fail.',Software,closed,2021-07-20T14:33:12Z,2021-07-20 19:44:02+00:00,2021-07-22T20:53:41Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/8439
8440,b'Bug: Converting from ONNX to ORT fails when setting Device=Direct ML [C++] [ONNX2ORT converter] [Direct ML]',Software,open,2021-07-20T16:51:13Z,2021-07-21 01:07:12+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8440
8450,b'Error while running the `sklearn-onnx` example model using `onnxruntime-web`',Software,closed,2021-07-21T10:10:59Z,2021-07-21 16:28:06+00:00,2021-07-22T15:45:40Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8450
8453,b'Huggingface Bert Perf regression on 1.8(default) compared with 1.7 openmp',Software,open,2021-07-21T16:55:55Z,2021-07-21 16:56:04+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8453
8461,b'Support for EfficientNMS_TRT plugin in TensorRT execution provider',Software,closed,2021-07-22T10:44:16Z,2021-08-02 17:55:02+00:00,2022-04-22T05:07:43Z,11,273,https://api.github.com/repos/microsoft/onnxruntime/issues/8461
8464,b'ORT_NO_EXCEPTIONS not working on DML provider',Software,closed,2021-07-22T16:16:34Z,2021-07-22 16:58:39+00:00,2021-08-09T10:22:33Z,0,17,https://api.github.com/repos/microsoft/onnxruntime/issues/8464
8465,"b""Python API summary documentation / docs doesn't include arg descriptions""",Software,closed,2021-07-22T16:36:13Z,2021-07-22 18:22:56+00:00,2021-08-10T06:57:31Z,0,18,https://api.github.com/repos/microsoft/onnxruntime/issues/8465
8475,b'Questions about Ort::Env',Software,closed,2021-07-23T13:02:51Z,2021-07-26 16:33:46+00:00,2021-07-26T16:33:46Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/8475
8482,b'compiler warning resulting from pytorch_cpuinfo in x64 and x86 builds of WinML Inbox',Software,closed,2021-07-23T23:36:19Z,2021-07-24 01:05:48+00:00,2021-08-20T19:54:00Z,0,27,https://api.github.com/repos/microsoft/onnxruntime/issues/8482
8486,"b'onnxruntime_eager library does not compile on Windows due to """"'",Software,closed,2021-07-24T16:27:45Z,2021-07-26 16:59:21+00:00,2021-07-27T22:16:46Z,2,3,https://api.github.com/repos/microsoft/onnxruntime/issues/8486
8488,b'Dynamic quantization not working on subgraphs',Software,closed,2021-07-24T16:38:28Z,2021-07-24 16:45:18+00:00,2021-07-24T16:45:17Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8488
8489,"b""`override_torch_manual_seed` doesn't assure integer seed""",Software,closed,2021-07-25T07:48:59Z,2021-07-27 18:23:53+00:00,2021-08-10T23:02:59Z,2,16,https://api.github.com/repos/microsoft/onnxruntime/issues/8489
8492,b'[CPU training] faster cpu training like SLIDE',Software,open,2021-07-26T07:49:28Z,2021-07-26 16:37:57+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8492
8496,"b'onnxruntime=1.4 Concat [ShapeInferenceError] axis must be in [-rank, rank-1] when rank=2 and axis=1'",Software,closed,2021-07-26T14:17:39Z,2021-07-27 20:13:37+00:00,2021-07-29T16:25:52Z,1,3,https://api.github.com/repos/microsoft/onnxruntime/issues/8496
8504,b'Error when getting InferenceSession',Software,closed,2021-07-27T02:13:56Z,2021-08-02 17:44:57+00:00,2021-08-02T18:48:24Z,6,6,https://api.github.com/repos/microsoft/onnxruntime/issues/8504
8505,b'onnxruntime.InferenceSession',Software,closed,2021-07-27T02:15:00Z,2021-07-27 07:17:27+00:00,2021-07-27T07:17:27Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8505
8506,b'onnxruntime-gpu slow onnxruntime faster',Software,closed,2021-07-27T07:18:24Z,2021-07-27 07:50:47+00:00,2021-07-27T07:50:47Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8506
8508,"b'Segmentation fault when shared_ptr<session> destruct, the shared_ptr<session> is in use of cuda provider'",Software,closed,2021-07-27T11:55:17Z,2021-07-27 17:17:20+00:00,2021-07-27T17:17:20Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8508
8513,b'Found regression on ORT 1.8.1',Software,open,2021-07-27T20:56:54Z,2021-07-27 21:20:12+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8513
8521,b'Android: Crash on ARM device',Software,closed,2021-07-28T03:35:05Z,2021-07-28 04:29:02+00:00,2021-07-28T04:29:02Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8521
8524,b'Does the onnxruntime.quantization.quantize_dynamic support GPU quantization?',Software,open,2021-07-28T07:17:46Z,2021-08-02 13:17:46+00:00,,5,,https://api.github.com/repos/microsoft/onnxruntime/issues/8524
8525,"b""Issues in loading Sklearn's SVC model in scala/Java with ONNX """,Software,closed,2021-07-28T07:33:51Z,2021-07-28 14:00:03+00:00,2021-08-18T07:52:07Z,0,21,https://api.github.com/repos/microsoft/onnxruntime/issues/8525
8526,b'Any tutorial for c++ inference?',Software,closed,2021-07-28T07:41:25Z,2021-07-28 14:45:52+00:00,2021-07-28T19:50:17Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8526
8527,b'Optimizing mbart model: ValueError: Message onnx.ModelProto exceeds maximum protobuf size of 2GB: 3468757994',Software,open,2021-07-28T07:51:24Z,2021-07-28 14:46:01+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8527
8528,b'Why exported gpt2.onnx has 15 inputs? (or How do I assign the past_state using C++ API)',Software,open,2021-07-28T08:23:51Z,2021-07-28 17:32:26+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8528
8531,b'new LearningModelSession not returning in Windows-Machine-Learning sample',Software,closed,2021-07-28T19:26:00Z,2021-08-02 16:34:32+00:00,2021-08-02T16:34:32Z,4,4,https://api.github.com/repos/microsoft/onnxruntime/issues/8531
8534,"b'installation instructions links to wrong URL for ""built from source""'",Documentation,closed,2021-07-28T22:47:21Z,2021-07-29 01:05:59+00:00,2021-08-02T18:49:31Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/8534
8535,b'invalid HTTPS certificate on https://onnxruntime.ai',Documentation,closed,2021-07-28T22:50:30Z,2021-07-29 01:06:11+00:00,2021-08-03T04:27:07Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/8535
8541,b'How to set multi handle on 1 single gpu to speedup inference?',Documentation,closed,2021-07-29T07:02:02Z,2021-07-29 07:17:46+00:00,2021-07-29T07:17:46Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8541
8543,b'Model run with TRT\xef\xbc\x8c But all node run with cuda',Software,open,2021-07-29T07:28:10Z,2021-07-30 16:17:54+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/8543
8544,b'gpu memory can not release.',Software,open,2021-07-29T09:25:23Z,2021-08-02 16:25:05+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/8544
8545,"b'Attempt to use the DefaultLogger but none has been registered, problem of ""Microsoft.ML.OnnxRuntime.Gpu"" in c#'",Software,closed,2021-07-29T10:33:23Z,2021-07-30 09:27:10+00:00,2021-08-12T06:37:47Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/8545
8546,b'Implement floor and ceiling for double type',Software,open,2021-07-29T13:16:05Z,2021-07-29 15:53:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8546
8547,b' numpy_helper.to_array interpretation',Software,closed,2021-07-29T15:45:41Z,2021-07-30 16:15:24+00:00,2021-07-30T16:15:24Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8547
8555,b'Static library usage',Software,open,2021-07-30T03:43:56Z,2021-07-30 03:44:29+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8555
8556,b'Add onnxruntime to Conan package manager',Software,open,2021-07-30T06:04:46Z,2021-07-30 16:05:52+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8556
8560,"b""ONNX Runtime 1.8.1 Infrence + cpp + windows10+cuda 11.0:  Cant'f find shared library""",Software,closed,2021-07-30T12:22:09Z,2021-07-30 15:58:49+00:00,2021-08-24T11:17:37Z,0,24,https://api.github.com/repos/microsoft/onnxruntime/issues/8560
8577,b'Openvino provider available only with admin privileges',Software,closed,2021-08-01T22:38:40Z,2021-08-01 23:52:40+00:00,2021-08-01T23:52:40Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8577
8578,b'Failed to use self created stream for a new cuda session',Software,closed,2021-08-02T00:30:37Z,2021-08-02 15:50:11+00:00,2021-08-09T01:56:21Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/8578
8579,"b'when set the ""session_options.AppendExecutionProvider_CUDA(options);"",  new Ort::Session break!'",Software,closed,2021-08-02T06:42:13Z,2021-08-02 15:57:38+00:00,2021-08-11T01:16:26Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/8579
8580,"b'Wrong inference result on onnxruntime-gpu, but onnxruntime result is correct.'",Software,closed,2021-08-02T13:32:10Z,2021-08-02 16:01:03+00:00,2021-08-06T09:11:33Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/8580
8581,"b'[Export onnx] Context: Bad node spec: output: ""18"" name: ""Constant_8"" op_type: ""Constant"" attribute'",Software,closed,2021-08-02T14:28:03Z,2021-08-02 16:04:34+00:00,2021-11-19T22:56:12Z,0,109,https://api.github.com/repos/microsoft/onnxruntime/issues/8581
8591,b'Dynamic Input Reshape Incorrect',Software,closed,2021-08-03T03:36:54Z,2021-08-03 17:04:02+00:00,2021-08-06T18:16:09Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/8591
8594,b'not defined in file libcublasLt.so.11',Software,closed,2021-08-03T09:22:46Z,2021-08-03 16:40:22+00:00,2021-08-07T11:30:14Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/8594
8595,b'Links to Vitis-AI Execution Provider information broken',Documentation,closed,2021-08-03T15:51:34Z,2021-08-03 16:38:39+00:00,2021-09-08T22:52:12Z,0,36,https://api.github.com/repos/microsoft/onnxruntime/issues/8595
8596,b'Build failure of onnxruntime Docker container with Vitis-AI',Software,open,2021-08-03T16:58:43Z,2021-08-03 17:11:42+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8596
8599,b'set log level with environment variable',Software,open,2021-08-03T17:45:09Z,2021-08-03 17:45:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8599
8601,b'optimizing bart model lead to performance degradation',Software,closed,2021-08-03T20:44:26Z,2021-08-05 08:50:08+00:00,2021-08-05T08:50:08Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8601
8606,b'API to get compatible ONNX version',Software,open,2021-08-03T23:09:35Z,2021-08-03 23:09:35+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8606
8609,b'[ONNXRuntimeError] : 10 : INVALID_GRAPH : This is an invalid model. Error in Node:model/multi_category_encoding/AsString : No Op registered for AsString with domain_version of 9',Software,closed,2021-08-04T01:41:50Z,2021-08-04 23:29:38+00:00,2021-08-09T20:27:41Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/8609
8611,b'How to get single op performance?',Software,open,2021-08-04T03:32:52Z,2021-08-04 16:42:48+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8611
8614,b'Still unable to perform CPU inference using onnxruntime-gpu Python package',Software,closed,2021-08-04T12:45:03Z,2021-08-04 13:35:06+00:00,2021-08-04T13:35:06Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8614
8623,"b""module 'onnxruntime' has no attribute 'InferenceSession'""",Software,closed,2021-08-05T11:20:08Z,2021-08-05 16:38:31+00:00,2021-08-09T21:53:09Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/8623
8624,"b""Non-zero status code returned while running Scaler node. Name:'Scaler' Status Message: D:\\a\\_work\\1\\s\\include\\onnxruntime\\core/common/logging/logging.h:313 onnxruntime::logging::LoggingManager::DefaultLogger Attempt to use DefaultLogger but none has been registered.""",Software,closed,2021-08-05T11:23:05Z,2021-08-05 16:30:31+00:00,2021-08-09T11:13:23Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/8624
8625,b'Padding effect quantizied ONNX quality',Software,closed,2021-08-05T11:46:23Z,2021-08-05 16:40:06+00:00,2021-08-11T07:13:12Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/8625
8626,b'Replace add_dependencies with target_link_libraries in library CMake',Software,closed,2021-08-05T18:14:03Z,2021-08-05 18:17:22+00:00,2021-08-05T18:17:22Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8626
8635,b'Fatal error: _DCNv2 is not a registered function/op',Software,closed,2021-08-06T06:33:29Z,2021-08-06 15:19:29+00:00,2021-08-17T14:39:07Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/8635
8636,b'The performance not got imporve',Software,open,2021-08-06T08:01:28Z,2021-08-06 15:30:10+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8636
8637,b'the latency of the fp16 onnx model is longger than that for the fp32 hg pytorch model',Software,open,2021-08-06T08:47:24Z,2021-08-06 15:32:34+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8637
8639,b'Add onnxruntime_extensions in onnxruntime docker file',Software,open,2021-08-06T11:16:30Z,2021-08-06 15:35:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8639
8640,b'ONNX Model Inferencing reported Model Unknown model file format version.',Software,closed,2021-08-06T12:07:58Z,2021-08-06 14:55:10+00:00,2021-08-06T14:55:10Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8640
8641,b'Unable to build onnxruntime for arm32v7',Software,closed,2021-08-06T16:42:02Z,2021-08-06 17:32:15+00:00,2021-08-06T17:32:15Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8641
8649,b'TypeError: initialize_session(): incompatible function arguments. The following argument types are supported:',Software,closed,2021-08-07T03:49:34Z,2021-08-07 20:45:35+00:00,2021-08-07T20:45:35Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8649
8655,b'Why  ONNX Runtime Server has been deprecated?',Software,closed,2021-08-09T02:03:22Z,2021-08-09 08:23:16+00:00,2021-08-09T08:23:16Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8655
8656,"b""TensorRT provider doesn't support CustomOp automatically fall back to CUDA EP""",Software,open,2021-08-09T02:50:18Z,2021-08-09 17:44:13+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8656
8657,"b'c++ no constructor of instance ""Ort:Session:Session"" '",Software,closed,2021-08-09T06:20:23Z,2021-08-09 06:27:44+00:00,2021-08-11T00:39:07Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8657
8660,b'ONNX Model making random predictions.',Software,open,2021-08-09T12:50:46Z,2021-08-09 16:34:39+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8660
8661,b'How to handle constant values in onnxruntime cpp inference',Software,closed,2021-08-09T13:07:15Z,2021-08-09 16:32:52+00:00,2021-08-10T10:53:03Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8661
8670,b'[ONNXRuntimeError] : 2 : INVALID_ARGUMENT when using modified LSTM op',Software,closed,2021-08-10T08:32:57Z,2021-08-10 09:21:10+00:00,2021-08-10T09:21:10Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8670
8675,"b""Language modeling loss by passing 'labels' while using ONNX inference session""",Software,closed,2021-08-10T18:19:29Z,2021-08-10 20:46:01+00:00,2021-11-17T19:55:55Z,0,99,https://api.github.com/repos/microsoft/onnxruntime/issues/8675
8681,b'LNK2001:unresolved external symbol OrtSessionOptionsAppendExecutionProvider_Tensorrt',Software,open,2021-08-11T00:57:06Z,2021-08-11 01:03:43+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8681
8684,b'onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Fatal error: _DCNv2 is not a registered function/op',Software,closed,2021-08-11T05:56:41Z,2021-08-11 06:12:29+00:00,2021-08-11T06:43:53Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8684
8685,b'PrepareForCompute Non concat axis dimensions must match: Axis 0 has mismatched dimensions of 1 and 0',Software,open,2021-08-11T06:56:55Z,2021-08-11 08:14:27+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8685
8697,b'I wonder if the part I found has missing.',Software,closed,2021-08-12T01:11:30Z,2021-08-12 02:07:40+00:00,2021-09-14T21:40:13Z,0,33,https://api.github.com/repos/microsoft/onnxruntime/issues/8697
8699,b'C# Load input node names by index',Software,open,2021-08-12T01:50:54Z,2021-08-12 02:08:30+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8699
8705,b'Partial graph execution',Software,open,2021-08-12T11:13:59Z,2021-08-12 18:43:39+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8705
8706,b'Build error on Jetson Xavier with CMake 3.21.1',Software,closed,2021-08-12T11:41:43Z,2021-08-12 18:45:50+00:00,2021-08-17T00:49:50Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/8706
8707,"b'Program received signal SIGSEGV, Segmentation fault when I Custruct Ort::Session'",Software,open,2021-08-12T12:50:23Z,2021-08-12 19:01:48+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8707
8713,b'Install onnxruntime training for CPU with pytorch 1.9.0',Software,closed,2021-08-12T19:36:48Z,2021-08-12 20:02:07+00:00,2021-08-30T20:52:48Z,0,18,https://api.github.com/repos/microsoft/onnxruntime/issues/8713
8735,"b""While i was doing the inference with onnxruntime, i got this error:     return self._sess.run(output_names, input_feed, run_options) onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running Slice node. Name:'Slice_1214' Status Message: slice.cc:260 FillVectorsFromInput Starts must be a 1-D array""",Software,closed,2021-08-13T19:31:23Z,2021-08-13 19:41:43+00:00,2021-08-16T07:48:34Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/8735
8737,b'Gemm fails if optional input C is not provided',Software,closed,2021-08-13T23:06:38Z,2021-08-13 23:16:16+00:00,2021-08-16T17:34:55Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/8737
8742,b'error with torch.sum or torch.tensor.mean operator on GPU',Software,open,2021-08-16T08:38:55Z,2021-08-16 16:01:40+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8742
8755,b'Symbolic shape inference error for loop node & seq(tensor)',Software,open,2021-08-17T05:11:57Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/8755
8756,b'cannot access https://onnxruntime.ai/docs/how-to/build.html',Documentation,closed,2021-08-17T18:05:31Z,2021-08-17 18:13:22+00:00,2021-10-18T23:15:45Z,0,62,https://api.github.com/repos/microsoft/onnxruntime/issues/8756
8761,b'wolfsaviour',Documentation,closed,2021-08-18T00:49:36Z,2021-08-18 00:49:54+00:00,2021-08-18T16:37:27Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8761
8765,b'Build error on Jetson Xavier with CMake-3.18.4',Documentation,closed,2021-08-18T06:31:13Z,2021-08-18 06:58:42+00:00,2021-08-18T06:58:41Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8765
8766,b'Batch infer occurs NAN',Software,open,2021-08-18T07:18:15Z,2021-08-18 15:41:42+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8766
8767,b'ML.NET on Jetson Nano',Software,closed,2021-08-18T08:53:30Z,2021-08-18 16:40:04+00:00,2021-09-07T16:00:59Z,0,20,https://api.github.com/repos/microsoft/onnxruntime/issues/8767
8770,"b""Static quantization for transformers models doesn't work""",Software,closed,2021-08-18T15:18:01Z,2021-08-18 15:45:58+00:00,2021-08-24T18:28:29Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/8770
8771,b'onnxruntime Jetson tx2 cuda',Software,open,2021-08-18T16:27:39Z,2021-08-18 16:42:47+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8771
8772,"b""onnnxruntime-training lists Windows as a supported platform on PyPI but doesn't have Windows wheels""",Software,closed,2021-08-18T17:32:21Z,2021-08-18 18:00:37+00:00,2021-08-20T15:53:25Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8772
8777,b'Controlling number of ThreadAllocations (CPU) of ONNX Runtinme C++ API',Software,closed,2021-08-18T22:15:33Z,2021-08-19 15:26:30+00:00,2021-08-19T16:59:14Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8777
8781,b'CUDA kernel not found in registries for Op type: Tile ',Software,closed,2021-08-19T01:54:05Z,2021-08-19 15:34:50+00:00,2021-08-20T18:25:52Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8781
8785,b'Error while converting the model: attempted relative import beyond top-level package',Software,open,2021-08-19T18:50:25Z,2021-08-19 18:51:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8785
8787,b'Cast Bug',Software,open,2021-08-20T00:09:28Z,2021-08-20 17:07:16+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8787
8789,"b""AttributeError: module 'onnxruntime' has no attribute 'set_default_logger_severity'""",Software,open,2021-08-20T04:38:52Z,2021-08-20 16:43:21+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8789
8790,b'build instractions are not found',Software,closed,2021-08-20T07:36:34Z,2021-08-20 07:37:15+00:00,2021-08-20T09:16:57Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8790
8791,b'IsNaN and Split have no double implementations',Software,open,2021-08-20T07:57:10Z,2021-08-20 16:27:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8791
8792,b'TensorRT EP high memory consumption',Software,open,2021-08-20T13:49:17Z,2021-08-20 16:56:42+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8792
8795,b'Missing mandatory parameter',Software,closed,2021-08-20T17:07:01Z,2021-08-20 17:13:49+00:00,2021-08-31T19:02:46Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/8795
8796,b'Error message could be even better....',Software,closed,2021-08-20T17:24:18Z,2021-08-20 19:18:30+00:00,2021-08-20T21:12:43Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8796
8797,"b'""Failed to find kernel error"" after building custom mobile ONNX iOS framework'",Software,open,2021-08-20T19:25:35Z,2021-08-20 19:53:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8797
8800,b'IO binding int64 type issue ',Software,closed,2021-08-20T22:34:14Z,2021-08-28 11:48:23+00:00,2021-08-28T11:48:26Z,7,7,https://api.github.com/repos/microsoft/onnxruntime/issues/8800
8808,b'Error: build with TensorRT support on NVIDIA Jetson Xavier',Software,open,2021-08-23T01:57:07Z,2021-08-23 17:39:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8808
8809,b'How can I set the empty ort_input?',Software,open,2021-08-23T02:27:53Z,2021-08-23 17:41:38+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8809
8811,b'Duplicate node name issue on scrfd (Face Detection) quantization',Software,open,2021-08-23T05:58:57Z,2021-08-23 17:44:23+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8811
8812,b'Performance degradation when a model fully fall backs to MLAS from an EP',Software,open,2021-08-23T11:13:15Z,2021-08-23 14:31:45+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8812
8818,"b'Add example usage of register_custom_ops_pytorch_exporter to ""Export PyTorch model"" doc'",Documentation,closed,2021-08-23T23:05:33Z,2021-08-25 21:27:35+00:00,2021-09-08T00:57:15Z,1,15,https://api.github.com/repos/microsoft/onnxruntime/issues/8818
8823,b'import torch greatly increase ONNX model gpu memory',Software,open,2021-08-24T03:46:59Z,2021-08-25 21:37:48+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/8823
8825,b'ORT Optimize constant folding remove needed node in Loop & If inner graph',Software,closed,2021-08-24T05:45:10Z,2021-08-25 17:55:40+00:00,2021-08-25T17:55:40Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8825
8828,b'Cannot create session with cuda (Windows+Cu11+Onnx1.8.1)',Software,closed,2021-08-24T11:56:34Z,2021-08-24 15:00:05+00:00,2021-08-26T08:54:16Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8828
8829,b'custom_op_library test in python cause segmentation fault',Software,open,2021-08-24T12:19:11Z,2021-09-01 02:11:10+00:00,,7,,https://api.github.com/repos/microsoft/onnxruntime/issues/8829
8835,b'Error building onnxruntime during Docker build on Mac',Software,closed,2021-08-24T21:10:39Z,2021-08-25 15:10:25+00:00,2021-08-25T16:47:03Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8835
8839,b'[Documentation Request]',Software,closed,2021-08-25T08:45:44Z,2021-08-25 16:48:59+00:00,2021-08-25T16:48:59Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8839
8849,b'gpt-2_onnx_models that do not include past_states - How does it work?',Software,open,2021-08-26T01:55:01Z,2022-04-19 03:54:26+00:00,,236,,https://api.github.com/repos/microsoft/onnxruntime/issues/8849
8851,b'while OpenVINO as execution  provider with onnxruntime in java and python get error Failed to load library libonnxruntime_providers_openvino.so',Software,open,2021-08-26T05:27:06Z,2021-08-26 06:01:14+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8851
8852,"b""Jetson Device | subprocess.CalledProcessError: Command '['/usr/local/bin/cmake', '--build', '/workspace/onnxruntime/build/Linux/Release', '--config', 'Release', '--', '-j6']' returned non-zero exit status 2.""",Software,closed,2021-08-26T05:45:50Z,2021-08-26 06:19:00+00:00,2021-08-27T09:19:11Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8852
8853,b'Issue with the transformers optimizer when arg --input_int32 is used',Software,closed,2021-08-26T13:16:25Z,2021-08-28 02:41:21+00:00,2021-09-14T21:40:38Z,1,19,https://api.github.com/repos/microsoft/onnxruntime/issues/8853
8854,b'Running multiple models concurrently is not thread safe',Software,closed,2021-08-26T16:01:58Z,2021-08-27 01:07:01+00:00,2021-09-01T11:32:56Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/8854
8858,b'onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Load model from ./dlrm_s_pytorch_10GB.onnx failed:Fatal error: ATen is not a registered function/op',Software,open,2021-08-26T19:05:39Z,2021-08-31 15:02:14+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/8858
8866,"b""TypeError: _onnx_model_path_to_ort_model_path() missing 1 required positional argument: 'optimization_level_str'""",Software,closed,2021-08-27T01:09:42Z,2021-08-27 18:29:52+00:00,2021-08-27T18:29:51Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8866
8872,b'[Documentation Request] ONNX GPU IOBinding example',Documentation,closed,2021-08-27T17:34:36Z,2021-08-27 17:52:33+00:00,2022-03-25T21:55:55Z,0,210,https://api.github.com/repos/microsoft/onnxruntime/issues/8872
8874,b'Readily available Python wheels for ARM?',Software,open,2021-08-27T19:42:41Z,2021-08-30 19:07:13+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/8874
8880,b'Inconsistent result for ONNX::Xor when number of elements vary',Software,closed,2021-08-27T23:23:46Z,2021-08-27 23:52:53+00:00,2021-09-02T04:38:56Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/8880
8881,b'OnnxRuntime Fails with Inference output shape error on Conv Operation',Software,closed,2021-08-28T01:18:55Z,2021-08-30 16:16:00+00:00,2021-08-31T16:00:55Z,2,3,https://api.github.com/repos/microsoft/onnxruntime/issues/8881
8890,b'[BUG] QLinearConv uses same value for all zero_points!',Software,open,2021-08-30T01:52:34Z,2021-08-30 17:50:02+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8890
8905,b'runtime error with DML: two nodes with same node name (Conv_xxx)',Software,closed,2021-08-31T09:33:19Z,2021-08-31 18:51:05+00:00,2022-01-25T21:10:59Z,0,147,https://api.github.com/repos/microsoft/onnxruntime/issues/8905
8907,b'cannot import name \xe2\x80\x98get_all_providers\xe2\x80\x98',Software,open,2021-08-31T13:45:11Z,2021-08-31 18:48:47+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8907
8908,b'RuntimeError: ONNX export failed: Couldn\xe2\x80\x99t export Python operator qfn',Software,closed,2021-08-31T17:06:25Z,2021-08-31 17:06:25+00:00,2021-09-01T19:56:50Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8908
8910,b'Runetime Error: Decoder with dynamic axes does not work with Encoder output',Software,open,2021-08-31T17:40:55Z,2021-10-25 03:27:51+00:00,,54,,https://api.github.com/repos/microsoft/onnxruntime/issues/8910
8920,b'Broken import in TrtTable Dict method',Software,closed,2021-09-01T09:51:29Z,2021-09-01 19:01:23+00:00,2021-09-07T07:29:19Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/8920
8921,b'Optimization now fails with AssertionError: Graph is not a DAG',Software,closed,2021-09-01T15:29:02Z,2021-09-01 18:57:18+00:00,2021-09-14T21:38:57Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/8921
8922,b'Why reports this Warning? Warning: Unsupported operator CylinderQuery. No schema registered for this operator',Software,closed,2021-09-01T17:23:30Z,2021-09-01 17:23:31+00:00,2021-11-19T22:54:11Z,0,79,https://api.github.com/repos/microsoft/onnxruntime/issues/8922
8929,b'How to get the value of tensors in subgraph?',Software,open,2021-09-01T21:16:22Z,2021-09-01 22:27:14+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8929
8933,"b""Build / CMake can't find nvcc""",Software,open,2021-09-01T22:52:16Z,2021-09-01 23:32:51+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8933
8938,b'The model run time become longer when i update the onnxruntime from version 1.7 to version 1.8',Software,open,2021-09-02T01:42:42Z,2021-09-02 02:41:47+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8938
8944,b'ms_experimental DFT feedback',Software,open,2021-09-02T09:12:30Z,2022-04-19 03:54:21+00:00,,228,,https://api.github.com/repos/microsoft/onnxruntime/issues/8944
8945,"b""error: 'floor' is not a member of 'std' when compiling from source with ms_experimental""",Software,open,2021-09-02T09:54:52Z,2021-09-02 19:04:27+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8945
8946,b'Build for Android: No toolchains found in the NDK toolchains folder for ABI with prefix: arm-linux-androideabi',Software,closed,2021-09-02T11:30:30Z,2021-09-02 16:54:30+00:00,2021-09-03T21:43:50Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/8946
8949,b'Apply GraphTransformer EP specific rules to DNNL EP',Software,open,2021-09-02T21:52:21Z,2021-09-03 05:44:20+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8949
8956,b'About custom op',Software,open,2021-09-03T02:23:40Z,2021-09-03 05:07:15+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8956
8957,b'onnx slower than original pytorch ner model?',Software,open,2021-09-03T02:38:11Z,2021-09-03 03:07:24+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8957
8958,b'ORT session.get_inputs() only returns 1 input instead of 2',Software,closed,2021-09-03T03:22:00Z,2021-09-03 05:43:37+00:00,2022-01-27T23:39:35Z,0,146,https://api.github.com/repos/microsoft/onnxruntime/issues/8958
8963,"b'Copyright/license data, especially for models'",Documentation,open,2021-09-03T17:08:27Z,2021-09-03 17:56:23+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8963
8968,b'CUDA build fails with RelWithDebInfo',Software,closed,2021-09-03T23:02:01Z,2021-09-03 23:29:26+00:00,2021-09-08T19:09:56Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/8968
8970,b'ONNX runtime produces different inference results for the same input',Software,closed,2021-09-04T23:26:46Z,2021-09-08 17:34:13+00:00,2021-11-02T17:34:16Z,3,58,https://api.github.com/repos/microsoft/onnxruntime/issues/8970
9031,b'[js/web] Unauthorized request when loading model from url',Software,open,2021-09-05T11:08:46Z,2021-09-10 19:53:22+00:00,,5,,https://api.github.com/repos/microsoft/onnxruntime/issues/9031
8971,b'Builld OnnxRuntime  with CPU architecture of MIPS',Software,open,2021-09-06T03:02:33Z,2021-09-07 18:40:54+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/8971
8972,b'Several failing tests with CUDA execution provider',Software,open,2021-09-06T03:46:54Z,2021-09-06 03:52:21+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8972
8975,b'Support specify the trt_engine_cache_path of OrtTensorRTProviderOptionsV2 with wide characters',Software,open,2021-09-07T02:54:53Z,2021-09-08 06:32:02+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/8975
8977,b'ONNX inference result are different to pytorch model',Software,open,2021-09-07T07:42:31Z,2021-09-17 02:17:39+00:00,,9,,https://api.github.com/repos/microsoft/onnxruntime/issues/8977
8978,b'No implementation found for long ai.onnxruntime.OrtSession$SessionOptions.createOptions(long)',Software,closed,2021-09-07T08:23:01Z,2021-09-08 06:47:56+00:00,2021-09-10T10:36:14Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/8978
8980,b'error: option --use_dml not recognized',Software,closed,2021-09-07T16:05:00Z,2021-09-07 16:15:07+00:00,2021-09-07T17:51:20Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/8980
8988,b'Support for ConvTranspose quantization?',Software,open,2021-09-07T22:18:28Z,2021-09-08 06:46:29+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8988
8995,"b'How to apply ""gpu_mem_limit"" to CUDA Execution Provider in C#?'",Software,closed,2021-09-08T03:26:35Z,2021-09-17 02:16:58+00:00,2022-01-06T19:06:16Z,8,120,https://api.github.com/repos/microsoft/onnxruntime/issues/8995
8999,b'Type error when runs an control flow model in ORT',Software,open,2021-09-08T11:24:57Z,2021-09-08 17:50:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/8999
9001,"b""cannot convert from 'initializer list' to 'Ort::Session' using VS2019 community""",Software,closed,2021-09-08T15:07:27Z,2021-09-08 17:18:00+00:00,2021-09-09T16:36:11Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9001
9011,b'cuda provider Ort::Session Segmentation fault (core dumped)',Software,closed,2021-09-09T08:30:20Z,2021-09-09 16:35:11+00:00,2021-09-14T08:00:42Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/9011
9012,"b'Can\'t get the .whl file when using ""--use_nnapi""'",Software,closed,2021-09-09T11:08:38Z,2021-09-09 16:55:31+00:00,2021-09-10T09:09:41Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9012
9015,b'1.8.2 : DirectML inference performance of model opset-13 is ~x4 slower than opset-9',Software,open,2021-09-09T12:09:52Z,2021-09-09 16:56:05+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9015
9016,b'Creating custom ONNX operator from model with C++ pytroch extension',Software,closed,2021-09-09T15:48:51Z,2021-09-09 17:00:37+00:00,2021-11-19T22:31:48Z,0,71,https://api.github.com/repos/microsoft/onnxruntime/issues/9016
9026,b'ONNXRuntimeError]RUNTIME_EXCEPTION : Non-zero status code returned while running Reshape node.',Software,open,2021-09-10T08:36:38Z,2021-09-10 17:10:20+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9026
9030,b'Unhandeled exception Microsoft C++ exception: std::runtime_error at memory location ',Software,open,2021-09-10T18:06:56Z,2021-09-11 06:23:16+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9030
9037,b'The inference results are different using onnxruntime-cpu and onnxruntime-gpu',Software,open,2021-09-13T03:37:21Z,2021-09-13 15:23:34+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9037
9038,b'Invalid value of arena_extend_strategy',Software,closed,2021-09-13T07:30:24Z,2021-09-13 17:25:23+00:00,2021-09-14T03:19:30Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9038
9039,b'NNAPI on Android works great with Samsung Galaxy S9 but not with Redmi Note 9',Software,open,2021-09-13T09:15:45Z,2021-09-13 17:26:31+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9039
9046,b'build failure with gcc 10 and cuda 11.4',Software,closed,2021-09-13T19:44:19Z,2021-09-13 21:19:14+00:00,2021-09-13T23:05:34Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9046
9052,"b""Unsupported gpu architecture 'compute_86'""",Software,closed,2021-09-14T08:40:48Z,2021-09-14 16:49:07+00:00,2021-09-16T02:55:40Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9052
9053,b'Onnx model train using ORTTrainer',Software,open,2021-09-14T10:31:03Z,2021-09-14 14:33:48+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9053
9054,b'Converting onnx to ORT with nnapi support',Software,closed,2021-09-14T11:49:42Z,2021-09-14 16:48:32+00:00,2021-09-17T11:17:01Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/9054
9056,b'RunOptions with memory.enable_memory_arena_shrinkage throws exception in 32 bit (at least on Windows)',Software,closed,2021-09-14T16:53:02Z,2021-09-14 20:23:08+00:00,2021-09-14T20:23:08Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9056
9068,b'inference caused memory full in jetson',Software,closed,2021-09-15T08:15:00Z,2021-09-15 08:17:08+00:00,2021-09-15T08:17:08Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9068
9069,"b""The example for quantization doesn't work""",Software,open,2021-09-15T13:40:20Z,2021-09-15 18:43:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9069
9072,b'Add allocator_stats.h to cmake build install',Software,open,2021-09-15T19:05:31Z,2022-04-19 02:54:33+00:00,,215,,https://api.github.com/repos/microsoft/onnxruntime/issues/9072
9078,"b""doc page for execution providers doesn't exist.""",Software,closed,2021-09-16T09:08:47Z,2021-09-16 13:18:32+00:00,2021-09-16T13:24:34Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9078
9082,b'Is there any OpenVino-Ort documentation for dotNet languages?',Software,closed,2021-09-16T13:54:57Z,2021-09-17 09:20:38+00:00,2021-09-17T09:20:38Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9082
9083,"b""[E:onnxruntime:, sequential_executor.cc:339 Execute] Non-zero status code returned while running Transpose node. Name:'model/unet3d_segmentation/conv3d_12/Conv3D__165' Status Message: CUDA error cudaErrorInvalidConfiguration:invalid configuration argument""",Software,open,2021-09-16T14:29:00Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/9083
9090,b'Op with name (Atan_994) and type (Atan) kernel not found in CPUExecutionProvider',Software,closed,2021-09-16T23:13:34Z,2021-09-17 00:33:32+00:00,2021-10-01T17:18:13Z,0,14,https://api.github.com/repos/microsoft/onnxruntime/issues/9090
9093,b'cross compile but onnx-ml.pb.cc error',Software,open,2021-09-17T07:21:58Z,2021-09-17 17:41:57+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9093
9095,b'C++ API more useful',Software,closed,2021-09-17T07:31:28Z,2021-09-17 21:19:58+00:00,2021-09-17T21:19:58Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9095
9096,b'32 cores is not faster than 16 cores',Software,closed,2021-09-17T07:34:15Z,2021-09-17 17:37:11+00:00,2021-09-20T20:13:38Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/9096
9097,b'returned non-zero exit status 1. when add option --build_wheel',Software,closed,2021-09-17T07:48:57Z,2021-09-17 13:13:11+00:00,2021-09-17T13:13:11Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9097
9098,b'how to build on centos6.9',Software,closed,2021-09-17T09:52:18Z,2021-09-17 17:12:35+00:00,2021-09-21T09:38:42Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/9098
9099,b'Quantization optimization for mobile',Software,closed,2021-09-17T11:32:56Z,2021-09-17 17:10:50+00:00,2021-09-21T07:44:44Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/9099
9103,b'bad link to add-execution-provider doc page',Documentation,closed,2021-09-17T20:09:22Z,2021-09-17 22:56:39+00:00,2021-09-21T18:31:55Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/9103
9110,b'Tutorial of building onnxruntime to wasm and call it by c++',Software,closed,2021-09-17T23:20:04Z,2021-09-20 17:54:21+00:00,2022-01-19T02:05:04Z,2,123,https://api.github.com/repos/microsoft/onnxruntime/issues/9110
9111,b'[ORT JNI] OpenVINO EP cannot be added into session options',Software,closed,2021-09-17T23:50:55Z,2021-09-17 23:58:09+00:00,2021-09-28T20:59:24Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/9111
9115,b'[GPU] The quantized-onnx-model is worse than onnx-model.',Software,open,2021-09-18T16:21:01Z,2021-09-20 17:54:46+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/9115
9116,b'Possible duplicated source code',Software,closed,2021-09-18T18:03:01Z,2021-09-20 17:53:52+00:00,2021-09-20T17:53:52Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9116
9117,"b'[js/web] ""Only one thread was configured for parallel execution. Hence will use sequential execution.""'",Software,closed,2021-09-19T02:50:13Z,2021-09-20 17:52:38+00:00,2021-09-23T04:31:29Z,1,4,https://api.github.com/repos/microsoft/onnxruntime/issues/9117
9118,b'onnxruntime 1.8.2 not yet available on pypi',Software,open,2021-09-19T08:47:39Z,2021-09-20 14:36:27+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/9118
9120,b'Flake8 PEP8 E402 error in 1.8.2',Software,open,2021-09-19T23:01:40Z,2021-09-20 17:47:36+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9120
9121,"b""how to input 'None' in cpp-version""",Software,open,2021-09-20T00:44:04Z,2021-09-20 17:43:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9121
9122,b'[OpenVINO-EP] Windows Build broken for Debug Mode',Software,closed,2021-09-20T10:26:18Z,2021-09-20 17:36:07+00:00,2021-09-21T03:39:18Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9122
9123,b'Question for Populating String Tensors in ONNX Runtime - C++',Software,closed,2021-09-20T10:56:51Z,2021-09-20 17:54:58+00:00,2021-09-24T16:50:29Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/9123
9124,b'CMake error: could not find git for clone of pybind11',Software,closed,2021-09-20T12:08:04Z,2021-09-20 16:56:50+00:00,2021-10-15T19:17:35Z,0,25,https://api.github.com/repos/microsoft/onnxruntime/issues/9124
9125,b'1.8.2 onnx-tensorrt \xe2\x80\x98kRNN\xe2\x80\x99 is not a member of \xe2\x80\x98nvinfer1::LayerType\xe2\x80\x99 with TensorRT8',Software,closed,2021-09-20T16:11:39Z,2021-09-20 16:39:49+00:00,2021-09-20T21:42:52Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9125
9161,b'Performance comparison between onnxruntime-web and onnxruntime-python',Software,closed,2021-09-20T20:09:34Z,2021-09-22 20:58:25+00:00,2021-10-01T07:33:43Z,2,10,https://api.github.com/repos/microsoft/onnxruntime/issues/9161
9136,b'segfault with cuda fns_candy_style_transfer tutorial',Software,closed,2021-09-21T07:43:59Z,2021-09-21 09:12:21+00:00,2021-09-21T16:35:54Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9136
9138,b'Create session has different gpu memory (EP: CUDA)',Software,open,2021-09-21T11:53:17Z,2021-09-22 02:53:24+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9138
9146,b'model load from memory',Software,closed,2021-09-22T03:29:09Z,2021-09-22 06:35:45+00:00,2021-09-22T06:35:45Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9146
9148,b'Problem with include in provider_options.h',Software,open,2021-09-22T05:37:36Z,2021-09-22 16:33:28+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9148
9152,b'How to optimize 32 bit memory/cpu usage in c++',Software,closed,2021-09-22T12:10:42Z,2021-09-22 16:31:20+00:00,2021-10-01T12:41:31Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/9152
9153,b'centos6.9+onnxruntimme1.4 build error',Software,closed,2021-09-22T12:54:00Z,2021-09-22 12:54:48+00:00,2021-09-26T21:17:21Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/9153
9154,b'error  on import_memory',Software,closed,2021-09-22T13:07:48Z,2021-09-22 14:26:37+00:00,2021-09-22T14:26:37Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9154
9155,b'Unit tests fail to build on AlpineLinux',Software,open,2021-09-22T17:30:37Z,2021-09-22 22:27:33+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9155
9156,b'Dynamic input/output batch size',Software,closed,2021-09-22T18:27:05Z,2021-09-24 16:27:57+00:00,2021-09-24T16:27:57Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9156
9158,b'Import Onnxruntime Prints Logs to Console',Software,closed,2021-09-22T20:19:05Z,2021-09-22 22:25:51+00:00,2021-10-13T22:15:44Z,0,21,https://api.github.com/repos/microsoft/onnxruntime/issues/9158
9162,b'Resnet - converted Onnx model is 2.9X slower than pyTorch model in V100 gpu',Software,closed,2021-09-22T23:10:06Z,2021-09-22 23:32:00+00:00,2021-12-01T03:27:34Z,0,69,https://api.github.com/repos/microsoft/onnxruntime/issues/9162
9164,b'Missing SessionOptionsAppendExecutionProvider_DML',Software,open,2021-09-23T03:15:52Z,2021-09-23 18:12:31+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9164
9165,b'Missing header in 1.9.0 win x64 GPU release',Software,closed,2021-09-23T14:07:59Z,2021-09-23 18:06:39+00:00,2021-09-23T18:06:39Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9165
9170,b'MKL linker error when building eager mode with torch ',Software,open,2021-09-24T01:39:12Z,2021-09-24 01:39:37+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9170
9171,b'[WinML] Return wgi::BitmapBounds to caller of bind',Software,open,2021-09-24T03:02:05Z,2021-09-24 03:03:59+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9171
9172,b'[WinML] Extend VideoFrame binding to have more option regarding scaling',Software,open,2021-09-24T03:13:54Z,2021-09-24 16:23:54+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9172
9174,b'error when compile with ComputeLibrary-21.08',Software,open,2021-09-24T05:06:42Z,2021-09-24 16:20:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9174
9178,b'[js/web] Inference failing on larger inputs',Software,closed,2021-09-24T15:04:17Z,2021-09-24 16:15:30+00:00,2021-09-26T16:57:04Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/9178
9185,"b'An exception when initialize session(env, model_path, session_options)'",Software,closed,2021-09-26T03:29:31Z,2021-09-26 12:34:19+00:00,2021-09-26T12:34:19Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9185
9187,b'mlas build fail',Software,open,2021-09-26T09:11:15Z,2021-09-27 15:01:08+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/9187
9189,b'Jupyterlab crash after installing onnxruntime even when uninstalling it',Software,closed,2021-09-26T09:30:35Z,2021-09-26 10:07:42+00:00,2021-09-26T10:07:42Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9189
9190,b'[ORTModule] unexpected tensor scalar type in onnx export',Software,closed,2021-09-26T12:39:39Z,2021-09-27 18:10:33+00:00,2021-10-12T16:03:15Z,1,16,https://api.github.com/repos/microsoft/onnxruntime/issues/9190
9192,b'ONNX pointwise convolution and group convolution are too slow',Software,open,2021-09-27T07:25:37Z,2021-09-27 07:40:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9192
9193,b'ai.onnxruntime.OrtException: Cannot convert class java.nio.HeapFloatBuffer to a OnnxTensor.',Software,closed,2021-09-27T10:15:41Z,2021-10-01 17:17:07+00:00,2021-10-01T17:17:07Z,4,4,https://api.github.com/repos/microsoft/onnxruntime/issues/9193
9194,b'[ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running FusedConv node.',Software,open,2021-09-27T10:25:04Z,2021-09-28 03:49:43+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9194
9195,b'[ONNXRuntimeError] Failed to createSession in Android.',Software,closed,2021-09-27T11:58:29Z,2021-09-27 18:27:08+00:00,2021-10-08T00:50:13Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/9195
9196,b'MaxPool operator support in operator set version 12+ for WebGL',Software,closed,2021-09-27T13:21:09Z,2021-09-27 18:43:24+00:00,2021-10-14T23:29:37Z,0,17,https://api.github.com/repos/microsoft/onnxruntime/issues/9196
9197,b'Error in Node: : Op registered for Upsample is deprecated in domain_version of 11',Software,closed,2021-09-27T13:46:06Z,2021-09-27 20:23:51+00:00,2021-10-21T12:35:59Z,0,23,https://api.github.com/repos/microsoft/onnxruntime/issues/9197
9198,b'set_providers with list',Software,closed,2021-09-27T14:12:57Z,2021-10-05 18:47:17+00:00,2021-10-05T18:47:16Z,8,8,https://api.github.com/repos/microsoft/onnxruntime/issues/9198
9200,b'[urgent] Cross build failed for IOS with reduced ops',Software,closed,2021-09-27T17:40:41Z,2021-09-27 18:35:32+00:00,2021-11-30T00:10:03Z,0,63,https://api.github.com/repos/microsoft/onnxruntime/issues/9200
9204,"b'Error due to a combination of a condition, convolution and batchnorm layers'",Software,closed,2021-09-28T00:11:12Z,2021-10-12 21:51:24+00:00,2021-10-12T21:51:24Z,14,14,https://api.github.com/repos/microsoft/onnxruntime/issues/9204
9208,b'InferenceSession.run in python is inconsistent in terms of performance',Software,open,2021-09-28T05:53:29Z,2021-09-28 07:01:55+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9208
9209,b'Does inference in Javascript support XGBoost models?',Software,closed,2021-09-28T14:52:32Z,2021-10-04 03:19:41+00:00,2022-04-22T00:29:47Z,5,205,https://api.github.com/repos/microsoft/onnxruntime/issues/9209
9217,b'orttrainer fails to run with latest pytorch builds',Software,closed,2021-09-29T03:02:35Z,2021-09-29 16:11:47+00:00,2021-10-01T17:50:24Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/9217
9220,b'Optimization support for different Transformer-based architectures',Software,closed,2021-09-29T14:35:52Z,2021-09-29 23:39:29+00:00,2021-10-11T18:36:36Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/9220
9222,"b""ORT 1.9.0 Build: nvcc error   : 'ptxas' died due to signal 11 (Invalid memory reference)""",Software,open,2021-09-29T18:46:07Z,2021-09-29 21:23:24+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9222
9225,b'arm install error',Software,open,2021-09-30T02:15:35Z,2021-10-04 03:13:50+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/9225
9226,b'm_session.RUN   crash',Software,open,2021-09-30T08:30:03Z,2022-04-19 02:54:22+00:00,,200,,https://api.github.com/repos/microsoft/onnxruntime/issues/9226
9245,b'Failed do Kind Kernel def Hash',Software,closed,2021-10-01T10:09:03Z,2021-10-01 18:48:59+00:00,2021-10-21T22:53:02Z,0,20,https://api.github.com/repos/microsoft/onnxruntime/issues/9245
9247,b'An error occurs while running with CUDAExecutionProvider on version 1.9.0',Software,open,2021-10-01T14:16:31Z,2021-10-01 20:01:02+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9247
9248,b'Unable to run android demo with custom model',Software,closed,2021-10-01T20:17:00Z,2021-10-01 20:48:16+00:00,2022-04-19T07:58:42Z,0,199,https://api.github.com/repos/microsoft/onnxruntime/issues/9248
9257,"b""TypeError: cannot resolve operator 'ConvTranspose' with opsets: ai.onnx v11""",Software,open,2021-10-02T19:28:45Z,2021-10-04 03:14:53+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/9257
9258,b'How to suppress CleanUnusedInitializers message',Software,closed,2021-10-03T06:07:43Z,2021-10-04 03:11:52+00:00,2021-10-07T06:12:13Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/9258
9259,b'Clone failed',Software,closed,2021-10-04T09:36:03Z,2021-10-04 16:19:25+00:00,2021-10-05T01:40:40Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9259
9260,"b""EntryPointNotFoundException: Unable to find an entry point named 'OrtGetApiBase' in DLL 'onnxruntime'""",Software,closed,2021-10-04T14:38:52Z,2021-10-04 19:17:50+00:00,2021-10-04T22:51:43Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9260
9271,b'[OpenVINO-EP] Windows Build Nuget is broken ',Software,open,2021-10-05T10:12:04Z,2021-10-05 15:58:52+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9271
9275,b'Question - Ort::Value re-assignment',Software,closed,2021-10-05T20:10:37Z,2021-10-06 00:27:13+00:00,2021-10-16T00:34:37Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/9275
9276,b'Onnxruntime in WSL with CUDA is much slower than windows',Software,closed,2021-10-05T21:09:44Z,2021-10-06 00:21:25+00:00,2022-04-19T16:41:35Z,0,195,https://api.github.com/repos/microsoft/onnxruntime/issues/9276
9285,b'Inference run much slower with nnapi on android device',Software,closed,2021-10-06T03:40:45Z,2021-10-06 07:15:36+00:00,2021-10-11T19:23:40Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/9285
9286,b'[build] Use vendored version of nlohmann-json instead of submodule',Software,open,2021-10-06T11:55:32Z,2021-10-06 15:47:49+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9286
9287,b'[build] Provide a way to disable building tests',Software,closed,2021-10-06T12:34:00Z,2021-10-06 15:48:02+00:00,2021-10-07T18:48:06Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9287
9288,b'[documentation] Broken link in build-interfacing docs',Documentation,closed,2021-10-06T13:04:30Z,2021-10-06 15:46:29+00:00,2021-10-18T23:11:53Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/9288
9289,b'Different memory consumption depending on the Nvidia generation.',Software,open,2021-10-06T16:23:20Z,2021-10-06 19:36:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9289
9291,"b""Is it on purpose that the combination of both build parameters '--x86' and 'msvc_toolset' impossible?""",Software,open,2021-10-06T17:50:49Z,2021-10-06 17:51:16+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9291
9292,"b'Onnxruntime-gpu always runs on CPU and never on GPU, [Roberta]'",Software,open,2021-10-06T20:36:39Z,2021-10-06 21:23:05+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9292
9296,"b""Rule-based graph transformers don't work on graphs with functions""",Software,open,2021-10-06T23:13:10Z,2021-10-07 00:58:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9296
9302,"b'Onnxruntime-gpu always runs on CPU and never on GPU, [yolo v5]'",Software,closed,2021-10-07T09:58:25Z,2021-10-07 17:00:37+00:00,2021-10-08T12:40:28Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9302
9309,"b""Can't load Cuda Provider on Linux due symbol lookup error""",Software,open,2021-10-08T06:27:00Z,2021-10-08 18:50:12+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9309
9313,b'ONNXRuntime CPU - Memory spiking continuously (Memory leak)',Software,open,2021-10-08T18:55:05Z,2021-10-11 04:50:59+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/9313
9321,b'Is there a way to add DMLExecutionProvider transformer profiler tool',Software,closed,2021-10-10T13:37:04Z,2021-10-11 17:03:50+00:00,2021-10-21T22:41:35Z,1,11,https://api.github.com/repos/microsoft/onnxruntime/issues/9321
9322,b'Issue loading model using onnx web ',Software,open,2021-10-10T17:04:39Z,2021-10-11 18:22:51+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/9322
9324,b'onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException',Software,open,2021-10-11T08:50:48Z,2021-10-11 19:58:32+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9324
9325,b'Offline optimization mode with CUDA EP',Software,open,2021-10-11T14:46:06Z,2021-10-11 18:06:35+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9325
9332,"b""error: '_Frees_ptr_opt_' has not been declared""",Software,open,2021-10-12T02:49:43Z,2021-10-12 04:46:27+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9332
9333,"b'Use Dropout in inference, but I want to use other Graph Optimizations in ONNX Runtime'",Software,closed,2021-10-12T03:36:36Z,2021-10-12 16:15:53+00:00,2021-10-14T13:48:48Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/9333
9334,b'ONNX inference in batch mode very slow ',Software,closed,2021-10-12T03:37:56Z,2021-10-12 21:42:38+00:00,2021-10-19T07:23:23Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/9334
9335,b'Change Onnxruntime version to 1.9.0 and then encounter Ort::Session session BUG .',Software,closed,2021-10-12T13:53:03Z,2021-10-12 13:59:09+00:00,2021-10-18T11:54:45Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/9335
9339,b'ORT fails when there is a shape inference issue in if node',Software,closed,2021-10-12T21:00:36Z,2021-10-12 21:04:10+00:00,2021-10-13T02:33:19Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9339
9345,b'Execution failure while executing depthwise convolution node with ArmNN Execution Provider',Software,open,2021-10-13T08:59:07Z,2021-10-13 19:03:08+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9345
9348,b'Using an svm regressor from sklearn',Software,open,2021-10-13T11:29:43Z,2021-10-13 18:19:02+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9348
9349,b'Execution failure while executing GNN Model',Software,open,2021-10-13T13:05:52Z,2021-10-13 19:05:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9349
9352,b'Unable to restrict the inference compute to single thread',Software,closed,2021-10-13T15:48:50Z,2021-10-13 16:02:46+00:00,2021-10-13T16:02:46Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9352
9359,b'[not an issue] test issue triage',Software,closed,2021-10-13T19:57:47Z,2021-10-13 19:57:58+00:00,2021-10-13T19:58:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9359
9362,b'ORT latest nightly is not available on PyPI',Software,closed,2021-10-14T01:53:18Z,2021-10-14 17:59:50+00:00,2021-11-11T01:33:52Z,0,27,https://api.github.com/repos/microsoft/onnxruntime/issues/9362
9364,b'onnxruntime-1.8.2. tensorrt_execution_provider.cc:539 onnxruntime::TensorrtExecutionProvider::TensorrtExecutionProvider [ONNXRuntimeError] : 11 : EP_FAIL : TensorRT EP could not open shared library from',Software,open,2021-10-14T07:13:49Z,2021-10-14 17:56:35+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9364
9365,"b""QLinearConv per-channel result  is wrong  and it's seem overflow when input is big for my model""",Software,open,2021-10-14T09:35:55Z,2021-10-14 09:57:05+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9365
9367,b'GetTensorMutableData is destructive',Software,open,2021-10-14T11:17:34Z,2021-10-14 17:54:23+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9367
9368,b'Crash with sigbus: illegal alignment on 32bit system when session run',Software,closed,2021-10-14T11:45:38Z,2021-10-14 17:53:39+00:00,2021-10-15T21:50:58Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9368
1016,b'[Loading Model] Matlab Exported LSTM Model',Software,closed,2019-05-13T16:17:02Z,2019-05-14 00:01:34+00:00,2019-05-23T02:55:45Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/1016
1021,"b'failed:[ShapeInferenceError] Attribute pads has incorrect size, when using onnxruntime to infer onnx model converted from pytorch model'",Software,closed,2019-05-14T03:01:46Z,2019-05-14 05:55:23+00:00,2019-05-15T14:55:10Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/1021
1024,"b'Crash in C# coreclr.dll, while running x86 Microsoft.ML.OnnxRuntime.InferenceSample'",Software,closed,2019-05-14T06:26:18Z,2019-05-14 17:57:56+00:00,2019-05-21T01:24:17Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/1024
1025,b'Clang support',Software,closed,2019-05-14T15:56:34Z,2019-05-14 17:56:59+00:00,2019-05-14T19:42:26Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1025
1034,"b""Can't Create Model Sessions on Different GPU""",Software,closed,2019-05-15T03:31:36Z,2019-05-15 17:22:24+00:00,2019-06-04T23:32:28Z,0,20,https://api.github.com/repos/microsoft/onnxruntime/issues/1034
1037,b'Update examples in documentation',Documentation,closed,2019-05-15T10:49:59Z,2019-05-15 23:51:54+00:00,2019-07-03T16:48:05Z,0,49,https://api.github.com/repos/microsoft/onnxruntime/issues/1037
1039,b'Fully convolutional NN support',Documentation,closed,2019-05-15T13:25:36Z,2019-05-21 07:52:29+00:00,2019-06-13T08:49:49Z,5,28,https://api.github.com/repos/microsoft/onnxruntime/issues/1039
1049,"b""Error: 'libcublas.so.9.1: cannot open shared object file: No such file or directory' with the latest Cuda version""",Documentation,closed,2019-05-16T12:45:46Z,2019-05-16 17:38:08+00:00,2019-05-16T17:38:08Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1049
1050,b'onnx Runtime error for keras Reshape layer with batch',Documentation,closed,2019-05-16T13:25:07Z,2019-05-16 18:38:47+00:00,2019-05-16T22:02:43Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1050
1053,b'Resnet50 fails if update submodule to latest ONNX',Documentation,closed,2019-05-16T21:13:36Z,2019-05-16 21:28:31+00:00,2019-05-20T18:16:37Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/1053
1056,"b""Onnx Backend API 'run_model' is broken""",Documentation,closed,2019-05-17T10:09:37Z,2019-05-17 19:04:02+00:00,2019-05-28T23:38:40Z,0,11,https://api.github.com/repos/microsoft/onnxruntime/issues/1056
1060,b'How to Create String Tensor Properly Using C API?',Documentation,closed,2019-05-18T00:04:15Z,2019-05-18 00:04:34+00:00,2019-05-20T18:22:16Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/1060
1063,b'Yolov3 Pytorch',Documentation,closed,2019-05-18T08:23:27Z,2019-05-20 20:37:35+00:00,2019-06-11T23:12:24Z,2,24,https://api.github.com/repos/microsoft/onnxruntime/issues/1063
1064,b'How can i build shared lib\xef\xbc\x9f',Documentation,closed,2019-05-20T10:52:02Z,2019-05-20 17:36:11+00:00,2019-05-20T17:36:11Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1064
1065,b'Compile Error when CTest pytorch-operator',Documentation,closed,2019-05-20T12:46:12Z,2019-05-24 19:19:15+00:00,2019-06-11T17:24:38Z,4,22,https://api.github.com/repos/microsoft/onnxruntime/issues/1065
1079,b'What is default backend for python CPU implementation?',Documentation,closed,2019-05-22T08:58:21Z,2019-05-23 05:31:31+00:00,2019-05-23T05:31:31Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1079
1080,"b'""Where"" Op Is Not Implemented'",Documentation,closed,2019-05-22T16:29:14Z,2019-05-22 17:23:17+00:00,2019-05-28T23:12:31Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/1080
1084,b'Exporter to support multidim operators',Documentation,closed,2019-05-22T22:02:47Z,2019-05-25 00:55:35+00:00,2019-05-25T00:55:35Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/1084
1086,b'Exporter to support aten:std',Documentation,closed,2019-05-22T22:27:04Z,2019-05-22 23:09:05+00:00,2019-05-22T23:09:05Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1086
1087,"b'A function decorator for PyTorch modules, to export ONNX'",Documentation,closed,2019-05-22T23:32:36Z,2019-05-23 17:33:29+00:00,2019-05-23T17:33:29Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1087
1088,b'Support Flatten ops (and extend its ONNX functionality)',Software,closed,2019-05-23T00:17:33Z,2019-05-23 20:03:35+00:00,2019-05-25T00:17:38Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/1088
1093,b'How to choose execution provider using Python?',Software,closed,2019-05-23T15:10:24Z,2019-05-24 08:04:54+00:00,2019-05-24T08:04:54Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1093
1094,b'The onnxruntime nuget package can be installed under xamarin forms and run on the android system?',Software,closed,2019-05-23T15:10:44Z,2019-05-23 23:32:49+00:00,2019-05-24T00:07:34Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/1094
1095,"b'Error ""trt_engine != nullptr was false"" when running inference of ONNX model'",Software,closed,2019-05-23T15:35:07Z,2019-05-23 18:46:49+00:00,2019-08-02T17:31:28Z,0,71,https://api.github.com/repos/microsoft/onnxruntime/issues/1095
1108,b'Is TVM Working ? ',Software,closed,2019-05-24T22:29:46Z,2019-05-24 23:35:26+00:00,2019-05-30T19:19:13Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/1108
1113,"b""cannot import name 'RunOptions' when executing in AWS lambda""",Software,closed,2019-05-27T16:45:47Z,2019-05-28 17:08:51+00:00,2019-06-04T00:24:17Z,1,7,https://api.github.com/repos/microsoft/onnxruntime/issues/1113
9370,b'ConvolutionTranspose padding mode SAME_UPPER/SAME_LOWER problem',Software,open,2021-10-14T13:33:57Z,2021-10-14 17:52:43+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9370
9371,b'Build on Jetson Xavier NX does not produce c++ API include and libs',Software,open,2021-10-14T18:12:10Z,2021-10-14 20:27:48+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9371
9375,b'ORT execution fails when a gradient builder is not registered for module-local functions',Software,open,2021-10-14T23:10:00Z,2021-10-15 14:26:24+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9375
9377,b'Where can I view its dependencies with different CUDA versions?',Software,closed,2021-10-15T03:53:09Z,2021-10-15 07:31:55+00:00,2021-10-15T07:31:55Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9377
9378,b'Rebuild wheel with TensorRT build options appears to be broken on Jetson   ',Software,closed,2021-10-15T07:16:22Z,2021-10-15 20:55:40+00:00,2021-10-18T09:38:27Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/9378
9379,"b'Please tell me how to switch to the specified version, such as onnxruntime 1.8.0. Can you give a command to switch to version 1.8.0?'",Software,closed,2021-10-15T07:34:01Z,2021-10-15 20:54:21+00:00,2021-10-25T01:14:06Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/9379
9384,b'No Op registered for ConstantOfShape with domain_version of 11',Software,closed,2021-10-15T09:32:23Z,2021-10-15 20:55:04+00:00,2021-11-04T21:35:21Z,0,20,https://api.github.com/repos/microsoft/onnxruntime/issues/9384
9385,b'pkg-config include paths should include API dir',Software,open,2021-10-15T11:15:23Z,2021-10-15 20:55:22+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9385
9387,b'OpenVINO EP not available',Software,open,2021-10-15T12:47:34Z,2021-10-15 20:52:36+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9387
9388,b'Does it have any tools to measure time of each layer?',Software,closed,2021-10-15T13:53:37Z,2021-10-15 20:52:19+00:00,2021-10-24T22:17:35Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/9388
9389,b'Graph is not a DAG when trying to convert HF model inputs to `int32`',Software,open,2021-10-15T14:52:28Z,2021-10-15 14:52:28+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9389
9396,"b'The Windows Debug build of onnxruntime fails with ""fatal error C1128""'",Software,closed,2021-10-15T18:11:13Z,2021-10-15 20:51:08+00:00,2021-11-13T03:32:22Z,0,28,https://api.github.com/repos/microsoft/onnxruntime/issues/9396
9403,"b'When onnxruntime_PREFER_SYSTEM_LIB is set, the onnxruntime build now breaks when some packages are missing'",Software,closed,2021-10-15T23:12:19Z,2021-10-18 22:04:19+00:00,2021-10-21T00:27:54Z,2,5,https://api.github.com/repos/microsoft/onnxruntime/issues/9403
9405,"b'my model is ST-gcn in mmskeletion, I convert it to onnx successfully,and onnxruntime can get resout,but the resout is wrong?'",Software,closed,2021-10-16T00:53:29Z,2021-10-18 21:09:51+00:00,2021-10-18T21:09:51Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/9405
9407,b'Is python faster than c++?',Software,closed,2021-10-16T01:29:56Z,2021-10-18 01:59:03+00:00,2021-10-19T23:09:00Z,2,3,https://api.github.com/repos/microsoft/onnxruntime/issues/9407
9408,b'Failed to find kernel for Softmax(11) (node Softmax_0). Op with name (Softmax_0) and type (Softmax) kernel not found in CPUExecutionProvider',Software,closed,2021-10-16T02:03:02Z,2021-10-18 10:19:24+00:00,2021-10-18T10:19:24Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/9408
9409,b'failed to load yolov4 model when options.AppendExecutionProvider_DML(0)',Software,closed,2021-10-16T08:59:26Z,2021-10-18 08:09:00+00:00,2022-02-28T10:03:55Z,1,135,https://api.github.com/repos/microsoft/onnxruntime/issues/9409
9410,b'INT8 input & FP32 output for single op',Software,closed,2021-10-18T01:33:30Z,2021-10-19 23:08:21+00:00,2021-10-19T23:08:21Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9410
9411,b'regression bug for ScatterND operator',Software,closed,2021-10-18T02:03:14Z,2021-10-25 00:22:33+00:00,2021-10-25T00:22:33Z,6,6,https://api.github.com/repos/microsoft/onnxruntime/issues/9411
9418,b'use v1.9.0 to load ONNX Opset 15 failed.',Software,closed,2021-10-18T04:37:46Z,2021-10-18 07:43:15+00:00,2021-10-18T11:53:09Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9418
9420,b'Why Float16 model takes twice as long as Float under GPU',Software,open,2021-10-18T12:19:39Z,2021-10-21 17:28:45+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/9420
9425,b'Relu getting dropped during quantization',Software,open,2021-10-18T19:37:50Z,2021-10-18 21:08:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9425
9428,b'MaxPool not getting quantized when preceded by Relu',Software,open,2021-10-18T21:19:53Z,2021-10-18 21:58:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9428
9429,b'The SVMClassifier node outputs 2 class scores when it should be a single score for non-probabilistic models',Software,open,2021-10-18T21:42:23Z,2021-10-19 01:05:11+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9429
9433,"b'CoreML provider (Python API): ANE/ GPU not used, falling back on CPU?'",Software,closed,2021-10-18T23:41:47Z,2021-10-19 01:29:01+00:00,2021-10-19T17:57:16Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9433
9434,b'InferenceSession status.IsOK() was false. Given model could not be parsed while creating inference session',Software,closed,2021-10-19T02:12:48Z,2021-10-21 21:46:56+00:00,2021-10-21T21:46:56Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/9434
9437,b'measure inference time',Software,open,2021-10-19T08:24:04Z,2022-04-19 01:54:13+00:00,,181,,https://api.github.com/repos/microsoft/onnxruntime/issues/9437
9438,"b""Unable to find an entry point named 'OrtSessionOptionsAppendExecutionProvider_CUDA' """,Software,closed,2021-10-19T10:27:38Z,2021-10-24 22:17:20+00:00,2021-10-24T22:17:20Z,5,5,https://api.github.com/repos/microsoft/onnxruntime/issues/9438
9439,b'1 - onnxruntime_test_all fails when building with OpenVINO support',Software,open,2021-10-19T13:27:39Z,2021-10-19 22:40:18+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9439
9442,b'Inference time gets slower over time (gpu + multithread)',Software,closed,2021-10-19T17:52:14Z,2021-10-21 08:15:26+00:00,2021-10-21T08:15:26Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9442
9458,b'[web] feature request: support WebGL inside web worker ',Software,open,2021-10-19T19:13:42Z,2021-10-20 06:27:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9458
9448,b'Inference Example for yolov4Tiny',Software,closed,2021-10-20T07:37:23Z,2021-10-20 22:20:13+00:00,2021-10-21T21:37:07Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9448
9449,b'inplace for Reshape operation ',Software,closed,2021-10-20T08:57:05Z,2021-10-20 18:41:26+00:00,2021-10-21T00:26:30Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9449
9451,b'Only CPUExecutionProvider is available in ONNX Runtime InferenceSession',Software,closed,2021-10-20T11:30:34Z,2021-10-20 18:33:18+00:00,2021-10-21T12:06:14Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9451
9453,"b""Browser report error info 'failed to call OrtRun(). error code = 2.'""",Software,closed,2021-10-20T14:33:12Z,2021-10-20 18:30:34+00:00,2021-10-21T00:21:45Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9453
9465,b'Errors When Calling onnxruntime.InferenceSession',Software,open,2021-10-20T22:13:33Z,2021-10-21 01:04:22+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9465
9467,b'Build flag issues for a GPU-enabled wheel',Software,open,2021-10-20T23:55:26Z,2021-10-21 01:00:13+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9467
9469,b'Linux GPU CI build is broken',Software,closed,2021-10-21T01:48:32Z,2021-10-21 05:33:21+00:00,2021-10-21T05:33:21Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9469
9472,"b'ONNXRuntime Python vs C++, different output using same models and inputs'",Software,closed,2021-10-21T10:22:44Z,2021-10-22 01:08:27+00:00,2021-11-10T06:52:25Z,0,19,https://api.github.com/repos/microsoft/onnxruntime/issues/9472
9473,b'[BUG] Issues when running inside Spark UDF of Spark',Software,closed,2021-10-21T11:26:28Z,2021-10-24 23:06:43+00:00,2021-10-24T23:06:43Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/9473
9475,b'Failed to load ort model on android. Any Idea ?',Software,open,2021-10-21T12:47:03Z,2021-10-21 18:07:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9475
9483,b'Javascript Node Alpine',Software,open,2021-10-21T17:09:52Z,2021-10-22 00:07:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9483
9494,"b""NOT_IMPLEMENTED : Could not find an implementation for Trilu(14) node with name 'Trilu_2""",Software,closed,2021-10-22T08:51:44Z,2021-10-25 00:05:32+00:00,2021-10-25T02:48:22Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/9494
9505,b'Compile (link) error for mac build',Software,closed,2021-10-22T21:37:06Z,2021-10-23 02:04:35+00:00,2021-10-23T02:04:35Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9505
9506,b'Expose option to strictly enforce shape and type correctness',Software,closed,2021-10-22T23:52:15Z,2021-10-22 23:52:16+00:00,2022-04-21T15:32:41Z,0,180,https://api.github.com/repos/microsoft/onnxruntime/issues/9506
9509,b'how to release gpu memory when keep onnxruntime session around.',Software,open,2021-10-23T05:17:42Z,2021-10-25 03:03:10+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/9509
9515,b'Build Failure in Gpu',Software,closed,2021-10-23T18:15:25Z,2021-10-24 23:59:02+00:00,2021-10-25T12:52:08Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9515
9517,b'Scikit-learn Logistic Regression page down',Documentation,closed,2021-10-23T19:38:55Z,2021-10-24 23:56:10+00:00,2021-10-25T18:48:08Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9517
9521,b'failed to use RandomForestRegressor ort in android studio',Software,open,2021-10-24T13:39:52Z,2021-10-24 13:59:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9521
9527,b'how to get a slice of tensor in Ort::value',Software,closed,2021-10-25T09:15:22Z,2021-10-25 17:41:48+00:00,2021-10-29T01:55:07Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/9527
9530,b'OnnxRuntime Build Failure in Docker',Software,open,2021-10-25T13:16:23Z,2021-10-25 17:46:56+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9530
9536,b'ONNX Runtime docs website search could be improved',Documentation,closed,2021-10-25T21:15:56Z,2021-10-26 01:14:39+00:00,2021-11-01T22:36:47Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/9536
9539,b'No implementation for Where(9)',Software,open,2021-10-25T23:19:18Z,2021-10-26 00:03:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9539
9544,b'UnicodeDecodeError when converting dialogpt to onnx format',Software,closed,2021-10-26T03:33:19Z,2021-10-28 09:26:16+00:00,2021-10-28T09:26:16Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/9544
9545,b'How to know onnx input json and pb content after I serve my onnx model with onnx runtime?',Software,closed,2021-10-26T04:11:21Z,2021-10-26 06:16:35+00:00,2021-10-26T06:16:34Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9545
9550,b'Nvidia GPU Memory',Software,closed,2021-10-26T08:40:05Z,2021-11-01 17:26:47+00:00,2021-11-01T17:26:47Z,6,6,https://api.github.com/repos/microsoft/onnxruntime/issues/9550
9553,"b""Unhandled exception. System.EntryPointNotFoundException: Unable to find an entry point named 'OrtSessionOptionsAppendExecutionProvider_ROCM' in shared library 'onnxruntime'.""",Software,closed,2021-10-26T09:49:23Z,2021-10-26 17:24:37+00:00,2021-11-09T06:22:49Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/9553
9560,b'Model InferenceSession.run fails on sklearn Pipeline with two TfidfVectorizers',Software,closed,2021-10-26T21:14:59Z,2021-10-27 19:01:47+00:00,2021-10-27T20:28:47Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9560
9565,b'Unable to restrict ONNX graph with multiple output nodes to single CPU core',Software,open,2021-10-27T03:54:30Z,2021-10-27 03:56:33+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9565
9568,b'Document the path separator convention?',Software,closed,2021-10-27T06:08:51Z,2021-10-27 06:08:52+00:00,2021-10-28T16:09:01Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9568
9569,"b'How to solve this problem? ""Failed to find kernel def hash... in kernel registries for ...""'",Software,open,2021-10-27T08:18:15Z,2021-10-27 08:18:49+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9569
9572,b'OMP_NUM_THREADS flag regression',Software,closed,2021-10-27T10:21:33Z,2021-10-27 19:21:58+00:00,2021-10-27T19:21:58Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9572
9573,b'Quantizing DistilBERT models after optimizing with ORT leads to invalid node input names',Software,open,2021-10-27T12:26:24Z,2021-10-27 17:30:44+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9573
9579,"b""CUDA provider headers aren't installed (but library is)""",Software,closed,2021-10-27T18:13:19Z,2021-10-27 18:50:28+00:00,2021-10-27T18:50:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9579
9582,b'Divergent results between CPU and DirectML',Software,open,2021-10-27T21:30:42Z,2021-10-27 23:01:55+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9582
9584,b'Handling Ort::IoBinding for DirectML EP (C++)?',Software,open,2021-10-28T00:52:50Z,2021-10-28 17:00:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9584
9592,b'Problem with output data when using quantized onnx model',Software,open,2021-10-28T07:33:32Z,2021-10-28 17:33:31+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9592
9593,b'Create Ort::Value struct with torch::tensor',Software,closed,2021-10-28T07:39:44Z,2021-10-28 17:36:16+00:00,2021-11-01T17:30:23Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/9593
9594,"b""onnxruntime-react-native can't load model""",Software,open,2021-10-28T07:51:24Z,2021-10-28 17:11:07+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9594
9597,b'wrong num_quantized_bins & num_bins',Software,closed,2021-10-28T09:18:35Z,2021-10-28 17:09:29+00:00,2022-01-11T18:56:34Z,0,75,https://api.github.com/repos/microsoft/onnxruntime/issues/9597
9598,b'bad accuracy on own quantized(INT8) yolov3 model',Software,open,2021-10-28T09:40:01Z,2021-10-28 09:41:39+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9598
9599,b'Dynamic quantization of multilingual miniLM - output does not match float32 version. Onnxruntime 1.9.0 ',Software,open,2021-10-28T11:32:09Z,2021-10-28 17:10:20+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9599
9604,b'OSError when converting cdialgpt to onnx format ',Software,open,2021-10-29T03:14:47Z,2021-11-01 19:21:20+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/9604
9625,b'onnx inference with multiprocess',Software,open,2021-10-30T08:30:28Z,2021-11-01 18:01:00+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/9625
9627,b'onnxruntime from source takes long (~O(10 minutes)) to build with CUDA support ',Software,closed,2021-10-30T14:44:19Z,2021-11-01 08:55:26+00:00,2021-11-01T17:00:34Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/9627
9628,b'build the master branch with cuda10.2/cudnn8.0',Software,open,2021-10-31T02:46:51Z,2021-11-01 17:48:55+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/9628
9629,b'Get nan as output ',Software,closed,2021-10-31T03:46:33Z,2021-11-01 17:57:58+00:00,2021-11-10T09:04:09Z,1,10,https://api.github.com/repos/microsoft/onnxruntime/issues/9629
9631,b'build bug with cuda 10.2 and cudnn8.0',Software,closed,2021-11-01T01:37:29Z,2021-11-01 17:51:24+00:00,2021-11-01T17:51:24Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9631
9635,"b""Weight's raw_data is empty so it leads to quantize weight failure""",Software,open,2021-11-01T07:54:05Z,2021-11-01 11:35:13+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9635
9636,b'Is is possible to develop custom c++ op (with cuda support) without building onnxruntime?',Software,open,2021-11-01T09:16:19Z,2021-11-01 15:23:05+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9636
9642,b'Need to register an op of QLinearFC',Software,open,2021-11-02T05:27:09Z,2021-11-02 06:08:20+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9642
9643,b'Help finding a weird memory leak.',Software,closed,2021-11-02T06:29:17Z,2021-11-02 08:06:11+00:00,2021-11-10T21:14:45Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/9643
9644,b'set GPU',Software,closed,2021-11-02T06:37:01Z,2021-11-02 07:24:39+00:00,2021-11-03T09:25:04Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9644
9645,b'set devices_id',Software,closed,2021-11-02T06:40:41Z,2021-11-02 07:24:26+00:00,2021-11-04T03:09:37Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9645
9646,b'Nuget package overrides AdditionalDependency variable',Software,closed,2021-11-02T11:47:58Z,2021-11-02 18:33:03+00:00,2022-01-12T07:30:41Z,0,70,https://api.github.com/repos/microsoft/onnxruntime/issues/9646
9647,b'[build] Is the current behaviour of build.py --cmake_extra_defines intended?',Software,closed,2021-11-02T13:01:47Z,2021-11-02 17:03:12+00:00,2022-03-22T18:54:47Z,0,140,https://api.github.com/repos/microsoft/onnxruntime/issues/9647
9654,b'how to support cuda10.2?',Software,open,2021-11-03T02:07:28Z,2021-11-03 02:07:29+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9654
9657,b'YAMNet model running on CudaExecutionProvider is 3x slower than running on tensorflow',Software,open,2021-11-03T09:49:27Z,2021-11-03 09:49:42+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9657
9658,"b'I want to compile it with vs2019, in windows, cuda10.2, but can not download the cmake\\external, could provide the cmake\\external file ?'",Software,closed,2021-11-03T12:28:47Z,2021-11-03 15:58:28+00:00,2021-11-03T15:58:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9658
9659,b'Undefined reference to `onnxruntime::KernelCreateInfo` when building with OpenVINO support for MYRIAD_FP16 on armv7',Software,closed,2021-11-03T14:36:54Z,2021-11-03 14:36:55+00:00,2021-12-10T10:49:04Z,0,36,https://api.github.com/repos/microsoft/onnxruntime/issues/9659
9660,b'Gap in inference time between onnxruntime and torch vanishes when increasing the batch size',Software,open,2021-11-03T16:12:25Z,2021-11-04 05:47:46+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9660
9663,b'InferenceSession initialization fails on graph with constants with IR version < 4',Software,closed,2021-11-03T21:43:59Z,2021-11-03 21:43:59+00:00,2021-11-11T23:13:29Z,0,8,https://api.github.com/repos/microsoft/onnxruntime/issues/9663
9666,b'whl install BUG',Software,open,2021-11-04T02:32:05Z,2021-11-04 06:03:03+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9666
9667,b'inconsistent inference time',Software,open,2021-11-04T03:47:34Z,2021-11-04 05:51:51+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9667
9671,b'Optimizations fails on a specific graph',Software,closed,2021-11-04T12:12:32Z,2021-11-04 12:12:32+00:00,2021-11-11T21:18:16Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/9671
9681,b'ort.env.wasm.numThreads seems not working on chrome ',Software,open,2021-11-05T20:29:02Z,2021-11-05 21:18:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9681
9683,b'windows vs2019 compile',Software,closed,2021-11-06T11:27:15Z,2021-11-08 18:19:18+00:00,2021-11-08T18:19:18Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/9683
9684,b'libonnxruntime.so crash',Software,open,2021-11-06T13:16:40Z,2021-11-06 13:47:22+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9684
9685,"b"" [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for Conv(1) node with name 'Conv_0'""",Software,open,2021-11-06T18:07:00Z,NA,,-100,,https://api.github.com/repos/microsoft/onnxruntime/issues/9685
9689,"b' yolov5 with the compiled onnxruntime by self\xef\xbc\x8cbut is so slow, not with the GPU'",Software,open,2021-11-07T15:04:15Z,2021-11-08 20:55:24+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/9689
9693,"b""MSVS enviroment path doesn't work.""",Software,closed,2021-11-08T06:44:24Z,2021-11-08 18:17:02+00:00,2021-11-08T18:17:02Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9693
9694,b'Quantization shrink model size but no inference speed improvement',Software,open,2021-11-08T08:15:19Z,2021-11-08 20:53:49+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9694
9695,b'\xe3\x80\x90BUG\xe3\x80\x91\xef\xbc\x9aRegister Type Can not find',Software,closed,2021-11-08T08:26:15Z,2021-11-08 08:26:15+00:00,2022-04-18T01:56:19Z,0,160,https://api.github.com/repos/microsoft/onnxruntime/issues/9695
9703,b'/bin/sh: 2: /tmp/tmp6717a310a32843fe842ff6fbdc078787.exec.cmd: nuget: not found',Software,open,2021-11-09T03:24:45Z,2022-04-18 19:54:17+00:00,,160,,https://api.github.com/repos/microsoft/onnxruntime/issues/9703
9704,"b'onnxruntime infer, the same input occasionally has different output'",Software,closed,2021-11-09T03:27:31Z,2021-11-10 23:50:28+00:00,2021-11-12T18:08:15Z,1,3,https://api.github.com/repos/microsoft/onnxruntime/issues/9704
9706,b'No performance gain from DirectML in C#',Software,open,2021-11-09T08:23:46Z,2021-11-09 17:46:44+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9706
9707,"b""Unable to load shared library 'onnxruntime' on MacOS (DllNotFoundException)""",Software,open,2021-11-09T09:54:18Z,2021-11-09 09:54:56+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9707
9708,b'DML EP Error: Disallow using DML with the software adapter (Microsoft Basic Display Adapter)',Software,open,2021-11-09T11:25:55Z,2021-11-09 17:47:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9708
9719,"b'DML EP is not executing nodes, despite it registering as a provider successfully'",Software,open,2021-11-10T12:39:56Z,2021-11-10 23:57:20+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9719
9724,b'Support for int64 with webgl backend of the web runtime',Software,open,2021-11-10T21:14:18Z,2021-11-10 23:57:34+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9724
9730,b'C# adding option for cudnn_conv_algo_search : DEFAULT',Software,closed,2021-11-11T05:48:45Z,2021-11-15 18:15:36+00:00,2022-01-06T19:03:15Z,4,56,https://api.github.com/repos/microsoft/onnxruntime/issues/9730
9731,"b""doesn't onnxruntime cpu support fp16?""",Software,closed,2021-11-11T05:56:28Z,2021-11-11 05:56:51+00:00,2021-11-12T03:07:16Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9731
9732,b'centos7 predict is slower than win10 on cpu?',Software,closed,2021-11-11T06:14:14Z,2021-11-11 16:45:30+00:00,2021-11-11T16:45:30Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9732
9735,b'ORT fails to build with Visual Studio 2022 and Cmake 3.22',Software,closed,2021-11-11T16:37:45Z,2021-11-11 16:40:31+00:00,2021-11-13T03:32:07Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9735
9736,"b""'PyEval_CallObjectWithKeywords': deprecated in 3.9 - fails to build ORT pyop bindings""",Software,closed,2021-11-11T16:44:29Z,2021-11-11 16:44:34+00:00,2021-11-11T21:37:56Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9736
9742,b'ouput of onnx model with custom op in the loop structrue  is confusing',Software,open,2021-11-12T07:36:37Z,2021-11-15 18:15:19+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/9742
9744,b'Linker flag /SAFESEH also on Linux 32bit build',Software,closed,2021-11-12T13:29:03Z,2021-11-12 20:33:00+00:00,2021-12-08T19:44:00Z,0,26,https://api.github.com/repos/microsoft/onnxruntime/issues/9744
9747,b'Python: Inconsistent error behavior when creating sessions for different providers',Software,closed,2021-11-12T20:24:58Z,2021-11-15 19:15:34+00:00,2021-11-29T17:40:14Z,2,16,https://api.github.com/repos/microsoft/onnxruntime/issues/9747
9753,b'Crashes when relu is followed by a clip',Software,closed,2021-11-13T05:32:33Z,2021-11-15 18:17:16+00:00,2021-11-17T01:59:03Z,2,3,https://api.github.com/repos/microsoft/onnxruntime/issues/9753
9754,"b""Inconsistency detected by ld.so: dl-version.c: 224: _dl_check_map_versions: Assertion `needed != NULL' failed!""",Software,open,2021-11-13T07:58:37Z,2021-11-15 18:48:22+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/9754
9755,b'[ONNXRuntimeError] ModelProto does not have a graph',Software,closed,2021-11-13T21:55:15Z,2021-11-14 03:52:17+00:00,2021-11-14T03:52:17Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9755
9756,b'How to build for multiple execution provider? ',Software,open,2021-11-14T03:42:51Z,2021-11-15 18:46:59+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/9756
9757,b'`Buffer is not defined` when using WebGL runtime',Software,closed,2021-11-14T12:54:53Z,2021-11-14 17:42:12+00:00,2021-11-24T22:14:42Z,0,10,https://api.github.com/repos/microsoft/onnxruntime/issues/9757
9758,b'float16 support in web runtimes',Software,open,2021-11-14T17:54:06Z,2021-11-15 18:17:45+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/9758
9759,b'OrtException creating session on Android',Software,closed,2021-11-14T20:25:00Z,2021-11-15 01:03:03+00:00,2021-11-15T21:43:57Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9759
9760,"b""[wasm runtime] Could not find an implementation for ArgMax(12) node with name 'ArgMax_1382'""",Software,open,2021-11-14T21:58:21Z,2021-11-15 01:04:22+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9760
9763,b'torch_ort.configure prints warning `cc1plus: warning: command line option \xe2\x80\x98-Wstrict-prototypes\xe2\x80\x99 is valid for C/ObjC but not for C++`',Software,open,2021-11-16T00:13:04Z,2021-11-16 18:52:41+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9763
9766,"b'when gpu is occupied, the inference slows down when i adopt a CUDA provider'",Software,open,2021-11-16T08:05:36Z,2021-11-16 18:19:52+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9766
9767,b'Inference is slower when running inside Docker',Software,open,2021-11-16T15:46:46Z,2021-11-16 18:20:12+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9767
9768,b'C++ api slower than python api',Software,closed,2021-11-16T15:55:52Z,2021-11-16 18:10:40+00:00,2021-12-01T00:20:22Z,0,14,https://api.github.com/repos/microsoft/onnxruntime/issues/9768
9778,b'Optimization changes the graph so it cannot run on Cuda',Software,open,2021-11-17T01:15:47Z,2021-11-17 01:23:27+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9778
9779,b'Can not build in RTX 3090',Software,open,2021-11-17T01:45:01Z,2021-11-17 18:39:30+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9779
9781,b'is there any python script for doing inference on yolo.onnx model?',Software,closed,2021-11-17T09:16:30Z,2021-11-17 18:45:26+00:00,2021-12-01T00:17:26Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/9781
9782,b'Add support for Python 3.10 pip install',Software,closed,2021-11-17T10:58:09Z,2021-11-17 18:22:15+00:00,2022-03-22T05:06:48Z,0,124,https://api.github.com/repos/microsoft/onnxruntime/issues/9782
9784,b'Subgraph resolution and model messages',Software,open,2021-11-17T17:04:42Z,2021-11-17 18:21:30+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9784
9786,b'Do we have official Golang support for ONNXRuntime?',Software,open,2021-11-17T19:19:48Z,2021-11-17 19:41:27+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9786
9789,b'Resize operator does not support FP16 tensor as input. ',Software,closed,2021-11-17T22:51:36Z,2021-11-17 23:35:05+00:00,2021-12-01T00:22:39Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/9789
9795,b'How to run multi models at the same time with GPU?',Software,closed,2021-11-18T09:43:33Z,2021-11-18 09:46:28+00:00,2021-12-01T00:16:04Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/9795
9796,b'Quantization for GRU',Software,closed,2021-11-18T15:13:52Z,2021-11-18 15:13:52+00:00,2022-04-18T21:58:33Z,0,151,https://api.github.com/repos/microsoft/onnxruntime/issues/9796
9799,b'Bad results during inference when using dynamic dimensions with the CUDA provider',Software,closed,2021-11-18T18:52:01Z,2021-11-18 19:17:47+00:00,2021-11-23T22:34:25Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/9799
9800,b'Onnx runtime threading is broken in gunicorn',Software,closed,2021-11-18T19:15:56Z,2021-11-22 04:52:55+00:00,2021-12-13T13:38:01Z,3,24,https://api.github.com/repos/microsoft/onnxruntime/issues/9800
9808,b'Problems with scan node when trying to run sklearn.gaussian_process.GaussianProcessRegressor()',Software,open,2021-11-19T00:05:50Z,2021-11-19 18:02:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9808
9815,b'Build error(use_cuda) in Centos7  ',Software,closed,2021-11-19T09:09:57Z,2021-11-19 22:25:03+00:00,2021-11-22T16:05:43Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/9815
9816,b'Unable to set CUDAExecutionProvider',Software,closed,2021-11-19T13:19:49Z,2021-11-19 13:52:05+00:00,2021-11-19T13:52:05Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9816
9818,b'Multi-dimensional tensor as the single-dimensional array input to CreateTensorWithDataAsOrtValue',Software,closed,2021-11-19T15:27:37Z,2021-11-19 15:42:55+00:00,2021-11-19T15:58:42Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9818
9829,b'onnxruntime.InferenceSession',Software,open,2021-11-22T08:40:22Z,2021-11-22 21:26:59+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9829
9831,b'[ONNXRuntimeError] : 1 : FAIL : Fatal error: test_custom is not a registered function/op',Software,open,2021-11-22T09:21:58Z,2021-11-22 21:29:07+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9831
9843,b'TopK return random value when Kth is inf',Software,closed,2021-11-23T03:49:19Z,2021-11-25 00:51:29+00:00,2022-01-14T21:57:41Z,1,52,https://api.github.com/repos/microsoft/onnxruntime/issues/9843
9844,b'solved',Software,closed,2021-11-23T07:00:14Z,2021-11-23 12:32:20+00:00,2021-11-23T18:19:24Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9844
9846,b'tensorrt backend version question',Software,open,2021-11-23T11:01:26Z,2021-11-23 13:55:23+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9846
9849,b'non-NEON Compatibility',Software,open,2021-11-23T17:11:55Z,2021-11-24 17:46:06+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/9849
9853,b'some model convert error question when tensorrt backend',Software,open,2021-11-24T04:10:33Z,2021-11-24 04:37:24+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9853
9857,b'The ONNX graph converted from tf.image.crop_and_resize() function will fail to be inferenced by latest version of ORT.',Software,closed,2021-11-24T16:05:58Z,2021-11-24 16:06:21+00:00,2021-11-30T06:30:16Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/9857
9862,b'`onnxruntime.InfereceSession` will stuck or crash in docker with `onnxruntime>1.6`',Software,open,2021-11-25T02:18:28Z,2022-01-14 11:43:22+00:00,,50,,https://api.github.com/repos/microsoft/onnxruntime/issues/9862
9865,b'custom op can not supported by onnxruntime',Software,open,2021-11-25T11:28:28Z,2021-11-26 08:30:03+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9865
9866,"b""How to Get Model's FLOPS In ORT?""",Software,closed,2021-11-26T06:21:34Z,2021-11-29 16:30:22+00:00,2021-11-29T16:30:22Z,3,3,https://api.github.com/repos/microsoft/onnxruntime/issues/9866
9867,b'How to do batch inference with onnx model?',Software,closed,2021-11-26T12:30:36Z,2021-11-29 17:49:38+00:00,2021-12-01T07:25:29Z,3,4,https://api.github.com/repos/microsoft/onnxruntime/issues/9867
9868,"b""Can't extract the shape of the output of `SequenceAt`.""",Software,closed,2021-11-26T13:18:07Z,2021-11-30 07:00:53+00:00,2021-12-01T12:22:42Z,3,4,https://api.github.com/repos/microsoft/onnxruntime/issues/9868
9871,b'Bart examples',Software,closed,2021-11-29T13:15:56Z,2021-11-30 06:54:26+00:00,2021-12-02T23:13:32Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/9871
9874,b'Segmentation Fault when calling Provider Host CPU',Software,closed,2021-11-29T21:16:53Z,2021-11-30 07:06:27+00:00,2021-12-09T15:39:43Z,0,9,https://api.github.com/repos/microsoft/onnxruntime/issues/9874
9878,b'Error message in ORT 1.9.0 is not as clear as previous ORT versions',Software,open,2021-11-29T23:45:34Z,2021-11-30 07:07:19+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9878
9887,"b""How to set the input layer to uint8 tensor instead of inserting 'QuantizeLinear'?""",Software,closed,2021-11-30T16:24:06Z,2021-11-30 17:40:44+00:00,2021-12-01T02:25:32Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9887
9890,b'different inference result between onnxruntime and pytorch',Software,open,2021-12-01T06:45:55Z,2021-12-09 20:21:52+00:00,,8,,https://api.github.com/repos/microsoft/onnxruntime/issues/9890
9891,b'Run multi-thread with CUDA',Software,open,2021-12-01T06:57:29Z,2021-12-01 17:32:54+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9891
9892,b'FP16 model inference time is two times of FP32 model',Software,closed,2021-12-01T07:51:23Z,2021-12-01 17:46:16+00:00,2021-12-06T06:00:41Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/9892
9893,b'fix error: conversion from gsl::span<const long int> to non-scalar type std::vector<long int> requested',Software,open,2021-12-01T10:18:44Z,2021-12-01 18:15:59+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9893
9894,b'Build Error on VS17/19 and Win10 VS',Software,closed,2021-12-01T16:12:27Z,2021-12-01 17:50:20+00:00,2021-12-06T14:54:39Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/9894
9903,b'Trying to set limit on GPU memory...',Software,closed,2021-12-02T01:48:09Z,2021-12-02 08:33:07+00:00,2021-12-02T08:33:07Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9903
9905,b'mnist insert all of node valueinfo to output and got segment fault',Software,closed,2021-12-02T03:21:45Z,2021-12-02 03:40:35+00:00,2021-12-02T03:40:35Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9905
9907,b'android build error ',Software,closed,2021-12-02T07:13:14Z,2021-12-02 18:50:45+00:00,2021-12-09T06:16:15Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/9907
9910,b'Is onednn integrated with onnxruntime by default?',Software,closed,2021-12-02T08:16:37Z,2021-12-02 10:00:28+00:00,2021-12-02T10:00:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9910
9911,b'ONNX model very slow for Sentence transformer model when max_seq_len of tokens = 512',Software,open,2021-12-02T16:31:26Z,2021-12-02 18:54:48+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9911
9915,b'Cast f32 -> bf16 -> f32 does not work as expected for graph inputs',Software,open,2021-12-02T19:59:34Z,2021-12-02 20:52:36+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9915
9919,"b""DLPack converter doesn't support bfloat16 type""",Software,closed,2021-12-02T22:46:00Z,2021-12-02 22:46:32+00:00,2021-12-02T23:08:53Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9919
9920,b'Missing Bfloat16 support in DLPack converter code',Software,open,2021-12-02T22:50:29Z,2021-12-03 16:14:14+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9920
9923,b'Python::Module Python::Numpy not found when building from source',Software,closed,2021-12-03T06:41:44Z,2021-12-09 04:23:57+00:00,2021-12-15T08:34:15Z,5,12,https://api.github.com/repos/microsoft/onnxruntime/issues/9923
9924,b'C++ native nuget package AdditionalDependencies',Software,closed,2021-12-03T09:49:20Z,2021-12-03 18:01:03+00:00,2022-01-12T07:30:41Z,0,39,https://api.github.com/repos/microsoft/onnxruntime/issues/9924
9926,b'cuda header used without -I',Software,open,2021-12-03T15:00:40Z,2021-12-03 16:17:00+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9926
9934,"b'ORT+TensorRT build, ""--config Debug"" works but ""--config Release"" failed'",Software,open,2021-12-04T02:46:10Z,2021-12-07 06:05:42+00:00,,3,,https://api.github.com/repos/microsoft/onnxruntime/issues/9934
9936,b'Yolov5 ORT train failed with onnxruntime backend',Software,open,2021-12-06T08:54:15Z,2021-12-06 08:54:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9936
9937,"b""can't find InferenceHighLevelDesign.md """,Software,closed,2021-12-06T10:22:50Z,2021-12-06 18:54:45+00:00,2021-12-06T18:54:45Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9937
9938,b'Question about quantization of batch normalization',Software,open,2021-12-06T10:43:35Z,2021-12-07 06:08:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9938
9939,b'Runtime exception with onnxruntime GPU',Software,closed,2021-12-06T13:47:03Z,2021-12-06 17:54:31+00:00,2022-01-27T23:38:07Z,0,52,https://api.github.com/repos/microsoft/onnxruntime/issues/9939
9940,"b'The input tensor cannot be reshaped to the requested shape. Input shape:{1,0}, requested shape:{-1,0}'",Software,closed,2021-12-06T15:11:46Z,2021-12-07 22:55:28+00:00,2021-12-08T08:45:21Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/9940
9945,b'[BUG on Onnxruntime+TensorRT] Assertion failed: input_dims.nbDims == 4 || input_dims.nbDims == 5 instanceNormalizationPlugin/instanceNormalizationPlugin.cu:181',Software,open,2021-12-07T01:12:24Z,2021-12-07 06:11:03+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9945
9948,b'ORT Eager aten view operation needs to share the same semantic with Pytorch view',Software,open,2021-12-07T05:41:49Z,2021-12-07 05:45:38+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9948
9949,b'ONNX model (roberta) that is 300MB in size uses around 1.9 GB of memory.',Software,open,2021-12-07T06:13:14Z,2021-12-07 23:00:48+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9949
9962,b'DML inferencing skipped on providing output tensor created by DML Allocator (command list not flushed)',Software,closed,2021-12-08T06:48:53Z,2021-12-08 07:15:11+00:00,2022-02-28T10:00:23Z,0,82,https://api.github.com/repos/microsoft/onnxruntime/issues/9962
9963,b'Release notes: 1.10',Software,closed,2021-12-08T08:44:32Z,2021-12-08 17:04:30+00:00,2021-12-08T18:58:20Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9963
9964,b'Find the operation of pytorch from onnx node information',Software,open,2021-12-08T09:32:13Z,2021-12-08 17:45:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9964
9966,"b'Missing depencencies for the official Python wheel (or, lacking documentation?)'",Software,open,2021-12-08T13:38:20Z,2021-12-08 18:11:20+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9966
9984,b'pip3 onnx==1.8.0 is not working on Jetson Xavier',Software,open,2021-12-09T07:45:20Z,2021-12-09 15:50:11+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9984
9986,b'Support for pip wheel tensorrt',Software,open,2021-12-09T09:28:59Z,2021-12-09 18:56:52+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9986
9987,b'C++ \xe7\xbc\x96\xe8\xaf\x91\xe5\x8a\xa8\xe6\x80\x81\xe9\x93\xbe\xe6\x8e\xa5\xe5\x99\xa8 \xe5\x87\xba\xe7\x8e\xb0\xe9\x97\xae\xe9\xa2\x98',Software,open,2021-12-09T13:25:23Z,2022-04-17 09:54:30+00:00,,128,,https://api.github.com/repos/microsoft/onnxruntime/issues/9987
9990,b'Session initialization takes long time on NVIDIA RTX type GPUs',Software,open,2021-12-09T18:24:17Z,2021-12-09 19:00:06+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9990
9992,b'Do Value outputs need to be explicitly released?',Software,closed,2021-12-09T21:32:50Z,2021-12-09 22:10:13+00:00,2021-12-09T22:10:13Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/9992
9998,b'Is there an API for multi-GPU inferencing?',Software,open,2021-12-10T02:38:13Z,2021-12-10 05:56:57+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/9998
9999,b'How to deploy a custom ONNX runtime in iOS app?',Software,closed,2021-12-10T02:47:46Z,2021-12-10 05:38:07+00:00,2021-12-14T03:02:11Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/9999
10000,b'Inference with iobinding is slower than without iobinding',Software,closed,2021-12-10T07:20:58Z,2021-12-11 06:39:46+00:00,2021-12-11T06:39:46Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10000
10001,b'Compilation ERROR  \xe2\x80\x98nodiscard\xe2\x80\x99',Software,closed,2021-12-10T08:05:56Z,2021-12-10 08:10:19+00:00,2021-12-10T17:42:42Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10001
10003,b'Version 1.10 introduces a bug making transformer graph optimization crashing',Software,closed,2021-12-10T14:54:06Z,2021-12-10 19:02:21+00:00,2021-12-16T14:34:35Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/10003
10015,"b' I try to use the GPU  , check for missing files ,""onnxruntime_providers_cuda.dll""'",Software,closed,2021-12-13T02:09:26Z,2021-12-13 20:09:55+00:00,2021-12-17T08:34:27Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/10015
10017,b'question about warnup long time',Software,open,2021-12-13T06:07:08Z,2021-12-13 20:11:20+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10017
10018,b'how to read/write the *.pb file in test_data_set_* came with onnx model',Software,closed,2021-12-13T10:33:14Z,2021-12-13 19:59:41+00:00,2021-12-13T19:59:41Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10018
10020,b'Mask-RCNN succesfully runs inference on empty image but gives CUDNN error if next image is not empty',Software,closed,2021-12-13T16:38:50Z,2021-12-13 20:13:53+00:00,2022-03-01T09:31:58Z,0,77,https://api.github.com/repos/microsoft/onnxruntime/issues/10020
10021,b'Lower Resnet50 accuracy with ONNXRuntime',Software,open,2021-12-13T18:07:32Z,2021-12-13 18:19:26+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10021
10029,b'Fatal error: SentencepieceTokenizer is not a registered function/op',Software,closed,2021-12-14T01:39:35Z,2021-12-14 01:58:33+00:00,2021-12-15T19:50:17Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/10029
10031,"b""[WebGL] cannot resolve operator 'ConstantOfShape' with opsets: ai.onnx v12""",Software,open,2021-12-14T03:38:18Z,2021-12-14 04:38:07+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10031
10036,b'how to create float tensor with missing value using java runtime',Software,open,2021-12-14T10:02:48Z,2021-12-14 23:25:22+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10036
10037,b'how to build an unit8 model!',Software,closed,2021-12-14T15:48:58Z,2021-12-14 21:42:37+00:00,2021-12-16T01:59:42Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/10037
10038,b'Importing onnxruntime on AWS Lambdas with ARM64 processor causes crash',Software,open,2021-12-14T18:37:19Z,2021-12-14 21:16:36+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10038
10039,b'ONNX runtime mysterious crash',Software,closed,2021-12-14T19:38:56Z,2021-12-14 21:08:54+00:00,2021-12-20T10:45:29Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/10039
10043,b'How to config the developing ide?',Software,closed,2021-12-15T04:42:21Z,2021-12-15 05:19:02+00:00,2021-12-15T05:19:02Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10043
10044,b'Segmentation fault : onnxruntime infer all outputs include all nodes with python API',Software,open,2021-12-15T06:45:08Z,2021-12-15 07:04:50+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10044
10045,"b'I can not run the tensorrt example ""quantized BERT model example""'",Software,open,2021-12-15T07:44:38Z,2021-12-15 08:00:52+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10045
10046,b'[BUG] Registered type of RoiAlign  does not work ',Software,open,2021-12-15T08:15:10Z,2021-12-15 08:15:11+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10046
10047,b'CUDA Cross-attention kernel',Software,open,2021-12-15T15:17:08Z,2021-12-15 23:04:42+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10047
10048,"b""System.MissingMethodException: Method not found: System.Memory'1<!0> Microsoft.ML.OnnxRuntime.Tensors.DenseTensor'1.get_Buffer() on iOS""",Software,open,2021-12-15T17:57:20Z,2021-12-15 18:18:44+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10048
10058,b'Unexpected numerical differences between batch and single row predictions',Software,open,2021-12-16T11:49:49Z,2021-12-17 08:51:21+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10058
10063,b'Linking custom library to onnxruntime fails on Linux',Software,open,2021-12-16T23:57:51Z,2021-12-17 00:49:37+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10063
10068,b'[ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for the node ArgMax_1094:ArgMax(11)',Software,closed,2021-12-17T06:32:05Z,2021-12-17 07:39:04+00:00,2021-12-23T09:15:18Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/10068
10069,b'GRU runtime error. ',Software,open,2021-12-17T06:41:02Z,2021-12-17 07:49:45+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10069
10070,b'How to use ep TensorrtExecutionProvider_fp16',Software,closed,2021-12-17T09:10:56Z,2021-12-17 18:30:41+00:00,2021-12-18T04:24:28Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10070
10071,"b'how to forward with a batch images, oncetime?'",Software,open,2021-12-17T10:15:33Z,2021-12-17 19:45:37+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10071
10074,"b'when my models input size is 3808, then i forward with yolov5, the memry is break.'",Software,open,2021-12-17T13:20:04Z,2021-12-17 19:48:17+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10074
10075,b'Model local functions not recognized by onnxruntime',Software,closed,2021-12-17T14:59:49Z,2021-12-17 20:20:25+00:00,2022-01-11T16:18:16Z,0,25,https://api.github.com/repos/microsoft/onnxruntime/issues/10075
10079,b'[fp16] InstanceNorm generate totally wrong result on fp16',Software,closed,2021-12-18T00:21:25Z,2021-12-18 01:03:19+00:00,2022-01-03T18:55:19Z,0,16,https://api.github.com/repos/microsoft/onnxruntime/issues/10079
10081,b'Do threading settings have any effect on GPU EPs',Software,open,2021-12-18T15:43:25Z,2021-12-20 15:00:06+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10081
10082,b'how to use dynamic_quant to quantize an onnx model with custom op',Software,closed,2021-12-20T03:01:53Z,2021-12-20 18:24:30+00:00,2021-12-21T01:57:26Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10082
10083,b'MaxPool shape inference is NOT matched with ONNX OP SPEC ',Software,open,2021-12-20T03:27:45Z,2021-12-20 18:30:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10083
10086,b'Same Pad_Head value in ORT for SAME_UPPER/SAME_LOWER if get negative odd pad value',Software,open,2021-12-20T09:37:59Z,2021-12-20 18:11:00+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10086
10087,b'DecoderAttention kernel Shape Inference bug on dynamic axes',Software,closed,2021-12-20T14:37:01Z,2021-12-20 18:55:22+00:00,2021-12-21T23:10:09Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/10087
10089,b'Python bindings give RuntimeError on multi input models',Software,open,2021-12-20T22:31:14Z,2021-12-21 16:40:47+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10089
10094,b'error: \xe2\x80\x98nodiscard\xe2\x80\x99 : onnxruntime DNNL/1DNN',Software,closed,2021-12-21T03:01:10Z,2021-12-21 16:41:11+00:00,2022-01-03T04:27:01Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/10094
10095,b'Memory leak',Software,closed,2021-12-21T08:19:39Z,2021-12-21 16:43:11+00:00,2021-12-24T06:29:15Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/10095
10096,b'segmentation fault when get subgraph in tensorrt provider',Software,open,2021-12-21T09:49:55Z,2021-12-21 16:46:00+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10096
10097,b'Why it is not possible to `pickle` an `InferenceSession` object?',Software,open,2021-12-21T12:12:46Z,2021-12-21 16:39:47+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10097
10098,b'Problem loading Scikit-Learn Pipeline With DictVectorizer',Software,closed,2021-12-21T15:07:13Z,2021-12-21 16:49:19+00:00,2022-01-19T19:21:58Z,0,29,https://api.github.com/repos/microsoft/onnxruntime/issues/10098
10099,b'ReduceMean consumes an unreasonable amount of VRAM',Software,open,2021-12-21T16:44:00Z,2021-12-21 16:51:45+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10099
10100,"b""Can't Use INT8 Input Data on Quantized Model""",Software,closed,2021-12-21T16:48:26Z,2021-12-21 16:51:32+00:00,2021-12-28T22:22:23Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/10100
10101,b'RandomNormal with integer output seems ill-specified',Software,closed,2021-12-21T17:32:33Z,2021-12-21 18:59:45+00:00,2021-12-22T01:08:38Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10101
10103,b'ORT gpu io binding output buffers corrupted over multiple inferences with resizing',Software,closed,2021-12-21T20:59:44Z,2021-12-21 21:00:04+00:00,2021-12-21T21:01:13Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10103
10104,"b'Thread affinity mask does not seem to have any effect, leading to inconsistent performance'",Software,closed,2021-12-21T22:44:24Z,2021-12-21 22:49:36+00:00,2021-12-23T23:56:34Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/10104
10108,b'How to create writable build-in buffers during inference?',Software,closed,2021-12-22T02:18:54Z,2021-12-22 14:05:44+00:00,2022-01-27T23:37:18Z,0,36,https://api.github.com/repos/microsoft/onnxruntime/issues/10108
10110,b'Using tensorrt execution provider is significantly slower than cuda execution provider',Software,closed,2021-12-22T05:13:54Z,2021-12-22 18:20:27+00:00,2021-12-22T19:42:37Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10110
10111,b'is batch inference supported in dynamic quantization?',Software,closed,2021-12-22T07:07:14Z,2021-12-22 18:17:20+00:00,2022-01-03T17:42:25Z,0,12,https://api.github.com/repos/microsoft/onnxruntime/issues/10111
10112,"b""What's the fastest way to view my implemented changes?""",Software,closed,2021-12-22T10:05:05Z,2021-12-22 18:16:50+00:00,2021-12-23T20:57:51Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/10112
10113,b'onnxruntime latest version segment fault',Software,open,2021-12-22T11:18:38Z,2021-12-22 18:16:25+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10113
10117,"b""AssignNodesToEpsFromHashesImpl Failed to find kernel def hash (14280390279553192696) in kernel registries for Einsum(12) node with name 'Einsum_382'.""",Software,open,2021-12-23T03:24:26Z,2021-12-23 09:52:23+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10117
10119,"b'onnxruntime_test_all fails at Gemm, Conv, Pool and Concat tests'",Software,open,2021-12-23T12:10:25Z,2021-12-23 19:31:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10119
10125,b'Error of building onnxruntime from source',Software,closed,2021-12-23T23:59:55Z,2021-12-24 00:53:35+00:00,2021-12-28T16:22:07Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/10125
10126,"b""Why I met Type 'seq(tensor(int64))' of operator (MemcpyFromHost) is invalid when using onnxruntime.InferenceSession() in GPU, and How to resolve it?  On emergency hold\xef\xbc\x8cthanks!""",Software,open,2021-12-24T07:43:48Z,2021-12-24 18:50:20+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10126
10127,b'ORTModule import error : with onnxruntime',Software,open,2021-12-24T10:48:45Z,2021-12-24 19:04:04+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10127
10128,b'BatchNorm fails on CUDA EP with zero length sequences',Software,open,2021-12-24T19:09:47Z,2021-12-24 20:21:00+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10128
10131,"b""What's the most time-consuming process in python's `InferenceSession` class init?""",Software,closed,2021-12-25T10:38:10Z,2021-12-25 10:38:11+00:00,2021-12-30T17:46:52Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/10131
10134,b'Large performance discrepancy between Chrome and Firefox onnxruntime-web WASM inference (unless Chrome profiler is enabled)',Software,closed,2021-12-27T00:00:23Z,2021-12-27 19:46:39+00:00,2021-12-27T22:42:22Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10134
10135,b'onnxruntime int8 quant slower than pytorch ',Software,open,2021-12-27T06:48:51Z,2021-12-27 19:48:29+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10135
10138,"b""Do you have any plan to add 'Round' Operator for gradient builder registry for orttrainer?""",Software,open,2021-12-27T08:44:58Z,2021-12-27 09:13:24+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10138
10139,b'[ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : BatchNormInternal',Software,open,2021-12-27T09:38:56Z,2021-12-27 19:52:49+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10139
10140,"b'onnxruntime-web build contains browser incompatible requires e.g. worker_threads, fs, os'",Software,open,2021-12-27T10:40:20Z,2021-12-27 20:51:32+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10140
10142,b'No Performance Benefit from OnnxRuntime.GPU in .NET',Software,open,2021-12-28T10:46:28Z,2021-12-28 19:03:43+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10142
10143,b'test_qresize',Software,closed,2021-12-28T13:30:09Z,2021-12-28 19:05:20+00:00,2022-01-05T02:01:16Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/10143
10144,b'Bug ld: error: undefined symbol: pthread_cancel  for android runtime AAR build',Software,open,2021-12-29T01:44:14Z,2021-12-29 18:43:08+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10144
10145,"b'ONNXRTv1.10 Model Format v8, works on python and crash on C++ run. '",Software,closed,2021-12-29T03:44:33Z,2021-12-30 18:42:48+00:00,2021-12-31T03:24:05Z,1,1,https://api.github.com/repos/microsoft/onnxruntime/issues/10145
10146,b'current version seem can not run at net6.0-android',Software,open,2021-12-29T06:07:10Z,2021-12-29 18:49:20+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10146
10147,b'Using ORT in a custom class: the program unexpectedly finished using CUDA execution provider.',Software,closed,2021-12-29T09:55:08Z,2021-12-29 11:44:30+00:00,2021-12-29T11:44:30Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10147
10148,b'Validate usage of dim_value (values should be > 0) and dim_param (all values with the same string should equate to the same size) in shapes in the model.',Software,open,2021-12-29T12:35:11Z,2021-12-29 18:50:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10148
10151,b'FusedMatMul kernel does not support the double data type',Software,open,2021-12-30T02:42:00Z,2021-12-30 18:39:07+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10151
10153,b'Performance question about some nodes generated by dynamic quantization',Software,open,2021-12-30T03:33:34Z,2021-12-30 18:41:22+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10153
10154,b'Sigmoid fails and output all zeros',Software,open,2021-12-30T06:01:06Z,2021-12-30 18:47:11+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10154
10155,b'Why does onnxruntime run slower on C++?',Software,open,2021-12-30T06:45:29Z,2022-04-17 08:54:21+00:00,,108,,https://api.github.com/repos/microsoft/onnxruntime/issues/10155
10158,b'Unable to compile with #include onnxruntime_cxx_api.h',Software,closed,2021-12-30T17:57:49Z,2021-12-30 23:07:19+00:00,2021-12-31T01:32:13Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10158
10159,b'Using tensorrt provider occasionally see dramatically increased inference time',Software,open,2021-12-30T22:12:06Z,2021-12-30 22:27:30+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10159
10164,b'sample code for vitis-ai provider using c/c++',Software,closed,2022-01-03T14:03:27Z,2022-01-03 23:01:21+00:00,2022-01-04T01:21:17Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10164
10165,b'[Bug] float64 clip not found in opset <= 11',Software,closed,2022-01-03T17:09:30Z,2022-01-03 17:09:31+00:00,2022-01-07T22:41:44Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/10165
10166,b'`InferenceSession` initialization hangs',Software,open,2022-01-03T19:59:45Z,2022-01-06 18:04:12+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/10166
10173,b'Improve logging for symbolic shape inference',Software,closed,2022-01-04T02:47:13Z,2022-01-04 03:00:48+00:00,2022-01-04T03:00:48Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10173
10179,b'Multiple ONNX models with individual threads using CUDA EP result in random crashes',Software,closed,2022-01-04T09:54:07Z,2022-01-04 22:15:27+00:00,2022-03-02T01:53:59Z,0,56,https://api.github.com/repos/microsoft/onnxruntime/issues/10179
10180,b'Question: Inference from CUDA allocated memory',Software,open,2022-01-04T16:55:50Z,2022-01-04 18:25:39+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10180
10182,b'ONNXRUNTIME import error in container in Jetson ',Software,closed,2022-01-04T17:21:10Z,2022-01-13 23:41:33+00:00,2022-01-13T23:41:33Z,9,9,https://api.github.com/repos/microsoft/onnxruntime/issues/10182
10194,b'Dynamic Shape performance',Software,open,2022-01-05T02:56:15Z,2022-04-17 08:54:17+00:00,,102,,https://api.github.com/repos/microsoft/onnxruntime/issues/10194
10196,b'Support for GPT-Neo and GPT-J models',Software,open,2022-01-05T08:09:42Z,2022-01-05 20:15:38+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10196
10197,b' [python api] ShapeInferenceError\xef\xbc\x9aMismatch between number of source and target dimensions. Source=2 Target=3 ',Software,closed,2022-01-05T14:34:28Z,2022-01-05 14:52:30+00:00,2022-01-13T02:19:56Z,0,7,https://api.github.com/repos/microsoft/onnxruntime/issues/10197
10203,b'GPU caculation resources confict between onnxruntime-directML inference and SDL2 render/display',Software,open,2022-01-06T03:47:24Z,2022-01-07 22:20:20+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10203
10206,b'TensorRT EP failed to set INT8 dynamic range.',Software,open,2022-01-06T08:21:31Z,2022-01-06 17:45:34+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10206
10207,b'int8 poor performance',Software,closed,2022-01-06T09:43:33Z,2022-01-06 17:41:21+00:00,2022-01-06T17:41:21Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10207
10208,b'gpu is 4 times slower than cpu on jetson xavier',Software,closed,2022-01-06T14:17:48Z,2022-01-06 17:45:19+00:00,2022-01-08T15:56:54Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/10208
10212,"b'Issue with ep:STVM, crash due to a null pointer'",Software,closed,2022-01-06T19:18:55Z,2022-01-06 19:18:55+00:00,2022-01-11T16:38:37Z,0,4,https://api.github.com/repos/microsoft/onnxruntime/issues/10212
10217,b'Create an OrtValue from a pytorch tensor on CUDA',Software,closed,2022-01-06T23:44:54Z,2022-01-06 23:44:55+00:00,2022-01-10T19:18:17Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/10217
10218,b'how to merge two of Ort::Value together?',Software,closed,2022-01-07T13:45:28Z,2022-01-07 13:45:58+00:00,2022-01-07T17:16:05Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10218
10224,b'how to merge two of Ort::Value together?',Software,open,2022-01-08T01:25:45Z,2022-01-10 07:18:42+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/10224
10226,b'Inference time fluctuates hugely after calling Thread.Sleep() in C # API',Software,closed,2022-01-08T03:19:11Z,2022-01-10 03:24:56+00:00,2022-03-01T21:44:37Z,2,52,https://api.github.com/repos/microsoft/onnxruntime/issues/10226
10228,"b""MeanVarianceNormalization on CPU doesn't use epsilon""",Software,open,2022-01-09T22:02:47Z,2022-01-11 00:07:19+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10228
10229,b'which onnxruntime version did cuda 11.2  need',Software,open,2022-01-10T05:06:30Z,2022-04-16 07:55:41+00:00,,96,,https://api.github.com/repos/microsoft/onnxruntime/issues/10229
10232,b'affine grid and grid sample support in onnxruntime',Software,open,2022-01-10T09:32:25Z,2022-01-10 09:34:23+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10232
10234,b'Gather node discrepancy for out of index indices',Software,open,2022-01-10T14:46:51Z,2022-01-10 23:32:25+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10234
10235,b'Build failure master branch in selector_action_transformer.cc in optimizer code',Software,closed,2022-01-10T18:57:03Z,2022-01-10 19:26:32+00:00,2022-01-11T00:23:56Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10235
10236,b'VS2019 Project Properties failed to load with ONNX DirectML NuGet package.',Software,open,2022-01-11T00:22:34Z,2022-04-16 07:55:39+00:00,,95,,https://api.github.com/repos/microsoft/onnxruntime/issues/10236
10238,b'Run model with a cupy array on CUDA',Software,open,2022-01-11T05:48:46Z,2022-01-11 20:39:53+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10238
10239,b'how to reduce gpu memory usage?',Software,open,2022-01-11T05:51:01Z,2022-01-11 20:35:11+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10239
10242,b'ValueError: Unsupported ONNX opset version: 13',Software,closed,2022-01-11T11:01:11Z,2022-01-11 20:49:36+00:00,2022-01-11T20:49:36Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10242
10244,b'unable to find library -latomic when build onnxruntime-web',Software,closed,2022-01-11T14:24:18Z,2022-01-11 19:24:35+00:00,2022-01-13T09:23:06Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/10244
10248,b'Execution Provider bridge for TFLite Delegates for Coral Edge TPUs',Software,open,2022-01-11T16:44:56Z,2022-01-11 20:51:07+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10248
10249,b'Error when omitting optional inputs within a model local function',Software,closed,2022-01-11T16:58:59Z,2022-03-08 09:54:43+00:00,2022-04-08T08:14:52Z,55,86,https://api.github.com/repos/microsoft/onnxruntime/issues/10249
10250,b'Error about missing type information when nesting model local functions',Software,open,2022-01-11T18:18:07Z,2022-03-08 09:51:40+00:00,,55,,https://api.github.com/repos/microsoft/onnxruntime/issues/10250
10253,b'Cannot load ort model for onnxruntime-react-native',Software,closed,2022-01-12T03:45:58Z,2022-01-12 23:08:44+00:00,2022-01-14T07:34:53Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/10253
10257,b'how to use docker and onnxruntime deploy onnx model on GPU?',Software,open,2022-01-12T07:22:17Z,2022-01-12 10:56:56+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10257
10259,b'extract_model fails when the model contains a model local function',Software,closed,2022-01-12T08:26:43Z,2022-01-12 16:20:40+00:00,2022-01-12T16:20:40Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10259
10267,b'much slower in GPU after quantization',Software,closed,2022-01-13T02:43:35Z,2022-01-13 08:14:32+00:00,2022-01-14T02:10:14Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10267
10270,b'Inconsistent inference timing on CPU ',Software,open,2022-01-13T07:01:07Z,2022-01-13 19:02:37+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10270
10271,b'Inference: Time in GPU is similar in CPU. GPU not speed up',Software,open,2022-01-13T08:36:22Z,2022-01-13 19:08:36+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10271
10273,b'multiple InferenceSession slowdown inference speed',Software,open,2022-01-13T09:23:22Z,2022-01-13 19:21:02+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10273
10275,b'DnnlExecutionProvider is not visible in python API ',Software,open,2022-01-13T15:31:25Z,2022-01-13 19:21:29+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10275
10278,b'Gemm layer is not quantized with QGemm node but with QLinearMatMul + QLinearAdd',Software,open,2022-01-13T17:05:19Z,2022-01-13 17:36:18+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10278
10279,b'C++ inference with IOBinding and DirectML',Software,closed,2022-01-13T17:45:45Z,2022-01-13 19:25:08+00:00,2022-02-07T20:15:47Z,0,25,https://api.github.com/repos/microsoft/onnxruntime/issues/10279
10283,b'add QLinearMatMul do not quantize per channel flag to quantize_static extra options',Software,open,2022-01-13T20:05:59Z,2022-01-18 21:18:15+00:00,,5,,https://api.github.com/repos/microsoft/onnxruntime/issues/10283
10286,b'ORTValue to Pytorch CUDA Tensor Interface ',Software,closed,2022-01-14T01:27:11Z,2022-01-14 21:14:27+00:00,2022-01-14T21:14:27Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10286
10290,b'ONNX Runtime DLL load Error',Software,open,2022-01-14T09:38:26Z,2022-01-19 00:54:06+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/10290
10291,"b""Python's flatbuffers version API """,Software,open,2022-01-14T10:25:04Z,2022-01-18 21:22:49+00:00,,4,,https://api.github.com/repos/microsoft/onnxruntime/issues/10291
10292,"b""Can't build docker file for arm32v7""",Software,closed,2022-01-14T10:52:09Z,2022-01-18 21:25:08+00:00,2022-01-25T03:06:10Z,4,10,https://api.github.com/repos/microsoft/onnxruntime/issues/10292
10293,b'How to write CUDA custom op?',Software,closed,2022-01-14T11:04:50Z,2022-01-17 06:11:27+00:00,2022-01-17T06:11:27Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/10293
10294,b'Symbolic shape infer issue: rank = 0 in handle_negative_axis',Software,closed,2022-01-15T02:07:23Z,2022-01-18 22:34:34+00:00,2022-03-10T00:59:28Z,3,53,https://api.github.com/repos/microsoft/onnxruntime/issues/10294
10295,b'error: \xe2\x80\x98Ort::g_api\xe2\x80\x99 should have been declared inside \xe2\x80\x98Ort\xe2\x80\x99 while compiling with g++',Software,closed,2022-01-15T04:21:09Z,2022-01-18 21:39:51+00:00,2022-02-01T05:12:25Z,3,17,https://api.github.com/repos/microsoft/onnxruntime/issues/10295
10298,b'Cannot find OrtCUDAProviderOptionsV2 APIs in released onnxruntime_c_api.h',Software,closed,2022-01-16T15:02:51Z,2022-01-18 21:55:09+00:00,2022-01-19T03:02:44Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/10298
10299,b'Bad results when using IOBinding with bind_input of non ortvalue type',Software,closed,2022-01-16T15:42:34Z,2022-01-16 15:58:04+00:00,2022-01-20T15:34:40Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/10299
10300,b'Crash on IOBinding synchronize_inputs()',Software,closed,2022-01-16T16:13:10Z,2022-01-18 22:14:48+00:00,2022-01-25T22:48:52Z,2,9,https://api.github.com/repos/microsoft/onnxruntime/issues/10300
10302,"b""React Native: Can't load a model: Can't create InferenceSession""",Software,open,2022-01-17T08:05:40Z,2022-01-17 09:13:31+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10302
10303,b'onnxruntime inference is around 5 times slower than pytorch when using GPU',Software,open,2022-01-17T08:05:42Z,2022-01-18 22:19:04+00:00,,1,,https://api.github.com/repos/microsoft/onnxruntime/issues/10303
10304,b'Optimize Albert HuggingFace model',Software,closed,2022-01-17T12:50:20Z,2022-01-17 13:06:56+00:00,2022-01-18T15:35:48Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/10304
10305,"b""bug: ONNX Runtime error: node->GetOutputEdgesCount() == 0 was false. Can't remove node""",Software,closed,2022-01-17T18:48:04Z,2022-01-18 22:21:08+00:00,2022-01-19T21:46:36Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/10305
10306,b'\xe9\x87\x8f\xe5\x8c\x96\xe9\x94\x99\xe8\xaf\xaf\xef\xbc\x8c\xe6\x88\x91\xe6\x9f\xa5\xe7\x9c\x8b\xe4\xba\x86\xe9\x93\xbe\xe6\x8e\xa5\xe5\xba\x93\xe7\xa1\xae\xe5\xae\x9e\xe6\xb2\xa1\xe7\x94\xa8\xe6\x89\xbe\xe4\xb8\xaa\xe6\x96\xb9\xe6\xb3\x95',Software,open,2022-01-18T03:52:33Z,2022-01-18 19:41:34+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10306
10308,b'A problem was encountered exporting an ONNX model with accuracy of FLOAT16',Software,open,2022-01-18T09:02:29Z,2022-01-18 22:24:31+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10308
10310,b'ValueError: The state dictionary of the model you are training to load is corrupted. Are you sure it was properly saved?',Software,closed,2022-01-18T12:12:19Z,2022-01-18 14:31:31+00:00,2022-01-18T14:31:31Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10310
10311,b'Bug: pthread sent an error! undefined:undefined: ortWasmThreaded is not defined',Software,open,2022-01-18T15:13:10Z,2022-01-18 15:27:41+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10311
10320,b'Finding symbolic names of the inputs shapes with C++ API',Software,closed,2022-01-19T09:02:50Z,2022-01-19 17:07:34+00:00,2022-02-02T13:11:39Z,0,14,https://api.github.com/repos/microsoft/onnxruntime/issues/10320
10322,b'Quantized int8 onnx GPT2 model returns different tokens whether using past_key_values or not for the same sentence',Software,open,2022-01-19T10:58:05Z,2022-01-19 22:04:48+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10322
10323,b'[Microsoft.ML.OnnxRuntime.GPU] onnxruntime::CudaCall CUDNN failure 4',Software,closed,2022-01-19T17:06:03Z,2022-01-19 17:09:54+00:00,2022-02-08T08:01:58Z,0,19,https://api.github.com/repos/microsoft/onnxruntime/issues/10323
10324,b'rationalize documentation on ORT-Windows integration',Documentation,open,2022-01-19T19:17:47Z,2022-01-19 19:17:48+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10324
10327,b'what is the right way to convert `ortValue`  to `torch.tensor` for GPU?',Software,open,2022-01-19T22:57:29Z,2022-01-20 00:00:21+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10327
10330,b'Onnxruntime multithread options [C++ CPU]',Software,open,2022-01-20T03:24:15Z,2022-01-20 18:22:44+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10330
10336,b'Failed to load Library - OnnxRuntime Yolov5 GPU Support C#',Software,closed,2022-01-20T08:12:10Z,2022-01-20 18:20:10+00:00,2022-01-25T16:20:27Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/10336
10339,b'Attention module not fused for custom GPT2 model',Software,closed,2022-01-20T11:42:36Z,2022-01-20 18:17:25+00:00,2022-02-05T19:29:16Z,0,16,https://api.github.com/repos/microsoft/onnxruntime/issues/10339
10340,b'Converting PyTorch to ONNX model increases file size for ALBert',Software,closed,2022-01-20T12:15:38Z,2022-01-20 17:56:18+00:00,2022-01-21T09:39:47Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10340
10342,b'onnx.load() | DecodeError: Error parsing message',Software,closed,2022-01-20T13:34:35Z,2022-01-20 18:08:32+00:00,2022-01-25T16:45:50Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/10342
10343,b'`Non-zero status code returned while running MatMul node` once too many requests',Software,open,2022-01-20T13:53:53Z,2022-01-20 17:43:27+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10343
10344,"b'quantize/__init__.py, line 97 | SyntaxError: Missing parentheses in call to \'print\'. Did you mean print(""Available input ports:"")?'",Software,closed,2022-01-20T16:36:21Z,2022-01-20 17:13:08+00:00,2022-01-20T17:13:07Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10344
10352,b'Issues when trying to use Onnxruntime and Tensorrt execution provider in a java application',Software,open,2022-01-21T07:09:00Z,2022-01-21 18:19:26+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10352
10355,b'Overflow detection for quantized/half/mixed precision models',Software,open,2022-01-21T22:49:47Z,2022-01-22 00:10:01+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10355
10359,b'Attention not fused',Software,open,2022-01-22T02:46:47Z,2022-01-24 03:31:47+00:00,,2,,https://api.github.com/repos/microsoft/onnxruntime/issues/10359
10361,b'Optional outputs of the Loop Node crash the InferenceSession',Software,closed,2022-01-22T19:11:31Z,2022-01-24 17:49:03+00:00,2022-01-25T09:12:41Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/10361
10363,b'How to use FillStringTensor() to fill 4D strings?',Software,closed,2022-01-23T19:32:28Z,2022-01-24 06:03:05+00:00,2022-01-24T06:03:05Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10363
10364,b'build onnxruntime error linux',Software,open,2022-01-24T05:36:28Z,2022-01-24 17:46:58+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10364
10366,b'integrate with Lightning ecosystem CI',Software,open,2022-01-24T11:18:35Z,2022-01-24 23:41:47+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10366
10367,b'Add CoreML EP to macOS builds so that Apple Silicon Macs can benefit from CoreML execution cores in the SOC',Software,closed,2022-01-24T14:36:31Z,2022-01-24 17:44:42+00:00,2022-02-27T23:13:24Z,0,34,https://api.github.com/repos/microsoft/onnxruntime/issues/10367
10369,b'ThreadPool unit test fails when compiling ONNXRuntime on Hybrid Core platform',Software,closed,2022-01-24T19:16:07Z,2022-01-24 19:38:45+00:00,2022-01-28T05:05:04Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/10369
10372,"b'""Type Error: Type parameter (T) of Optype (MatMul) bound to different types (tensor(int32) and tensor(int64) in node (MatMul_627)""'",Software,closed,2022-01-24T23:13:18Z,2022-01-24 23:34:44+00:00,2022-01-27T23:18:02Z,0,3,https://api.github.com/repos/microsoft/onnxruntime/issues/10372
10375,b'Could you please tell me what means the error message and how to resolve this error message?',Software,closed,2022-01-25T04:39:17Z,2022-01-25 06:03:23+00:00,2022-01-25T07:16:25Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10375
10377,"b""Can't bind ONNXRT C++ Application to single core using numa with sequential executor mode using default CPU EP (MLAS)""",Software,closed,2022-01-25T07:23:42Z,2022-01-26 18:30:53+00:00,2022-01-28T20:08:55Z,1,3,https://api.github.com/repos/microsoft/onnxruntime/issues/10377
10378,b'Error happened while building onnxruntime',Software,open,2022-01-25T08:30:09Z,2022-01-25 18:26:26+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10378
10380,"b'HI, is onnxruntime-web going to support WeChat Mini-program like tfjs?'",Software,closed,2022-01-25T09:17:21Z,2022-01-25 18:27:14+00:00,2022-04-12T04:02:58Z,0,76,https://api.github.com/repos/microsoft/onnxruntime/issues/10380
10382,b'Question about hidden states in onnx DistilGPT2',Software,open,2022-01-25T15:44:27Z,2022-01-25 18:27:55+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10382
10388,b'MLAS Library Documentation',Software,closed,2022-01-25T18:12:18Z,2022-01-25 18:16:57+00:00,2022-01-25T18:16:57Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10388
10389,b'installation via pip fails on python 3.10.2',Software,closed,2022-01-25T18:21:46Z,2022-01-25 18:38:02+00:00,2022-01-25T18:38:03Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10389
10399,"b""onnxruntime.capi.onnxruntime_pybind11_state.InvalidGraph: [ONNXRuntimeError] : 10 : INVALID_GRAPH : Load model from ./model1.onnx failed:This is an invalid model. Type Error: Type 'tensor(int64)' of input parameter (655) of operator (Clip) in node (Clip_354) is invalid.""",Software,closed,2022-01-26T08:14:26Z,2022-01-26 18:32:16+00:00,2022-01-31T18:26:24Z,0,5,https://api.github.com/repos/microsoft/onnxruntime/issues/10399
10401,b'.PDB file still included in NuGet and required to run application',Software,open,2022-01-26T18:06:57Z,2022-01-26 18:33:59+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10401
10402,b'Floating point exception with FasterSCNN model',Software,open,2022-01-26T20:04:46Z,2022-01-27 14:40:36+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10402
10403,b'[Documentation] some quantized operators not present in ContribOperators.md',Software,open,2022-01-26T20:17:06Z,2022-01-26 20:23:15+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10403
10407,b'Help',Software,closed,2022-01-27T06:06:41Z,2022-01-31 16:57:18+00:00,2022-01-31T16:57:18Z,4,4,https://api.github.com/repos/microsoft/onnxruntime/issues/10407
10409,b'ONNX Runtime C++ with OpenVino EP stuck at Run',Software,open,2022-01-27T07:28:00Z,2022-01-27 18:38:49+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10409
10410,b'[WinML] [C++/WinRT] Empty output after GPU to GPU inference via VideoFrame',Software,closed,2022-01-27T10:44:26Z,2022-01-27 18:43:08+00:00,2022-01-28T13:18:50Z,0,1,https://api.github.com/repos/microsoft/onnxruntime/issues/10410
10411,b'Graph Input will not be treated as constant value/weight',Software,open,2022-01-27T15:17:21Z,2022-01-27 18:41:24+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10411
10412,b'Is TensorRT execution provider caching is thread-safe',Software,open,2022-01-27T16:06:28Z,2022-01-27 18:40:41+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10412
10419,b'Loading a Keras model with custom layers into Microsoft.ML',Software,open,2022-01-28T00:38:17Z,2022-01-28 22:53:14+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10419
10422,b'Quantization of video action recognition model',Software,open,2022-01-28T03:28:24Z,2022-02-11 10:14:42+00:00,,14,,https://api.github.com/repos/microsoft/onnxruntime/issues/10422
10427,b'Onnxruntime NuGet package works on android apk builded with Mono but not with IL2CPP using Unity.',Software,closed,2022-01-28T09:27:07Z,2022-01-28 09:28:57+00:00,2022-02-15T23:42:52Z,0,18,https://api.github.com/repos/microsoft/onnxruntime/issues/10427
10430,"b""'Error: unrecognized input '' for node: Resize' on onnxruntime-web-bundler opset 13 webgl""",Software,closed,2022-01-28T21:30:52Z,2022-01-28 21:31:12+00:00,2022-01-31T13:04:47Z,0,2,https://api.github.com/repos/microsoft/onnxruntime/issues/10430
10433,"b'For SENet152 model, ORT1.10.0 runs much slower than ORT1.7.0, only 1/8'",Software,closed,2022-01-29T02:26:00Z,2022-01-29 03:45:11+00:00,2022-02-11T21:43:39Z,0,13,https://api.github.com/repos/microsoft/onnxruntime/issues/10433
10435,b'How to build from source on macOS m1??',Software,closed,2022-01-29T11:08:54Z,2022-01-31 10:59:39+00:00,2022-01-31T17:58:36Z,1,2,https://api.github.com/repos/microsoft/onnxruntime/issues/10435
10436,b'Why onnxruntime M1 arm64 binary release slower than x86 arch?',Software,closed,2022-01-29T11:30:11Z,2022-01-31 17:59:25+00:00,2022-01-31T17:59:25Z,2,2,https://api.github.com/repos/microsoft/onnxruntime/issues/10436
10437,b'ort-web Error: invalid input shape. when using webgl backend and there is a torch.nn.BatchNorm1d layer in the network',Software,open,2022-01-29T14:29:41Z,2022-01-29 14:39:09+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10437
10438,b'quadro telsa is test? OK?',Software,open,2022-01-30T10:57:06Z,2022-04-16 05:55:27+00:00,,75,,https://api.github.com/repos/microsoft/onnxruntime/issues/10438
10439,b'Details for trying OnnxRuntime Inferencing while trying for Android mobile device',Software,closed,2022-01-31T13:20:01Z,2022-01-31 18:04:57+00:00,2022-02-07T11:20:18Z,0,6,https://api.github.com/repos/microsoft/onnxruntime/issues/10439
10440,b'cast BatchNorm2d to int32 ',Software,open,2022-01-31T13:32:25Z,2022-01-31 17:54:29+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10440
10443,b'TensorRT input: 717 has no shape specified.',Software,open,2022-02-01T06:52:39Z,2022-02-01 17:13:25+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10443
10444,"b""warning: 'cpuinfo_arm_fixup_raspberry_pi_chipset'""",Software,open,2022-02-01T08:42:14Z,2022-02-01 17:24:30+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10444
10446,b'Error with model input size',Software,open,2022-02-01T15:53:27Z,2022-02-01 17:17:12+00:00,,0,,https://api.github.com/repos/microsoft/onnxruntime/issues/10446
10451,b'Question about packed data in QGEMM kernel',Software,closed,2022-02-02T04:52:15Z,2022-02-02 04:54:22+00:00,2022-02-02T21:47:23Z,0,0,https://api.github.com/repos/microsoft/onnxruntime/issues/10451
